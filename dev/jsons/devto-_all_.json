[
  {
    "publisherId": "devto",
    "publisherName": "Dev.to",
    "specTitle": "전체",
    "categories": [
      "_all_"
    ],
    "specUrl": "https://dev.to/feed",
    "title": "React Native Tab View",
    "partialText": "&lt;p&gt;Listen, yesterday I was messing around with &lt;strong&gt;React Native Tab View (app)&lt;/strong&gt; and ran into something that looked like a random performance glitch but turned out to be completely predictable once I slowed down and looked properly.&lt;/p&gt;\n\n&lt;p&gt;The symptom was simple: brutal lag and frame drops when switching tabs. Not always, but consistently enough to make the app feel… cheap. Especially on older iPhones and even on a mid-range Android device. Swiping between tabs stuttered, and sometimes the content would flash blank for a split second before rendering.&lt;/p&gt;\n\n&lt;p&gt;At first I assumed it was just the emulator being slow. That was my first mistake.&lt;/p&gt;\n\n&lt;p&gt;What I did first (and why it didn’t help)&lt;/p&gt;\n\n&lt;p&gt;I started by testing on a simulator. Laggy. Then I blamed hot reload. Restarted Metro, cleared cache with &lt;code&gt;--reset-cache&lt;/code&gt;, rebuilt the app. Slight improvement, but the jank was still there.&lt;/p&gt;\n\n&lt;p&gt;Then I thought maybe my tab scenes were too heavy, so I removed some images and temporarily mocked out API calls. Still not smooth.&lt;/p&gt;\n\n&lt;p&gt;At that point I began suspecting something deeper in how React Native Tab View handles rendering and scene mounting.&lt;/p&gt;\n\n&lt;p&gt;For reference, this is the library I’m talking about:&lt;br&gt;\n&lt;a href=\"https://www.npmjs.com/package/react-native-tab-view\" rel=\"noopener noreferrer\"&gt;https://www.npmjs.com/package/react-native-tab-view&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And if you’re looking for general React Native docs, they’re here:&lt;br&gt;\n&lt;a href=\"https://reactnative.dev/docs/getting-started\" rel=\"noopener noreferrer\"&gt;https://reactnative.dev/docs/getting-started&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;What I realized&lt;/p&gt;\n\n&lt;p&gt;The key thing about React Native Tab View is that by default it renders all scenes upfront unless you configure it otherwise. That means if you have three tabs, and each tab loads a heavy component tree, they’re all mounting immediately.&lt;/p&gt;\n\n&lt;p&gt;In my case, each tab had:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;A FlatList with ~50 items&lt;/li&gt;\n&lt;li&gt;Image thumbnails&lt;/li&gt;\n&lt;li&gt;Some derived state&lt;/li&gt;\n&lt;li&gt;A couple of memoized selectors&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Individually fine. Together? Not so fine.&lt;/p&gt;\n\n&lt;p&gt;What made it worse is that I wasn’t using &lt;code&gt;lazy&lt;/code&gt; loading. So even if the user never swiped to the third tab, it was already rendered and sitting there in memory.&lt;/p&gt;\n\n&lt;p&gt;Once I looked at it through that lens, the lag made sense. It wasn’t the animation that was slow — it was React reconciling too much stuff during tab transitions.&lt;/p&gt;\n\n&lt;p&gt;What actually helped&lt;/p&gt;\n\n&lt;p&gt;Two things made a dramatic difference.&lt;/p&gt;\n\n&lt;p&gt;First, I enabled lazy loading:&lt;br&gt;\n&lt;/p&gt;\n\n&lt;div class=\"highlight js-code-highlight\"&gt;\n&lt;pre class=\"highlight jsx\"&gt;&lt;code&gt;&lt;span class=\"p\"&gt;&amp;lt;&lt;/span&gt;&lt;span class=\"nc\"&gt;TabView&lt;/span&gt;\n  &lt;span class=\"na\"&gt;lazy&lt;/span&gt;\n  &lt;span class=\"na\"&gt;renderScene&lt;/span&gt;&lt;span class=\"p\"&gt;=&lt;/span&gt;&lt;span class=\"si\"&gt;{&lt;/span&gt;&lt;span class=\"nx\"&gt;renderScene&lt;/span&gt;&lt;span class=\"si\"&gt;}&lt;/span&gt;\n  &lt;span class=\"err\"&gt;...&lt;/span&gt;\n&lt;span class=\"p\"&gt;/&amp;gt;&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;/div&gt;\n\n\n\n&lt;p&gt;That alone stopped off-screen tabs from mounting immediately.&lt;/p&gt;\n\n&lt;p&gt;Second, I wrapped heavy tab components in &lt;code&gt;React.memo&lt;/code&gt; and made sure props were stable. I found that one of my inline arrow functions was causing re-renders on every swipe because the reference kept changing.&lt;/p&gt;\n\n&lt;p&gt;After those changes, the swipe animation became noticeably smoother. Not perfect, but “production-ready smooth.”&lt;/p&gt;\n\n&lt;p&gt;I also checked how the library recommends optimizing scenes in their examples and discussions. While digging, I found this page useful — the resource I used:&lt;br&gt;\n&lt;a href=\"https://b3netmedia.com/developer/37356-react-native-tab-view.html\" rel=\"noopener noreferrer\"&gt;https://b3netmedia.com/developer/37356-react-native-tab-view.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It helped confirm that lazy rendering and memoization are not “micro-optimizations” here — they’re expected usage patterns if your scenes aren’t trivial.&lt;/p&gt;\n\n&lt;p&gt;One more subtle issue&lt;/p&gt;\n\n&lt;p&gt;There’s also a prop called &lt;code&gt;lazyPreloadDistance&lt;/code&gt;. By default it preloads adjacent tabs. That means even with &lt;code&gt;lazy&lt;/code&gt; enabled, the next tab may render earlier than you expect.&lt;/p&gt;\n\n&lt;p&gt;Setting:&lt;br&gt;\n&lt;/p&gt;\n\n&lt;div class=\"highlight js-code-highlight\"&gt;\n&lt;pre class=\"highlight jsx\"&gt;&lt;code&gt;&lt;span class=\"nx\"&gt;lazyPreloadDistance&lt;/span&gt;&lt;span class=\"o\"&gt;=&lt;/span&gt;&lt;span class=\"p\"&gt;{&lt;/span&gt;&lt;span class=\"mi\"&gt;0&lt;/span&gt;&lt;span class=\"p\"&gt;}&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;/div&gt;\n\n\n\n&lt;p&gt;made behavior more predictable. Tabs only mounted when actually navigated to.&lt;/p&gt;\n\n&lt;p&gt;On iOS especially, that reduced initial CPU spikes.&lt;/p&gt;\n\n&lt;p&gt;Testing on real devices&lt;/p&gt;\n\n&lt;p&gt;Here’s the part I almost skipped — testing on actual hardware.&lt;/p&gt;\n\n&lt;p&gt;Simulators exaggerate some performance problems and hide others. When I ran the updated build on a physical iPhone, the difference was obvious. Before optimization, there was a visible hitch when swiping quickly back and forth. After optimization, the transition stayed within 60fps most of the time.&lt;/p&gt;\n\n&lt;p&gt;On Android, I also enabled the performance monitor (&lt;code&gt;Cmd + D&lt;/code&gt; → Show Perf Monitor) and watched the JS and UI thread FPS. The drops aligned exactly with scene re-renders.&lt;/p&gt;\n\n&lt;p&gt;So it wasn’t guesswork anymore — it was measurable.&lt;/p&gt;\n\n&lt;p&gt;Why this happens specifically with tab views&lt;/p&gt;\n\n&lt;p&gt;Tab views feel lightweight conceptually, but technically they’re coordinating:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Gesture handlers&lt;/li&gt;\n&lt;li&gt;Animated values&lt;/li&gt;\n&lt;li&gt;Scene mounting/unmounting&lt;/li&gt;\n&lt;li&gt;React reconciliation&lt;/li&gt;\n&lt;li&gt;Possibly network requests&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If even one tab triggers a heavy synchronous calculation during render, the animation thread suffers.&lt;/p&gt;\n\n&lt;p&gt;React Native’s architecture makes it especially important to avoid unnecessary re-renders during gestures. Anything synchronous inside render or effect hooks can become visible as UI stutter.&lt;/p&gt;\n\n&lt;p&gt;What I’d do differently next time&lt;/p&gt;\n\n&lt;p&gt;Honestly, I wouldn’t scaffold tab screens with full production logic from day one. I’d start with lightweight placeholders, measure performance, and then gradually layer in complexity.&lt;/p&gt;\n\n&lt;p&gt;And I’d enable &lt;code&gt;lazy&lt;/code&gt; immediately instead of treating it as an optional tweak.&lt;/p&gt;\n\n&lt;p&gt;Quick checklist for future me&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Enable &lt;code&gt;lazy&lt;/code&gt; on TabView.&lt;/li&gt;\n&lt;li&gt;Consider setting &lt;code&gt;lazyPreloadDistance={0}&lt;/code&gt; if scenes are heavy.&lt;/li&gt;\n&lt;li&gt;Wrap tab scenes in &lt;code&gt;React.memo&lt;/code&gt;.&lt;/li&gt;\n&lt;li&gt;Avoid inline functions that change on every render.&lt;/li&gt;\n&lt;li&gt;Test on a real device early, not just a simulator.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;After those changes, the app felt completely different. Same UI, same logic — just structured in a way that doesn’t fight the rendering model.&lt;/p&gt;\n\n&lt;p&gt;It’s funny how performance issues often look mysterious until you realize they’re just side effects of default behaviors. React Native Tab View isn’t broken. It just assumes your scenes are reasonably light unless you tell it otherwise.&lt;/p&gt;\n\n&lt;p&gt;Anyway, figured I’d share while it’s still fresh in my head. If you ever see weird tab lag in a React Native project, chances are it’s not the animation system — it’s what you’re rendering behind it.&lt;/p&gt;",
    "date": "2026-02-27T15:29:08.000Z",
    "url": "https://dev.to/tyropon/react-native-tab-view-1na7"
  },
  {
    "publisherId": "devto",
    "publisherName": "Dev.to",
    "specTitle": "전체",
    "categories": [
      "_all_"
    ],
    "specUrl": "https://dev.to/feed",
    "title": "My AI Agents Create Their Own Bug Fixes — But None of Them Have Credentials",
    "partialText": "&lt;p&gt;&lt;a href=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fr71tgxgsf7q8a4zuc7gd.jpg\" class=\"article-body-image-wrapper\"&gt;&lt;img src=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fr71tgxgsf7q8a4zuc7gd.jpg\" alt=\"Zero-trust duck room: a bouncer-proxy checks JWT tokens while a detective duck watches the fleet\" width=\"800\" height=\"427\"&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;In &lt;a href=\"https://dev.to/nesquikm/i-run-a-fleet-of-ai-agents-in-production-heres-the-architecture-that-keeps-them-honest-3l1h\"&gt;Part 1&lt;/a&gt;, I described the architecture of a fleet of single-purpose AI agents: one job per agent, containerized isolation, cheap LLMs for simple tasks, frontier models for reasoning, append-only logging, and a consistent proxy interface.&lt;/p&gt;\n\n&lt;p&gt;That's the skeleton. But architecture without security is just organized chaos with good diagrams.&lt;/p&gt;\n\n&lt;p&gt;Here's a stat that should keep you up at night: according to the &lt;a href=\"https://www.gravitee.io/blog/state-of-ai-agent-security-2026-report-when-adoption-outpaces-control\" rel=\"noopener noreferrer\"&gt;State of AI Agent Security 2026&lt;/a&gt; report, 45.6% of teams still use shared API keys for agent-to-agent authentication, and only 14.4% have full security approval for their entire AI agent fleet. We're building autonomous systems and authenticating them like it's 2019.&lt;/p&gt;\n\n&lt;p&gt;Here's the part that actually matters: how these agents do powerful things — querying sensitive data, creating pull requests, analyzing telemetry — without ever holding dangerous permissions. And how the system improves itself over time without anyone trusting a bot with a merge button.&lt;/p&gt;\n\n&lt;p&gt;To be precise about \"no credentials\": no stored API keys. No standing tokens. No secrets in environment variables, config files, or prompts. Credentials are minted per workflow run, injected into the sidecar proxy — never into the container — and expire within minutes. The agents cannot leak what they never hold.&lt;/p&gt;\n\n&lt;h2&gt;\n  \n  \n  The Intern With the Admin Password\n&lt;/h2&gt;\n\n&lt;p&gt;Let's talk about how most people give AI agents access to things.&lt;/p&gt;\n\n&lt;p&gt;Step 1: Create API credentials. Step 2: Paste them into the agent's environment variables. Step 3: Hope the agent only uses them for what you intended. Step 4: Forget about the credentials. Step 5: Read about it on the front page of the internet.&lt;/p&gt;\n\n&lt;p&gt;This is the \"just in case\" model. The agent has standing credentials — always valid, broadly scoped, sitting in a config file or environment variable like a house key under the doormat. Maybe you rotate them quarterly. Maybe.&lt;/p&gt;\n\n&lt;p&gt;With traditional software, this is already risky. With AI agents, it's genuinely terrifying. These are systems that &lt;em&gt;take orders from text&lt;/em&gt;. Their behavior is shaped by prompts, which can be manipulated. A prompt injection attack on an agent with standing database credentials isn't a theoretical risk — it's business as usual.&lt;/p&gt;\n\n&lt;p&gt;You wouldn't give an intern the admin password on their first day. Don't give it to a bot that will confidently get things wrong on a regular basis.&lt;/p&gt;\n\n&lt;h2&gt;\n  \n  \n  From \"Just in Case\" to \"Just in Time\"\n&lt;/h2&gt;\n\n&lt;p&gt;The core principle: &lt;strong&gt;agents have zero standing permissions&lt;/strong&gt;. No stored credentials. No API keys. No database passwords. Not in environment variables, not in config files, not in prompts, not anywhere inside the container. Zero.&lt;/p&gt;\n\n&lt;p&gt;When a workflow needs an agent to do something, the orchestrator creates a &lt;strong&gt;short-lived, narrowly-scoped JWT&lt;/strong&gt; for exactly the services that agent needs to query — and only for the duration of that workflow run.&lt;/p&gt;\n\n&lt;p&gt;Here's the lifecycle:&lt;br&gt;\n&lt;/p&gt;\n\n&lt;div class=\"highlight js-code-highlight\"&gt;\n&lt;pre class=\"highlight plaintext\"&gt;&lt;code&gt;Orchestrator receives task\n  → Creates JIT JWT: {agent: \"telemetry\", scope: \"read:telemetry\", workflow: \"wf-7829\", exp: 5min}\n  → Configures container proxy with this token\n  → Agent runs, makes requests through proxy\n  → Proxy injects JWT into outbound requests\n  → Workflow completes\n  → Token expires within minutes\n  → Nothing persists\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;/div&gt;\n\n\n\n&lt;p&gt;The agent never sees the token. The token lives in the proxy configuration, injected by the orchestrator. The agent calls &lt;code&gt;proxy/telemetry/query&lt;/code&gt;, the proxy adds &lt;code&gt;Authorization: Bearer &amp;lt;jwt&amp;gt;&lt;/code&gt;, forwards the request, gets the response, strips auth headers, and returns clean data.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;No credentials in data.&lt;/strong&gt; Not in prompts, not in agent context, not in logs. The agent literally cannot leak what it doesn't have. You can't social-engineer a password out of someone who was never told it. A prompt injection attack on a read-only agent gets you... the ability to ask the proxy for data the agent was already authorized to request. Congratulations, you've hacked your way into doing exactly what the agent was supposed to do anyway. On a write-capable agent (like the PR creator), the risk is more real — but it's still confined to the agent's specific role, its rate limits, and the mandatory human-in-the-loop review before anything merges.&lt;/p&gt;\n\n&lt;p&gt;To be clear: secretless doesn't mean harmless. The agent can still &lt;em&gt;trigger actions&lt;/em&gt; through the proxy — that's delegated authority, and it's real power. But the blast radius is capped by the token's scope, the proxy's rate limits, and the role's action allowlist. A compromised agent can waste your compute budget for 5 minutes. It can't steal long-lived credentials or open arbitrary outbound connections, and any data access is limited to the narrow scope of its short-lived token.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;No ever-living tokens.&lt;/strong&gt; Every token is created per workflow run and expires when the workflow completes. There's nothing to rotate because there's nothing that persists. Your credential rotation policy is \"tokens die automatically, every time.\" The security team's favorite rotation schedule is \"never needs one.\"&lt;/p&gt;\n\n&lt;p&gt;If you want the academic framing: the recent &lt;a href=\"https://arxiv.org/abs/2509.13597\" rel=\"noopener noreferrer\"&gt;Agentic JWT paper&lt;/a&gt; formalizes this as \"intent tokens\" — JWTs that bind each agent action to a specific user intent, workflow step, and agent identity checksum. It's the same principle: scope tokens to intent, not to identity. We arrived at the same pattern independently; it's nice to see it getting formal treatment.&lt;/p&gt;\n\n&lt;h2&gt;\n  \n  \n  RBAC: Roles Are for Bots Too\n&lt;/h2&gt;\n\n&lt;p&gt;Role-Based Access Control isn't just for humans. Every agent type has a role definition. Here's a subset:&lt;br&gt;\n&lt;/p&gt;\n\n&lt;div class=\"highlight js-code-highlight\"&gt;\n&lt;pre class=\"highlight yaml\"&gt;&lt;code&gt;&lt;span class=\"na\"&gt;roles&lt;/span&gt;&lt;span class=\"pi\"&gt;:&lt;/span&gt;\n  &lt;span class=\"na\"&gt;crash-tracker&lt;/span&gt;&lt;span class=\"pi\"&gt;:&lt;/span&gt;\n    &lt;span class=\"na\"&gt;services&lt;/span&gt;&lt;span class=\"pi\"&gt;:&lt;/span&gt; &lt;span class=\"pi\"&gt;[&lt;/span&gt;&lt;span class=\"nv\"&gt;crash-reporting&lt;/span&gt;&lt;span class=\"pi\"&gt;]&lt;/span&gt;\n    &lt;span class=\"na\"&gt;actions&lt;/span&gt;&lt;span class=\"pi\"&gt;:&lt;/span&gt; &lt;span class=\"pi\"&gt;[&lt;/span&gt;&lt;span class=\"nv\"&gt;read&lt;/span&gt;&lt;span class=\"pi\"&gt;]&lt;/span&gt;\n    &lt;span class=\"na\"&gt;data&lt;/span&gt;&lt;span class=\"pi\"&gt;:&lt;/span&gt; &lt;span class=\"pi\"&gt;[&lt;/span&gt;&lt;span class=\"nv\"&gt;crash-reports&lt;/span&gt;&lt;span class=\"pi\"&gt;,&lt;/span&gt; &lt;span class=\"nv\"&gt;stack-traces&lt;/span&gt;&lt;span class=\"pi\"&gt;]&lt;/span&gt;\n    &lt;span class=\"na\"&gt;limits&lt;/span&gt;&lt;span class=\"pi\"&gt;:&lt;/span&gt; &lt;span class=\"pi\"&gt;{&lt;/span&gt; &lt;span class=\"nv\"&gt;max_requests_per_min&lt;/span&gt;&lt;span class=\"pi\"&gt;:&lt;/span&gt; &lt;span class=\"nv\"&gt;30&lt;/span&gt;&lt;span class=\"pi\"&gt;,&lt;/span&gt; &lt;span class=\"nv\"&gt;max_response_size&lt;/span&gt;&lt;span class=\"pi\"&gt;:&lt;/span&gt; &lt;span class=\"nv\"&gt;50kb&lt;/span&gt; &lt;span class=\"pi\"&gt;}&lt;/span&gt;\n\n  &lt;span class=\"na\"&gt;analytics-agent&lt;/span&gt;&lt;span class=\"pi\"&gt;:&lt;/span&gt;\n    &lt;span class=\"na\"&gt;services&lt;/span&gt;&lt;span class=\"pi\"&gt;:&lt;/span&gt; &lt;span class=\"pi\"&gt;[&lt;/span&gt;&lt;span class=\"nv\"&gt;analytics-dashboard&lt;/span&gt;&lt;span class=\"pi\"&gt;]&lt;/span&gt;\n    &lt;span class=\"na\"&gt;actions&lt;/span&gt;&lt;span class=\"pi\"&gt;:&lt;/span&gt; &lt;span class=\"pi\"&gt;[&lt;/span&gt;&lt;span class=\"nv\"&gt;read&lt;/span&gt;&lt;span class=\"pi\"&gt;,&lt;/span&gt; &lt;span class=\"nv\"&gt;query&lt;/span&gt;&lt;span class=\"pi\"&gt;]&lt;/span&gt;\n    &lt;span class=\"na\"&gt;data&lt;/span&gt;&lt;span class=\"pi\"&gt;:&lt;/span&gt; &lt;span class=\"pi\"&gt;[&lt;/span&gt;&lt;span class=\"nv\"&gt;user-metrics&lt;/span&gt;&lt;span class=\"pi\"&gt;,&lt;/span&gt; &lt;span class=\"nv\"&gt;funnel-data&lt;/span&gt;&lt;span class=\"pi\"&gt;]&lt;/span&gt;\n    &lt;span class=\"na\"&gt;limits&lt;/span&gt;&lt;span class=\"pi\"&gt;:&lt;/span&gt; &lt;span class=\"pi\"&gt;{&lt;/span&gt; &lt;span class=\"nv\"&gt;max_requests_per_min&lt;/span&gt;&lt;span class=\"pi\"&gt;:&lt;/span&gt; &lt;span class=\"nv\"&gt;20&lt;/span&gt;&lt;span class=\"pi\"&gt;,&lt;/span&gt; &lt;span class=\"nv\"&gt;max_response_size&lt;/span&gt;&lt;span class=\"pi\"&gt;:&lt;/span&gt; &lt;span class=\"nv\"&gt;200kb&lt;/span&gt; &lt;span class=\"pi\"&gt;}&lt;/span&gt;\n\n  &lt;span class=\"na\"&gt;code-reviewer&lt;/span&gt;&lt;span class=\"pi\"&gt;:&lt;/span&gt;\n    &lt;span class=\"na\"&gt;services&lt;/span&gt;&lt;span class=\"pi\"&gt;:&lt;/span&gt; &lt;span class=\"pi\"&gt;[&lt;/span&gt;&lt;span class=\"nv\"&gt;code-repository&lt;/span&gt;&lt;span class=\"pi\"&gt;]&lt;/span&gt;\n    &lt;span class=\"na\"&gt;actions&lt;/span&gt;&lt;span class=\"pi\"&gt;:&lt;/span&gt; &lt;span class=\"pi\"&gt;[&lt;/span&gt;&lt;span class=\"nv\"&gt;read&lt;/span&gt;&lt;span class=\"pi\"&gt;,&lt;/span&gt; &lt;span class=\"nv\"&gt;create-pr&lt;/span&gt;&lt;span class=\"pi\"&gt;]&lt;/span&gt;\n    &lt;span class=\"na\"&gt;data&lt;/span&gt;&lt;span class=\"pi\"&gt;:&lt;/span&gt; &lt;span class=\"pi\"&gt;[&lt;/span&gt;&lt;span class=\"nv\"&gt;source-code&lt;/span&gt;&lt;span class=\"pi\"&gt;,&lt;/span&gt; &lt;span class=\"nv\"&gt;pull-requests&lt;/span&gt;&lt;span class=\"pi\"&gt;]&lt;/span&gt;\n    &lt;span class=\"na\"&gt;forbidden_paths&lt;/span&gt;&lt;span class=\"pi\"&gt;:&lt;/span&gt; &lt;span class=\"pi\"&gt;[&lt;/span&gt;&lt;span class=\"nv\"&gt;auth/*&lt;/span&gt;&lt;span class=\"pi\"&gt;,&lt;/span&gt; &lt;span class=\"nv\"&gt;.ci/*&lt;/span&gt;&lt;span class=\"pi\"&gt;,&lt;/span&gt; &lt;span class=\"nv\"&gt;security/*&lt;/span&gt;&lt;span class=\"pi\"&gt;]&lt;/span&gt;\n    &lt;span class=\"na\"&gt;limits&lt;/span&gt;&lt;span class=\"pi\"&gt;:&lt;/span&gt; &lt;span class=\"pi\"&gt;{&lt;/span&gt; &lt;span class=\"nv\"&gt;max_diff_lines&lt;/span&gt;&lt;span class=\"pi\"&gt;:&lt;/span&gt; &lt;span class=\"nv\"&gt;500&lt;/span&gt;&lt;span class=\"pi\"&gt;,&lt;/span&gt; &lt;span class=\"nv\"&gt;max_runtime&lt;/span&gt;&lt;span class=\"pi\"&gt;:&lt;/span&gt; &lt;span class=\"nv\"&gt;300s&lt;/span&gt; &lt;span class=\"pi\"&gt;}&lt;/span&gt;\n\n  &lt;span class=\"na\"&gt;pr-creator&lt;/span&gt;&lt;span class=\"pi\"&gt;:&lt;/span&gt;\n    &lt;span class=\"na\"&gt;services&lt;/span&gt;&lt;span class=\"pi\"&gt;:&lt;/span&gt; &lt;span class=\"pi\"&gt;[&lt;/span&gt;&lt;span class=\"nv\"&gt;code-repository&lt;/span&gt;&lt;span class=\"pi\"&gt;]&lt;/span&gt;\n    &lt;span class=\"na\"&gt;actions&lt;/span&gt;&lt;span class=\"pi\"&gt;:&lt;/span&gt; &lt;span class=\"pi\"&gt;[&lt;/span&gt;&lt;span class=\"nv\"&gt;read&lt;/span&gt;&lt;span class=\"pi\"&gt;,&lt;/span&gt; &lt;span class=\"nv\"&gt;create-pr&lt;/span&gt;&lt;span class=\"pi\"&gt;,&lt;/span&gt; &lt;span class=\"nv\"&gt;create-branch&lt;/span&gt;&lt;span class=\"pi\"&gt;]&lt;/span&gt;\n    &lt;span class=\"na\"&gt;data&lt;/span&gt;&lt;span class=\"pi\"&gt;:&lt;/span&gt; &lt;span class=\"pi\"&gt;[&lt;/span&gt;&lt;span class=\"nv\"&gt;source-code&lt;/span&gt;&lt;span class=\"pi\"&gt;]&lt;/span&gt;\n    &lt;span class=\"na\"&gt;forbidden_paths&lt;/span&gt;&lt;span class=\"pi\"&gt;:&lt;/span&gt; &lt;span class=\"pi\"&gt;[&lt;/span&gt;&lt;span class=\"nv\"&gt;auth/*&lt;/span&gt;&lt;span class=\"pi\"&gt;,&lt;/span&gt; &lt;span class=\"nv\"&gt;.ci/*&lt;/span&gt;&lt;span class=\"pi\"&gt;,&lt;/span&gt; &lt;span class=\"nv\"&gt;security/*&lt;/span&gt;&lt;span class=\"pi\"&gt;]&lt;/span&gt;\n    &lt;span class=\"na\"&gt;test_policy&lt;/span&gt;&lt;span class=\"pi\"&gt;:&lt;/span&gt; &lt;span class=\"s\"&gt;can_add_new, cannot_modify_existing&lt;/span&gt;\n    &lt;span class=\"na\"&gt;limits&lt;/span&gt;&lt;span class=\"pi\"&gt;:&lt;/span&gt; &lt;span class=\"pi\"&gt;{&lt;/span&gt; &lt;span class=\"nv\"&gt;max_diff_lines&lt;/span&gt;&lt;span class=\"pi\"&gt;:&lt;/span&gt; &lt;span class=\"nv\"&gt;500&lt;/span&gt;&lt;span class=\"pi\"&gt;,&lt;/span&gt; &lt;span class=\"nv\"&gt;max_files_changed&lt;/span&gt;&lt;span class=\"pi\"&gt;:&lt;/span&gt; &lt;span class=\"nv\"&gt;10&lt;/span&gt; &lt;span class=\"pi\"&gt;}&lt;/span&gt;\n\n  &lt;span class=\"c1\"&gt;# telemetry-analyzer, channel-scanner, etc. follow the same pattern&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;/div&gt;\n\n\n\n&lt;p&gt;The crash tracker can read crash reports. That's it. Not \"crash reports and also maybe telemetry if it asks nicely.\" The proxy enforces these roles structurally — the agent can't request outside its role because the proxy doesn't have endpoints for services the role doesn't include.&lt;/p&gt;\n\n&lt;p&gt;This is the key distinction: &lt;strong&gt;roles are defined in config, not in prompts&lt;/strong&gt;. The security model is structural, not behavioral. You're not saying \"please only query analytics\" in the system prompt and hoping the LLM listens. You're saying \"the only endpoint that exists is analytics\" at the infrastructure level. Prompt injection can't circumvent a wall that has no door.&lt;/p&gt;\n\n&lt;h2&gt;\n  \n  \n  Validation: Trust, But Verify. Actually, Don't Trust.\n&lt;/h2&gt;\n\n&lt;p&gt;Every agent output goes through validation before anything happens. This is not optional. It's not a \"nice to have.\" It's a stage in the workflow pipeline that cannot be skipped.&lt;/p&gt;\n\n&lt;p&gt;For routine outputs — crash classifications, metric summaries — schema validation is enough. The output either matches the expected structure or it doesn't. Zod schemas, strict mode, no exceptions.&lt;/p&gt;\n\n&lt;p&gt;For consequential decisions — \"should we alert the team about this anomaly?\", \"is this PR worth creating?\" — I use &lt;strong&gt;cross-evaluation with multiple LLMs&lt;/strong&gt;. The same question goes to 2–3 models, and the system measures consensus: council discussions, structured voting with confidence scores, adversarial debate, and model-as-judge evaluation.&lt;/p&gt;\n\n&lt;p&gt;A caveat: multi-LLM consensus isn't magic. Models share training data and can converge on the same mistake — correlated failures are real. Cross-evaluation works best when paired with deterministic checks: schema validation, static analysis, and regression tests that don't care what any model thinks. The LLMs catch the subtle stuff; the deterministic checks catch the obvious stuff. Together they cover more than either alone.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Integrated test suites with synthetic data.&lt;/strong&gt; Each agent can be instructed on how to generate synthetic test data for its domain. This means:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;CI runs with mocked LLMs (deterministic, fast, for regression testing)&lt;/li&gt;\n&lt;li&gt;Integration tests with real LLMs (for evaluation and quality assessment)&lt;/li&gt;\n&lt;li&gt;New agents can be added without regression risk — they're tested in isolation first&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Evaluation isn't a phase. It runs on every output, every time.&lt;/p&gt;\n\n&lt;h2&gt;\n  \n  \n  The Meta-Workflow: The System That Fixes Itself\n&lt;/h2&gt;\n\n&lt;p&gt;This is my favorite part. And the part people don't believe until they see it.&lt;/p&gt;\n\n&lt;p&gt;There's a special workflow — the meta-workflow — that doesn't serve users or teams directly. Its job is to analyze the logs from &lt;strong&gt;all other agents&lt;/strong&gt;. It runs under its own role: read-only access to the log store, write access to the code repository (for staging PRs), and nothing else.&lt;/p&gt;\n\n&lt;p&gt;Remember the append-only logging from Part 1? Every prompt, every response, every decision, every proxy call? The meta-workflow reads all of it.&lt;/p&gt;\n\n&lt;p&gt;Here's what it does:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Separates happy paths from failure paths.&lt;/strong&gt; Most agent runs succeed quietly. The meta-workflow builds a baseline of \"normal\" — typical response times, common classifications, expected output shapes. Then it flags the runs that deviate. Not based on error codes alone — based on behavioral patterns. \"The crash tracker classified 47 reports today, but 12 of them took 3x longer than average and returned unusually short classifications.\" That's not an error. It's a degradation trend that a simple health check would miss.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Detects security anomalies.&lt;/strong&gt; Did an agent make an unusual sequence of proxy requests? Did the telemetry agent suddenly start querying twice as often with different parameters? The meta-workflow flags access-pattern drift, unusual request sequences, and anything that looks like exploration rather than execution.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Stages PRs with proposed fixes.&lt;/strong&gt; When the meta-workflow identifies a concrete problem — a prompt that's producing lower-quality outputs, a workflow configuration that's making redundant proxy calls — it uses a coding agent CLI to &lt;strong&gt;draft a pull request&lt;/strong&gt; with the proposed fix, along with the log evidence that triggered it.&lt;/p&gt;\n\n&lt;p&gt;A prompt that's causing classification drift? The meta-workflow drafts an updated prompt, tests it against synthetic data, and opens a PR with the diff, a test report, and the specific log entries that showed the degradation. The reviewer doesn't just see \"AI thinks this is better\" — they see the receipts.&lt;/p&gt;\n\n&lt;p&gt;The quality gates are strict and enforced via branch protection rules and a dedicated bot account with limited repository permissions: PRs from the meta-workflow can't modify test files, can't touch auth code, can't change CI configuration, and must pass the full test suite before they're even visible for review. The agent can propose changes to prompts, configs, and workflow logic. It can't propose changes to its own guardrails. That's a hard boundary.&lt;/p&gt;\n\n&lt;p&gt;Is it noisy? Sometimes. Log analysis produces false positives, and not every staged PR is worth merging. But the signal-to-noise ratio improves over time — because the meta-workflow's own &lt;em&gt;analysis prompts&lt;/em&gt; (not its guardrails or security config) are subject to the same improvement cycle. The distinction matters: it can get better at spotting problems, but it can't loosen its own constraints.&lt;/p&gt;\n\n&lt;p&gt;The system facilitates its own improvement over time. With one non-negotiable constraint:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Human-in-the-loop everywhere.&lt;/strong&gt; An agent can create a PR but not merge it. An agent can flag an anomaly but not take corrective action. An agent can draft an alert but a human decides whether to send it. No irreversible actions happen without human approval.&lt;/p&gt;\n\n&lt;p&gt;The continuous improvement loop looks like this:&lt;br&gt;\n&lt;/p&gt;\n\n&lt;div class=\"highlight js-code-highlight\"&gt;\n&lt;pre class=\"highlight plaintext\"&gt;&lt;code&gt;Agents run workflows\n  → Append-only logs accumulate\n  → Meta-workflow analyzes logs (daily / on-demand)\n  → Identifies: degradation trends, security anomalies, quality drifts\n  → Stages PRs with fixes + test evidence\n  → Human reviews and merges (or doesn't)\n  → Next cycle, the improved system produces better logs\n  → Meta-workflow sees improvement (or spots new issues)\n  → Repeat\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;/div&gt;\n\n\n\n&lt;p&gt;This isn't self-modifying AI in the scary sci-fi sense. It's a CI/CD pipeline where one of the contributors happens to be an AI that reads its own logs. The human is always in the loop. The merge button is always manual.&lt;/p&gt;\n\n&lt;h2&gt;\n  \n  \n  Threat Model: What Can Still Go Wrong\n&lt;/h2&gt;\n\n&lt;p&gt;No architecture is bulletproof. Here's what I worry about and how the system mitigates each:&lt;/p&gt;\n\n&lt;div class=\"table-wrapper-paragraph\"&gt;&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;Threat&lt;/th&gt;\n&lt;th&gt;Mitigation&lt;/th&gt;\n&lt;th&gt;Residual risk&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;\n&lt;strong&gt;Prompt injection&lt;/strong&gt; via agent input&lt;/td&gt;\n&lt;td&gt;Agents can't expand permissions; proxy enforces role boundaries regardless of what agent requests&lt;/td&gt;\n&lt;td&gt;Agent could waste compute within its allowed scope&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;\n&lt;strong&gt;Data exfiltration&lt;/strong&gt; through crafted outputs&lt;/td&gt;\n&lt;td&gt;Agents have no network egress; output goes through proxy which strips sensitive metadata&lt;/td&gt;\n&lt;td&gt;Agent could encode data in its \"normal\" outputs — monitoring catches anomalous output patterns&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;\n&lt;strong&gt;Confused deputy&lt;/strong&gt; (proxy misusing its authority)&lt;/td&gt;\n&lt;td&gt;Proxy is deterministic, minimal-state, rule-based, and audited. No LLM in the proxy path&lt;/td&gt;\n&lt;td&gt;Misconfigured role definitions could over-scope access&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;\n&lt;strong&gt;Log poisoning&lt;/strong&gt; (agent manipulating its own audit trail)&lt;/td&gt;\n&lt;td&gt;Append-only log store; agents write through a separate logging channel they can't read or modify&lt;/td&gt;\n&lt;td&gt;A compromised logging pipeline upstream of the store&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;\n&lt;strong&gt;Self-reinforcing bugs&lt;/strong&gt; (meta-workflow making things worse)&lt;/td&gt;\n&lt;td&gt;PRs can't modify tests, auth, or CI; full test suite must pass; human reviews every merge&lt;/td&gt;\n&lt;td&gt;Subtle quality regressions that pass tests&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;\n&lt;strong&gt;Correlated LLM failures&lt;/strong&gt; in cross-evaluation&lt;/td&gt;\n&lt;td&gt;Deterministic checks (schema validation, static analysis) run alongside LLM evaluation&lt;/td&gt;\n&lt;td&gt;Novel failure modes that neither LLMs nor deterministic checks catch&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;&lt;/div&gt;\n\n&lt;p&gt;The honest answer: this system reduces the blast radius and raises the cost of attacks. It doesn't eliminate risk. Nothing does. But \"the agent can waste 5 minutes of compute within its allowed scope\" is a very different threat profile from \"the agent has the database password.\"&lt;/p&gt;\n\n&lt;h2&gt;\n  \n  \n  The Boring Parts Are the Point\n&lt;/h2&gt;\n\n&lt;p&gt;If you've read this far, you might have noticed a pattern: most of this article is about tokens, proxies, role configs, and logging. Not about the AI. Not about the prompts. Not about which model is smartest.&lt;/p&gt;\n\n&lt;p&gt;That's intentional.&lt;/p&gt;\n\n&lt;p&gt;The interesting parts of a multi-agent system — self-healing workflows, autonomous PR creation, cross-model evaluation — are only possible because the boring parts are solid. JIT tokens mean you don't wake up to a credential leak. Container proxies mean prompt injection is a nuisance, not a catastrophe. RBAC means a misbehaving agent can't cascade. Append-only logs mean the meta-workflow has something to analyze.&lt;/p&gt;\n\n&lt;p&gt;The boring infrastructure &lt;em&gt;is&lt;/em&gt; the product. The AI agents are just the tenants.&lt;/p&gt;\n\n&lt;p&gt;If you're building multi-agent systems, don't start with the prompts. Start with the proxy. Start with the token lifecycle. Start with the logging pipeline. Get the padded room right, then worry about what the agent inside it is saying.&lt;/p&gt;\n\n&lt;p&gt;The &lt;a href=\"https://cloudsecurityalliance.org/blog/2026/02/02/the-agentic-trust-framework-zero-trust-governance-for-ai-agents\" rel=\"noopener noreferrer\"&gt;Cloud Security Alliance's Agentic Trust Framework&lt;/a&gt; puts it well: \"No AI agent should be trusted by default, regardless of purpose or claimed capability.\" The framework maps five core elements — identity, behavior, data governance, segmentation, incident response — that align with everything described in this series. It's worth reading if you're designing agent infrastructure.&lt;/p&gt;\n\n&lt;p&gt;Once the foundation is solid, the ambitious parts take care of themselves.&lt;/p&gt;\n\n\n\n\n&lt;p&gt;&lt;em&gt;This is Part 2 of a two-part series on multi-agent AI architecture in production. &lt;a href=\"https://dev.to/nesquikm/i-run-a-fleet-of-ai-agents-in-production-heres-the-architecture-that-keeps-them-honest-3l1h\"&gt;Part 1&lt;/a&gt; covers agent architecture, container isolation, tiered LLMs, and observability.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;The multi-LLM evaluation patterns mentioned in this article (council, voting, debate, judge) are open-source in &lt;a href=\"https://github.com/nesquikm/mcp-rubber-duck\" rel=\"noopener noreferrer\"&gt;mcp-rubber-duck&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;",
    "date": "2026-02-27T15:27:53.000Z",
    "url": "https://dev.to/nesquikm/my-ai-agents-create-their-own-bug-fixes-but-none-of-them-have-credentials-2ho8"
  },
  {
    "publisherId": "devto",
    "publisherName": "Dev.to",
    "specTitle": "전체",
    "categories": [
      "_all_"
    ],
    "specUrl": "https://dev.to/feed",
    "title": "I Run a Fleet of AI Agents in Production — Here's the Architecture That Keeps Them Honest",
    "partialText": "&lt;p&gt;&lt;a href=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fotx188ayhalo4nznb0ow.jpg\" class=\"article-body-image-wrapper\"&gt;&lt;img src=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fotx188ayhalo4nznb0ow.jpg\" alt=\"Duck mission control: specialized rubber ducks in padded cubicles\" width=\"800\" height=\"427\"&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Everyone's building AI agents. Tutorials show you how to make one. \"Build an AI agent in 15 minutes!\" Great. Now build twelve of them. Give them access to your analytics, your crash reports, your codebase, your telemetry pipeline, and your user acquisition channels. Run them every day. Sleep well at night.&lt;/p&gt;\n\n&lt;p&gt;That's a different tutorial. And judging by the numbers, most people are skipping it: according to the &lt;a href=\"https://www.gravitee.io/blog/state-of-ai-agent-security-2026-report-when-adoption-outpaces-control\" rel=\"noopener noreferrer\"&gt;State of AI Agent Security 2026&lt;/a&gt; report, 88% of organizations reported confirmed or suspected security incidents involving AI agents in the past year, while only 47% of deployed agents receive any active monitoring. We're building fleets and forgetting to install brakes.&lt;/p&gt;\n\n&lt;p&gt;I built a company-wide system of AI agents — not a chatbot, not a copilot, a fleet of about a dozen specialized bots running hundreds of tasks per day across almost every team. Analytics, crash monitoring, code review, telemetry analysis, user channel scanning. Each one has a job. None of them have credentials.&lt;/p&gt;\n\n&lt;p&gt;Here's how the architecture works.&lt;/p&gt;\n\n&lt;h2&gt;\n  \n  \n  One Agent, One Job\n&lt;/h2&gt;\n\n&lt;p&gt;The first design decision was the most important: &lt;strong&gt;no general-purpose agents&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;It's tempting to build one smart agent that can \"do everything.\" Query analytics, check crash reports, review code, scan forums. Give it a massive prompt, a dozen tools, and broad API credentials. It'll figure it out.&lt;/p&gt;\n\n&lt;p&gt;It will also figure out how to do things you never intended. The blast radius of a general-purpose agent is your entire infrastructure.&lt;/p&gt;\n\n&lt;p&gt;Instead, every agent in the system has exactly one responsibility:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;\n&lt;strong&gt;Crash tracker&lt;/strong&gt; — monitors crash reporting services, classifies crash patterns, flags regressions&lt;/li&gt;\n&lt;li&gt;\n&lt;strong&gt;Analytics agent&lt;/strong&gt; — queries dashboards, spots anomalies, generates reports&lt;/li&gt;\n&lt;li&gt;\n&lt;strong&gt;Telemetry analyzer&lt;/strong&gt; — processes app telemetry, identifies performance degradation&lt;/li&gt;\n&lt;li&gt;\n&lt;strong&gt;Code reviewer&lt;/strong&gt; — scans for quality issues, suggests improvements&lt;/li&gt;\n&lt;li&gt;\n&lt;strong&gt;Channel scanner&lt;/strong&gt; — watches user acquisition streams (forums, social media) for sentiment and opportunities&lt;/li&gt;\n&lt;li&gt;\n&lt;strong&gt;PR creator&lt;/strong&gt; — takes findings from other agents and autonomously drafts pull requests&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The orchestrator dispatches. Specialized agents execute. This is the supervisor-agent pattern. The routing layer — which agent gets which task — is &lt;strong&gt;deterministic&lt;/strong&gt;: config-driven rules, not LLM reasoning. You don't want stochastic decision-making in the control plane. But for high-stakes decisions (is this anomaly real? should we alert?), the orchestrator can invoke multi-LLM evaluation — council discussions, structured voting, adversarial debate — before acting. Deterministic routing, intelligent validation.&lt;/p&gt;\n\n&lt;p&gt;It works for the same reason microservices work: small, focused units are easier to test, monitor, debug, and — crucially — contain when they misbehave.&lt;/p&gt;\n\n&lt;p&gt;A crash tracker that goes haywire can't accidentally query your revenue data. It doesn't have access. It doesn't even know revenue data exists.&lt;/p&gt;\n\n&lt;p&gt;Yes, squint at this and it looks like a job queue with fancy workers. That's intentional. The orchestration layer is deliberately boring: deterministic routing, structured queues, config-driven dispatch. The workers are the non-deterministic part, and the architecture's entire job is containing that non-determinism. Treating agents as regular distributed-systems citizens — with all the operational discipline that implies — is what makes them safe to run unsupervised.&lt;/p&gt;\n\n&lt;h2&gt;\n  \n  \n  Not Every Agent Needs a Frontier Brain\n&lt;/h2&gt;\n\n&lt;p&gt;Here's where cost engineering comes in. People default to running every agent on the most expensive model available. That's like hiring a senior architect to sort your mail.&lt;/p&gt;\n\n&lt;p&gt;A crash log classifier? Runs fine on a small model — Haiku-tier or open-weight. It's pattern matching against known categories — fast, cheap, reliable. The telemetry analyzer that just flags threshold breaches? Same tier.&lt;/p&gt;\n\n&lt;p&gt;The analysis synthesizer that takes outputs from six agents and produces a coherent executive summary? That one gets the frontier model. The PR creator that needs to understand code context and write meaningful commit messages? Frontier.&lt;/p&gt;\n\n&lt;p&gt;When 80% of your fleet runs on models that cost 1/50th of the frontier tier, your average cost per task drops dramatically. The expensive models earn their cost on the 20% of tasks that actually need reasoning. Everything else is glorified JSON transformation, and you should price it accordingly.&lt;/p&gt;\n\n&lt;p&gt;For context: the fleet's average cost per task is around $0.02. Frontier model calls average $0.15 each, but they're only 20% of volume. The monthly bill for running the entire fleet — hundreds of tasks per day — stays under $500. Compare that to a single senior engineer's daily rate.&lt;/p&gt;\n\n&lt;h2&gt;\n  \n  \n  The Padded Room with a Mail Slot\n&lt;/h2&gt;\n\n&lt;p&gt;This is the part that makes people uncomfortable, and it's also the part that lets me sleep at night.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Every agent lives in a container with no outbound network access except to its local sidecar proxy.&lt;/strong&gt; No API keys, no tokens, no direct access to any service. The container can compute and talk to exactly one thing: the proxy on loopback.&lt;/p&gt;\n\n&lt;p&gt;If you've worked with service meshes (Envoy, Istio), the pattern is familiar — a &lt;strong&gt;sidecar proxy&lt;/strong&gt; sits next to each agent container and mediates all external communication. The agent calls &lt;code&gt;proxy/analytics/query&lt;/code&gt;. The proxy injects authentication, forwards the request to the actual analytics service, gets the response, strips any auth metadata, and returns clean data to the agent.&lt;/p&gt;\n\n&lt;p&gt;The agent never sees a credential. It can still &lt;em&gt;trigger actions&lt;/em&gt; that use credentials — that's delegated authority, and it's real power. But the agent can't exfiltrate tokens, can't connect to unexpected services, and can't expand its own permissions. The proxy enforces rate limits, request quotas, and maximum response sizes per agent role. If the crash tracker suddenly starts making 10x its normal request volume, the proxy throttles it before it overwhelms downstream systems.&lt;/p&gt;\n\n&lt;p&gt;Think of it as a padded room with a mail slot. The agent slides requests through the slot. Answers come back. But the door doesn't open. The agent doesn't know what's on the other side of the wall. It doesn't even know which building it's in.&lt;/p&gt;\n\n&lt;p&gt;Here's what a request looks like through the mail slot:&lt;br&gt;\n&lt;/p&gt;\n\n&lt;div class=\"highlight js-code-highlight\"&gt;\n&lt;pre class=\"highlight json\"&gt;&lt;code&gt;&lt;span class=\"p\"&gt;{&lt;/span&gt;&lt;span class=\"w\"&gt;\n  &lt;/span&gt;&lt;span class=\"nl\"&gt;\"action\"&lt;/span&gt;&lt;span class=\"p\"&gt;:&lt;/span&gt;&lt;span class=\"w\"&gt; &lt;/span&gt;&lt;span class=\"s2\"&gt;\"query\"&lt;/span&gt;&lt;span class=\"p\"&gt;,&lt;/span&gt;&lt;span class=\"w\"&gt;\n  &lt;/span&gt;&lt;span class=\"nl\"&gt;\"service\"&lt;/span&gt;&lt;span class=\"p\"&gt;:&lt;/span&gt;&lt;span class=\"w\"&gt; &lt;/span&gt;&lt;span class=\"s2\"&gt;\"analytics\"&lt;/span&gt;&lt;span class=\"p\"&gt;,&lt;/span&gt;&lt;span class=\"w\"&gt;\n  &lt;/span&gt;&lt;span class=\"nl\"&gt;\"params\"&lt;/span&gt;&lt;span class=\"p\"&gt;:&lt;/span&gt;&lt;span class=\"w\"&gt; &lt;/span&gt;&lt;span class=\"p\"&gt;{&lt;/span&gt;&lt;span class=\"w\"&gt; &lt;/span&gt;&lt;span class=\"nl\"&gt;\"metric\"&lt;/span&gt;&lt;span class=\"p\"&gt;:&lt;/span&gt;&lt;span class=\"w\"&gt; &lt;/span&gt;&lt;span class=\"s2\"&gt;\"dau\"&lt;/span&gt;&lt;span class=\"p\"&gt;,&lt;/span&gt;&lt;span class=\"w\"&gt; &lt;/span&gt;&lt;span class=\"nl\"&gt;\"range\"&lt;/span&gt;&lt;span class=\"p\"&gt;:&lt;/span&gt;&lt;span class=\"w\"&gt; &lt;/span&gt;&lt;span class=\"s2\"&gt;\"7d\"&lt;/span&gt;&lt;span class=\"w\"&gt; &lt;/span&gt;&lt;span class=\"p\"&gt;},&lt;/span&gt;&lt;span class=\"w\"&gt;\n  &lt;/span&gt;&lt;span class=\"nl\"&gt;\"workflow_id\"&lt;/span&gt;&lt;span class=\"p\"&gt;:&lt;/span&gt;&lt;span class=\"w\"&gt; &lt;/span&gt;&lt;span class=\"s2\"&gt;\"wf-7829\"&lt;/span&gt;&lt;span class=\"p\"&gt;,&lt;/span&gt;&lt;span class=\"w\"&gt;\n  &lt;/span&gt;&lt;span class=\"nl\"&gt;\"agent\"&lt;/span&gt;&lt;span class=\"p\"&gt;:&lt;/span&gt;&lt;span class=\"w\"&gt; &lt;/span&gt;&lt;span class=\"s2\"&gt;\"analytics-agent\"&lt;/span&gt;&lt;span class=\"w\"&gt;\n&lt;/span&gt;&lt;span class=\"p\"&gt;}&lt;/span&gt;&lt;span class=\"w\"&gt;\n&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;\n\n&lt;/div&gt;\n\n\n\n&lt;p&gt;The proxy validates this against the agent's role definition, injects auth, forwards it, and returns clean data. An unknown &lt;code&gt;service&lt;/code&gt; value? Rejected. An action not in the agent's role? Rejected. Rate limit exceeded? Queued or rejected. The agent doesn't get an error message explaining &lt;em&gt;why&lt;/em&gt; — it just gets \"not available.\" This minimizes service-discovery leakage — the agent can't even enumerate what endpoints exist.&lt;/p&gt;\n\n&lt;p&gt;Here's the flow visually:&lt;br&gt;\n&lt;/p&gt;\n\n&lt;div class=\"highlight js-code-highlight\"&gt;\n&lt;pre class=\"highlight plaintext\"&gt;&lt;code&gt;┌─────────────────────┐    loopback only     ┌─────────────────────┐\n│   Agent Container   │ ──────────────────→  │    Sidecar Proxy    │\n│                     │  proxy/analytics/    │                     │\n│ • No network egress │      query           │ • Validates role    │\n│ • No credentials    │                      │ • Injects auth      │\n│ • No service        │ ←──────────────────  │ • Rate limits       │\n│   discovery         │  clean JSON data     │ • Strips metadata   │\n│                     │                      │ • Logs everything   │\n└─────────────────────┘                      └────────┬────────────┘\n                                                      │\n                                                      │ authenticated\n                                                      │ request\n                                                      ▼\n                                             ┌─────────────────────┐\n                                             │  External Service   │\n                                             │  (Analytics, Git,   │\n                                             │   Crash Reporting)  │\n                                             └─────────────────────┘\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;/div&gt;\n\n\n\n&lt;p&gt;This consistent data interface works as a universal abstraction layer. Whether the underlying source is a SQL database, an Elasticsearch cluster, a third-party API, or a codebase repository — the agent queries the same proxy interface. The proxy translates.&lt;/p&gt;\n\n&lt;h2&gt;\n  \n  \n  Coding Agents as CLI Subprocesses\n&lt;/h2&gt;\n\n&lt;p&gt;One pattern I didn't expect to use so heavily: &lt;strong&gt;running a coding agent CLI as a subprocess inside agent workflows&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;Some agents don't need to be LLM wrappers themselves. The code review agent, for example, identifies areas for improvement using a cheap model, then invokes a coding agent via CLI to actually understand the code context, generate fixes, and create PRs. The agent orchestrates; the coding CLI does the heavy lifting.&lt;/p&gt;\n\n&lt;p&gt;This subprocess runs in its own sandbox with hard limits: max runtime, max tokens, max diff size, read-only access to the repo (writes go through a staging area), and a forbidden-paths list that includes auth modules and CI configs. The coding agent can propose new test cases alongside its changes, but it can't modify existing tests or test infrastructure — it can't \"fix\" a failing test by weakening the assertion.&lt;/p&gt;\n\n&lt;p&gt;The PR creator bot works similarly — it collects findings from multiple agents, synthesizes them, then invokes the coding CLI to draft the actual changes with full codebase context. The result: autonomous bots that search for improvements, draft fixes, and open PRs — all without a human writing a single line of code.&lt;/p&gt;\n\n&lt;p&gt;Humans still review and merge. Obviously. We haven't lost our minds entirely.&lt;/p&gt;\n\n&lt;h2&gt;\n  \n  \n  Log Everything, Trust Nothing\n&lt;/h2&gt;\n\n&lt;p&gt;If you can't observe it, you can't trust it. And with a fleet of autonomous agents making decisions all day, trust needs to be earned through data, not assumed through vibes.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Append-only logging.&lt;/strong&gt; Every proxy request, every LLM prompt and response, every decision point — logged to an immutable store. Auth headers and tokens are never logged; prompts and responses go through structured redaction (PII and secret scrubbing) before write. This isn't \"standard backend logging.\" With traditional services you log requests and errors. With AI agents you also need to log &lt;em&gt;reasoning&lt;/em&gt; — the full prompt, the full response, the confidence signals (where the model provides them), and which model produced which output. When an agent starts classifying crashes differently than it did last week, you need to diff the prompts and responses, not just the status codes.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Correlation IDs&lt;/strong&gt; across agent workflows. When the orchestrator dispatches a task to three agents, every log entry carries the same workflow ID. You can reconstruct the entire multi-agent conversation from dispatch to result.&lt;/p&gt;\n\n&lt;p&gt;This paid off when the crash tracker started silently misclassifying reports. No errors, no alerts — it was just gradually less accurate. A model update had shifted its classification boundaries. Because we had full prompt-response logging with correlation IDs, we could diff the tracker's outputs across two weeks. The pattern was clear: shorter responses, lower confidence signals, and a category distribution that had drifted from baseline. Without immutable prompt-response logs, this would have been invisible until someone noticed bad data in a report weeks later.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Modular architecture is observability for free.&lt;/strong&gt; Because each agent is single-purpose and containerized, you get independent monitoring per agent. Dashboard shows the crash tracker is slow? You know exactly where to look. The analytics agent's error rate is climbing? It's not contaminating the telemetry analyzer. Each agent is its own observability boundary.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Unit testing with synthetic data.&lt;/strong&gt; Every agent includes instructions for generating synthetic data for its domain. A crash tracker gets synthetic crash reports. An analytics agent gets synthetic dashboards. They can be tested in isolation — with mocked LLMs for deterministic CI runs, and with real LLMs for integration tests.&lt;/p&gt;\n\n&lt;p&gt;One caveat: if the LLM generates both the test data and the responses, you're testing the model against itself — a hallucination echo chamber. The synthetic data templates are human-authored, seeded from real production incidents and known edge cases. The LLM gets to &lt;em&gt;respond&lt;/em&gt; to the synthetic inputs, but it doesn't get to &lt;em&gt;define&lt;/em&gt; what \"hard\" looks like. That's your job.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Sandboxed environments for prototyping.&lt;/strong&gt; New agents start in a sandbox — same container isolation, same proxy interface, but pointed at synthetic data. You can prototype a new \"security scanner\" agent without it ever touching production services. When it's ready, you point the proxy at the real endpoints. The agent doesn't know the difference. It was always just sliding paper through a mail slot.&lt;/p&gt;\n\n&lt;h2&gt;\n  \n  \n  How It All Fits Together\n&lt;/h2&gt;\n\n&lt;p&gt;Here's a single workflow traced end to end — a telemetry spike turning into a pull request:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Orchestrator&lt;/strong&gt; receives a scheduled telemetry analysis task. It creates a workflow (&lt;code&gt;wf-8341&lt;/code&gt;), selects the telemetry analyzer agent, and dispatches.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Telemetry analyzer&lt;/strong&gt; (running on a cheap model) queries &lt;code&gt;proxy/telemetry/metrics&lt;/code&gt; for the last 24 hours. The proxy validates the request against the agent's role, injects authentication, forwards it, and returns clean data. The agent flags a 3x latency regression on the payments endpoint.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Orchestrator&lt;/strong&gt; receives the flag. Because it's a potential regression (high stakes), it triggers cross-evaluation: the same data goes to two additional models. All three agree — this is real, not noise.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Orchestrator&lt;/strong&gt; dispatches the finding to the &lt;strong&gt;PR creator&lt;/strong&gt; agent with a new JIT token scoped to &lt;code&gt;read:source-code, create-pr, create-branch&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;PR creator&lt;/strong&gt; invokes a coding agent CLI as a subprocess. The CLI runs in a sandbox with read-only repo access, a forbidden-paths list, and hard limits on runtime and diff size. It identifies the likely cause (a missing database index on a recently added column), drafts a migration, and adds a new benchmark test.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;PR creator&lt;/strong&gt; opens a pull request with the fix, the telemetry evidence, and a link to the workflow trace (&lt;code&gt;wf-8341&lt;/code&gt;).&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Everything is logged&lt;/strong&gt;: every proxy call, every LLM prompt and response, every decision point — all carrying &lt;code&gt;wf-8341&lt;/code&gt; as the correlation ID. The token expires. The containers reset.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;A human reviews the PR, checks the telemetry evidence, and merges. Or doesn't.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Total time: about 4 minutes. Total cost: under $0.30 (one frontier model call for the PR, cheap models for everything else). Human time: the 2 minutes it takes to review the PR.&lt;/p&gt;\n\n&lt;h2&gt;\n  \n  \n  What's Next\n&lt;/h2&gt;\n\n&lt;p&gt;This architecture keeps agents productive and observable. But observability without security is just surveillance theater — congratulations, you can now watch your agents leak data in high definition.&lt;/p&gt;\n\n&lt;p&gt;In &lt;a href=\"https://dev.to/nesquikm/my-ai-agents-create-their-own-bug-fixes-but-none-of-them-have-credentials-2ho8\"&gt;Part 2&lt;/a&gt;, I'll cover the security model that makes all of this safe: zero-trust with JIT tokens via JWT, RBAC for agents, a container proxy that means no credential ever touches an agent, and the meta-workflow — a special agent that analyzes logs from all other agents, identifies problems, and stages PRs to fix them. The system facilitates its own improvement, with human review at every step.&lt;/p&gt;\n\n&lt;p&gt;Because the boring parts — tokens, proxies, role definitions, logging — are what make the ambitious parts possible.&lt;/p&gt;\n\n\n\n\n&lt;p&gt;&lt;em&gt;This is Part 1 of a two-part series on multi-agent AI architecture in production. &lt;a href=\"https://dev.to/nesquikm/my-ai-agents-create-their-own-bug-fixes-but-none-of-them-have-credentials-2ho8\"&gt;Part 2&lt;/a&gt; covers security, JIT tokens, and self-healing workflows.&lt;/em&gt;&lt;/p&gt;",
    "date": "2026-02-27T15:27:49.000Z",
    "url": "https://dev.to/nesquikm/i-run-a-fleet-of-ai-agents-in-production-heres-the-architecture-that-keeps-them-honest-3l1h"
  },
  {
    "publisherId": "devto",
    "publisherName": "Dev.to",
    "specTitle": "전체",
    "categories": [
      "_all_"
    ],
    "specUrl": "https://dev.to/feed",
    "title": "Gildav",
    "partialText": "&lt;p&gt;Listen, yesterday I was tinkering with &lt;strong&gt;Gildav (app)&lt;/strong&gt; and ran into one of those annoying macOS permission walls that looks simple on the surface but ends up eating your evening.&lt;/p&gt;\n\n&lt;p&gt;The issue was this: the app launched fine, interface loaded, buttons clickable — but it just wouldn’t access any of my files. Every time I tried to open or save something, nothing happened. No proper error dialog, just silent failure. At first I thought it was a bug in the app itself. Turns out, it was macOS being “helpful.”&lt;/p&gt;\n\n&lt;p&gt;What I did first (and what didn’t work)&lt;/p&gt;\n\n&lt;p&gt;My first instinct was the classic routine: delete and reinstall. I grabbed a fresh copy, moved it into Applications, relaunched. Same behavior. Then I assumed maybe it didn’t like my working folder, so I tried putting test files on the Desktop. Still nothing.&lt;/p&gt;\n\n&lt;p&gt;I even checked file permissions manually via Finder → Get Info to see if something weird was going on with read/write flags. Everything looked normal. I briefly considered that the app was just broken.&lt;/p&gt;\n\n&lt;p&gt;Then I remembered how macOS handles file access since Mojave — all that privacy sandboxing. Apps can’t just freely read your Documents, Desktop, Downloads, external drives, etc. They need explicit permission under Privacy &amp;amp; Security.&lt;/p&gt;\n\n&lt;p&gt;What I realized&lt;/p&gt;\n\n&lt;p&gt;macOS treats access to certain folders as protected. If the app doesn’t explicitly request access the right way — or if you dismissed the permission prompt once — it can silently lose access.&lt;/p&gt;\n\n&lt;p&gt;Apple explains this here:&lt;br&gt;\n&lt;a href=\"https://support.apple.com/en-us/HT210190\" rel=\"noopener noreferrer\"&gt;https://support.apple.com/en-us/HT210190&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The key section is about granting apps access to files and folders. If the app doesn’t appear there, it might never have been properly registered with the system.&lt;/p&gt;\n\n&lt;p&gt;In my case, Gildav wasn’t showing up under “Files and Folders” or “Full Disk Access” at all. Which meant macOS wasn’t letting it touch anything sensitive.&lt;/p&gt;\n\n&lt;p&gt;What actually helped&lt;/p&gt;\n\n&lt;p&gt;Here’s what finally fixed it:&lt;/p&gt;\n\n&lt;p&gt;I went to System Settings → Privacy &amp;amp; Security → Full Disk Access.&lt;/p&gt;\n\n&lt;p&gt;Gildav wasn’t listed, so I manually added it using the “+” button and selected the app from Applications. After that, I toggled it on.&lt;/p&gt;\n\n&lt;p&gt;Relaunched the app — and suddenly file access worked perfectly. It could open files from Documents, save outputs, even read from an external drive.&lt;/p&gt;\n\n&lt;p&gt;That was it. No bug. Just macOS privacy restrictions doing their thing.&lt;/p&gt;\n\n&lt;p&gt;For context, Apple’s broader developer documentation on app sandboxing is here:&lt;br&gt;\n&lt;a href=\"https://developer.apple.com/documentation/security/app_sandbox\" rel=\"noopener noreferrer\"&gt;https://developer.apple.com/documentation/security/app_sandbox&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Reading through that made it clearer why this happens. If the developer hasn’t implemented scoped bookmarks or proper entitlement handling, macOS may block access outside the app’s container unless you explicitly grant broader permission.&lt;/p&gt;\n\n&lt;p&gt;I also checked whether there was a Mac App Store version, because apps distributed through the store tend to handle permissions more predictably. General App Store search entry point is here:&lt;br&gt;\n&lt;a href=\"https://apps.apple.com/\" rel=\"noopener noreferrer\"&gt;https://apps.apple.com/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;But Gildav seems to be distributed independently, which makes sense why it relies more on manual permission handling.&lt;/p&gt;\n\n&lt;p&gt;I found this page useful while digging around for confirmation that others had similar behavior — the resource I used:&lt;br&gt;\n&lt;a href=\"https://dejavu-ks.com/developer/85597-gildav.html\" rel=\"noopener noreferrer\"&gt;https://dejavu-ks.com/developer/85597-gildav.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It helped me rule out that it was some unique corruption on my machine.&lt;/p&gt;\n\n&lt;p&gt;Why this happens more often now&lt;/p&gt;\n\n&lt;p&gt;Since macOS Mojave and especially on Ventura and Sonoma, Apple tightened privacy controls significantly. Apps must explicitly request access to:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Desktop&lt;/li&gt;\n&lt;li&gt;Documents&lt;/li&gt;\n&lt;li&gt;Downloads&lt;/li&gt;\n&lt;li&gt;External volumes&lt;/li&gt;\n&lt;li&gt;Network volumes&lt;/li&gt;\n&lt;li&gt;Removable media&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If the app doesn’t prompt properly, or if you clicked “Don’t Allow” once without realizing, macOS doesn’t keep nagging you. It just quietly blocks access.&lt;/p&gt;\n\n&lt;p&gt;That silent failure is the confusing part. There’s no big red warning. The app just behaves as if nothing exists.&lt;/p&gt;\n\n&lt;p&gt;One more thing I tested&lt;/p&gt;\n\n&lt;p&gt;Before granting Full Disk Access, I tried just enabling it under “Files and Folders.” But since Gildav wasn’t even appearing in that list, there was nothing to toggle. That’s when I understood it wasn’t triggering the standard permission request flow.&lt;/p&gt;\n\n&lt;p&gt;Adding it manually to Full Disk Access essentially overrides the sandbox limitation and gives it broad read/write capability. Not something you should do for random apps, but for a trusted utility it’s reasonable.&lt;/p&gt;\n\n&lt;p&gt;Also important: after adding it, you must fully quit and relaunch the app. Just closing the window isn’t enough.&lt;/p&gt;\n\n&lt;p&gt;On performance and stability&lt;/p&gt;\n\n&lt;p&gt;After granting access, everything behaved normally. No crashes, no CPU spikes, no weird background activity. So it clearly wasn’t a stability issue. The app just needed permission to do its job.&lt;/p&gt;\n\n&lt;p&gt;It’s funny how often macOS problems look like app bugs when they’re actually OS-level policies.&lt;/p&gt;\n\n&lt;p&gt;What I’ll do differently next time&lt;/p&gt;\n\n&lt;p&gt;Next time an app “can’t see” my files, I won’t waste time reinstalling first. I’ll immediately check Privacy &amp;amp; Security.&lt;/p&gt;\n\n&lt;p&gt;Because reinstalling doesn’t reset macOS privacy decisions the way people think it does. Those permissions are stored separately by the system.&lt;/p&gt;\n\n&lt;p&gt;Quick checklist for future me&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;If an app can’t access files, check Privacy &amp;amp; Security first.&lt;/li&gt;\n&lt;li&gt;Look under “Files and Folders.”&lt;/li&gt;\n&lt;li&gt;If it’s not listed, consider adding it to “Full Disk Access.”&lt;/li&gt;\n&lt;li&gt;Fully quit and relaunch after changing permissions.&lt;/li&gt;\n&lt;li&gt;Only grant broad access to apps you trust.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Honestly, once I understood it was a permissions issue, the fix took under two minutes. The hour before that was me chasing the wrong problem.&lt;/p&gt;\n\n&lt;p&gt;Anyway, just sharing in case you ever hit the same wall. macOS security is great in theory, but sometimes it feels like it protects you from your own software.&lt;/p&gt;",
    "date": "2026-02-27T15:27:04.000Z",
    "url": "https://dev.to/tyropon/gildav-5eff"
  },
  {
    "publisherId": "devto",
    "publisherName": "Dev.to",
    "specTitle": "전체",
    "categories": [
      "_all_"
    ],
    "specUrl": "https://dev.to/feed",
    "title": "Teaching AI Agents by Example: The End of brittle selectors",
    "partialText": "&lt;h1&gt;\n  \n  \n  The Brittle Selector Problem\n&lt;/h1&gt;\n\n&lt;p&gt;If you've ever built browser automation, you know the pain. You spend hours crafting the perfect XPath or CSS selector, test it thoroughly, deploy it to production... and then the target website updates their CSS framework and everything breaks.&lt;br&gt;\n&lt;/p&gt;\n\n&lt;div class=\"highlight js-code-highlight\"&gt;\n&lt;pre class=\"highlight javascript\"&gt;&lt;code&gt;&lt;span class=\"c1\"&gt;// Yesterday this worked&lt;/span&gt;\n&lt;span class=\"kd\"&gt;const&lt;/span&gt; &lt;span class=\"nx\"&gt;submitBtn&lt;/span&gt; &lt;span class=\"o\"&gt;=&lt;/span&gt; &lt;span class=\"k\"&gt;await&lt;/span&gt; &lt;span class=\"nx\"&gt;page&lt;/span&gt;&lt;span class=\"p\"&gt;.&lt;/span&gt;&lt;span class=\"nf\"&gt;$&lt;/span&gt;&lt;span class=\"p\"&gt;(&lt;/span&gt;&lt;span class=\"dl\"&gt;'&lt;/span&gt;&lt;span class=\"s1\"&gt;#submit-button&lt;/span&gt;&lt;span class=\"dl\"&gt;'&lt;/span&gt;&lt;span class=\"p\"&gt;);&lt;/span&gt;\n\n&lt;span class=\"c1\"&gt;// Today it's broken because the ID changed to 'btn-submit-primary'&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;/div&gt;\n\n\n\n&lt;p&gt;This isn't just annoying—it's a fundamental limitation in how we teach AI agents to interact with the web.&lt;/p&gt;\n\n&lt;h2&gt;\n  \n  \n  Why Demonstration Beats Specification\n&lt;/h2&gt;\n\n&lt;p&gt;Humans don't learn by reading CSS selectors. We learn by watching, doing, and repeating. A child learns to tie their shoes by watching their parent, not by reading a DOM specification.&lt;/p&gt;\n\n&lt;p&gt;AI agents should learn the same way.&lt;/p&gt;\n\n&lt;p&gt;When you record your screen performing a task, you're capturing:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;\n&lt;strong&gt;Intent&lt;/strong&gt; - What you're trying to accomplish&lt;/li&gt;\n&lt;li&gt;\n&lt;strong&gt;Context&lt;/strong&gt; - The surrounding UI elements that help identify targets&lt;/li&gt;\n&lt;li&gt;\n&lt;strong&gt;Flow&lt;/strong&gt; - The sequence of actions and decision points&lt;/li&gt;\n&lt;li&gt;\n&lt;strong&gt;Recovery&lt;/strong&gt; - How you handle errors or unexpected states&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;This is infinitely more robust than a list of selectors.&lt;/p&gt;\n\n&lt;h2&gt;\n  \n  \n  The SKILL.md Approach\n&lt;/h2&gt;\n\n&lt;p&gt;SKILL.md files capture the essence of a task in a format that's both human-readable and machine-executable. Instead of:&lt;br&gt;\n&lt;/p&gt;\n\n&lt;div class=\"highlight js-code-highlight\"&gt;\n&lt;pre class=\"highlight yaml\"&gt;&lt;code&gt;&lt;span class=\"c1\"&gt;# Fragile approach&lt;/span&gt;\n&lt;span class=\"na\"&gt;click&lt;/span&gt;&lt;span class=\"pi\"&gt;:&lt;/span&gt; &lt;span class=\"s2\"&gt;\"&lt;/span&gt;&lt;span class=\"s\"&gt;#submit-btn\"&lt;/span&gt;\n&lt;span class=\"na\"&gt;fill&lt;/span&gt;&lt;span class=\"pi\"&gt;:&lt;/span&gt; &lt;span class=\"s2\"&gt;\"&lt;/span&gt;&lt;span class=\"s\"&gt;#email-field\"&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;/div&gt;\n\n\n\n&lt;p&gt;You get:&lt;br&gt;\n&lt;/p&gt;\n\n&lt;div class=\"highlight js-code-highlight\"&gt;\n&lt;pre class=\"highlight markdown\"&gt;&lt;code&gt;&lt;span class=\"gh\"&gt;# Book a Demo Workflow&lt;/span&gt;\n\n&lt;span class=\"gu\"&gt;## Goal&lt;/span&gt;\nSchedule a product demo through the website booking form\n\n&lt;span class=\"gu\"&gt;## Workflow&lt;/span&gt;\n&lt;span class=\"p\"&gt;1.&lt;/span&gt; Navigate to /book-demo\n&lt;span class=\"p\"&gt;2.&lt;/span&gt; Identify the booking calendar widget\n&lt;span class=\"p\"&gt;3.&lt;/span&gt; Select first available time slot\n&lt;span class=\"p\"&gt;4.&lt;/span&gt; Fill contact information\n&lt;span class=\"p\"&gt;5.&lt;/span&gt; Confirm booking\n\n&lt;span class=\"gu\"&gt;## Context Signals&lt;/span&gt;\n&lt;span class=\"p\"&gt;-&lt;/span&gt; Look for calendar UI with time slots\n&lt;span class=\"p\"&gt;-&lt;/span&gt; Form should have email, name, company fields\n&lt;span class=\"p\"&gt;-&lt;/span&gt; Success indicator: confirmation message or email\n\n&lt;span class=\"gu\"&gt;## Error Handling&lt;/span&gt;\n&lt;span class=\"p\"&gt;-&lt;/span&gt; If no slots available, try next day\n&lt;span class=\"p\"&gt;-&lt;/span&gt; If form validation fails, check required fields\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;/div&gt;\n\n\n\n&lt;p&gt;The difference? This skill description is &lt;strong&gt;resilient&lt;/strong&gt;. It describes what to look for, not where to find it.&lt;/p&gt;\n\n&lt;h2&gt;\n  \n  \n  Real-World Impact\n&lt;/h2&gt;\n\n&lt;p&gt;I've seen teams spend weeks maintaining brittle automation scripts. With demonstration-based skill creation:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;\n&lt;strong&gt;5 minutes&lt;/strong&gt; to record a new workflow&lt;/li&gt;\n&lt;li&gt;\n&lt;strong&gt;Zero&lt;/strong&gt; ongoing maintenance when the UI updates&lt;/li&gt;\n&lt;li&gt;\n&lt;strong&gt;Reusable&lt;/strong&gt; skills across different agent frameworks&lt;/li&gt;\n&lt;li&gt;\n&lt;strong&gt;Shareable&lt;/strong&gt; knowledge within teams&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;\n  \n  \n  The Bigger Picture\n&lt;/h2&gt;\n\n&lt;p&gt;We're moving from an era of \"telling computers what to do\" to \"showing them what we want.\" This shift democratizes automation—you don't need to be a developer to teach an AI agent. You just need to know how to do the task yourself.&lt;/p&gt;\n\n&lt;p&gt;For developers, this means focusing on high-level orchestration rather than low-level DOM manipulation. For businesses, it means capturing institutional knowledge in executable form.&lt;/p&gt;\n\n&lt;h2&gt;\n  \n  \n  Try It Yourself\n&lt;/h2&gt;\n\n&lt;p&gt;Want to see demonstration-based skill creation in action?&lt;/p&gt;\n\n&lt;p&gt;🚀 Check out &lt;a href=\"https://skillforge.expert\" rel=\"noopener noreferrer\"&gt;SkillForge&lt;/a&gt; — record your screen, get a SKILL.md file&lt;/p&gt;\n\n&lt;p&gt;🔥 Support our &lt;a href=\"https://www.producthunt.com/products/skillforge-2\" rel=\"noopener noreferrer\"&gt;Product Hunt launch&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;What workflows in your daily life would you automate if you could just show an AI how to do them?&lt;/p&gt;\n\n\n\n\n&lt;h1&gt;\n  \n  \n  ai #automation #showdev #webdev\n&lt;/h1&gt;",
    "date": "2026-02-27T15:26:50.000Z",
    "url": "https://dev.to/syncchain2026helix/teaching-ai-agents-by-example-the-end-of-brittle-selectors-jpc"
  },
  {
    "publisherId": "devto",
    "publisherName": "Dev.to",
    "specTitle": "전체",
    "categories": [
      "_all_"
    ],
    "specUrl": "https://dev.to/feed",
    "title": "AI API Pricing Comparison 2026: The Real Cost of GPT-4.1, Claude Sonnet 4.6, and Gemini 2.5",
    "partialText": "&lt;h1&gt;\n  \n  \n  AI API Pricing Comparison 2026: The Real Cost of GPT-4.1, Claude Sonnet 4.6, and Gemini 2.5\n&lt;/h1&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;A data-driven breakdown of what you actually pay for AI API calls across OpenAI, Anthropic, Google, OpenRouter, and LemonData, including the hidden costs nobody talks about.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n\n\n\n&lt;h2&gt;\n  \n  \n  Why This Comparison Exists\n&lt;/h2&gt;\n\n&lt;p&gt;AI API pricing looks simple on the surface: input tokens cost X, output tokens cost Y. But once you factor in prompt caching, minimum deposits, payment friction, and currency conversion losses, the real cost can vary significantly depending on where you buy your tokens.&lt;/p&gt;\n\n&lt;p&gt;Here's a side-by-side look at five platforms across the most popular models as of early 2026. All prices are in USD per 1 million tokens unless otherwise noted.&lt;/p&gt;\n\n&lt;p&gt;Platforms compared:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;OpenAI (direct): api.openai.com&lt;/li&gt;\n&lt;li&gt;Anthropic (direct): api.anthropic.com&lt;/li&gt;\n&lt;li&gt;Google (direct): Vertex AI / AI Studio&lt;/li&gt;\n&lt;li&gt;OpenRouter: openrouter.ai&lt;/li&gt;\n&lt;li&gt;LemonData: api.lemondata.cc&lt;/li&gt;\n&lt;/ul&gt;\n\n\n\n\n&lt;h2&gt;\n  \n  \n  Token Pricing: The Core Numbers\n&lt;/h2&gt;\n\n&lt;h3&gt;\n  \n  \n  OpenAI Models\n&lt;/h3&gt;\n\n&lt;div class=\"table-wrapper-paragraph\"&gt;&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;Model&lt;/th&gt;\n&lt;th&gt;Metric&lt;/th&gt;\n&lt;th&gt;OpenAI Direct&lt;/th&gt;\n&lt;th&gt;OpenRouter&lt;/th&gt;\n&lt;th&gt;LemonData&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;GPT-4.1&lt;/td&gt;\n&lt;td&gt;Input / 1M tokens&lt;/td&gt;\n&lt;td&gt;$2.00&lt;/td&gt;\n&lt;td&gt;$2.00&lt;/td&gt;\n&lt;td&gt;~$2.00&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;&lt;/td&gt;\n&lt;td&gt;Output / 1M tokens&lt;/td&gt;\n&lt;td&gt;$8.00&lt;/td&gt;\n&lt;td&gt;$8.00&lt;/td&gt;\n&lt;td&gt;~$8.00&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;GPT-4.1-mini&lt;/td&gt;\n&lt;td&gt;Input / 1M tokens&lt;/td&gt;\n&lt;td&gt;$0.40&lt;/td&gt;\n&lt;td&gt;$0.40&lt;/td&gt;\n&lt;td&gt;~$0.40&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;&lt;/td&gt;\n&lt;td&gt;Output / 1M tokens&lt;/td&gt;\n&lt;td&gt;$1.60&lt;/td&gt;\n&lt;td&gt;$1.60&lt;/td&gt;\n&lt;td&gt;~$1.60&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;GPT-4o&lt;/td&gt;\n&lt;td&gt;Input / 1M tokens&lt;/td&gt;\n&lt;td&gt;$2.50&lt;/td&gt;\n&lt;td&gt;$2.50&lt;/td&gt;\n&lt;td&gt;~$2.50&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;&lt;/td&gt;\n&lt;td&gt;Output / 1M tokens&lt;/td&gt;\n&lt;td&gt;$10.00&lt;/td&gt;\n&lt;td&gt;$10.00&lt;/td&gt;\n&lt;td&gt;~$10.00&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;o3&lt;/td&gt;\n&lt;td&gt;Input / 1M tokens&lt;/td&gt;\n&lt;td&gt;$2.00&lt;/td&gt;\n&lt;td&gt;$2.00&lt;/td&gt;\n&lt;td&gt;~$2.00&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;&lt;/td&gt;\n&lt;td&gt;Output / 1M tokens&lt;/td&gt;\n&lt;td&gt;$8.00&lt;/td&gt;\n&lt;td&gt;$8.00&lt;/td&gt;\n&lt;td&gt;~$8.00&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;o4-mini&lt;/td&gt;\n&lt;td&gt;Input / 1M tokens&lt;/td&gt;\n&lt;td&gt;$1.10&lt;/td&gt;\n&lt;td&gt;$1.10&lt;/td&gt;\n&lt;td&gt;~$1.10&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;&lt;/td&gt;\n&lt;td&gt;Output / 1M tokens&lt;/td&gt;\n&lt;td&gt;$4.40&lt;/td&gt;\n&lt;td&gt;$4.40&lt;/td&gt;\n&lt;td&gt;~$4.40&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;&lt;/div&gt;\n\n&lt;h3&gt;\n  \n  \n  Anthropic Models\n&lt;/h3&gt;\n\n&lt;div class=\"table-wrapper-paragraph\"&gt;&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;Model&lt;/th&gt;\n&lt;th&gt;Metric&lt;/th&gt;\n&lt;th&gt;Anthropic Direct&lt;/th&gt;\n&lt;th&gt;OpenRouter&lt;/th&gt;\n&lt;th&gt;LemonData&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;Claude Opus 4.6&lt;/td&gt;\n&lt;td&gt;Input / 1M tokens&lt;/td&gt;\n&lt;td&gt;$5.00&lt;/td&gt;\n&lt;td&gt;$5.00&lt;/td&gt;\n&lt;td&gt;~$5.00&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;&lt;/td&gt;\n&lt;td&gt;Output / 1M tokens&lt;/td&gt;\n&lt;td&gt;$25.00&lt;/td&gt;\n&lt;td&gt;$25.00&lt;/td&gt;\n&lt;td&gt;~$25.00&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Claude Sonnet 4.6&lt;/td&gt;\n&lt;td&gt;Input / 1M tokens&lt;/td&gt;\n&lt;td&gt;$3.00&lt;/td&gt;\n&lt;td&gt;$3.00&lt;/td&gt;\n&lt;td&gt;~$3.00&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;&lt;/td&gt;\n&lt;td&gt;Output / 1M tokens&lt;/td&gt;\n&lt;td&gt;$15.00&lt;/td&gt;\n&lt;td&gt;$15.00&lt;/td&gt;\n&lt;td&gt;~$15.00&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Claude Haiku 4.5&lt;/td&gt;\n&lt;td&gt;Input / 1M tokens&lt;/td&gt;\n&lt;td&gt;$1.00&lt;/td&gt;\n&lt;td&gt;$1.00&lt;/td&gt;\n&lt;td&gt;~$1.00&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;&lt;/td&gt;\n&lt;td&gt;Output / 1M tokens&lt;/td&gt;\n&lt;td&gt;$5.00&lt;/td&gt;\n&lt;td&gt;$5.00&lt;/td&gt;\n&lt;td&gt;~$5.00&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;&lt;/div&gt;\n\n&lt;h3&gt;\n  \n  \n  Google Models\n&lt;/h3&gt;\n\n&lt;div class=\"table-wrapper-paragraph\"&gt;&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;Model&lt;/th&gt;\n&lt;th&gt;Metric&lt;/th&gt;\n&lt;th&gt;Google Direct&lt;/th&gt;\n&lt;th&gt;OpenRouter&lt;/th&gt;\n&lt;th&gt;LemonData&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;Gemini 2.5 Pro&lt;/td&gt;\n&lt;td&gt;Input / 1M tokens&lt;/td&gt;\n&lt;td&gt;$1.25&lt;/td&gt;\n&lt;td&gt;$1.25&lt;/td&gt;\n&lt;td&gt;~$1.25&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;&lt;/td&gt;\n&lt;td&gt;Output / 1M tokens&lt;/td&gt;\n&lt;td&gt;$10.00&lt;/td&gt;\n&lt;td&gt;$10.00&lt;/td&gt;\n&lt;td&gt;~$10.00&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Gemini 2.5 Flash&lt;/td&gt;\n&lt;td&gt;Input / 1M tokens&lt;/td&gt;\n&lt;td&gt;$0.30&lt;/td&gt;\n&lt;td&gt;$0.30&lt;/td&gt;\n&lt;td&gt;~$0.30&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;&lt;/td&gt;\n&lt;td&gt;Output / 1M tokens&lt;/td&gt;\n&lt;td&gt;$2.50&lt;/td&gt;\n&lt;td&gt;$2.50&lt;/td&gt;\n&lt;td&gt;~$2.50&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;&lt;/div&gt;\n\n&lt;p&gt;Key observations:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;OpenRouter charges 0% markup on model pricing itself, but applies a 5.5% platform fee on usage. LemonData prices are at or near official rates.&lt;/li&gt;\n&lt;li&gt;For high-volume users, the effective cost difference between platforms comes down to payment friction and caching support rather than token prices.&lt;/li&gt;\n&lt;li&gt;Google AI Studio offers a generous free tier for Gemini models, worth noting for low-volume users&lt;/li&gt;\n&lt;/ul&gt;\n\n\n\n\n&lt;h2&gt;\n  \n  \n  Prompt Caching: The Overlooked Cost Saver\n&lt;/h2&gt;\n\n&lt;p&gt;Prompt caching can reduce costs by 50-90% for repetitive workloads (system prompts, few-shot examples, document analysis). Not all platforms support it equally.&lt;/p&gt;\n\n&lt;div class=\"table-wrapper-paragraph\"&gt;&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;Model&lt;/th&gt;\n&lt;th&gt;Cache Write / 1M tokens&lt;/th&gt;\n&lt;th&gt;Cache Read / 1M tokens&lt;/th&gt;\n&lt;th&gt;Platform&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;GPT-4.1&lt;/td&gt;\n&lt;td&gt;N/A (automatic)&lt;/td&gt;\n&lt;td&gt;$1.00 (50% of input)&lt;/td&gt;\n&lt;td&gt;OpenAI&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Claude Sonnet 4.6&lt;/td&gt;\n&lt;td&gt;$3.75&lt;/td&gt;\n&lt;td&gt;$0.30&lt;/td&gt;\n&lt;td&gt;Anthropic&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Claude Sonnet 4.6&lt;/td&gt;\n&lt;td&gt;$3.75&lt;/td&gt;\n&lt;td&gt;$0.30&lt;/td&gt;\n&lt;td&gt;LemonData&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Gemini 2.5 Pro&lt;/td&gt;\n&lt;td&gt;N/A&lt;/td&gt;\n&lt;td&gt;$0.125&lt;/td&gt;\n&lt;td&gt;Google&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;&lt;/div&gt;\n\n&lt;p&gt;How caching works per provider:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;OpenAI: Automatic prompt caching. No write cost. Cached input tokens are billed at 50% of standard input price. Caching kicks in for prompts &amp;gt; 1024 tokens.&lt;/li&gt;\n&lt;li&gt;Anthropic: Explicit caching via &lt;code&gt;cache_control&lt;/code&gt; breakpoints. Write cost is 25% higher than standard input. Read cost is 90% cheaper. Cache TTL is 5 minutes (extended on hit).&lt;/li&gt;\n&lt;li&gt;Google: Context caching available for Gemini models. Pricing varies by model and storage duration.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Bottom line:&lt;/strong&gt; If your application sends the same system prompt repeatedly, caching alone can cut your bill in half. Make sure your platform of choice passes through caching support. Some aggregators strip cache headers.&lt;/p&gt;\n\n&lt;p&gt;LemonData passes through prompt caching parameters for all supported models, including Anthropic's explicit &lt;code&gt;cache_control&lt;/code&gt; and OpenAI's automatic caching.&lt;/p&gt;\n\n\n\n\n&lt;h2&gt;\n  \n  \n  Video Generation: Seedance 2.0\n&lt;/h2&gt;\n\n&lt;p&gt;Video generation models use a fundamentally different pricing model: you pay per generation or per second of output, not per token.&lt;/p&gt;\n\n&lt;div class=\"table-wrapper-paragraph\"&gt;&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;Model&lt;/th&gt;\n&lt;th&gt;Metric&lt;/th&gt;\n&lt;th&gt;Official Price&lt;/th&gt;\n&lt;th&gt;LemonData&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;Seedance 2.0&lt;/td&gt;\n&lt;td&gt;Per 5s video&lt;/td&gt;\n&lt;td&gt;~$0.10&lt;/td&gt;\n&lt;td&gt;~$0.10&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;&lt;/td&gt;\n&lt;td&gt;Per 10s video&lt;/td&gt;\n&lt;td&gt;~$0.20&lt;/td&gt;\n&lt;td&gt;~$0.20&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;&lt;/div&gt;\n\n&lt;p&gt;Notes:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Seedance 2.0 supports both text-to-video and image-to-video&lt;/li&gt;\n&lt;li&gt;Pricing is typically per request, with cost varying by output duration and resolution&lt;/li&gt;\n&lt;li&gt;LemonData charges per request for Seedance, with pricing at or near official rates&lt;/li&gt;\n&lt;/ul&gt;\n\n\n\n\n&lt;h2&gt;\n  \n  \n  Beyond Token Prices: The Hidden Costs\n&lt;/h2&gt;\n\n&lt;p&gt;Raw token pricing only tells part of the story. Here are the costs that don't show up in pricing tables.&lt;/p&gt;\n\n&lt;h3&gt;\n  \n  \n  1. Minimum Deposits and Prepayment\n&lt;/h3&gt;\n\n&lt;div class=\"table-wrapper-paragraph\"&gt;&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;Platform&lt;/th&gt;\n&lt;th&gt;Minimum Deposit&lt;/th&gt;\n&lt;th&gt;Free Tier&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;OpenAI&lt;/td&gt;\n&lt;td&gt;$5 minimum top-up&lt;/td&gt;\n&lt;td&gt;New accounts get limited free credits&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Anthropic&lt;/td&gt;\n&lt;td&gt;$5 minimum top-up&lt;/td&gt;\n&lt;td&gt;New accounts get limited free credits&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Google AI Studio&lt;/td&gt;\n&lt;td&gt;None (free tier available)&lt;/td&gt;\n&lt;td&gt;Generous free tier for Gemini models&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;OpenRouter&lt;/td&gt;\n&lt;td&gt;$5 minimum purchase&lt;/td&gt;\n&lt;td&gt;Free tier: 25+ models, 50 requests/day&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;LemonData&lt;/td&gt;\n&lt;td&gt;$5 minimum top-up&lt;/td&gt;\n&lt;td&gt;$1 free credits on signup&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;&lt;/div&gt;\n\n&lt;h3&gt;\n  \n  \n  2. Payment Method Friction\n&lt;/h3&gt;\n\n&lt;p&gt;This matters more than most people think, especially for developers outside the US/EU.&lt;/p&gt;\n\n&lt;div class=\"table-wrapper-paragraph\"&gt;&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;Platform&lt;/th&gt;\n&lt;th&gt;Payment Methods&lt;/th&gt;\n&lt;th&gt;Non-USD Friction&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;OpenAI&lt;/td&gt;\n&lt;td&gt;Visa/Mastercard/Amex&lt;/td&gt;\n&lt;td&gt;~1-3% FX fee on non-USD cards&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Anthropic&lt;/td&gt;\n&lt;td&gt;Visa/Mastercard&lt;/td&gt;\n&lt;td&gt;~1-3% FX fee on non-USD cards&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Google&lt;/td&gt;\n&lt;td&gt;Google Cloud billing&lt;/td&gt;\n&lt;td&gt;Varies by region&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;OpenRouter&lt;/td&gt;\n&lt;td&gt;Crypto, credit card&lt;/td&gt;\n&lt;td&gt;Crypto has no FX fee; cards vary&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;LemonData&lt;/td&gt;\n&lt;td&gt;WeChat Pay, Alipay, card&lt;/td&gt;\n&lt;td&gt;Native CNY, zero FX loss for Chinese users&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;&lt;/div&gt;\n\n&lt;p&gt;&lt;strong&gt;For developers in China:&lt;/strong&gt; The FX friction is real. A Chinese developer paying OpenAI with a Visa card loses roughly 1-3% on currency conversion, plus potential foreign transaction fees. Over a year of moderate usage ($50-100/month), that adds up to $10-30 in pure waste. LemonData accepts WeChat/Alipay in CNY, eliminating this entirely.&lt;/p&gt;\n\n&lt;h3&gt;\n  \n  \n  3. Subscription Waste\n&lt;/h3&gt;\n\n&lt;p&gt;Many developers conflate API access with subscription products:&lt;/p&gt;\n\n&lt;div class=\"table-wrapper-paragraph\"&gt;&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;Product&lt;/th&gt;\n&lt;th&gt;Cost&lt;/th&gt;\n&lt;th&gt;What You Get&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;ChatGPT Plus&lt;/td&gt;\n&lt;td&gt;$20/month&lt;/td&gt;\n&lt;td&gt;Chat interface, GPT-4o access, limited GPT-4.1&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Claude Pro&lt;/td&gt;\n&lt;td&gt;$20/month&lt;/td&gt;\n&lt;td&gt;Chat interface, higher usage limits&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;API (pay-as-you-go)&lt;/td&gt;\n&lt;td&gt;$0/month + usage&lt;/td&gt;\n&lt;td&gt;Programmatic access, any model&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;&lt;/div&gt;\n\n&lt;p&gt;If you use less than ~$20 worth of API calls per month, the subscription is more expensive. For reference, $20 buys you roughly:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;~50 million GPT-4.1-mini input tokens&lt;/li&gt;\n&lt;li&gt;~20 million Claude Haiku 4.5 input tokens&lt;/li&gt;\n&lt;li&gt;~2,000-3,000 typical GPT-4.1 conversations (assuming ~2K input + 1K output per conversation)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Most individual developers and small projects fall well under $20/month in API usage.&lt;/p&gt;\n\n\n\n\n&lt;h2&gt;\n  \n  \n  Cost Scenarios: What Real Usage Looks Like\n&lt;/h2&gt;\n\n&lt;h3&gt;\n  \n  \n  Scenario 1: Indie Developer, AI-Powered Feature\n&lt;/h3&gt;\n\n&lt;ul&gt;\n&lt;li&gt;500 API calls/day, average 1K input + 500 output tokens per call&lt;/li&gt;\n&lt;li&gt;Model: GPT-4.1-mini&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;div class=\"table-wrapper-paragraph\"&gt;&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;Platform&lt;/th&gt;\n&lt;th&gt;Monthly Cost&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;OpenAI Direct&lt;/td&gt;\n&lt;td&gt;~$18/mo&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;LemonData&lt;/td&gt;\n&lt;td&gt;~$18-20/mo&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;&lt;/div&gt;\n\n&lt;h3&gt;\n  \n  \n  Scenario 2: Startup, Customer Support Bot\n&lt;/h3&gt;\n\n&lt;ul&gt;\n&lt;li&gt;5,000 API calls/day, average 2K input + 1K output tokens&lt;/li&gt;\n&lt;li&gt;Model: Claude Sonnet 4.6&lt;/li&gt;\n&lt;li&gt;Heavy system prompt reuse (caching applicable)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;div class=\"table-wrapper-paragraph\"&gt;&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;Platform&lt;/th&gt;\n&lt;th&gt;Monthly Cost (no cache)&lt;/th&gt;\n&lt;th&gt;Monthly Cost (with cache)&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;Anthropic Direct&lt;/td&gt;\n&lt;td&gt;~$3,150/mo&lt;/td&gt;\n&lt;td&gt;~$2,502/mo&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;LemonData&lt;/td&gt;\n&lt;td&gt;~$3,150/mo&lt;/td&gt;\n&lt;td&gt;~$2,502/mo&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;&lt;/div&gt;\n\n&lt;h3&gt;\n  \n  \n  Scenario 3: AI Coding Tool, Multi-Model\n&lt;/h3&gt;\n\n&lt;ul&gt;\n&lt;li&gt;2,000 calls/day split across GPT-4.1 (40%), Claude Sonnet 4.6 (40%), Gemini 2.5 Pro (20%)&lt;/li&gt;\n&lt;li&gt;Average 3K input + 2K output tokens&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;div class=\"table-wrapper-paragraph\"&gt;&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;Platform&lt;/th&gt;\n&lt;th&gt;Monthly Cost&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;Multiple direct APIs&lt;/td&gt;\n&lt;td&gt;~$1,749/mo (sum of 3 providers)&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;OpenRouter&lt;/td&gt;\n&lt;td&gt;~$1,840/mo&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;LemonData&lt;/td&gt;\n&lt;td&gt;~$1,749-1,800/mo&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;&lt;/div&gt;\n\n&lt;p&gt;Note: Using multiple direct APIs means managing 3 separate accounts, billing systems, and API keys. Aggregators simplify this to a single account. OpenRouter's ~$1,840 figure reflects their 5.5% platform fee on top of base model pricing.&lt;/p&gt;\n\n\n\n\n&lt;h2&gt;\n  \n  \n  Platform Feature Comparison\n&lt;/h2&gt;\n\n&lt;p&gt;Beyond pricing, platform capabilities matter for production use.&lt;/p&gt;\n\n&lt;div class=\"table-wrapper-paragraph\"&gt;&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;Feature&lt;/th&gt;\n&lt;th&gt;OpenAI&lt;/th&gt;\n&lt;th&gt;Anthropic&lt;/th&gt;\n&lt;th&gt;Google&lt;/th&gt;\n&lt;th&gt;OpenRouter&lt;/th&gt;\n&lt;th&gt;LemonData&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;Models available&lt;/td&gt;\n&lt;td&gt;OpenAI only&lt;/td&gt;\n&lt;td&gt;Anthropic only&lt;/td&gt;\n&lt;td&gt;Google only&lt;/td&gt;\n&lt;td&gt;400+&lt;/td&gt;\n&lt;td&gt;300+&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;OpenAI-compatible API&lt;/td&gt;\n&lt;td&gt;Yes&lt;/td&gt;\n&lt;td&gt;No (own format)&lt;/td&gt;\n&lt;td&gt;No (own format)&lt;/td&gt;\n&lt;td&gt;Yes&lt;/td&gt;\n&lt;td&gt;Yes&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Streaming&lt;/td&gt;\n&lt;td&gt;Yes&lt;/td&gt;\n&lt;td&gt;Yes&lt;/td&gt;\n&lt;td&gt;Yes&lt;/td&gt;\n&lt;td&gt;Yes&lt;/td&gt;\n&lt;td&gt;Yes&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Prompt caching&lt;/td&gt;\n&lt;td&gt;Automatic&lt;/td&gt;\n&lt;td&gt;Explicit&lt;/td&gt;\n&lt;td&gt;Context caching&lt;/td&gt;\n&lt;td&gt;Passthrough&lt;/td&gt;\n&lt;td&gt;Passthrough&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Function calling&lt;/td&gt;\n&lt;td&gt;Yes&lt;/td&gt;\n&lt;td&gt;Yes (tools)&lt;/td&gt;\n&lt;td&gt;Yes&lt;/td&gt;\n&lt;td&gt;Yes&lt;/td&gt;\n&lt;td&gt;Yes&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Vision&lt;/td&gt;\n&lt;td&gt;Yes&lt;/td&gt;\n&lt;td&gt;Yes&lt;/td&gt;\n&lt;td&gt;Yes&lt;/td&gt;\n&lt;td&gt;Yes&lt;/td&gt;\n&lt;td&gt;Yes&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Video generation&lt;/td&gt;\n&lt;td&gt;Sora&lt;/td&gt;\n&lt;td&gt;No&lt;/td&gt;\n&lt;td&gt;Veo&lt;/td&gt;\n&lt;td&gt;Via providers&lt;/td&gt;\n&lt;td&gt;Seedance 2.0 + others&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Rate limits&lt;/td&gt;\n&lt;td&gt;Tier-based&lt;/td&gt;\n&lt;td&gt;Tier-based&lt;/td&gt;\n&lt;td&gt;Quota-based&lt;/td&gt;\n&lt;td&gt;Credit-based&lt;/td&gt;\n&lt;td&gt;Role-based&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;CNY payment&lt;/td&gt;\n&lt;td&gt;No&lt;/td&gt;\n&lt;td&gt;No&lt;/td&gt;\n&lt;td&gt;No&lt;/td&gt;\n&lt;td&gt;No&lt;/td&gt;\n&lt;td&gt;Yes&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;&lt;/div&gt;\n\n\n\n\n&lt;h2&gt;\n  \n  \n  Recommendations\n&lt;/h2&gt;\n\n&lt;p&gt;Choose direct APIs if:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;You need guaranteed SLA and direct vendor support&lt;/li&gt;\n&lt;li&gt;You're processing highly sensitive data under strict compliance requirements&lt;/li&gt;\n&lt;li&gt;You only use one provider's models&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Choose an aggregator (OpenRouter / LemonData) if:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;You want access to multiple providers through one API&lt;/li&gt;\n&lt;li&gt;You're in a region where direct API access is difficult (payment, network)&lt;/li&gt;\n&lt;li&gt;You want to switch models without changing your integration&lt;/li&gt;\n&lt;li&gt;You're building a product that needs model flexibility&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Choose LemonData specifically if:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;You're based in China and want native CNY payment&lt;/li&gt;\n&lt;li&gt;You need direct network access without VPN&lt;/li&gt;\n&lt;li&gt;You want 300+ models including Chinese providers (Qwen, DeepSeek, etc.)&lt;/li&gt;\n&lt;/ul&gt;\n\n\n\n\n&lt;h2&gt;\n  \n  \n  Methodology and Disclaimers\n&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;All prices reflect early 2026 pricing as published on official pricing pages&lt;/li&gt;\n&lt;li&gt;Prices change frequently. Always check the provider's official pricing page for the most current rates&lt;/li&gt;\n&lt;li&gt;Aggregator pricing includes their margin; direct API pricing does not include payment processing fees&lt;/li&gt;\n&lt;li&gt;\"Hidden costs\" calculations assume typical non-US developer payment scenarios&lt;/li&gt;\n&lt;li&gt;Scenario calculations use simplified token counts; real-world usage varies&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Price sources to verify:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;OpenAI: &lt;a href=\"https://openai.com/api/pricing\" rel=\"noopener noreferrer\"&gt;https://openai.com/api/pricing&lt;/a&gt;\n&lt;/li&gt;\n&lt;li&gt;Anthropic: &lt;a href=\"https://www.anthropic.com/pricing\" rel=\"noopener noreferrer\"&gt;https://www.anthropic.com/pricing&lt;/a&gt;\n&lt;/li&gt;\n&lt;li&gt;Google: &lt;a href=\"https://ai.google.dev/pricing\" rel=\"noopener noreferrer\"&gt;https://ai.google.dev/pricing&lt;/a&gt;\n&lt;/li&gt;\n&lt;li&gt;OpenRouter: &lt;a href=\"https://openrouter.ai/models\" rel=\"noopener noreferrer\"&gt;https://openrouter.ai/models&lt;/a&gt;\n&lt;/li&gt;\n&lt;li&gt;LemonData: &lt;a href=\"https://docs.lemondata.cc/pricing\" rel=\"noopener noreferrer\"&gt;https://docs.lemondata.cc/pricing&lt;/a&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n\n\n\n\n&lt;p&gt;&lt;em&gt;Last updated: February 2026. Prices in this article are approximate and subject to change. Always check the provider's official pricing page for the most current rates.&lt;/em&gt;&lt;/p&gt;\n\n\n\n\n&lt;p&gt;&lt;em&gt;Try LemonData: &lt;a href=\"https://lemondata.cc/r/blog-pricing\" rel=\"noopener noreferrer\"&gt;lemondata.cc&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;\n\n\n\n\n&lt;p&gt;&lt;em&gt;Cut your AI API costs by 30-70% with LemonData — 300+ models, one key → &lt;a href=\"https://lemondata.cc/r/IV0-8FOH\" rel=\"noopener noreferrer\"&gt;lemondata.cc/r/IV0-8FOH&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;",
    "date": "2026-02-27T15:26:21.000Z",
    "url": "https://dev.to/lemondata_dev/ai-api-pricing-comparison-2026-the-real-cost-of-gpt-41-claude-sonnet-46-and-gemini-25-11co"
  },
  {
    "publisherId": "devto",
    "publisherName": "Dev.to",
    "specTitle": "전체",
    "categories": [
      "_all_"
    ],
    "specUrl": "https://dev.to/feed",
    "title": "When Doctors Are Too Tired to Think Slow: Building CLARA with Gemini 3 Pro",
    "partialText": "&lt;p&gt;&lt;em&gt;This is a submission for the &lt;a href=\"https://dev.to/challenges/mlh-built-with-google-gemini-02-25-26\"&gt;Built with Google Gemini: Writing Challenge&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;\n\n&lt;h2&gt;\n  \n  \n  &lt;strong&gt;What I Built with Google Gemini&lt;/strong&gt;\n&lt;/h2&gt;\n\n&lt;p&gt;Diagnostic error affects &lt;em&gt;12 million Americans annually&lt;/em&gt;. Behind that number are real encounters - patients who leave uncertain, physicians who move to the next room carrying doubt.&lt;/p&gt;\n\n&lt;p&gt;In women's health, this crisis is particularly acute: women are diagnosed on average 4 years later than men. A major factor driving this gap is &lt;em&gt;Diagnostic Shadowing&lt;/em&gt;, a cognitive bias where a patient's physical symptoms are inadvertently misattributed to their psychiatric or chronic history.&lt;/p&gt;\n\n&lt;p&gt;It’s important to understand that this is rarely negligence. It is a breakdown of &lt;em&gt;Dual Process Theory&lt;/em&gt; under pressure. High cognitive load forces burnt-out physicians to rely on System 1 (fast, heuristic thinking) just to keep up, bypassing System 2 (slow, analytical thinking). Necessary mental shortcuts can occasionally become unintended clinical blind spots.&lt;/p&gt;\n\n&lt;p&gt;To help solve this, I built &lt;strong&gt;CLARA (Clinical Logic Assessment &amp;amp; Reasoning Assistant)&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;CLARA is a multimodal AI agent powered by Gemini 3 Pro. She acts as a Cognitive Forcing Strategy - an \"External System 2\" that supports physicians when cognitive bandwidth is limited.&lt;/p&gt;\n\n&lt;p&gt;Unlike standard AI medical scribes that merely record &lt;em&gt;what&lt;/em&gt; is said, CLARA analyzes the &lt;em&gt;logic&lt;/em&gt; of the encounter. Because Gemini 3 Pro is natively multimodal, CLARA can process consented consultation audio directly.&lt;/p&gt;\n\n&lt;p&gt;Designed as a post-encounter safety net, CLARA reviews recorded consultations prior to discharge, identifying high-risk reasoning patterns and generating standardized “Clinical Insights” in JSON format. In doing so, she transforms the subjective experience of “being dismissed” into objective, actionable data, protecting patients while supporting physicians under human constraints.&lt;/p&gt;\n\n&lt;h2&gt;\n  \n  \n  &lt;strong&gt;Demo&lt;/strong&gt;\n&lt;/h2&gt;\n\n\n&lt;div class=\"ltag__cloud-run\"&gt;\n  &lt;iframe height=\"600px\" src=\"https://clara-144308352836.us-south1.run.app/\"&gt;\n  &lt;/iframe&gt;\n&lt;/div&gt;\n\n\n&lt;p&gt;Check out the &lt;a href=\"https://github.com/innacampo/clara\" rel=\"noopener noreferrer\"&gt;CLARA Github repository&lt;/a&gt; and &lt;a href=\"https://clara-144308352836.us-south1.run.app/\" rel=\"noopener noreferrer\"&gt;live demo&lt;/a&gt;.&lt;br&gt;\nTest files can be downloaded &lt;a href=\"https://github.com/innacampo/clara/tree/main/test_files\" rel=\"noopener noreferrer\"&gt;here&lt;/a&gt; or try the Sample Cases. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Frisbyc9u3tsgshtre448.gif\" class=\"article-body-image-wrapper\"&gt;&lt;img src=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Frisbyc9u3tsgshtre448.gif\" alt=\" CLARA UI: an audio transcript is analyzed and the JSON \" width=\"426\" height=\"240\"&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;h2&gt;\n  \n  \n  &lt;strong&gt;What I Learned&lt;/strong&gt;\n&lt;/h2&gt;\n\n&lt;p&gt;Building CLARA taught me two massive lessons - one technical, and one deeply human.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;1. The Human Element: Empathy in AI Design&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Initially, I named the project the Clinical Logic Assessment &amp;amp; Reasoning &lt;em&gt;Auditor&lt;/em&gt;. I programmed the AI to hunt for \"dangerous biases\" and output \"Audit Flags.\" I quickly realized that this punitive framing would alienate the very people I was trying to help. Physicians are already under immense strain. I learned to completely rewrite my system prompts to shift the tone from evaluative to collaborative. CLARA is now an &lt;em&gt;Assistant&lt;/em&gt; that looks for unintended clinical blind spots and offers gentle clinical nudges. Designing AI begins with understanding the psychology of the end user.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;2. The Technical Element: Securing API Keys&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;While prototyping in Google AI Studio, I initially used the generated client-side JavaScript implementation. That approach quickly revealed a production concern: exposing the Gemini API key in the browser.&lt;/p&gt;\n\n&lt;p&gt;To harden the architecture, I introduced a dedicated Node.js/Express backend layer. The frontend now sends analysis requests to my server, which securely manages the API key via environment variables and handles all communication with Gemini. This shift transformed CLARA from a prototype into a securely deployable AI service.&lt;/p&gt;\n\n&lt;h2&gt;\n  \n  \n  &lt;strong&gt;Google Gemini Feedback&lt;/strong&gt;\n&lt;/h2&gt;\n\n&lt;p&gt;&lt;strong&gt;What Worked Well:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Gemini 3 Pro’s native multimodality was transformative for this build. Not having to chain a separate Speech-to-Text model with an LLM significantly simplified the architecture. Furthermore, Gemini's ability to digest complex psychological concepts (like Anchoring Bias and Premature Closure) and apply them to raw conversational dialogue (while strictly adhering to my requested JSON output schema) was flawless.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Where I Ran Into Friction:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;The primary friction point emerged around production security. Google AI Studio excels at rapid prototyping, and the generated client-side JavaScript is perfect for experimentation. However, moving toward deployment requires architectural adjustments, since client-side implementations expose API keys in the browser. &lt;/p&gt;\n\n&lt;p&gt;It would be powerful to see AI Studio offer a “full-stack” export option (for example, a minimal Node.js backend paired with a frontend scaffold) or include a more explicit production-readiness guide. That small addition could significantly reduce the learning curve for developers transitioning from prototype to secure deployment. This experience reinforced how important it is to think about security architecture as early as the prototyping phase when building AI systems.&lt;/p&gt;\n\n&lt;p&gt;Overall, building with Gemini 3 Pro allowed me to address a systemic healthcare issue with tools that did not exist just a few years ago.&lt;/p&gt;",
    "date": "2026-02-27T15:25:28.000Z",
    "url": "https://dev.to/innacampo/when-doctors-are-too-tired-to-think-slow-building-clara-with-gemini-3-pro-hpe"
  },
  {
    "publisherId": "devto",
    "publisherName": "Dev.to",
    "specTitle": "전체",
    "categories": [
      "_all_"
    ],
    "specUrl": "https://dev.to/feed",
    "title": "ConfDroid Puppet Modules - Gitea",
    "partialText": "&lt;h2&gt;\n  \n  \n  ConfDroid Gitea Module – Self-Hosted Git Made Easy with Puppet\n&lt;/h2&gt;\n\n&lt;p&gt;We’re continuing the ConfDroid Puppet modules series with another practical piece of the puzzle! Following the solid foundations from &lt;code&gt;confdroid_puppet&lt;/code&gt; and the reliable database layer in &lt;code&gt;confdroid_postgresql&lt;/code&gt;, we now move to the version control layer.&lt;/p&gt;\n\n&lt;p&gt;Today we’re excited to spotlight &lt;a href=\"https://sourcecode.confdroid.com/confdroid/confdroid_gitea\" rel=\"noopener noreferrer\"&gt;&lt;strong&gt;confdroid_gitea&lt;/strong&gt;&lt;/a&gt; — a clean, secure Puppet module that deploys and manages a standalone Gitea instance: the lightweight, self-hosted Git service loved by teams who want GitHub-like features without the cloud dependency.&lt;/p&gt;\n\n&lt;p&gt;Whether you’re running internal code reviews, hosting private repositories for CI/CD pipelines, or simply need a fast local Git server, this module gets Gitea up and running quickly, consistently, and securely on Rocky Linux 9 (and compatible DNF-based systems) with Puppet 8.&lt;/p&gt;\n\n&lt;h2&gt;\n  \n  \n  What is confdroid_gitea?\n&lt;/h2&gt;\n\n&lt;p&gt;In essence, it’s your all-in-one Puppet class for installing and operating a production-grade &lt;strong&gt;standalone Gitea server&lt;/strong&gt; using official binary releases — no RPM packaging required. The module handles binary download and installation, user and directory setup, configuration generation, systemd service management, firewall rules, SELinux contexts, and integration points for PostgreSQL and Prometheus.&lt;/p&gt;\n\n&lt;p&gt;It follows the same composable, layered ConfDroid philosophy: infrastructure → platform → application services. Once this module is applied, your Gitea instance is ready to host repositories, serve the web UI on port 3000, expose metrics, and connect securely to a PostgreSQL backend.&lt;/p&gt;\n\n&lt;h2&gt;\n  \n  \n  Key Features\n&lt;/h2&gt;\n\n&lt;h3&gt;\n  \n  \n  Core Components (always included)\n&lt;/h3&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Downloads and installs the official Gitea binary (version-controlled via parameter) to &lt;code&gt;/usr/local/bin/gitea&lt;/code&gt;\n&lt;/li&gt;\n&lt;li&gt;Creates a dedicated system user (&lt;code&gt;gitea&lt;/code&gt;) and home directory structure (&lt;code&gt;/var/lib/gitea&lt;/code&gt; for repos, attachments, logs)&lt;/li&gt;\n&lt;li&gt;Manages the main configuration file (&lt;code&gt;/etc/gitea/app.ini&lt;/code&gt;) via templating — fully overridable through parameters and Hiera (if used)&lt;/li&gt;\n&lt;li&gt;Full systemd service lifecycle: creation, enablement, start/stop/restart&lt;/li&gt;\n&lt;li&gt;Firewall rule to open the web port (default 3000/tcp) (requires puppetlabs-firewall)&lt;/li&gt;\n&lt;li&gt;SELinux context enforcement on all relevant paths (works in enforcing mode)&lt;/li&gt;\n&lt;li&gt;Built-in Prometheus metrics endpoint (/metrics) for easy monitoring integration&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3&gt;\n  \n  \n  Database Backend Options\n&lt;/h3&gt;\n\n&lt;ul&gt;\n&lt;li&gt;\n&lt;strong&gt;SQLite&lt;/strong&gt; — default, perfect for testing or very small setups&lt;/li&gt;\n&lt;li&gt;\n&lt;strong&gt;PostgreSQL&lt;/strong&gt; — strongly recommended for production; integrates seamlessly with &lt;code&gt;confdroid_postgresql&lt;/code&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Important Note: Standalone Servers Only.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Like the PostgreSQL module, &lt;code&gt;confdroid_gitea&lt;/code&gt; is designed strictly for standalone instances. It does not support clustering, high availability, load balancing across multiple nodes, or any distributed Git setups. For HA environments, pair it with an external reverse proxy, load balancer, and shared storage/replication solution.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;h2&gt;\n  \n  \n  How to Use It\n&lt;/h2&gt;\n\n&lt;p&gt;Lookup &lt;a href=\"https://sourcecode.confdroid.com/confdroid/confdroid_gitea#deployment\" rel=\"noopener noreferrer\"&gt;https://sourcecode.confdroid.com/confdroid/confdroid_gitea#deployment&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;When using Postgres as database backend, this needs to be set up as prerequisite on the database server first, ie. using &lt;code&gt;confdroid_postgresql&lt;/code&gt;.&lt;/p&gt;\n\n&lt;p&gt;Gitea will automatically pick up the database connection details from parameters (DB host, name, user, password) passed via Hiera (if used) or ENC.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Security hardening is automatic:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Strict file ownership (&lt;code&gt;gitea:gitea&lt;/code&gt;)&lt;/li&gt;\n&lt;li&gt;Correct SELinux types (&lt;code&gt;httpd_sys_content_t&lt;/code&gt;, &lt;code&gt;httpd_config_t&lt;/code&gt;, etc.)&lt;/li&gt;\n&lt;li&gt;Firewall restricted to the Gitea port only&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;For HTTPS, use an external reverse proxy (e.g., via HAproxy or Nginx) — the module does not handle TLS termination itself. I am using haproxy myself using &lt;code&gt;confdroid_haproxy&lt;/code&gt;, soon to be published here, which does automatic handling of TLS via &lt;code&gt;Let's encrypt&lt;/code&gt;for all backends.&lt;/p&gt;\n\n&lt;h2&gt;\n  \n  \n  Why Choose confdroid_gitea?\n&lt;/h2&gt;\n\n&lt;p&gt;You get a battle-tested, idempotent Gitea deployment that aligns perfectly with the rest of the ConfDroid stack. No manual binary downloads, no fighting permissions, no forgetting firewall rules — everything is version-controlled, repeatable, and secure by default.&lt;/p&gt;\n\n&lt;p&gt;It’s especially powerful when combined with:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;confdroid_postgresql for reliable, performant storage&lt;/li&gt;\n&lt;li&gt;confdroid_prometheus for scraping Gitea metrics&lt;/li&gt;\n&lt;li&gt;External proxy modules for domain-based access and SSL&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;\n  \n  \n  What’s Coming Next\n&lt;/h2&gt;\n\n&lt;p&gt;We’re actively expanding the ConfDroid ecosystem. Future enhancements for this module may include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;More granular app.ini section overrides&lt;/li&gt;\n&lt;li&gt;Deeper integration with upcoming monitoring and backup modules&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;All additions will remain optional and toggleable to keep the module lean.&lt;/p&gt;\n\n&lt;h2&gt;\n  \n  \n  Ready to Get Started?\n&lt;/h2&gt;\n\n&lt;p&gt;Check out the source:&lt;/p&gt;\n\n&lt;p&gt;DeepWiki documentation: &lt;a href=\"https://deepwiki.com/grizzlycoda/puppet_collection/4.5-confdroid_gitea\" rel=\"noopener noreferrer\"&gt;https://deepwiki.com/grizzlycoda/puppet_collection/4.5-confdroid_gitea&lt;/a&gt;&lt;br&gt;\nRepository: &lt;a href=\"https://sourcecode.confdroid.com/confdroid/confdroid_gitea\" rel=\"noopener noreferrer\"&gt;https://sourcecode.confdroid.com/confdroid/confdroid_gitea&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Add it to your Puppetfile, declare the class, run Puppet — and enjoy your own self-hosted Git service in minutes.&lt;br&gt;\nQuestions, feature requests, or production war stories? Drop them in the &lt;a href=\"https://feedback.confdroid.com/\" rel=\"noopener noreferrer\"&gt;ConfDroid feedback portal&lt;/a&gt;. We love hearing how the collection is being used in the real world.&lt;br&gt;\nLet’s keep building reliable, automated infrastructure — one module at a time! 🚀&lt;br&gt;\nWhat service would you like to see automated next? Let us know below.&lt;/p&gt;\n\n\n\n\n&lt;p&gt;Did you find this post helpful?  You can support me.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.buymeacoffee.com/grizzly_coda\" rel=\"noopener noreferrer\"&gt;&lt;img src=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F2znn4km0i2jib7ru1sm9.png\" alt=\"\" width=\"170\" height=\"37\"&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://hetzner.cloud/?ref=EY14C8Tema9j\" rel=\"noopener noreferrer\"&gt;&lt;img src=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fyab43i0ysz9uwuq267u0.png\" alt=\"Hetzner Referral\" width=\"400\" height=\"37\"&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://confdroid.substack.com/subscribe?params=%5Bobject%20Object%5D\" rel=\"noopener noreferrer\"&gt;&lt;img src=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F9r49xyl05rwkjb52xbqg.png\" alt=\"Substack\" width=\"250\" height=\"30\"&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://feedback.confdroid.com/\" rel=\"noopener noreferrer\"&gt;&lt;img src=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fy7d47hck6vziak35nfgf.png\" alt=\"ConfDroid Feedback Portal\" width=\"300\" height=\"63\"&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;h2&gt;\n  \n  \n  Related posts\n&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://confdroid.com/confdroid-puppet-module-pilot/\" rel=\"noopener noreferrer\"&gt;Confdroid Puppet Modules - Pilot&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://confdroid.com/confdroid-puppet-module-puppet/\" rel=\"noopener noreferrer\"&gt;Confdroid Puppet Modules - Puppet&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://confdroid.com/confdroid-puppet-module-resources/\" rel=\"noopener noreferrer\"&gt;ConfDroid Puppet Modules - confdroid_resources&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://confdroid.com/confdroid-puppet-module-postgresql/\" rel=\"noopener noreferrer\"&gt;ConfDroid Puppet Modules - Postgresql&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;",
    "date": "2026-02-27T15:24:47.000Z",
    "url": "https://dev.to/12ww1160/confdroid-puppet-modules-gitea-1ejn"
  },
  {
    "publisherId": "devto",
    "publisherName": "Dev.to",
    "specTitle": "전체",
    "categories": [
      "_all_"
    ],
    "specUrl": "https://dev.to/feed",
    "title": "FB2Combiner",
    "partialText": "&lt;p&gt;Listen, yesterday I went down a little rabbit hole with &lt;strong&gt;FB2Combiner (app)&lt;/strong&gt; and figured I’d share, because it was one of those “this should take five minutes” things that turned into an hour of poking around macOS security.&lt;/p&gt;\n\n&lt;p&gt;The short version: it wouldn’t open. Classic macOS message — &lt;em&gt;“FB2Combiner is damaged and can’t be opened. You should move it to the Trash.”&lt;/em&gt; Which is always slightly dramatic.&lt;/p&gt;\n\n&lt;p&gt;What I did first (and what didn’t work)&lt;/p&gt;\n\n&lt;p&gt;At first I assumed the download was corrupted. So I deleted it, re-downloaded it, tried again. Same message. Then I did the usual right-click → Open trick to bypass the simple Gatekeeper warning. Nope. Same “damaged” dialog. That’s when I started thinking this wasn’t actually about corruption.&lt;/p&gt;\n\n&lt;p&gt;I even ran:&lt;br&gt;\n&lt;/p&gt;\n\n&lt;div class=\"highlight js-code-highlight\"&gt;\n&lt;pre class=\"highlight plaintext\"&gt;&lt;code&gt;xattr -d com.apple.quarantine /Applications/FB2Combiner.app\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;/div&gt;\n\n\n\n&lt;p&gt;because sometimes it’s just the quarantine flag. Still didn’t launch. So clearly not just that.&lt;/p&gt;\n\n&lt;p&gt;What I eventually realized&lt;/p&gt;\n\n&lt;p&gt;The “damaged” message on macOS often doesn’t literally mean the app is broken. A lot of the time it’s Gatekeeper blocking an app that isn’t notarized or signed the way Apple expects. And macOS sometimes phrases that block as “damaged,” which is… not the most helpful wording.&lt;/p&gt;\n\n&lt;p&gt;Apple explains how Gatekeeper works here:&lt;br&gt;\n&lt;a href=\"https://support.apple.com/en-us/102445\" rel=\"noopener noreferrer\"&gt;https://support.apple.com/en-us/102445&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And if you want the deeper technical explanation, their developer doc on notarization is here:&lt;br&gt;\n&lt;a href=\"https://developer.apple.com/documentation/security/notarizing_macos_software_before_distribution\" rel=\"noopener noreferrer\"&gt;https://developer.apple.com/documentation/security/notarizing_macos_software_before_distribution&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Basically, if the app isn’t notarized (or macOS can’t verify it), the system may refuse to launch it outright.&lt;/p&gt;\n\n&lt;p&gt;What actually helped&lt;/p&gt;\n\n&lt;p&gt;Here’s what finally worked for me.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I went to &lt;strong&gt;System Settings → Privacy &amp;amp; Security&lt;/strong&gt;.&lt;/li&gt;\n&lt;li&gt;Scrolled down after attempting to open the app.&lt;/li&gt;\n&lt;li&gt;There was a message saying FB2Combiner was blocked.&lt;/li&gt;\n&lt;li&gt;Clicked &lt;strong&gt;“Open Anyway.”&lt;/strong&gt;\n&lt;/li&gt;\n&lt;li&gt;Confirmed in the next dialog.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;After that, it launched normally.&lt;/p&gt;\n\n&lt;p&gt;The key detail is that you have to &lt;em&gt;attempt to open the app first&lt;/em&gt;, let it fail, and then immediately go to Privacy &amp;amp; Security. The “Open Anyway” option only appears for a short time after the failed launch attempt.&lt;/p&gt;\n\n&lt;p&gt;In my case, the app itself was fine. It was just macOS refusing to trust it automatically.&lt;/p&gt;\n\n&lt;p&gt;Why this happens with smaller utilities&lt;/p&gt;\n\n&lt;p&gt;FB2Combiner isn’t a big App Store product; it’s more of a niche utility for merging FB2 ebook files into one combined file. Tools like this are often distributed outside the Mac App Store, which means they don’t always go through Apple’s notarization pipeline.&lt;/p&gt;\n\n&lt;p&gt;If an app &lt;em&gt;is&lt;/em&gt; distributed via the App Store, macOS doesn’t complain because Apple has already verified it. For comparison, here’s the general App Store entry point:&lt;br&gt;\n&lt;a href=\"https://apps.apple.com/\" rel=\"noopener noreferrer\"&gt;https://apps.apple.com/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If FB2Combiner were there, this whole thing probably wouldn’t have happened. But a lot of indie tools live outside that ecosystem.&lt;/p&gt;\n\n&lt;p&gt;One more thing I checked&lt;/p&gt;\n\n&lt;p&gt;I wanted to make sure it wasn’t an architecture issue (like trying to run an Intel-only binary on Apple Silicon with a weird build). So I quickly checked the app with:&lt;br&gt;\n&lt;/p&gt;\n\n&lt;div class=\"highlight js-code-highlight\"&gt;\n&lt;pre class=\"highlight plaintext\"&gt;&lt;code&gt;file /Applications/FB2Combiner.app/Contents/MacOS/FB2Combiner\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;/div&gt;\n\n\n\n&lt;p&gt;Just to confirm it wasn’t some ancient 32-bit build. It wasn’t. Modern macOS won’t even run 32-bit apps anymore, so that would’ve been a dead end.&lt;/p&gt;\n\n&lt;p&gt;Also worth noting: if you see “can’t be opened because Apple cannot check it for malicious software,” that’s slightly different wording, but it’s the same underlying mechanism — Gatekeeper.&lt;/p&gt;\n\n&lt;p&gt;I found this page useful while digging through the details and comparing behaviors:&lt;br&gt;\n&lt;a href=\"https://bandcinstallersgroup.com/developer/19246-fb2combiner.html\" rel=\"noopener noreferrer\"&gt;https://bandcinstallersgroup.com/developer/19246-fb2combiner.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It didn’t magically fix things, but it helped confirm that other people were seeing the same behavior and that the app itself wasn’t fundamentally broken.&lt;/p&gt;\n\n&lt;p&gt;Important distinction: “damaged” vs actually damaged&lt;/p&gt;\n\n&lt;p&gt;If the app were truly corrupted, you’d usually see it fail even after removing the quarantine attribute or using “Open Anyway.” It might crash instantly, or macOS would refuse to execute it with a different kind of error (like a missing executable or invalid code signature).&lt;/p&gt;\n\n&lt;p&gt;In my case, once I explicitly allowed it in Privacy &amp;amp; Security, it ran perfectly. Combined a few FB2 files without issues.&lt;/p&gt;\n\n&lt;p&gt;So the problem wasn’t the binary — it was macOS enforcing its security policy.&lt;/p&gt;\n\n&lt;p&gt;On newer macOS versions&lt;/p&gt;\n\n&lt;p&gt;Apple has been steadily tightening this behavior. Each major release makes it slightly more annoying to run unsigned software. That’s good from a security standpoint, but slightly frustrating when you’re just trying to use a harmless niche utility.&lt;/p&gt;\n\n&lt;p&gt;If “Open Anyway” doesn’t appear, sometimes the workaround is:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Try launching from Finder (not from Spotlight or Launchpad).&lt;/li&gt;\n&lt;li&gt;Make sure the app is in /Applications.&lt;/li&gt;\n&lt;li&gt;Attempt to open it once to trigger the block.&lt;/li&gt;\n&lt;li&gt;Immediately check Privacy &amp;amp; Security.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Occasionally you also need to temporarily disable Gatekeeper via Terminal (&lt;code&gt;spctl --master-disable&lt;/code&gt;), but honestly I’d avoid that unless absolutely necessary. It’s overkill for something like this.&lt;/p&gt;\n\n&lt;p&gt;What I’ll do differently next time&lt;/p&gt;\n\n&lt;p&gt;Honestly, I wasted time assuming the file was broken. Next time I see the word “damaged” on macOS, I’ll interpret it as “security policy conflict” first, not literal corruption.&lt;/p&gt;\n\n&lt;p&gt;Quick checklist for future me (and you)&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Try right-click → Open first.&lt;/li&gt;\n&lt;li&gt;If blocked, go straight to System Settings → Privacy &amp;amp; Security.&lt;/li&gt;\n&lt;li&gt;Look for “Open Anyway.”&lt;/li&gt;\n&lt;li&gt;Only mess with &lt;code&gt;xattr&lt;/code&gt; if that doesn’t work.&lt;/li&gt;\n&lt;li&gt;Avoid disabling Gatekeeper system-wide unless there’s no alternative.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;After that, FB2Combiner worked fine. No crashes, no weird behavior, no file permission issues. Just macOS being cautious.&lt;/p&gt;\n\n&lt;p&gt;Anyway, figured I’d share in case you ever hit the same thing. It’s one of those small, annoying Mac moments that feels bigger than it is — and once you know what’s really happening, it’s pretty straightforward.&lt;/p&gt;",
    "date": "2026-02-27T15:24:27.000Z",
    "url": "https://dev.to/tyropon/fb2combiner-3365"
  },
  {
    "publisherId": "devto",
    "publisherName": "Dev.to",
    "specTitle": "전체",
    "categories": [
      "_all_"
    ],
    "specUrl": "https://dev.to/feed",
    "title": "Supporting a Birding Community",
    "partialText": "&lt;p&gt;Niche communities exist and they are always looking for new ways to utilize the data they have at hand to improve or enhance the other services out there. Bird watching has always been a hobby of mine and I grew up with my dad taking me on trips to Ontario's Pointe Pelee National Park every May for the spring migration. &lt;/p&gt;\n\n&lt;p&gt;Over the years the use of digital has improved this conservation practice with the introduction of tools like eBird and Merlin. There are a few edge cases out there where local communities want to track rare birds, share sightings and make it more accessible. I decided to see what I could do and my first take at using Claude Code. Over a weeks time I created a fully functional app that allows users to track sightings utilizing eBird data and then also create custom tracking locations with which individuals can share with other birders easily. &lt;/p&gt;\n\n&lt;p&gt;Entirely built using Claude Code, only needing a little bit of knowledge to setup Vercel and some Postgres DB setup. The rest was a blast.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://bird-tracker-seven.vercel.app/\" rel=\"noopener noreferrer\"&gt;Rare Bird Tracker&lt;/a&gt;&lt;/p&gt;",
    "date": "2026-02-27T15:24:07.000Z",
    "url": "https://dev.to/jason_law_bcc3bee50ff3e69/supporting-a-birding-community-2kle"
  },
  {
    "publisherId": "devto",
    "publisherName": "Dev.to",
    "specTitle": "전체",
    "categories": [
      "_all_"
    ],
    "specUrl": "https://dev.to/feed",
    "title": "Build a Viral Hook Generator using YouTube Transcripts & OpenAI",
    "partialText": "&lt;p&gt;The first 15 seconds of a YouTube video dictate its success. If the \"hook\" fails, the viewer clicks away, retention plummets, and the algorithm buries the video.&lt;/p&gt;\n\n&lt;p&gt;What if you could analyze the exact words top creators use in their first 15 seconds, and use AI to generate similar hooks for your own niche?&lt;/p&gt;\n\n&lt;p&gt;In this tutorial, we'll build a Python script that:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Fetches a viral YouTube video.&lt;/li&gt;\n&lt;li&gt;Extracts the transcript (subtitles).&lt;/li&gt;\n&lt;li&gt;Isolates the first 15 seconds of spoken text (the Hook).&lt;/li&gt;\n&lt;li&gt;Uses OpenAI (ChatGPT) to reverse-engineer the psychology of the hook and generate new ones for your topic.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;h2&gt;\n  \n  \n  The Tech Stack\n&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Python 3&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;\n&lt;strong&gt;&lt;a href=\"https://sociavault.com\" rel=\"noopener noreferrer\"&gt;SociaVault API&lt;/a&gt;&lt;/strong&gt; (to fetch YouTube transcripts without dealing with headless browsers or CAPTCHAs)&lt;/li&gt;\n&lt;li&gt;\n&lt;strong&gt;OpenAI API&lt;/strong&gt; (to analyze and generate text)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;\n  \n  \n  Step 1: Setup\n&lt;/h2&gt;\n\n&lt;p&gt;Install the required libraries:&lt;br&gt;\n&lt;/p&gt;\n\n&lt;div class=\"highlight js-code-highlight\"&gt;\n&lt;pre class=\"highlight shell\"&gt;&lt;code&gt;pip &lt;span class=\"nb\"&gt;install &lt;/span&gt;requests openai python-dotenv\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;/div&gt;\n\n\n\n&lt;p&gt;Create a &lt;code&gt;.env&lt;/code&gt; file:&lt;br&gt;\n&lt;/p&gt;\n\n&lt;div class=\"highlight js-code-highlight\"&gt;\n&lt;pre class=\"highlight plaintext\"&gt;&lt;code&gt;SOCIAVAULT_API_KEY=your_sociavault_key\nOPENAI_API_KEY=your_openai_key\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;/div&gt;\n\n\n\n&lt;h2&gt;\n  \n  \n  Step 2: Fetching the Transcript\n&lt;/h2&gt;\n\n&lt;p&gt;YouTube's official API makes getting transcripts incredibly difficult. We'll use SociaVault's YouTube Transcript endpoint, which returns a clean JSON array of text and timestamps.&lt;br&gt;\n&lt;/p&gt;\n\n&lt;div class=\"highlight js-code-highlight\"&gt;\n&lt;pre class=\"highlight python\"&gt;&lt;code&gt;&lt;span class=\"kn\"&gt;import&lt;/span&gt; &lt;span class=\"n\"&gt;os&lt;/span&gt;\n&lt;span class=\"kn\"&gt;import&lt;/span&gt; &lt;span class=\"n\"&gt;requests&lt;/span&gt;\n&lt;span class=\"kn\"&gt;from&lt;/span&gt; &lt;span class=\"n\"&gt;openai&lt;/span&gt; &lt;span class=\"kn\"&gt;import&lt;/span&gt; &lt;span class=\"n\"&gt;OpenAI&lt;/span&gt;\n&lt;span class=\"kn\"&gt;from&lt;/span&gt; &lt;span class=\"n\"&gt;dotenv&lt;/span&gt; &lt;span class=\"kn\"&gt;import&lt;/span&gt; &lt;span class=\"n\"&gt;load_dotenv&lt;/span&gt;\n\n&lt;span class=\"nf\"&gt;load_dotenv&lt;/span&gt;&lt;span class=\"p\"&gt;()&lt;/span&gt;\n\n&lt;span class=\"n\"&gt;SOCIAVAULT_KEY&lt;/span&gt; &lt;span class=\"o\"&gt;=&lt;/span&gt; &lt;span class=\"n\"&gt;os&lt;/span&gt;&lt;span class=\"p\"&gt;.&lt;/span&gt;&lt;span class=\"nf\"&gt;getenv&lt;/span&gt;&lt;span class=\"p\"&gt;(&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"s\"&gt;SOCIAVAULT_API_KEY&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"p\"&gt;)&lt;/span&gt;\n&lt;span class=\"n\"&gt;OPENAI_KEY&lt;/span&gt; &lt;span class=\"o\"&gt;=&lt;/span&gt; &lt;span class=\"n\"&gt;os&lt;/span&gt;&lt;span class=\"p\"&gt;.&lt;/span&gt;&lt;span class=\"nf\"&gt;getenv&lt;/span&gt;&lt;span class=\"p\"&gt;(&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"s\"&gt;OPENAI_API_KEY&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"p\"&gt;)&lt;/span&gt;\n\n&lt;span class=\"n\"&gt;client&lt;/span&gt; &lt;span class=\"o\"&gt;=&lt;/span&gt; &lt;span class=\"nc\"&gt;OpenAI&lt;/span&gt;&lt;span class=\"p\"&gt;(&lt;/span&gt;&lt;span class=\"n\"&gt;api_key&lt;/span&gt;&lt;span class=\"o\"&gt;=&lt;/span&gt;&lt;span class=\"n\"&gt;OPENAI_KEY&lt;/span&gt;&lt;span class=\"p\"&gt;)&lt;/span&gt;\n\n&lt;span class=\"k\"&gt;def&lt;/span&gt; &lt;span class=\"nf\"&gt;get_video_transcript&lt;/span&gt;&lt;span class=\"p\"&gt;(&lt;/span&gt;&lt;span class=\"n\"&gt;video_id&lt;/span&gt;&lt;span class=\"p\"&gt;):&lt;/span&gt;\n    &lt;span class=\"nf\"&gt;print&lt;/span&gt;&lt;span class=\"p\"&gt;(&lt;/span&gt;&lt;span class=\"sa\"&gt;f&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"s\"&gt;Fetching transcript for video: &lt;/span&gt;&lt;span class=\"si\"&gt;{&lt;/span&gt;&lt;span class=\"n\"&gt;video_id&lt;/span&gt;&lt;span class=\"si\"&gt;}&lt;/span&gt;&lt;span class=\"s\"&gt;...&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"p\"&gt;)&lt;/span&gt;\n\n    &lt;span class=\"n\"&gt;url&lt;/span&gt; &lt;span class=\"o\"&gt;=&lt;/span&gt; &lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"s\"&gt;https://api.sociavault.com/v1/youtube/video/transcript&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;\n    &lt;span class=\"n\"&gt;headers&lt;/span&gt; &lt;span class=\"o\"&gt;=&lt;/span&gt; &lt;span class=\"p\"&gt;{&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"s\"&gt;Authorization&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"p\"&gt;:&lt;/span&gt; &lt;span class=\"sa\"&gt;f&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"s\"&gt;Bearer &lt;/span&gt;&lt;span class=\"si\"&gt;{&lt;/span&gt;&lt;span class=\"n\"&gt;SOCIAVAULT_KEY&lt;/span&gt;&lt;span class=\"si\"&gt;}&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"p\"&gt;}&lt;/span&gt;\n\n    &lt;span class=\"n\"&gt;response&lt;/span&gt; &lt;span class=\"o\"&gt;=&lt;/span&gt; &lt;span class=\"n\"&gt;requests&lt;/span&gt;&lt;span class=\"p\"&gt;.&lt;/span&gt;&lt;span class=\"nf\"&gt;get&lt;/span&gt;&lt;span class=\"p\"&gt;(&lt;/span&gt;&lt;span class=\"n\"&gt;url&lt;/span&gt;&lt;span class=\"p\"&gt;,&lt;/span&gt; &lt;span class=\"n\"&gt;headers&lt;/span&gt;&lt;span class=\"o\"&gt;=&lt;/span&gt;&lt;span class=\"n\"&gt;headers&lt;/span&gt;&lt;span class=\"p\"&gt;,&lt;/span&gt; &lt;span class=\"n\"&gt;params&lt;/span&gt;&lt;span class=\"o\"&gt;=&lt;/span&gt;&lt;span class=\"p\"&gt;{&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"s\"&gt;video_id&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"p\"&gt;:&lt;/span&gt; &lt;span class=\"n\"&gt;video_id&lt;/span&gt;&lt;span class=\"p\"&gt;})&lt;/span&gt;\n\n    &lt;span class=\"k\"&gt;if&lt;/span&gt; &lt;span class=\"n\"&gt;response&lt;/span&gt;&lt;span class=\"p\"&gt;.&lt;/span&gt;&lt;span class=\"n\"&gt;status_code&lt;/span&gt; &lt;span class=\"o\"&gt;==&lt;/span&gt; &lt;span class=\"mi\"&gt;200&lt;/span&gt;&lt;span class=\"p\"&gt;:&lt;/span&gt;\n        &lt;span class=\"k\"&gt;return&lt;/span&gt; &lt;span class=\"n\"&gt;response&lt;/span&gt;&lt;span class=\"p\"&gt;.&lt;/span&gt;&lt;span class=\"nf\"&gt;json&lt;/span&gt;&lt;span class=\"p\"&gt;().&lt;/span&gt;&lt;span class=\"nf\"&gt;get&lt;/span&gt;&lt;span class=\"p\"&gt;(&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"s\"&gt;data&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"p\"&gt;,&lt;/span&gt; &lt;span class=\"p\"&gt;[])&lt;/span&gt;\n    &lt;span class=\"k\"&gt;else&lt;/span&gt;&lt;span class=\"p\"&gt;:&lt;/span&gt;\n        &lt;span class=\"k\"&gt;raise&lt;/span&gt; &lt;span class=\"nc\"&gt;Exception&lt;/span&gt;&lt;span class=\"p\"&gt;(&lt;/span&gt;&lt;span class=\"sa\"&gt;f&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"s\"&gt;Failed to fetch transcript: &lt;/span&gt;&lt;span class=\"si\"&gt;{&lt;/span&gt;&lt;span class=\"n\"&gt;response&lt;/span&gt;&lt;span class=\"p\"&gt;.&lt;/span&gt;&lt;span class=\"n\"&gt;text&lt;/span&gt;&lt;span class=\"si\"&gt;}&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"p\"&gt;)&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;/div&gt;\n\n\n\n&lt;h2&gt;\n  \n  \n  Step 3: Isolating the Hook\n&lt;/h2&gt;\n\n&lt;p&gt;The SociaVault API returns data like this:&lt;br&gt;\n&lt;/p&gt;\n\n&lt;div class=\"highlight js-code-highlight\"&gt;\n&lt;pre class=\"highlight json\"&gt;&lt;code&gt;&lt;span class=\"p\"&gt;[&lt;/span&gt;&lt;span class=\"w\"&gt;\n  &lt;/span&gt;&lt;span class=\"p\"&gt;{&lt;/span&gt;&lt;span class=\"nl\"&gt;\"text\"&lt;/span&gt;&lt;span class=\"p\"&gt;:&lt;/span&gt;&lt;span class=\"w\"&gt; &lt;/span&gt;&lt;span class=\"s2\"&gt;\"In 2008, a mysterious programmer...\"&lt;/span&gt;&lt;span class=\"p\"&gt;,&lt;/span&gt;&lt;span class=\"w\"&gt; &lt;/span&gt;&lt;span class=\"nl\"&gt;\"start\"&lt;/span&gt;&lt;span class=\"p\"&gt;:&lt;/span&gt;&lt;span class=\"w\"&gt; &lt;/span&gt;&lt;span class=\"mf\"&gt;0.5&lt;/span&gt;&lt;span class=\"p\"&gt;,&lt;/span&gt;&lt;span class=\"w\"&gt; &lt;/span&gt;&lt;span class=\"nl\"&gt;\"duration\"&lt;/span&gt;&lt;span class=\"p\"&gt;:&lt;/span&gt;&lt;span class=\"w\"&gt; &lt;/span&gt;&lt;span class=\"mf\"&gt;4.2&lt;/span&gt;&lt;span class=\"p\"&gt;},&lt;/span&gt;&lt;span class=\"w\"&gt;\n  &lt;/span&gt;&lt;span class=\"p\"&gt;{&lt;/span&gt;&lt;span class=\"nl\"&gt;\"text\"&lt;/span&gt;&lt;span class=\"p\"&gt;:&lt;/span&gt;&lt;span class=\"w\"&gt; &lt;/span&gt;&lt;span class=\"s2\"&gt;\"changed the financial world forever.\"&lt;/span&gt;&lt;span class=\"p\"&gt;,&lt;/span&gt;&lt;span class=\"w\"&gt; &lt;/span&gt;&lt;span class=\"nl\"&gt;\"start\"&lt;/span&gt;&lt;span class=\"p\"&gt;:&lt;/span&gt;&lt;span class=\"w\"&gt; &lt;/span&gt;&lt;span class=\"mf\"&gt;4.7&lt;/span&gt;&lt;span class=\"p\"&gt;,&lt;/span&gt;&lt;span class=\"w\"&gt; &lt;/span&gt;&lt;span class=\"nl\"&gt;\"duration\"&lt;/span&gt;&lt;span class=\"p\"&gt;:&lt;/span&gt;&lt;span class=\"w\"&gt; &lt;/span&gt;&lt;span class=\"mf\"&gt;3.1&lt;/span&gt;&lt;span class=\"p\"&gt;}&lt;/span&gt;&lt;span class=\"w\"&gt;\n&lt;/span&gt;&lt;span class=\"p\"&gt;]&lt;/span&gt;&lt;span class=\"w\"&gt;\n&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;\n\n&lt;/div&gt;\n\n\n\n&lt;p&gt;We want to extract only the text spoken in the first 15-20 seconds.&lt;br&gt;\n&lt;/p&gt;\n\n&lt;div class=\"highlight js-code-highlight\"&gt;\n&lt;pre class=\"highlight python\"&gt;&lt;code&gt;&lt;span class=\"k\"&gt;def&lt;/span&gt; &lt;span class=\"nf\"&gt;extract_hook&lt;/span&gt;&lt;span class=\"p\"&gt;(&lt;/span&gt;&lt;span class=\"n\"&gt;transcript_data&lt;/span&gt;&lt;span class=\"p\"&gt;,&lt;/span&gt; &lt;span class=\"n\"&gt;max_seconds&lt;/span&gt;&lt;span class=\"o\"&gt;=&lt;/span&gt;&lt;span class=\"mi\"&gt;20&lt;/span&gt;&lt;span class=\"p\"&gt;):&lt;/span&gt;\n    &lt;span class=\"n\"&gt;hook_text&lt;/span&gt; &lt;span class=\"o\"&gt;=&lt;/span&gt; &lt;span class=\"p\"&gt;[]&lt;/span&gt;\n\n    &lt;span class=\"k\"&gt;for&lt;/span&gt; &lt;span class=\"n\"&gt;segment&lt;/span&gt; &lt;span class=\"ow\"&gt;in&lt;/span&gt; &lt;span class=\"n\"&gt;transcript_data&lt;/span&gt;&lt;span class=\"p\"&gt;:&lt;/span&gt;\n        &lt;span class=\"c1\"&gt;# If the segment starts after our max time, stop collecting\n&lt;/span&gt;        &lt;span class=\"k\"&gt;if&lt;/span&gt; &lt;span class=\"n\"&gt;segment&lt;/span&gt;&lt;span class=\"p\"&gt;[&lt;/span&gt;&lt;span class=\"sh\"&gt;'&lt;/span&gt;&lt;span class=\"s\"&gt;start&lt;/span&gt;&lt;span class=\"sh\"&gt;'&lt;/span&gt;&lt;span class=\"p\"&gt;]&lt;/span&gt; &lt;span class=\"o\"&gt;&amp;gt;&lt;/span&gt; &lt;span class=\"n\"&gt;max_seconds&lt;/span&gt;&lt;span class=\"p\"&gt;:&lt;/span&gt;\n            &lt;span class=\"k\"&gt;break&lt;/span&gt;\n        &lt;span class=\"n\"&gt;hook_text&lt;/span&gt;&lt;span class=\"p\"&gt;.&lt;/span&gt;&lt;span class=\"nf\"&gt;append&lt;/span&gt;&lt;span class=\"p\"&gt;(&lt;/span&gt;&lt;span class=\"n\"&gt;segment&lt;/span&gt;&lt;span class=\"p\"&gt;[&lt;/span&gt;&lt;span class=\"sh\"&gt;'&lt;/span&gt;&lt;span class=\"s\"&gt;text&lt;/span&gt;&lt;span class=\"sh\"&gt;'&lt;/span&gt;&lt;span class=\"p\"&gt;])&lt;/span&gt;\n\n    &lt;span class=\"k\"&gt;return&lt;/span&gt; &lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"s\"&gt; &lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"p\"&gt;.&lt;/span&gt;&lt;span class=\"nf\"&gt;join&lt;/span&gt;&lt;span class=\"p\"&gt;(&lt;/span&gt;&lt;span class=\"n\"&gt;hook_text&lt;/span&gt;&lt;span class=\"p\"&gt;).&lt;/span&gt;&lt;span class=\"nf\"&gt;replace&lt;/span&gt;&lt;span class=\"p\"&gt;(&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"se\"&gt;\\n&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"p\"&gt;,&lt;/span&gt; &lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"s\"&gt; &lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"p\"&gt;)&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;/div&gt;\n\n\n\n&lt;h2&gt;\n  \n  \n  Step 4: AI Analysis &amp;amp; Generation\n&lt;/h2&gt;\n\n&lt;p&gt;Now we pass the viral hook to OpenAI. We'll ask the AI to analyze &lt;em&gt;why&lt;/em&gt; the hook works (the psychology, the curiosity gap) and then generate 3 new hooks for our own topic using the same framework.&lt;br&gt;\n&lt;/p&gt;\n\n&lt;div class=\"highlight js-code-highlight\"&gt;\n&lt;pre class=\"highlight python\"&gt;&lt;code&gt;&lt;span class=\"k\"&gt;def&lt;/span&gt; &lt;span class=\"nf\"&gt;generate_new_hooks&lt;/span&gt;&lt;span class=\"p\"&gt;(&lt;/span&gt;&lt;span class=\"n\"&gt;viral_hook&lt;/span&gt;&lt;span class=\"p\"&gt;,&lt;/span&gt; &lt;span class=\"n\"&gt;my_topic&lt;/span&gt;&lt;span class=\"p\"&gt;):&lt;/span&gt;\n    &lt;span class=\"nf\"&gt;print&lt;/span&gt;&lt;span class=\"p\"&gt;(&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"se\"&gt;\\n&lt;/span&gt;&lt;span class=\"s\"&gt;Analyzing hook with AI...&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"p\"&gt;)&lt;/span&gt;\n\n    &lt;span class=\"n\"&gt;prompt&lt;/span&gt; &lt;span class=\"o\"&gt;=&lt;/span&gt; &lt;span class=\"sa\"&gt;f&lt;/span&gt;&lt;span class=\"sh\"&gt;\"\"\"&lt;/span&gt;&lt;span class=\"s\"&gt;\n    Here is the opening hook (first 20 seconds) of a highly viral YouTube video:\n    &lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"si\"&gt;{&lt;/span&gt;&lt;span class=\"n\"&gt;viral_hook&lt;/span&gt;&lt;span class=\"si\"&gt;}&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"s\"&gt;\n\n    Step 1: Analyze the psychology of this hook. Why does it grab attention? What curiosity gap does it open?\n    Step 2: Using the exact same psychological framework and pacing, write 3 new YouTube hooks for a video about: &lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"si\"&gt;{&lt;/span&gt;&lt;span class=\"n\"&gt;my_topic&lt;/span&gt;&lt;span class=\"si\"&gt;}&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"s\"&gt;.\n\n    Format the output clearly.\n    &lt;/span&gt;&lt;span class=\"sh\"&gt;\"\"\"&lt;/span&gt;\n\n    &lt;span class=\"n\"&gt;response&lt;/span&gt; &lt;span class=\"o\"&gt;=&lt;/span&gt; &lt;span class=\"n\"&gt;client&lt;/span&gt;&lt;span class=\"p\"&gt;.&lt;/span&gt;&lt;span class=\"n\"&gt;chat&lt;/span&gt;&lt;span class=\"p\"&gt;.&lt;/span&gt;&lt;span class=\"n\"&gt;completions&lt;/span&gt;&lt;span class=\"p\"&gt;.&lt;/span&gt;&lt;span class=\"nf\"&gt;create&lt;/span&gt;&lt;span class=\"p\"&gt;(&lt;/span&gt;\n        &lt;span class=\"n\"&gt;model&lt;/span&gt;&lt;span class=\"o\"&gt;=&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"s\"&gt;gpt-4-turbo&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"p\"&gt;,&lt;/span&gt;\n        &lt;span class=\"n\"&gt;messages&lt;/span&gt;&lt;span class=\"o\"&gt;=&lt;/span&gt;&lt;span class=\"p\"&gt;[&lt;/span&gt;\n            &lt;span class=\"p\"&gt;{&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"s\"&gt;role&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"p\"&gt;:&lt;/span&gt; &lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"s\"&gt;system&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"p\"&gt;,&lt;/span&gt; &lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"s\"&gt;content&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"p\"&gt;:&lt;/span&gt; &lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"s\"&gt;You are an expert YouTube retention strategist and scriptwriter.&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"p\"&gt;},&lt;/span&gt;\n            &lt;span class=\"p\"&gt;{&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"s\"&gt;role&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"p\"&gt;:&lt;/span&gt; &lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"s\"&gt;user&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"p\"&gt;,&lt;/span&gt; &lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"s\"&gt;content&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"p\"&gt;:&lt;/span&gt; &lt;span class=\"n\"&gt;prompt&lt;/span&gt;&lt;span class=\"p\"&gt;}&lt;/span&gt;\n        &lt;span class=\"p\"&gt;],&lt;/span&gt;\n        &lt;span class=\"n\"&gt;temperature&lt;/span&gt;&lt;span class=\"o\"&gt;=&lt;/span&gt;&lt;span class=\"mf\"&gt;0.7&lt;/span&gt;\n    &lt;span class=\"p\"&gt;)&lt;/span&gt;\n\n    &lt;span class=\"k\"&gt;return&lt;/span&gt; &lt;span class=\"n\"&gt;response&lt;/span&gt;&lt;span class=\"p\"&gt;.&lt;/span&gt;&lt;span class=\"n\"&gt;choices&lt;/span&gt;&lt;span class=\"p\"&gt;[&lt;/span&gt;&lt;span class=\"mi\"&gt;0&lt;/span&gt;&lt;span class=\"p\"&gt;].&lt;/span&gt;&lt;span class=\"n\"&gt;message&lt;/span&gt;&lt;span class=\"p\"&gt;.&lt;/span&gt;&lt;span class=\"n\"&gt;content&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;/div&gt;\n\n\n\n&lt;h2&gt;\n  \n  \n  Step 5: Running the Generator\n&lt;/h2&gt;\n\n&lt;p&gt;Let's test it. We'll use a viral MrBeast or documentary-style video ID, and ask it to generate hooks for a video about \"Learning to Code in 2026\".&lt;br&gt;\n&lt;/p&gt;\n\n&lt;div class=\"highlight js-code-highlight\"&gt;\n&lt;pre class=\"highlight python\"&gt;&lt;code&gt;&lt;span class=\"k\"&gt;def&lt;/span&gt; &lt;span class=\"nf\"&gt;main&lt;/span&gt;&lt;span class=\"p\"&gt;():&lt;/span&gt;\n    &lt;span class=\"c1\"&gt;# Example: A viral tech/documentary video ID\n&lt;/span&gt;    &lt;span class=\"n\"&gt;target_video_id&lt;/span&gt; &lt;span class=\"o\"&gt;=&lt;/span&gt; &lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"s\"&gt;dQw4w9WgXcQ&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt; &lt;span class=\"c1\"&gt;# Replace with a real viral video ID\n&lt;/span&gt;    &lt;span class=\"n\"&gt;my_video_topic&lt;/span&gt; &lt;span class=\"o\"&gt;=&lt;/span&gt; &lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"s\"&gt;How to learn Python fast in 2026&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;\n\n    &lt;span class=\"k\"&gt;try&lt;/span&gt;&lt;span class=\"p\"&gt;:&lt;/span&gt;\n        &lt;span class=\"c1\"&gt;# 1. Get transcript\n&lt;/span&gt;        &lt;span class=\"n\"&gt;transcript&lt;/span&gt; &lt;span class=\"o\"&gt;=&lt;/span&gt; &lt;span class=\"nf\"&gt;get_video_transcript&lt;/span&gt;&lt;span class=\"p\"&gt;(&lt;/span&gt;&lt;span class=\"n\"&gt;target_video_id&lt;/span&gt;&lt;span class=\"p\"&gt;)&lt;/span&gt;\n\n        &lt;span class=\"c1\"&gt;# 2. Extract the hook\n&lt;/span&gt;        &lt;span class=\"n\"&gt;viral_hook&lt;/span&gt; &lt;span class=\"o\"&gt;=&lt;/span&gt; &lt;span class=\"nf\"&gt;extract_hook&lt;/span&gt;&lt;span class=\"p\"&gt;(&lt;/span&gt;&lt;span class=\"n\"&gt;transcript&lt;/span&gt;&lt;span class=\"p\"&gt;,&lt;/span&gt; &lt;span class=\"n\"&gt;max_seconds&lt;/span&gt;&lt;span class=\"o\"&gt;=&lt;/span&gt;&lt;span class=\"mi\"&gt;20&lt;/span&gt;&lt;span class=\"p\"&gt;)&lt;/span&gt;\n        &lt;span class=\"nf\"&gt;print&lt;/span&gt;&lt;span class=\"p\"&gt;(&lt;/span&gt;&lt;span class=\"sa\"&gt;f&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"se\"&gt;\\n&lt;/span&gt;&lt;span class=\"s\"&gt;Extracted Viral Hook:&lt;/span&gt;&lt;span class=\"se\"&gt;\\n\\\"&lt;/span&gt;&lt;span class=\"si\"&gt;{&lt;/span&gt;&lt;span class=\"n\"&gt;viral_hook&lt;/span&gt;&lt;span class=\"si\"&gt;}&lt;/span&gt;&lt;span class=\"se\"&gt;\\\"&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"p\"&gt;)&lt;/span&gt;\n\n        &lt;span class=\"c1\"&gt;# 3. Generate new hooks\n&lt;/span&gt;        &lt;span class=\"n\"&gt;results&lt;/span&gt; &lt;span class=\"o\"&gt;=&lt;/span&gt; &lt;span class=\"nf\"&gt;generate_new_hooks&lt;/span&gt;&lt;span class=\"p\"&gt;(&lt;/span&gt;&lt;span class=\"n\"&gt;viral_hook&lt;/span&gt;&lt;span class=\"p\"&gt;,&lt;/span&gt; &lt;span class=\"n\"&gt;my_video_topic&lt;/span&gt;&lt;span class=\"p\"&gt;)&lt;/span&gt;\n\n        &lt;span class=\"nf\"&gt;print&lt;/span&gt;&lt;span class=\"p\"&gt;(&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"se\"&gt;\\n&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt; &lt;span class=\"o\"&gt;+&lt;/span&gt; &lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"s\"&gt;=&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"o\"&gt;*&lt;/span&gt;&lt;span class=\"mi\"&gt;50&lt;/span&gt;&lt;span class=\"p\"&gt;)&lt;/span&gt;\n        &lt;span class=\"nf\"&gt;print&lt;/span&gt;&lt;span class=\"p\"&gt;(&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"s\"&gt;AI GENERATED RESULTS&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"p\"&gt;)&lt;/span&gt;\n        &lt;span class=\"nf\"&gt;print&lt;/span&gt;&lt;span class=\"p\"&gt;(&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"s\"&gt;=&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"o\"&gt;*&lt;/span&gt;&lt;span class=\"mi\"&gt;50&lt;/span&gt;&lt;span class=\"p\"&gt;)&lt;/span&gt;\n        &lt;span class=\"nf\"&gt;print&lt;/span&gt;&lt;span class=\"p\"&gt;(&lt;/span&gt;&lt;span class=\"n\"&gt;results&lt;/span&gt;&lt;span class=\"p\"&gt;)&lt;/span&gt;\n\n    &lt;span class=\"k\"&gt;except&lt;/span&gt; &lt;span class=\"nb\"&gt;Exception&lt;/span&gt; &lt;span class=\"k\"&gt;as&lt;/span&gt; &lt;span class=\"n\"&gt;e&lt;/span&gt;&lt;span class=\"p\"&gt;:&lt;/span&gt;\n        &lt;span class=\"nf\"&gt;print&lt;/span&gt;&lt;span class=\"p\"&gt;(&lt;/span&gt;&lt;span class=\"sa\"&gt;f&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"s\"&gt;Error: &lt;/span&gt;&lt;span class=\"si\"&gt;{&lt;/span&gt;&lt;span class=\"n\"&gt;e&lt;/span&gt;&lt;span class=\"si\"&gt;}&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"p\"&gt;)&lt;/span&gt;\n\n&lt;span class=\"k\"&gt;if&lt;/span&gt; &lt;span class=\"n\"&gt;__name__&lt;/span&gt; &lt;span class=\"o\"&gt;==&lt;/span&gt; &lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"s\"&gt;__main__&lt;/span&gt;&lt;span class=\"sh\"&gt;\"&lt;/span&gt;&lt;span class=\"p\"&gt;:&lt;/span&gt;\n    &lt;span class=\"nf\"&gt;main&lt;/span&gt;&lt;span class=\"p\"&gt;()&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;/div&gt;\n\n\n\n&lt;h2&gt;\n  \n  \n  The Output\n&lt;/h2&gt;\n\n&lt;p&gt;The AI will output something like:&lt;br&gt;\n&lt;/p&gt;\n\n&lt;div class=\"highlight js-code-highlight\"&gt;\n&lt;pre class=\"highlight plaintext\"&gt;&lt;code&gt;Extracted Viral Hook:\n\"I spent 100 days locked in a room with nothing but a laptop. And what I discovered about human psychology completely terrified me.\"\n\n==================================================\nAI GENERATED RESULTS\n==================================================\nAnalysis:\nThis hook uses the \"Extreme Commitment\" framework combined with a \"Negative Discovery\" curiosity gap. It establishes immediate authority (100 days) and promises a shocking revelation (terrified me).\n\nNew Hooks for \"How to learn Python fast in 2026\":\n\nHook 1: \"I spent 30 days analyzing the code of the top 1% of software engineers. And the secret they use to learn new languages completely broke my understanding of programming.\"\n\nHook 2: \"I locked myself in my office for a week to learn Python from scratch. And the shortcut I discovered makes traditional coding bootcamps look like a complete scam.\"\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;/div&gt;\n\n\n\n&lt;h2&gt;\n  \n  \n  Why This is a Game Changer\n&lt;/h2&gt;\n\n&lt;p&gt;Instead of guessing what makes a good intro, you are programmatically scraping proven, data-backed hooks and applying their underlying frameworks to your own content.&lt;/p&gt;\n\n&lt;p&gt;By using &lt;strong&gt;&lt;a href=\"https://sociavault.com\" rel=\"noopener noreferrer\"&gt;SociaVault&lt;/a&gt;&lt;/strong&gt;, you bypass the nightmare of YouTube's official API quotas and transcript scraping blocks. You get clean data, instantly.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;&lt;a href=\"https://sociavault.com\" rel=\"noopener noreferrer\"&gt;Get your free API key at SociaVault.com&lt;/a&gt; and start reverse-engineering virality today.&lt;/strong&gt;&lt;/p&gt;",
    "date": "2026-02-27T15:24:00.000Z",
    "url": "https://dev.to/olams/build-a-viral-hook-generator-using-youtube-transcripts-openai-42f0"
  },
  {
    "publisherId": "devto",
    "publisherName": "Dev.to",
    "specTitle": "전체",
    "categories": [
      "_all_"
    ],
    "specUrl": "https://dev.to/feed",
    "title": "AI-Friendly Bug Reports: An Issue Template That Actually Works",
    "partialText": "&lt;p&gt;A lot of “bug reports” are really &lt;em&gt;feelings&lt;/em&gt;:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;“Sometimes it crashes.”&lt;/li&gt;\n&lt;li&gt;“Login is broken.”&lt;/li&gt;\n&lt;li&gt;“It’s slow.”&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Humans can often debug those anyway (by asking follow-up questions in chat). But if you want fast, reliable help from a teammate, an on-call rotation, or a coding assistant, you need something closer to a &lt;strong&gt;reproducible experiment&lt;/strong&gt; than a complaint.&lt;/p&gt;\n\n&lt;p&gt;In this post I’ll show you an issue template that produces bug reports your future self can actually work with. It’s optimized for clarity, reproduction, and safe sharing.&lt;/p&gt;\n\n\n\n\n&lt;h2&gt;\n  \n  \n  The three failure modes of bad bug reports\n&lt;/h2&gt;\n\n&lt;p&gt;Most low-quality issues fail in one of these ways:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;\n&lt;strong&gt;Ambiguous contract&lt;/strong&gt;: it’s unclear what “correct” behavior is.&lt;/li&gt;\n&lt;li&gt;\n&lt;strong&gt;Non-reproducible&lt;/strong&gt;: no steps, no data, no environment.&lt;/li&gt;\n&lt;li&gt;\n&lt;strong&gt;Missing boundaries&lt;/strong&gt;: the report includes everything &lt;em&gt;except&lt;/em&gt; what matters (or it contains secrets you can’t share).&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;A good template fixes all three by forcing the reporter to answer a small set of questions &lt;em&gt;up front&lt;/em&gt;.&lt;/p&gt;\n\n\n\n\n&lt;h2&gt;\n  \n  \n  The goal: reduce uncertainty, not add text\n&lt;/h2&gt;\n\n&lt;p&gt;A common misconception is that “good bug reports are long.”&lt;/p&gt;\n\n&lt;p&gt;Good bug reports are &lt;strong&gt;precise&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;They can be short if they include the right variables:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;what you expected&lt;/li&gt;\n&lt;li&gt;what happened instead&lt;/li&gt;\n&lt;li&gt;how to reproduce&lt;/li&gt;\n&lt;li&gt;in which environment&lt;/li&gt;\n&lt;li&gt;with what inputs&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Think of each field as a knob you’re setting so someone else can recreate your world.&lt;/p&gt;\n\n\n\n\n&lt;h2&gt;\n  \n  \n  Copy/paste: an AI-friendly (and human-friendly) bug report template\n&lt;/h2&gt;\n\n&lt;p&gt;Drop this into GitHub Issues (or your tracker of choice) and adjust as needed.&lt;br&gt;\n&lt;/p&gt;\n\n&lt;div class=\"highlight js-code-highlight\"&gt;\n&lt;pre class=\"highlight markdown\"&gt;&lt;code&gt;&lt;span class=\"gu\"&gt;## Summary&lt;/span&gt;\n&lt;span class=\"c\"&gt;&amp;lt;!-- One sentence. What’s broken? --&amp;gt;&lt;/span&gt;\n\n&lt;span class=\"gu\"&gt;## Expected vs Actual&lt;/span&gt;\n&lt;span class=\"gs\"&gt;**Expected:**&lt;/span&gt;\n\n&lt;span class=\"gs\"&gt;**Actual:**&lt;/span&gt;\n\n&lt;span class=\"gu\"&gt;## Reproduction steps&lt;/span&gt;\n&lt;span class=\"p\"&gt;1.&lt;/span&gt;\n&lt;span class=\"p\"&gt;2.&lt;/span&gt;\n&lt;span class=\"p\"&gt;3.&lt;/span&gt;\n\n&lt;span class=\"gu\"&gt;### Minimal repro (optional but ideal)&lt;/span&gt;\n&lt;span class=\"c\"&gt;&amp;lt;!-- Link a repo, gist, or a short code snippet. --&amp;gt;&lt;/span&gt;\n\n&lt;span class=\"gu\"&gt;## Environment&lt;/span&gt;\n&lt;span class=\"p\"&gt;-&lt;/span&gt; App version / commit:\n&lt;span class=\"p\"&gt;-&lt;/span&gt; Runtime: (Node 20, Python 3.12, JVM 21, etc.)\n&lt;span class=\"p\"&gt;-&lt;/span&gt; OS: (macOS 14.3, Ubuntu 22.04, Windows 11)\n&lt;span class=\"p\"&gt;-&lt;/span&gt; Deployment: (local / staging / prod)\n&lt;span class=\"p\"&gt;-&lt;/span&gt; Browser (if relevant):\n\n&lt;span class=\"gu\"&gt;## Inputs / data&lt;/span&gt;\n&lt;span class=\"c\"&gt;&amp;lt;!-- Smallest input that triggers the bug. Redact secrets. --&amp;gt;&lt;/span&gt;\n\n&lt;span class=\"gu\"&gt;## Logs / screenshots&lt;/span&gt;\n&amp;lt;!-- Paste relevant logs (surround with &lt;span class=\"sb\"&gt;```&lt;/span&gt;\n\n), or attach screenshots. --&amp;gt;\n\n&lt;span class=\"gu\"&gt;## Impact&lt;/span&gt;\n&lt;span class=\"p\"&gt;-&lt;/span&gt; Frequency: (always / often / rare)\n&lt;span class=\"p\"&gt;-&lt;/span&gt; Severity: (blocks release / major / minor)\n&lt;span class=\"p\"&gt;-&lt;/span&gt; Workaround (if any):\n\n&lt;span class=\"gu\"&gt;## Notes / hypotheses (optional)&lt;/span&gt;\n&lt;span class=\"c\"&gt;&amp;lt;!-- What changed recently? Any suspicion? --&amp;gt;&lt;/span&gt;\n\n\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;/div&gt;\n\n&lt;p&gt;Why this works:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;\n&lt;strong&gt;Expected vs Actual&lt;/strong&gt; prevents “it’s broken” issues.&lt;/li&gt;\n&lt;li&gt;\n&lt;strong&gt;Reproduction steps&lt;/strong&gt; makes it an experiment.&lt;/li&gt;\n&lt;li&gt;\n&lt;strong&gt;Environment&lt;/strong&gt; avoids debugging the wrong version.&lt;/li&gt;\n&lt;li&gt;\n&lt;strong&gt;Inputs&lt;/strong&gt; forces the report to become concrete.&lt;/li&gt;\n&lt;li&gt;\n&lt;strong&gt;Impact&lt;/strong&gt; helps triage without a meeting.&lt;/li&gt;\n&lt;/ul&gt;\n\n\n\n\n&lt;h2&gt;\n  \n  \n  Example: “Login is broken” rewritten into something actionable\n&lt;/h2&gt;\n\n&lt;h3&gt;\n  \n  \n  Vague report\n&lt;/h3&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Login is broken in staging.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;h3&gt;\n  \n  \n  Template-filled report\n&lt;/h3&gt;\n\n&lt;p&gt;&lt;strong&gt;Summary&lt;/strong&gt;&lt;br&gt;\nLogin fails for users with 2FA enabled in staging.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Expected:&lt;/strong&gt; After entering correct username/password and TOTP, user lands on &lt;code&gt;/dashboard&lt;/code&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Actual:&lt;/strong&gt; After submitting TOTP, user is redirected back to &lt;code&gt;/login&lt;/code&gt; with &lt;code&gt;Invalid session&lt;/code&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Reproduction steps&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Go to &lt;code&gt;https://staging.example.com/login&lt;/code&gt;\n&lt;/li&gt;\n&lt;li&gt;Log in with a 2FA-enabled account&lt;/li&gt;\n&lt;li&gt;Enter any valid TOTP&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;Environment&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;App version / commit: &lt;code&gt;3c1b7a2&lt;/code&gt;\n&lt;/li&gt;\n&lt;li&gt;Runtime: Node 20.11&lt;/li&gt;\n&lt;li&gt;OS: Ubuntu 22.04 (staging)&lt;/li&gt;\n&lt;li&gt;Browser: Chrome 121&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Logs&lt;/strong&gt;&lt;/p&gt;\n\n&lt;div class=\"highlight js-code-highlight\"&gt;\n&lt;pre class=\"highlight plaintext\"&gt;&lt;code&gt;\ntext\nAuthService: verifyTotp ok userId=...\nSessionService: createSession failed reason=REDIS_TIMEOUT\n\n\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;/div&gt;\n\n&lt;p&gt;In one page, you’ve narrowed the search space from “anything in auth” to “session persistence under staging load.”&lt;/p&gt;\n\n\n\n\n&lt;h2&gt;\n  \n  \n  The “minimum reproducible input” trick\n&lt;/h2&gt;\n\n&lt;p&gt;If you only adopt one habit, make it this: &lt;strong&gt;shrink inputs until the bug still happens&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;Examples:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;A failing JSON payload → remove fields until it still fails.&lt;/li&gt;\n&lt;li&gt;A flaky test → isolate a single test file and a single seed.&lt;/li&gt;\n&lt;li&gt;A UI bug → reduce to one route and one user state.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;This single move turns debugging from detective work into science.&lt;/p&gt;\n\n&lt;p&gt;A practical phrasing you can embed in your template:&lt;/p&gt;\n\n&lt;div class=\"highlight js-code-highlight\"&gt;\n&lt;pre class=\"highlight plaintext\"&gt;&lt;code&gt;\nmd\nProvide the smallest input/config that still reproduces the issue.\nIf you can’t shrink it, explain why.\n\n\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;/div&gt;\n\n\n\n\n&lt;h2&gt;\n  \n  \n  Make it safe to share (so people will actually fill it)\n&lt;/h2&gt;\n\n&lt;p&gt;Templates fail when they demand information people &lt;em&gt;can’t&lt;/em&gt; provide.&lt;/p&gt;\n\n&lt;p&gt;Add explicit safe-sharing guidance:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;“Redact tokens, cookies, and PII.”&lt;/li&gt;\n&lt;li&gt;“If logs contain secrets, paste only the relevant lines and replace values with &lt;code&gt;&amp;lt;REDACTED&amp;gt;&lt;/code&gt;.”&lt;/li&gt;\n&lt;li&gt;“If you can’t share data, describe the &lt;em&gt;shape&lt;/em&gt; of the data.”&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Example:&lt;/p&gt;\n\n&lt;div class=\"highlight js-code-highlight\"&gt;\n&lt;pre class=\"highlight plaintext\"&gt;&lt;code&gt;\nmd\nInput shape: ~500KB JSON, contains 2 arrays (`items`, `discounts`), item count ~2,000.\nBug reproduces only when `discounts[].type = \"tiered\"`.\n\n\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;/div&gt;\n\n\n\n&lt;p&gt;You’ll be surprised how often “data shape” is enough to unlock a fix.&lt;/p&gt;\n\n\n\n\n&lt;h2&gt;\n  \n  \n  Optional upgrade: add a “clarifying questions first” workflow\n&lt;/h2&gt;\n\n&lt;p&gt;When issues are still too fuzzy, don’t jump to solutions. Add a simple rule for triage:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Maintainer (or assistant) asks 5–10 targeted questions.&lt;/li&gt;\n&lt;li&gt;Reporter answers.&lt;/li&gt;\n&lt;li&gt;Only then do you propose a fix or a PR.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;This prevents the classic failure mode: implementing a patch for an imagined problem.&lt;/p&gt;\n\n\n\n\n&lt;h2&gt;\n  \n  \n  Shipping this in a real repo (quick checklist)\n&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Keep the template to &lt;strong&gt;one screen&lt;/strong&gt; (people don’t scroll).&lt;/li&gt;\n&lt;li&gt;Mark most sections as “optional but recommended.”&lt;/li&gt;\n&lt;li&gt;Make &lt;strong&gt;Expected vs Actual&lt;/strong&gt; required.&lt;/li&gt;\n&lt;li&gt;Include one filled-in example in your CONTRIBUTING.md.&lt;/li&gt;\n&lt;li&gt;If you have multiple products, create separate templates (UI bug vs API bug vs performance issue).&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;When your bug reports improve, everything else improves with them:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;faster fixes&lt;/li&gt;\n&lt;li&gt;better collaboration&lt;/li&gt;\n&lt;li&gt;fewer “can you reproduce?” comments&lt;/li&gt;\n&lt;li&gt;more reliable help from tools and teammates&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If you want, take the template above, paste it into your tracker today, and adjust it after the first five issues. That feedback loop is where the real win is.&lt;/p&gt;",
    "date": "2026-02-27T15:23:21.000Z",
    "url": "https://dev.to/novaelvaris/ai-friendly-bug-reports-an-issue-template-that-actually-works-4a2o"
  }
]