[
  {
    "publisherId": "daangn",
    "publisherName": "당근마켓 테크",
    "specTitle": "React Native",
    "categories": [
      "mobile",
      "frontend"
    ],
    "specUrl": "https://medium.com/feed/daangn",
    "title": "서버를 위한 Redux: Node.js 이벤트 소싱 라이브러리 개발기",
    "partialText": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*gIudw1xt0amPdg4bzieFGQ.png\" /></figure><p>안녕하세요. 당근 프론트엔드코어 리더를 맡고 있는 Tony예요. 저희 팀은 70명이 넘는 당근의 프론트엔드 엔지니어분들이 더 편하고 즐겁게 개발할 수 있도록 개발 환경을 다듬는 일을 하고 있어요.</p><p>내부 도구를 만들다보면 감사 처리, 롤백, 알림처럼 요구사항이 점점 더 복잡해지게 되는데요. 최근 이처럼 복잡한 요구사항들을 잘 관리하고자 ‘이벤트 소싱 패턴’을 도입했어요.</p><p>이 글에서는 이 패턴이 만들어진 배경과 함께 더 쉽게 쓰실 수 있도록저희가 직접 만들고 오픈소싱한 라이브러리를 소개하려고해요. 이벤트 소싱이 어쩌면 복잡하고 어려운 개념일 수 있지만, 프론트엔드 엔지니어링을 해보셨다면 쉽게 접할 수 있는 ‘Redux’를 서버로 옮겨놓았다고 생각하면 좀 더 쉽게 몰입하실 수 있을 거예요.</p><p>프론트엔드와 백엔드 엔지니어는 각각 다른 문제를 해결하고 있기에 어쩌면 서로 다른 세상에 살고 있다고 볼 수도 있는데요. 오늘 이 글을 통해 비즈니스 로직에 대하여 프론트엔드와 백엔드 엔지니어가 서로 이야기를 나눌 수 있는 공통점이 생기면 좋겠어요. 그럼 시작하겠습니다.</p><h3>배경</h3><p>먼저 API 서버 엔지니어링에 대해서 이야기 해보도록 할게요. 흔히 API 서버는 DB에 데이터를 저장하고, 동시에 그데이터를 읽고 처리해서 클라이언트에 응답을 주는 역할을 해요.그리고 DB에 데이터를 만들고, 읽고, 수정하고, 지우는 일련의 행위를 CRUD(Create, Read, Update, Delete)라고 부르죠.</p><p>우리가 만들어야하는 기능은 대부분 DB에 대한 CRUD를 통해 간단하게 설계할 수 있을 거예요. 게시판을 예로 들자면, 글을 작성하고, 수정하고, 삭제하고, 불러오는 기능만 있다면DB CRUD 기능으로도 충분히 간단한 구현이 가능할 거예요.</p><p>하지만 만약 CRUD로 표현하기 어려운 개념이 등장하면 어떻게 될까요?예를 들어 같은 게시판이라도 글에 승인이라는 개념이 들어간다면요. 글이 올라온 뒤운영자가 이를 승인하거나 거절할 수 있어야 한다면 이를 어떻게 구현하면 좋을까요? 혹은 수정 기록을 남겨야 한다면어떻게 구현할 수 있을까요?</p><p>전통적인 CRUD 방식에서는 이런 요구사항을 만족하기 위해 추가적인 테이블과 복잡한 로직이 필요해요. 예를 들어:</p><ul><li><strong>승인 기능</strong>: status 컬럼을 추가하고, 승인/거절 시간을 기록하는 컬럼들을 만들고...</li><li><strong>수정 기록</strong>: 별도의 히스토리 테이블을 만들고, 매번 수정할 때마다 이전 데이터를 복사해서 저장하고…</li><li><strong>롤백 기능</strong>: 어떤 상태로 되돌릴지 추적하고, 복잡한 로직으로 데이터를 복원하고…</li></ul><p>이런 기능들을 하나씩 추가하다 보면 코드가 점점 복잡해지고, 유지보수가 어려워지게 됩니다. 더 큰 문제는 이런 방식으로는 “왜 이렇게 되었는가”를 추적하기가 어렵다는 점이에요. 현재 상태만 저장되어 있을 뿐, 그 과정에서 무슨 일이 있었는지는 알 수 없거든요.</p><h3>이벤트 소싱: 모든 변경을 기록하다</h3><p>이벤트 소싱(Event Sourcing)은 이런 문제들을 해결하는 패턴이에요. 핵심 아이디어는 아주 간단해요:</p><blockquote><em>“현재 상태”만 저장하는 대신, “상태를 변경시킨 모든 이벤트”를 저장하자</em></blockquote><p>예를 들어, 게시글의 현재 상태가 “승인됨”이라면, CRUD 방식에서는 status: &quot;approved&quot; 이렇게 저장하겠죠. 하지만 이벤트 소싱에서는 이렇게 저장해요:</p><pre>1. 게시글이 작성됨 (content: &quot;안녕하세요&quot;, author: &quot;Tony&quot;)<br>2. 게시글이 수정됨 (content: &quot;안녕하세요 수정했어요&quot;)<br>3. 게시글이 승인됨 (approver: &quot;관리자&quot;, reason: &quot;적절한 내용&quot;)</pre><p>이렇게 하면 어떤 좋은 점이 있을까요?</p><ul><li><strong>완벽한 감사 로그</strong>: 누가, 언제, 무엇을, 왜 했는지 모두 기록돼요.</li><li><strong>타임머신 기능</strong>: 과거 어느 시점의 상태든 재구성할 수 있어요.</li><li><strong>롤백이 쉬워요</strong>: 특정 시점 이후의 이벤트를 무시하면 되니까요.</li><li><strong>비즈니스 인사이트</strong>: 데이터가 어떻게 변했는지 분석할 수 있어요.</li></ul><h3>Redux를 아시나요?</h3><p>프론트엔드 엔지니어라면 Redux를 들어보셨을 거에요. Redux는 React 애플리케이션의 상태를 관리하는 라이브러리인데요, 사실 Redux가 사용하는 패턴이 바로 이벤트 소싱과 매우 유사해요.</p><p>Redux에서는 이렇게 작동하죠:</p><pre>// 1. Action (이벤트와 유사)<br>dispatch({<br>  type: &#39;user/profileUpdated&#39;,<br>  payload: { bio: &#39;Hello&#39; },<br>});<br><br>// 2. Reducer (상태를 계산)<br>function userReducer(state, action) {<br>  switch (action.type) {<br>    case &#39;user/profileUpdated&#39;:<br>      return { ...state, bio: action.payload.bio };<br>    default:<br>      return state;<br>  }<br>}</pre><p>이벤트 소싱도 같아요:</p><pre>// 1. Event (Action과 유사)<br>dispatch(&#39;user:profile_updated&#39;, { bio: &#39;Hello&#39; });<br><br>// 2. Reducer (상태를 계산)<br>function userReducer(prevState, event) {<br>  switch (event.eventName) {<br>    case &#39;user:profile_updated&#39;:<br>      return { ...prevState, bio: event.body.bio };<br>    default:<br>      return prevState;<br>  }<br>}</pre><p>차이점이 있다면:</p><ul><li><strong>Redux</strong>: 브라우저 메모리에서 상태를 관리</li><li><strong>이벤트 소싱</strong>: 데이터베이스에 영구적으로 이벤트를 저장</li></ul><p>결국 “이벤트를 통해 상태를 관리한다”는 핵심 아이디어는 동일합니다. Redux를 써본 적이 있다면, 이벤트 소싱은 이미 반쯤 이해하신 셈이에요.</p><h3>Ventyd: TypeScript를 위한 이벤트 소싱 라이브러리</h3><p>내부 도구를 개발하면서 이벤트 소싱을 도입하려고 했지만 TypeScript 환경에서 쉽게 사용할 수 있는 라이브러리를 찾기 어려웠어요. 그래서 직접 만들기로 했습니다. 목표는 명확했어요:</p><ol><li><strong>Redux 처럼 친숙하게</strong>: 프론트엔드 엔지니어와 일반적인 Node.js 엔지니어도 쉽게 이해할 수 있도록</li><li><strong>TypeScript 퍼스트</strong>: 타입 안정성을 최우선으로</li><li><strong>유연하게</strong>: 어떤 DB든, 어떤 검증 라이브러리든 사용할 수 있게</li></ol><p>이렇게 해서 만들어진 라이브러리가 <strong>Ventyd예요.</strong></p><h3>간단한 사용 예시</h3><p>User 엔티티를 만드는 과정을 보여드릴게요:</p><h3>1. 스키마 정의</h3><p>먼저 어떤 이벤트가 있고, 어떤 상태를 가질지 정의해요:</p><pre>import { defineSchema } from &#39;ventyd&#39;;<br>import { valibot, v } from &#39;ventyd/valibot&#39;;<br><br>const userSchema = defineSchema(&#39;user&#39;, {<br>  schema: valibot({<br>    event: {<br>      // 사용자가 생성될 때<br>      created: v.object({<br>        nickname: v.string(),<br>        email: v.pipe(v.string(), v.email()),<br>      }),<br><br>      // 프로필이 수정될 때<br>      profile_updated: v.object({<br>        nickname: v.optional(v.string()),<br>        bio: v.optional(v.string()),<br>      }),<br><br>      // 사용자가 삭제될 때<br>      deleted: v.object({<br>        reason: v.optional(v.string()),<br>      }),<br><br>      // 사용자가 복구될 때<br>      restored: v.object({}),<br>    },<br><br>    // 최종 상태의 형태<br>    state: v.object({<br>      nickname: v.string(),<br>      email: v.pipe(v.string(), v.email()),<br>      bio: v.optional(v.string()),<br>      deletedAt: v.nullable(v.optional(v.string())),<br>    }),<br>  }),<br>  initialEventName: &#39;user:created&#39;,<br>});</pre><blockquote>Valibot 대신 Zod, TypeBox, ArkType 등 원하는 검증 라이브러리를 사용할 수 있어요. (<a href=\"https://ventyd.com/docs/schema\">https://ventyd.com/docs/schema</a>)</blockquote><h3>2. Reducer 정의</h3><p>이벤트가 발생했을 때 상태를 어떻게 변경할지 정의해요:</p><pre>import { defineReducer } from &#39;ventyd&#39;;<br><br>const userReducer = defineReducer(userSchema, (prevState, event) =&gt; {<br>  switch (event.eventName) {<br>    case &#39;user:created&#39;:<br>      return {<br>        nickname: event.body.nickname,<br>        email: event.body.email,<br>        bio: undefined,<br>        deletedAt: null,<br>      };<br>    case &#39;user:profile_updated&#39;:<br>      return {<br>        ...prevState,<br>        ...(event.body.nickname &amp;&amp; { nickname: event.body.nickname }),<br>        ...(event.body.bio !== undefined &amp;&amp; { bio: event.body.bio }),<br>      };<br>    case &#39;user:deleted&#39;:<br>      return {<br>        ...prevState,<br>        deletedAt: event.eventCreatedAt,<br>      };<br>    case &#39;user:restored&#39;:<br>      return {<br>        ...prevState,<br>        deletedAt: null,<br>      };<br>    default:<br>      return prevState;<br>  }<br>});</pre><p>Redux의 reducer와 같이 이전 상태와 이벤트를 받아 다음 상태를 계산하는 순수함수를 작성하면 돼요.</p><h3>3. Entity 클래스 정의</h3><p>비즈니스 로직을 담은 클래스를 만들어요:</p><pre>import { Entity, mutation } from &#39;ventyd&#39;;<br><br>class User extends Entity(userSchema, userReducer) {<br>  // 편리한 getter들<br>  get nickname() {<br>    return this.state.nickname;<br>  }<br>  get isDeleted() {<br>    return this.state.deletedAt !== null;<br>  }<br><br>  // 비즈니스 메서드: 프로필 수정<br>  updateProfile = mutation(this, (dispatch, updates: { nickname?: string; bio?: string }) =&gt; {<br>    // 비즈니스 규칙 검증<br>    if (this.isDeleted) {<br>      throw new Error(&#39;삭제된 사용자는 수정할 수 없습니다&#39;);<br>    }<br>    // 이벤트 발행<br>    dispatch(&#39;user:profile_updated&#39;, updates);<br>  })<br><br>  // 비즈니스 메서드: 삭제<br>  delete = mutation(this, (dispatch, reason?: string) =&gt; {<br>    if (this.isDeleted) {<br>      throw new Error(&#39;이미 삭제된 사용자입니다&#39;);<br>    }<br>    dispatch(&#39;user:deleted&#39;, { reason });<br>  })<br><br>  // 비즈니스 메서드: 복구<br>  restore = mutation(this, (dispatch) =&gt; {<br>    if (!this.isDeleted) {<br>      throw new Error(&#39;삭제되지 않은 사용자입니다&#39;);<br>    }<br>    dispatch(&#39;user:restored&#39;, {});<br>  })<br>}</pre><h3>4. Repository 생성</h3><p>코어 비즈니스 로직이 끝났어요. 이제 작성한 비즈니스 로직을 DB와 연동할 수 있는 Repository를 만들어요:</p><pre>import { createRepository, Adapter } from &#39;ventyd&#39;;<br><br>const myAdapter: Adapter = {<br>  // 직접 DB 연결을 구현해요<br>};<br><br>const userRepository = createRepository(User, {<br>  adapter: myAdapter,<br>  plugins: [<br>    // 감사 로그 플러그인<br>    auditLogPlugin,<br>    // 알림 플러그인<br>    notificationPlugin,<br>  ],<br>});</pre><blockquote>Ventyd는 따로 미리 만들어진 어댑터를 제공하지 않아요. 각자가 서버 환경에서 사용하고 계신 DB, ORM으로 직접 구현해서 주입할 수 있도록 일부러 설계되었어요. (<a href=\"https://ventyd.vercel.app/docs/database\">https://ventyd.vercel.app/docs/database</a>)</blockquote><h3>5. 사용하기</h3><pre>// 새 사용자 생성<br>const user = User.create({<br>  body: {<br>    nickname: &#39;Tony&#39;,<br>    email: &#39;tony@example.com&#39;,<br>  },<br>});<br><br>// 프로필 수정<br>user.updateProfile({<br>  bio: &#39;당근 Software Engineer&#39;,<br>});<br><br>// DB에 저장<br>await userRepository.commit(user);<br><br>// 나중에 불러오기<br>const loadedUser = await userRepository.findOne({<br>  entityId: user.entityId,<br>});<br><br>console.log(loadedUser?.nickname); // &#39;Tony&#39;<br>console.log(loadedUser?.bio); // &#39;당근 Software Engineer&#39;</pre><blockquote>💡 만약 <em>entityId</em>가 아닌 다른 필드들로 쿼리가 필요하다면, DB에 인덱싱하는 로직을 어댑터 또는 플러그인으로 직접 구현하시면 돼요. 관련한 내용은 아래 문서를 확인하세요. (<a href=\"https://ventyd.com/docs/querying\">https://ventyd.com/docs/querying</a>)</blockquote><h3>실제로 어떻게 쓰고 있나요?</h3><p>당근에서는 내부 도구들에 Ventyd를 적용하고 있어요. 특히 아래 같은 상황에서 매우 유용하게 사용하고 있는데요. 더 구체적인 상황을 하나씩 설명해 볼게요.</p><h3>예시 1: 프론트엔드 배포 플랫폼</h3><p>당근에서 만드는 프론트엔드 배포 플랫폼에서는 배포 프로세스의 모든 단계를 추적하고 있어요.</p><pre>// 아래 코드는 실제 코드가 아닌 예시입니다<br><br>// 배포가 시작되고<br>deployment.create({<br>  projectId: &#39;my-app&#39;,<br>  branch: &#39;main&#39;,<br>  commit: &#39;a1b2c3d&#39;,<br>});<br><br>// 빌드가 진행되고<br>deployment.startBuild();<br>deployment.completeBuild({ artifactUrl: &#39;s3://...&#39; });<br><br>// 검증을 거치고<br>deployment.runTests();<br>deployment.completeTests({ success: true });<br><br>// 배포되고<br>deployment.deploy({ environment: &#39;production&#39; });<br><br>// 문제가 생기면 롤백<br>deployment.rollback({ reason: &#39;high error rate&#39; });<br><br>// -&gt; 모든 과정이 이벤트로 기록됩니다</pre><p>이렇게 하면 이 배포는 누가, 언제, 어떤 커밋으로 배포했고, 왜 롤백했는지 같은 질문에 바로 답할 수 있어요. 특히 특정 기능이 배포되었을 때슬랙으로 알림을 받는 등 변경사항을 추적하는 코드가 필요할 경우 기존에는 여러 지점에 패치를 해야했지만, 이벤트 소싱 패턴을 사용하면 모든 변경을 한 곳에서 다루기 때문에, 변경 사항을 추적하는 로직도 한곳에 모을 수 있습니다.</p><pre>const myRepository = createRepository(Deployment, {<br>  // ...<br>  plugins: [<br>    // 변경사항이 commit 될때 슬랙 알림을 받아요.<br>    slackPlugin(),<br>  ],<br>});</pre><h3>예시 2: 게임 상태 관리</h3><p>게임 상태를 다루면서도 흥미로운 활용 사례를 발견했어요. 얼마 전 미니 게임을 개발하면서 게임에서 발생하는 이벤트와 그로 인해 계산되는 상태를 Ventyd Entity로 정의했어요. 그리고 이 코어 로직을 클라이언트와 서버 양쪽에서 동시에 활용했습니다:</p><pre>// 아래 코드는 실제 코드가 아닌 예시입니다<br><br>// 게임 상태 Entity 정의<br>class GameState extends Entity(gameSchema, gameReducer) {<br>  movePlayer(direction: &#39;up&#39; | &#39;down&#39; | &#39;left&#39; | &#39;right&#39;) {<br>    dispatch(&#39;game:player_moved&#39;, { direction });<br>  }<br>  collectItem(itemId: string) {<br>    dispatch(&#39;game:item_collected&#39;, { itemId });<br>  }<br>}<br><br>// 클라이언트에서: 서버 없이 즉시 게임 상태 계산<br>function handlePlayerAction(action: GameAction) {<br><br>  // 로컬에서 즉시 상태 업데이트 (낙관적 업데이트)<br>  localGameState.movePlayer(action.direction);<br><br>  // 백그라운드에서 서버에 이벤트 전송 (동기화)<br>  sendToServer({<br>    events: localGameState.uncommittedEvents,<br>  })<br>}<br><br>// 서버에서: 같은 Entity로 검증 및 저장<br>async function processGameEvents(events: Event[]) {<br>  const gameState = await gameRepository.findOne({ entityId });<br><br>  // 이벤트 재생하여 상태 검증<br>  for (const event of events) {<br>    gameState.applyEvent(event); // 부정행위 검증도 가능!<br>  }<br><br>  await gameRepository.commit(gameState);<br>}</pre><p>이를 통해 아래와 같은 이점들을 얻을 수 있었어요.</p><ul><li><strong>즉각적인 반응성</strong>: 클라이언트에서 서버 응답을 기다리지 않고 즉시 게임 상태를 업데이트할 수 있어요.</li><li><strong>오프라인 지원</strong>: 네트워크 연결이 끊겨도 게임을 계속하고, 나중에 서버에 동기화할 수 있어요.</li><li><strong>부정행위 방지</strong>: 서버에서 같은 로직으로 이벤트를 재생하면서 검증할 수 있어요.</li><li><strong>재현 가능</strong>: 모든 게임 플레이가 이벤트로 기록되어 있어서 버그 재현이나 리플레이 기능 구현이 쉬워요.</li></ul><p>조금 특이한 사례이긴 하지만 프론트엔드와 백엔드가 같은 도메인 로직을 공유할 수 있다는 것이 Ventyd를 사용했을때 큰 장점이 될 수도 있다는 걸 확인한 셈이죠.</p><h3>백엔드 엔지니어 관점에서</h3><p>백엔드 엔지니어에게는 이런 장점이 있어요:</p><ol><li><strong>도메인 주도 설계(DDD)</strong>: Entity를 도메인 객체로 자연스럽게 모델링할 수 있어요.</li><li><strong>테스트하기 쉬움</strong>: 순수 함수인 Reducer는 테스트가 매우 쉬워요.</li><li><strong>버그 추적</strong>: 프로덕션에서 문제가 생겼을 때, 이벤트 로그를 보면 정확히 무슨 일이 있었는지 알 수 있어요</li><li><strong>성능 최적화</strong>: 읽기와 쓰기를 분리(CQRS)해서 각각 최적화할 수 있어요.</li></ol><h3>프론트엔드 엔지니어 관점에서</h3><p>프론트엔드 엔지니어라면 이렇게 대응해서 생각해볼 수 있어요.</p><ul><li><strong>Schema</strong> = TypeScript interface 정의</li><li><strong>Event</strong> = Redux action</li><li><strong>Reducer</strong> = Redux reducer</li><li><strong>Entity</strong> = 비즈니스 로직을 가진 React Hook (useReducer 같은)</li><li><strong>Repository</strong> = API 클라이언트</li></ul><p>익숙한 개념들이죠. Ventyd를 사용하면 프론트엔드와 백엔드가 같은 언어로 비즈니스 로직을 이야기할 수 있어요..</p><p>예를 들어:</p><pre>// 프론트엔드 (Redux)<br>dispatch({ type: &#39;user/profileUpdated&#39;, payload: { bio: &#39;Hello&#39; } });<br><br>// 백엔드 (Ventyd)<br>dispatch(&#39;user:profile_updated&#39;, { bio: &#39;Hello&#39; });</pre><p>이벤트를 중심으로 한 구조가 비슷해서, 프론트엔드와 백엔드가 서로의 코드를 이해하기가 훨씬 쉬워져요.</p><h3>마치며</h3><p>Ventyd는 당근에서 이벤트 소싱을 TypeScript 생태계에서 더 쉽게 사용할 수 있도록 만든 라이브러리예요. Redux를 사용해본 프론트엔드 엔지니어라면 빠르게 익숙해질 수 있고, 백엔드 엔지니어에게도 어렵지 않으면서 동시에 강력한 도구가 될 수 있다고 생각해요.</p><p>무엇보다 중요한 건, 프론트엔드와 백엔드 엔지니어가 이벤트와 상태라는 공통의 언어로 소통할 수 있게 된다는 점이에요. 이를 통해 더 나은 협업과 더 나은 소프트웨어를 만들 수 있기를 바랍니다.</p><p>관심 있으시다면 한번 사용해 보세요!</p><h3>링크</h3><ul><li>웹사이트: <a href=\"https://ventyd.com\">https://ventyd.com</a></li><li>GitHub: <a href=\"https://github.com/daangn/ventyd\">https://github.com/daangn/ventyd</a></li><li>NPM: <a href=\"https://www.npmjs.com/package/ventyd\">https://www.npmjs.com/package/ventyd</a></li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=0b2cd4f4a569\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://medium.com/daangn/%EC%84%9C%EB%B2%84%EB%A5%BC-%EC%9C%84%ED%95%9C-redux-node-js-%EC%9D%B4%EB%B2%A4%ED%8A%B8-%EC%86%8C%EC%8B%B1-%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC-%EA%B0%9C%EB%B0%9C%EA%B8%B0-0b2cd4f4a569\">서버를 위한 Redux: Node.js 이벤트 소싱 라이브러리 개발기</a> was originally published in <a href=\"https://medium.com/daangn\">당근 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2026-01-23T05:34:40.000Z",
    "url": "https://medium.com/daangn/%EC%84%9C%EB%B2%84%EB%A5%BC-%EC%9C%84%ED%95%9C-redux-node-js-%EC%9D%B4%EB%B2%A4%ED%8A%B8-%EC%86%8C%EC%8B%B1-%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC-%EA%B0%9C%EB%B0%9C%EA%B8%B0-0b2cd4f4a569?source=rss----4505f82a2dbd---4"
  },
  {
    "publisherId": "daangn",
    "publisherName": "당근마켓 테크",
    "specTitle": "React Native",
    "categories": [
      "mobile",
      "frontend"
    ],
    "specUrl": "https://medium.com/feed/daangn",
    "title": "당근페이 백엔드 아키텍처가 걸어온 여정",
    "partialText": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*n9g8WhEmaRXe6siBZ3mBrg.png\" /></figure><p>안녕하세요, 당근페이팀에서 백엔드 엔지니어로 일하고 있는 제레미예요. 지난 4년 동안 당근머니 시스템을 구축하고 송금 서비스를 성장시켜 왔고, 현재는 오프라인 결제팀에서 당근머니와 포인트 사용 경험을 동네 가게 결제로 넓히고 있어요.</p><p>당근페이팀의 백엔드는 Money 라는 하나의 작은 프로젝트에서 출발했어요. 지금은 수십 개의 서비스를 하나의 프로젝트에 운영하고 있고요. 이 과정에서 세 번의 큰 변화가 있었어요. 이 글을 통해 단순했던 계층형 아키텍처(Layered Architecture)에서 헥사고날 아키텍처(Hexagonal Architecture)를 거쳐, 클린 아키텍처(Clean Architecture)와 모노레포(Monorepo)로 확장된 현재까지의 이야기를 들려드리려고 해요.</p><blockquote><em>Any organization that designs a system (defined broadly) will produce a design whose structure is a copy of the organization’s communication structure.<br></em>- Melvin Conway</blockquote><p>어떤 조직이 시스템을 설계하면, 그 조직의 커뮤니케이션 구조를 본뜬 형태가 된다는 말이 있어요. 어떤 조직 구조를 가지고 있고 어떻게 협업하는지가 프로젝트 구조, 모듈 경계, API 설계 등 코드베이스에 그대로 반영된다는 의미예요. 초기 당근페이팀에는 계정 서비스팀, 송금 서비스팀 그리고 결제 서비스팀이 있었고 백엔드 엔지니어들이 담당하는 프로젝트도 User, Money, Payment로 나뉘어져 있었어요.</p><p>저는 송금 서비스팀에서 당근머니와 송금 서비스를 만들었고, 주로 Money 프로젝트에 기여했어요. 저희 팀은 초기에 당근머니 생태계와 송금 서비스만 담당했었는데, 당근페이 전체 서비스가 빠르게 성장하면서 팀의 책임 영역도 자연스럽게 확장되었어요.</p><p>특히 혜택과 이벤트를 관리하는 프로모션, 회계를 담당하는 빌링, 당근 포인트까지 서비스 도메인이 늘어날 때마다 코드베이스의 복잡도도 함께 증가했어요. 새로운 기능을 추가할 때마다 기존 코드와의 의존성을 고려해야 했고, 코드 변경 사항의 영향 범위를 예측하기 점점 어려워졌어요.</p><p>성장통을 겪으면서 저희 팀은 빠르게 기능을 추가하는 것을 넘어서, 지속 가능한 개발을 위해서는 아키텍처도 함께 진화해야 한다는 것을 깨달았어요. 빠르게 변하는 비즈니스 요구사항에 대응하면서 코드 품질을 유지하고 팀 간 협업을 원활하게 하려면 어떤 아키텍처가 필요할까요? 정답은 없지만 당근페이팀이 서비스 성장과 함께 겪어온 아키텍처 변화 과정을 단계별로 살펴보면서, 각 변화의 배경과 그 과정에서 얻은 인사이트들을 공유드릴게요.</p><h3>첫 번째: Layered Architecture</h3><p>2021년으로 거슬러 올라갈게요. 당근페이팀은 2021년 봄, “동네 생활 금융을 편하게” 라는 비전을 가지고 만들어졌어요. 당근페이팀의 첫 번째 미션은 동네에서 이웃과 중고거래를 할 때, 누구나 손쉽게 송금할 수 있도록 돕는 서비스를 출시하는 것이었어요.</p><p>모두가 전자금융업 라이선스 취득과 송금 서비스 오픈이라는 목표에 집중했고, 엔지니어들도 송금 기능 구현에 전력을 다했어요. 계정, 은행 입출금 그리고 당근머니 관리가 핵심 요소로 정의됐고 각 요소를 담당하는 프로젝트가 만들어졌어요.</p><ul><li>User: 사용자 계정과 인증을 담당해요.</li><li>Banking: 출금 계좌를 관리하고 은행 입출금을 담당해요.</li><li>Money: 당근머니 지갑을 구현하고 사용자에게 송금 기능을 제공해요. 이 글의 주제가 되는 프로젝트이기도 해요.</li></ul><p>당근의 핵심 성장 동력 중 하나는 ‘빠른 실행력을 바탕으로 기민하게 움직이는 것’ 이에요. 이런 철학에 맞춰서 최초 Money 프로젝트는 Controller — Service — Repository 형태의 계층형 아키텍처로 구성됐어요. 단순하고 직관적인 구조 덕분에 프로젝트를 쉽게 이해할 수 있었고 복잡한 설계 고민 없이 빠르게 기능을 개발하고 실험할 수 있었어요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*QmcRPfZL7CYI5wfY5q3JSg.png\" /><figcaption>첫 번째 프로젝트 구조(Layered Architecture)</figcaption></figure><p>이 구조를 바탕으로 2021년 9월에 전자금융업자 라이선스 취득했고, 같은 해 11월에 중고거래 송금 기능을 빠르게 출시할 수 있었어요. 성공적인 출시 이후 서비스가 예상보다 빠른 속도로 성장했어요. 중고거래 송금 기능에 만족한 사용자들의 피드백을 바탕으로 새로운 기능들이 하나둘 추가됐고, 비즈니스 영역도 점차 확장됐어요. 송금 내역, 계좌송금, 송금 프로모션 이벤트, FDS 연동 등 수많은 기능들이 짧은 시간에 추가되면서 코드베이스의 복잡도가 기하급수적으로 증가했어요.</p><p>아키텍처의 Service 계층은 유스케이스 경계 없이 서로의 내부 구현에 직접 의존하게 됐고, 복잡한 호출이 꼬리를 물며 스파게티처럼 얽히기 시작했어요. 당근머니 지갑 등 핵심 비즈니스 로직을 담당하는 Service 클래스는 여러 Service 로부터 입력, 출력 뿐만 아니라 검증, 권한 등 횡단 관심사까지 떠안게 되면서 변경에 취약해졌어요.</p><p>복잡한 Service 간 참조는 테스트 작성과 리팩터링도 어렵게 만들었어요. 빠른 출시를 가능하게 했던 계층형 아키텍처는 시간이 지나면서 언젠가 해결해야 할 기술 부채로 자리 잡게 됐죠.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*50HY4rQ4y96ib8POLMVglA.jpeg\" /><figcaption>복잡하게 얽힌 Layered Architecture 구조</figcaption></figure><h3>두 번째: Hexagonal Architecture</h3><p>당근페이팀은 매년 12월 마지막 2주 동안 Refactoring Day 시간을 가지고 있어요. Refactoring Day는 잠시 서비스 배포를 멈추고, 리프레시를 위해 휴가를 가거나 쌓여 있던 기술 부채를 해결하는 시간이에요.</p><p>저 역시 2022년 12월 마지막 주에 휴가를 계획 중이었는데 갑작스럽게 일정이 취소되면서 2주의 자유 시간이 생겼어요. 2주면 정말 많은 것을 할 수 있는 시간인데 무얼 하며 보내야 할지고민하던 중, 그동안 시간이 충분치 않아서 오랫동안 생각만 하고 있던 Money 프로젝트 아키텍처 고민이 떠올랐고 어떤 문제가 있는지부터 하나씩 정의해 보기로 했어요.</p><ol><li>Service 계층 간 의존 관계가 불분명해서, 순환 참조가 발생하고 코드 응집도가 낮다.</li><li>Service 클래스 간 강한 결합이 발생해서, 코드 재사용이 어렵고 비슷하지만 서로 다른 중복 코드가 발생한다.</li><li>모든 코드베이스에 Spring 기술이 침투해서, 구현 기술과 독립적으로 비즈니스 로직을 작성할 수 없다.</li></ol><p>이 문제들을 해결해야만 내년, 그리고 그 이후의 서비스 성장에 맞춰 팀 전체가 유저 임팩트를 빠르게 만들어낼 수 있다고 판단했어요. 1번과 2번 문제를 해결하기 위해서는 계층 간 응집도는 높이고 결합도는 낮추는 방향의 구조 개선이 필요했고, 3번 문제를 해결하려면 구현 기술과 독립적인 비즈니스 로직을 작성할 수 있는 기반이 요구됐죠.</p><p>물론 도메인 계층에서 인프라 의존성을 역전시키고, 파사드나 인터페이스를 잘 설계하면 이런 문제들을 어느 정도 완화할 수는 있었어요. 하지만 팀과 코드베이스가 빠르게 커지는 상황에서는 ‘잘 지키자’ 는 규칙만으로는 한계가 분명했어요. 새로운 기능과 사람이 계속 합류하다 보니, 의도하지 않은 의존성이 다시 스며들고, 구조적인 제약보다 관습에 의존하게 되는 순간들이 반복됐거든요.</p><p>헥사고날 아키텍처는 이런 문제를 사람이 아니라 구조로 제어하려는 선택이었어요. 애플리케이션 핵심 로직과 외부 구현을 명확히 분리하고, 포트를 통해서만 의존성이 연결되도록 강제함으로써, 잘못된 의존성이 아예 만들어지기 어려운 형태를 지향했어요. 특히 팀 규모가 커질수록, 각자의 판단에 맡기기보다 구조 자체가 올바른 방향으로 유도해 주는 설계가 필요하다고 느꼈어요.</p><p>당시에 헥사고날 아키텍처를 여러 프로젝트에 적용해본 경험을 통해, 이런 강한 제약이 오히려 팀 전체의 생산성과 일관성을 높여준다는 확신을 얻었고, Money 프로젝트에도 이 구조를 도입하기로 결정했어요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/626/1*T8Z-mCJ-Eq0Jzrx2SEBVHw.png\" /><figcaption><a href=\"https://en.wikipedia.org/wiki/Hexagonal_architecture_(software)\">https://en.wikipedia.org/wiki/Hexagonal_architecture_(software)</a></figcaption></figure><p>계층형 아키텍처에서 발생한 강결합 문제를 풀기 위해 도메인 규칙을 중심으로 구현부(UI, DB, 외부 API 등)를 명확히 분리하는 방향으로 아키텍처를 재구성했어요. 크게 domain, usecase, adapter 세 가지 모듈로 나누었고 저희 팀은 이 구조를 Money 2.0 이라고 부르고 있어요.</p><ul><li><strong>domain</strong>: 당근머니를 다루는 지갑의 입금과 출금 같은 도메인 핵심 규칙을 정의하는 모듈이에요. Domain Entity, Domain Event, Domain Policy, Value Object 등이 이 안에 있고, 어떤 프레임워크나 외부 기술에도 의존하지 않는 POJO(Plain Old Java Object) 모듈로 구성되어 있어요.</li><li><strong>usecase</strong>: 하나의 사용자 시나리오(송금, 충전, 환불 등) 단위로 응집하는 모듈이에요. 트랜잭션 경계, 검증, 도메인 정책 조합, 포트 호출을 책임지고, domain 모듈만 참조해요. 덕분에 동일한 유스케이스를 REST API, 이벤트 컨슈머, 배치 잡 등 여러 애플리케이션에서 재사용할 수 있었어요.</li><li><strong>adapter</strong>: domain 모듈에서 정의한 인터페이스를 구현하는 모듈이에요. 데이터베이스, 메시지 브로커, 외부 API 호출, 그리고 Web, Batch, Admin 같은 애플리케이션 입출력을 담당해요. usecase와 domain을 참조하고 구현해요.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*VFmm-7Eivnv1xFupwykOdA.png\" /><figcaption>두 번째 프로젝트 구조(Hexagonal Architecture)</figcaption></figure><p>모듈 간 의존 규칙은 아래처럼 설정했어요.</p><ul><li>money-domain: 어떤 모듈에도 의존하지 않아요.</li><li>money-usecase → money-domain 모듈만 의존해요.</li><li>money-adapter → money-usecase, money-domain 모듈에 의존해요(외부 기술/프레임워크 포함).</li><li>각 애플리케이션(money-api, money-admin-api, money-batch)은 어댑터를 조립해 런타임 구성을 완성해요.</li></ul><p>전환해야 할 기능도 많고 코드 구조 역시 달랐기 때문에, 한 번에 바꾸기보다는 Strangler Fig Pattern과 Feature Toggle을 활용해 점진적으로 전환하기로 했어요.</p><ul><li><strong>Strangler Fig Pattern</strong>: 기존 코드를 한 번에 바꾸지 않고, 새 모듈로 유스케이스 단위의 기능을 옮겨가며 점진적으로 교체하는 전략이에요. 마치 나무에 붙은 덩굴이 점차 원래 줄기를 감싸면서 교체하는 것과 비슷하다고 해서 붙은 이름이에요. <a href=\"https://martinfowler.com/bliki/StranglerFigApplication.html\">참고: Martin Fowler — Strangler Fig</a></li><li><strong>Feature Toggle</strong>: 새로운 아키텍처로 옮긴 기능을 플래그로 제어해서, 필요할 때는 기존 로직을 사용하고 안정화되면 새 버전을 단계적으로 적용하는 방식이에요. 위험을 최소화하면서도 빠르게 전환을 진행할 수 있었어요. <a href=\"https://medium.com/daangn/%EB%A7%A4%EC%9D%BC-%EB%B0%B0%ED%8F%AC%ED%95%98%EB%8A%94-%ED%8C%80%EC%9D%B4-%EB%90%98%EB%8A%94-%EC%97%AC%EC%A0%95-2-feature-toggle-%ED%99%9C%EC%9A%A9%ED%95%98%EA%B8%B0-b52c4a1810cd\">참고: 매일 배포하는 팀이 되는 여정(2) — Feature Toggle 활용하기</a></li></ul><p>Refactoring Day 기간 동안 계층형 아키텍처에서 헥사고날 아키텍처로 전환하기 위해 컨벤션, 모듈 구조를 포함한 전체 설계와 몇 가지 유스케이스 전환을 마쳤어요. 새로 추가된 기능들은 헥사고날 아키텍처에 맞춰서 작성하고, 계층형 아키텍처의 기존 기능들은 틈틈이 전환을 진행했어요.</p><p>헥사고날 아키텍처로의 전환이 가져다 준 가장 큰 변화는 비즈니스 로직이 기술적 세부사항으로부터 명확하게 분리되었다는 점이에요. 이전에는 모든 로직에 Spring 뿐만 아니라 다양한 외부 구현 기술이 뒤섞여 있어서 코드 수정시 연쇄적인 변경이 자주 발생했지만, 이제는 각 모듈이 자신의 역할에만 집중할 수 있게 됐어요.</p><p>Domain 모듈은 오직 핵심 도메인 규칙만을, UseCase 모듈은 유저 시나리오 작성만을, Adapter 모듈은 외부 연동만을 담당해요. 덕분에 코드베이스 전체의 모듈 간 결합도를 크게 낮출 수 있었고 구현 기술에 의존하지 않고 비즈니스 로직 작성에만 집중할 수 있는 환경이 만들어졌어요. 서비스가 더 확장되더라도 유지보수성과 테스트 용이성을 확보할 수 있었어요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*pzWkX-_p5tmoQY5j2XTvKg.png\" /><figcaption>Hexagonal Architecture 적용후 변화</figcaption></figure><p>Money 2.0 구조는 당근머니를 하나은행 계좌와 통합해서 사용할 수 있는 당근머니 하나통장, 당근페이 송금 기능을 당근마켓의 모든 서비스에서 사용할 수 있게 도와주는 송금 티켓 플랫폼 등 2023년 한 해 동안 기술적으로 도전적이었던 문제들을 해결할 수 있게 도와준 기반이 되기도 했어요.</p><h3>Hexagonal Architecture 적용 이후</h3><p>팀에서 새로운 제품을 만든다면, 엔지니어는 어떤 일을 먼저 하게 될까요? 비즈니스 요구사항을 분석하거나 구현에 필요한 기술적 요구사항을 검토할 거예요. 이와 동시에 코드 작성을 위한 프로젝트를 세팅하고, 보일러플레이트를 만들거예요.</p><p>제로부터 하나씩 쌓아 올리는 과정은 모두에게 색다른 경험을 주고 높은 자유도를 보장하기 때문에 많은 엔지니어가 새로운 프로젝트에 코드를 작성하는걸 선호해요. 그러다보면 이 과정에 들어가는 비용을 줄이고 더 빠르고 쉽게 프로젝트를 세팅할 수 있도록 우리 팀만의 프로젝트 템플릿(Scaffolding)을 만들거예요. 이제 누구나 스크립트 한 번이면 프로젝트를 초기화할 수 있는 환경이 만들어졌어요.</p><p>하지만 이렇게 쉽게 프로젝트를 늘려가다 보면 서비스 성장과 함께 팀에서 관리하는 프로젝트는 한 개, 두 개를 넘어 금세 수십 개로 불어나요. 팀의 엔지니어가 3명인데 관리해야 할 프로젝트가 20개를 넘는다고 상상해보세요.</p><p>처음엔 같은 프로젝트 템플릿으로 시작했더라도 각 프로젝트의 코드 컨벤션과 라이브러리 버전은 날이 갈수록 달라질 거예요. 결국 같은 팀에서 관리하지만 서로 다른 방식으로 개발되고 유지보수는 점점 더 어려워져요. 새로 합류한 엔지니어는 일관되지 않은 모습을 보고 혼란을 느낄 수도 있어요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/980/1*9djt1UPUJHNi6cN_6Koljg.png\" /><figcaption><a href=\"https://monorepo.tools/\">https://monorepo.tools/</a></figcaption></figure><p>저희 팀은 새로운 제품을 만들때 별도 프로젝트를 생성할 때도 있었고, 팀의 메인 프로젝트인 Money 안에 추가하기도 했어요. 새로운 프로젝트를 빠르게 생성할 수 있게 도와주는 템플릿 프로젝트가 있었지만, Money 프로젝트 안에는 서비스를 빠르게 확장할 수 있게 도와주는 플랫폼성 기능들을 제공하고 있어서 대부분 이곳에 추가되었어요.</p><p>사용자에게 혜택이나 광고를 서빙하는 배너 서비스와 당근포인트를 관리하는 포인트 서비스가 Money 프로젝트 안에 생성됐어요. 편의 기능들을 재사용할 수 있고 정형화되어 있는 구조에 맞춰 빠른 개발이 가능하다는 장점이 있었죠. 하지만 비즈니스 로직과 외부 구현체의 경계만 존재하고, 도메인 간 경계가 없는 헥사고날 아키텍처 안에 서로 다른 도메인 서비스가 공존하다 보니 여러 문제점이 드러나기 시작했어요.</p><h4>문제 1. 기준 없이 Adapter 모듈에 수많은 구현 클래스가 추가되었어요</h4><p>특정 라이브러리를 사용한 구현 세부 사항이나 외부 시스템 연동은 헥사고날 아키텍처의 Adapter 모듈에 위치해요. 역할과 책임이 명확해서 큰 고민 없이 인터페이스 구현체들은 Adapter 모듈에 추가됐어요. 하지만 이런 장점은 Adapter 모듈을 참조하는 여러 부트스트랩 애플리케이션 입장에서 불필요한 의존성을 참조하게 되는 역효과를 가져왔어요.</p><p>배너 서비스의 구현체, 포인트 서비스의 구현체 모두 Adapter 모듈에 작성되어서 머니 서비스 애플리케이션에는 필요하지 않은 배너와 포인트 의존성이 포함된 채 구동되었어요. Adapter 모듈은 아키텍처 의도와 다르게 언젠간 정리되어야 할 부채가 쌓여가는 공간이 되어버렸어요.</p><p>Domain Repository 구현체도 Adapter 모듈의 out 패키지 하위에 위치해 있었어요. 고민 없이 빠르게 구현할 수 있다는 장점이 있지만, 머니·포인트·배너 등 특정 Domain Repository의 구현체를 찾기 어렵고 어떤 의존성을 가지고 있는지 코드를 보지 않으면 파악하기 힘들어졌어요. Domain Repository 구현체들이 한곳에 모여 있으면서 얻을 수 있는 장점은 생각 없이 코드를 추가할 수 있다는 점 정도뿐이었어요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*siPFBOPqR-isdPJ47f2KWQ.png\" /><figcaption>기준 없이 추가된 Adapter Layer의 수많은 구현 클래스</figcaption></figure><h4>문제 2. 배포할 서비스와 관계 없는 서비스들이 배포되었어요</h4><p>저희 팀은 trunk-based development 방법론에 맞춰 개발하고 있어서 Main Branch에 변경 사항이 발생하면 애플리케이션이 자동으로 배포돼요. 배포 트리거에 특정 도메인이나 서비스별 구분을 두고 있지 않다 보니, 머니 서비스의 코드가 변경되면 전혀 관계 없는 배너와 포인트 서비스도 함께 배포 됐어요. 서비스별로 패키지 이름을 구분해서 일괄 배포되는 문제를 일부 해결할 수는 있었지만, 패키지를 넘나드는 코드 참조가 생기면 문제는 여전히 발생했어요. 결국 근본적인 문제 해결 방법은 아니었죠.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*rrV_SDL2ylVJJIZNjW7r1Q.png\" /><figcaption>money-internal-api를 배포하는데 banner, point 등 모든 서비스가 배포되는 현상</figcaption></figure><p>이 외에도 초기에 누릴 수 있었던 재사용 가능한 편의 기능, 외부 구현체와의 관심사 분리 등의 장점은 시간이 갈수록 오히려 개발 생산성이 저하되는 문제로 이어졌어요.수십 번의 배포를 반복하며 빠른 속도로 일하는 저희 팀의 비즈니스 전개를 방해하는 요소가 되었고 해결해야 할 문제로 다가왔어요.</p><h3>세 번째: Clean Architecture &amp; Monorepo</h3><p>Money 2.0 설계는 계층형 아키텍처의 문제를 풀기 위해 핵심 로직과 외부 구현을 분리하는 헥사고날 아키텍처를 기반으로 했지만, 도메인 간 관심사 분리는 충분히 고려하지 못했어요. 그래서 여러 도메인이 한 지붕 아래에서 잘 지낼 수 있게 도와주는 새로운 구조가 필요해졌어요.</p><p>소프트웨어 아키텍처는 개념이나 추상적인 이론만 놓고 보면 장점이 분명해 보여요. 하지만 중요한 건, 이런 아키텍처나 패턴을 우리 팀의 상황에 맞는 구체적인 규칙과 구조로 어떻게 풀어내느냐예요. 헥사고날 아키텍처를 애플리케이션(Application), 포트(Port), 어댑터(Adapter) 모듈로 나눈다고 했을 때, 각 모듈을 코드베이스에 어떻게 배치할지, 네이밍은 어떤 기준으로 맞출지, 그리고 구체 클래스들을 런타임에 어떤 방식으로 조합할지 등 아주 구체적인 고민이 필요해요. 결국 이 아키텍처를 우리 팀의 일하는 방식과 프로젝트 특성에 맞게 적용하기 위해서는, 개념을 넘어 실제로 동작하는 규칙과 형태를 정의해야 했어요.</p><p>머니, 포인트, 쿠폰, 기프팅 등 여러 도메인 서비스들을 하나의 프로젝트에 관리하면서 발생하는 문제를 해결하기 위해, 새로운 구조가 달성해야 할 목표와 고려해야 할 내용들을 논의하였고 Robert C. Martin의 클린 아키텍처(Clean Architecture)를 베이스로 한 모노레포(Monorepo) 모듈 구조를 만들었어요.</p><h4>목표</h4><ul><li><strong>도메인 모듈화</strong>: 단일 프로젝트 내에서 도메인별 모듈을 명확히 분리하고, 도메인 간 의존 관계를 명시적으로 관리해요.</li><li><strong>의존성 역전</strong>: 고수준 모듈(도메인, 비즈니스 로직)은 저수준 모듈(외부 시스템, 인프라 구현)에 직접 의존하지 않고, 모든 의존성은 추상화된 인터페이스를 기준으로 설계하여 구현 교체와 테스트가 용이한 구조를 만들어요.</li><li><strong>확장성과 유지보수성</strong>: 애플리케이션 비즈니스 로직이 특정 구현에 의존하지 않는 헥사고날 아키텍처의 장점을 유지하면서, 새로운 도메인과 기능이 추가되더라도 기존 코드에 미치는 영향을 최소화해요.</li><li><strong>배포 독립성</strong>: 특정 도메인의 변경이 다른 도메인 서비스의 배포로 이어지지 않도록 해요. 서비스 단위의 독립적인 배포가 가능하도록 구조를 설계해요.</li><li><strong>테스트 용이성</strong>: 모듈별 독립적인 테스트 환경을 제공하고, Fixture 및 Stubbing 모듈을 통해 외부 의존성 없이 테스트할 수 있도록 해요.</li></ul><h4>기본 아키텍처</h4><p>베이스로 삼은 클린 아키텍처(Clean Architecture)의 핵심은 한 단어 The Dependency Rule 로 표현할 수 있어요. ‘의존성은 항상 안쪽(비즈니스 규칙)으로만 향해야 한다’ 는 말이에요. 이 규칙을 바탕으로 모듈의 의존 관계를 고수준 정책이 저수준 구현을 의존하지 않도록 설계했어요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/772/1*PVgABZDP57QZJJrJLjb1aQ.png\" /><figcaption><a href=\"https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html\">https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html</a></figcaption></figure><h4>프로젝트 모듈 구조</h4><p>크게 bootstrap, core, infrastructure, library, platform, usecase 여섯 개의 모듈로 구성되어 있어요. 모듈 사이의 모든 상호작용은 구체 클래스가 아닌 인터페이스를 통해 이루어지고, 각 모듈은 독립적으로 개발, 테스트 그리고 교체될 수 있어요.</p><p>bootstrap:</p><ul><li>모든 레이어의 의존성을 조립해서 애플리케이션을 실행하는 최상위 모듈이에요.</li><li>머니, 포인트, 프로모션, 선물하기 등 각 서비스의 애플리케이션들이 디렉터리 단위로 구분되어 있어요.</li></ul><p>core:</p><ul><li>각 도메인의 핵심 비즈니스 규칙을 정의하는 모듈이에요.</li><li>core:{domain}:domain: 외부 기술에 의존하지 않고 비즈니스 규칙을 정의해요.</li><li>core:{domain}:data: core:domain 모듈에서 정의한 인터페이스를 구현해요.</li></ul><p>infrastructure:</p><ul><li>애플리케이션 실행에 필요한 기술적인 세부사항을 모아놓은 모듈이에요.</li><li>상위 레이어의 어댑터들이 이 모듈의 기술들을 사용해서 구현체를 완성해요.</li></ul><p>library:</p><ul><li>Async, Logging, Retry 등 모든 모듈에서 공통으로 사용하는 횡단 관심사를 제공하는 모듈이에요.</li></ul><p>platform:</p><ul><li>인증, FDS, 당근채팅 등 도메인과 관련된 외부 플랫폼을 연동한 모듈이에요.</li></ul><p>usecase:</p><ul><li>계좌등록, 송금, 더치페이 등 하나의 사용자 시나리오 단위의 비즈니스 로직을 작성하는 모듈이에요.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*fjgSHiqusYt857MZG_64kQ.png\" /><figcaption>세 번째 프로젝트 구조(Clean Architecture &amp; Monorepo)</figcaption></figure><h3>Clean Architecture &amp; Monorepo 적용 이후</h3><h4>1. Hexagonal Architecture 구조에서 발생하던 문제가 해결 되었어요</h4><p>모든 서비스에서 공통으로 사용하던 도메인과 어댑터 모듈이 사라지고 도메인마다 별도 모듈을 구성함으로써 각 도메인을 독립적으로 관리할 수 있게 됐어요. money-domain 모듈에 있던 머니, 포인트, 배너 등 다양한 서비스의 도메인 규칙들은 core:{domain}:domain 모듈 하위로 분리되었고, money-adapter 모듈에 존재했던 구현체들이 각 도메인의 관심사에 맞게 core:{domain}:data 모듈 하위로 분리되었어요.</p><p>bootstrap 모듈에서 각 애플리케이션 구동에 필요한 모듈만 조합할 수 있게 되면서 헥사고날 아키텍처에서 발생하던 서비스 배포 문제도 함께 해결됐어요. 머니 송금 유스케이스의 변경 사항은 머니 부트스트랩 하위의 애플리케이션에만 영향을 주고 관계 없는 다른 애플리케이션에는 영향을 주지 않는 구조가 된 거예요.</p><h4>2. 비즈니스 임팩트를 빠르게 만들 수 있는 환경을 만들었어요</h4><p>수십 개의 서비스를 하나의 프로젝트에서 운영하다 보니 자연스럽게 조직 전반에 걸친 다양한 툴이 만들어졌어요. 그중 하나가 디렉터리 구조, 공통 설정, 의존성, Test Scaffolding 등 애플리케이션 구성에 필요한 모든 보일러플레이트를 만들어주는 도구예요. 새로운 애플리케이션 구성이 필요하면 엔지니어는 버튼 한 번만으로 빠르게 초기 코드베이스를 완성할 수 있었어요.</p><p>프로젝트 통합 이후 코드 라인 수는 빠르게 늘었지만, 이때마다 저희 팀이 집요하게 지킨 건 피드백 루프의 속도였어요. 전체 코드 라인 수는 전년 대비 2배 가까이 늘었는데도 팀원 모두 빌드 속도를 틈틈이 개선해서 엔지니어가 체감하는 빌드 소요 시간은 늘지 않았어요. 빌드·테스트·배포가 늦어지지 않으니 작은 변경도 부담 없이 자주 릴리즈하고, 작은 실험 → 빠른 릴리즈 → 빠른 피드백 → 다음 개선의 사이클을 유지할 수 있었어요. 그 결과 사용자의 피드백을 빠르게 반영해서 비즈니스 임팩트를 더 짧은 주기로 만들어낼 수 있게 되었어요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*2pjR7gmjfTtuBh1GM2KKNw.png\" /><figcaption>코드 라인수 증가(192%↑)에 따른 평균 빌드 소요 시간과 배포 횟수 비교</figcaption></figure><h4>3. 일관된 시스템을 만들고 기술적 성숙도를 공유할 수 있게 되었어요</h4><p>복잡한 마이크로서비스 환경에서 일관된 기준이 없으면 시스템에 문제가 발생했을 때 문제 원인(Root Cause)를 찾기 어렵고 문제 해결이 특정 개인에 의존해야 하는 현상이 생길 수도 있어요. A 서비스와 B 서비스 간에 타임아웃 설정은 어떻게 되어 있는지, A 서비스가 어떤 의존성을 가지고 빌드 되는지 등 모노레포에 적용된 가시성 높은 규칙들 덕분에 개인이 아닌 코드 기여자 누구라도 문제 해결에 뛰어들 수 있게 되었고 해결에 소요되는 시간도 단축시킬 수 있었어요.</p><p>수십 개의 프로젝트를 관리해 본 경험이 있으시다면 공통으로 개선해야 할 부분이나 린트, 테스트, 빌드, 배포 기준 등이 서비스마다 모두 달라서 유지보수가 어려웠던 경험이 떠오를 거예요. 모노레포 도입 이후에는 한 번의 개선이 모든 곳에 원자적으로 반영이 되어서 의존성 관리, 변경과 탐색이 훨씬 쉬워졌어요. 트러블 슈팅을 통한 레슨런이 모노레포의 모든 서비스에 반영될 수 있었고, 안정성과 일관성이 중요한 금융 서비스에 신뢰를 더할 수 있었어요.</p><p>이제는 어떤 서비스가 언제 배포되었고 배포로 인한 에러는 없었는지 릴리즈 리포팅을 자동화하면서 배포 과정이 이전보다 더 투명해졌어요. 또 런북(Runbook)을 바탕으로 사람이 모니터링하던 운영 방식을 시스템으로 자동화하면서 장애 대응 역시 개인이 아닌 팀 전체의 역량으로 축적되고 있어요.</p><h4>4. 엔지니어링 역량이 함께 성장할 수 있는 환경을 만들었어요</h4><p>효과적인 성장을 위해서는 문제 인식과 개선 그리고 피드백 사이클을 만드는 게 중요해요. 모노레포는 이 사이클을 반강제적으로 만들어 주었어요😅 서로 다른 목적 조직이 하나의 프로젝트에 코드를 기여하게 되면서, 개선해야 할 부분이 보이면 이전보다 더 적극적으로 공유했고, 모두가 공감할 만한 문제가 수면 위로 올라오면 관심 있는 누구든, 혹은 주간 온콜 담당자가 문제를 해결했어요.</p><p>특히 코드 리뷰는 피드백 사이클의 중요한 축이 되었어요. 변경 사항이 한 곳에 모이면서 코드가 더 잘 보이게 되었고, 그만큼 리뷰 참여와 코멘트도 자연스럽게 늘어났어요. 코드 리뷰는 단순한 승인 절차를 넘어, 설계 의도를 공유하고 서로 배우는 주요한 협업 수단이자 함께 성장할 수 있는 기반이 되었어요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*xka98JRckNT8jN-jP12wKQ.png\" /><figcaption>PR 생성과 코드 리뷰 수</figcaption></figure><p>라이브러리 버전 업그레이드, Generational ZGC 적용, Gradle Build Cache 적용, TestContainer 도입, Stream Application 활용, 온콜 시스템 자동화 등 시스템 안정성과 개발 생산성을 높이기 위한 엔지니어링 작업은 한 번에 여러 서비스에 임팩트를 줄 수 있어서, 특정 팀만의 일이 아니라 모두의 관심사가 되었어요. 이런 작업을 함께 논의하고 설계하고 실제로 적용해보는 과정에서 각자의 전문 영역을 넘어 서로의 관점을 배우게 되었고 자연스럽게 공통의 엔지니어링 기준이 생겼어요. 결과적으로 ‘내 서비스만 잘 만들기’ 를 넘어, 조직 전체의 기술 수준을 한 단계 끌어올리는 데 기여하고 있다는 감각이 팀원들의 중요한 성장 동력이 되었던 것 같아요.</p><h4>회고</h4><p>이번 회고에서는 좋았던 점(Keep)보다는 어렵거나 힘들었던 것(Problem), 그리고 더 잘해보고 싶은 점(Try)에 대해 이야기를 많이 나누었어요. 덕분에 지금의 방식이 어느 정도 자리를 잡았고, 다음 단계를 고민할 시점이라는 공감대가 생겼죠. 모노레포는 저희가 그 방향성 덕분에 하나의 팀(One Team)으로 일할 수 있는 환경을 만들어 주었어요. 다른 컴포넌트의 구조를 자연스럽게 이해하게 되었고, 코드 리뷰와 논의를 통해 개인의 경험이 팀 전체의 지식으로 확산되는 흐름이 만들어졌거든요. 무엇보다 ‘내가 맡은 영역’을 넘어 서로의 고민을 함께 나눌 수 있다는 점이 동료들에게 긍정적으로 받아들여졌던 것 같아요.</p><p>물론 장점만 있었던 건 아니에요. 코드베이스가 커질수록 빌드 속도 문제나 인지 부하에 대한 부담이 점점 더 또렷해졌고, 모듈과 레이어의 경계를 사람마다 조금씩 다르게 해석할 수 있다는 점도 알게 되었어요. 지금은 감당 가능한 수준이지만, 팀과 코드가 더 커진다면 이 방식이 계속 유효할지에 대한 고민도 자연스럽게 나왔고요.</p><p>이번 회고를 통해 다시 느낀 건, 모노레포가 어떤 팀에게나 항상 정답은 아니라는 점이었어요. 지금의 팀 규모와 문제 상황에서는 ‘함께 보고, 함께 고치고, 함께 책임지는’ 구조가 큰 힘을 발휘했지만, 이 선택이 언제까지나 최선일 수는 없으니까요. 그래서 중요한 건 모노레포 자체가 아니라, 현재 팀의 문제를 가장 잘 해결해줄 수 있는 도구를 찾는 것이라고 생각해요. 저희도 물론 언젠가 팀의 상황이 달라진다면, 다른 선택을 하게 될 수도 있을 거예요. 그리고 이 여정은 Lorde, William, Winter, Leo, Clover, Robin 동료들과 함께였기에 가능했어요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*FEzrF0yVSdl3xjgpkgW3Ow.png\" /><figcaption>머니 서비스팀 백엔드 엔지니어 KPT(Keep, Problem, Try) 회고</figcaption></figure><h3>마치며</h3><p>세계적으로 유명한 리더십 코치 Marshall Goldsmith는 그의 저서 What Got You Here Won’t Get You There 에서 “과거의 성공 방식이 미래의 성공을 보장하지 않는다”고 말해요. 즉 지금까지의 성공 방식이 항상 미래의 성공을 보장하지 않기 때문에, 문제를 인식하고 개선하며 변화에 맞춰 나가야만 한계를 뚫고 성장할 수 있다는 뜻이에요.</p><p>당근페이 백엔드 프로젝트도 그랬어요. 위에서 설명했듯 단순한 Layered Architecture에서 출발해 Hexagonal Architecture를 거쳐, 지금의 Clean Architecture와 Monorepo로 확장되기까지, 이 글에 담지 못한 수백 가지의 작은 변화들도 있었어요. 물론 지금 구조가 당장 내일의 환경에 맞지 않을 수도 있기 때문에 그 때에 맞춰서 또 변화를 준비해야 할 수도 있어요. 그렇기에 지금도 저희는 변화를 준비하고 있고요.</p><p>모노레포는 개발의 불편함을 단번에 없애주는 마법은 아니었어요. 하지만 그 불편함을 혼자가 아닌 팀원 전체가 공유하게 만들어주었어요. 덕분에 반복적인 개선이 쌓여 모두의 성장으로 이어지는 문화가 자리잡을 수 있었어요. 더 나은 코드 리뷰 환경, 고민을 덜어주는 코딩 컨벤션, 빌드 속도 개선과 자동화가 자연스러운 일상이 된 것처럼요.</p><p>물론 이런 변화로 동시에 새로운 과제들도 나타났어요. 코드베이스가 더 커질수록 구조를 어떻게 유지할지, 개발자 경험(Developer Experience)을 어떻게 지켜낼지, 그리고 이런 문화를 어떻게 다음 단계까지 확장해 나갈지는 여전히 고민해야 할 문제예요. 저희는 지금이 완성이 아니라, 과정이라고 생각하고 있어요. 계속해서 더 나은 방향을 실험하고 개선해 나가려고 해요.</p><p>금융 서비스에서 더 빠르고 안정적으로 비즈니스와 유저 임팩트를 만들어가기 위해, 아직 함께 풀어야 할 과제가 많아요. 이 여정에 함께 고민하고 만들어갈 백엔드 엔지니어 동료를 기다리고 있어요. Mission Critical 환경에서 당근페이 비즈니스를 성장시키는 도전에 관심이 있다면, 아래 채용 공고도 한 번 읽어보세요.</p><ul><li><a href=\"https://team.daangn.com/jobs/4511184003/\">Software Engineer, Backend — 당근페이 (Kotlin)</a></li></ul><p>당근페이팀에 더 궁금한 게 있으시다면 댓글을 달아주시거나 <a href=\"mailto:jeremy.kim@daangnpay.com\">jeremy.kim@daangn.com</a> 으로 연락해주셔도 좋아요.</p><p>긴 글 읽어주셔서 감사합니다.</p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=98615d5a6b06\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://medium.com/daangn/%EB%8B%B9%EA%B7%BC%ED%8E%98%EC%9D%B4-%EB%B0%B1%EC%97%94%EB%93%9C-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98%EA%B0%80-%EA%B1%B8%EC%96%B4%EC%98%A8-%EC%97%AC%EC%A0%95-98615d5a6b06\">당근페이 백엔드 아키텍처가 걸어온 여정</a> was originally published in <a href=\"https://medium.com/daangn\">당근 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2026-01-15T05:40:53.000Z",
    "url": "https://medium.com/daangn/%EB%8B%B9%EA%B7%BC%ED%8E%98%EC%9D%B4-%EB%B0%B1%EC%97%94%EB%93%9C-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98%EA%B0%80-%EA%B1%B8%EC%96%B4%EC%98%A8-%EC%97%AC%EC%A0%95-98615d5a6b06?source=rss----4505f82a2dbd---4"
  },
  {
    "publisherId": "daangn",
    "publisherName": "당근마켓 테크",
    "specTitle": "React Native",
    "categories": [
      "mobile",
      "frontend"
    ],
    "specUrl": "https://medium.com/feed/daangn",
    "title": "Building Event Center: Karrot’s User Event Management Platform",
    "partialText": "<h4>The Journey from Restructuring User Event <strong>Conventions</strong> to Building an Admin Platform</h4><p>Hi there! I’m Mika, a frontend engineer on <a href=\"https://www.karrotmarket.com/?in=manhattan-7426\">Karrot’s</a> Data team.</p><p>At Karrot, massive amounts of user events are collected every day. These events are essential for designing experiments, improving our products, and making data-driven decisions. But as the logs scaled, managing them effectively became increasingly important.</p><p>That’s why we restructured our company-wide logging convention and built a platform called <em>Event Center</em> — an admin platform for managing user events across the company. We shifted from a Git-based, code-centric workflow to a UI-driven approach, automating as much manual work as possible. The goal was to handle user events more consistently and safely.</p><p>In this post, I’ll share our journey — from why we restructured our logging system to how we designed and implemented Event Center. If you’re dealing with similar challenges, hopefully this gives you some ideas!</p><h3>1. User Events: The Starting Point for Data-Driven Decisions</h3><p>Millions of users interact with the <em>Karrot</em> app every day, leaving behind traces of their behavior. Small actions like “viewed a marketplace listing,” “tapped the chat button,” or “added to favorites” accumulate into valuable data.</p><p>This data helps us improve user experience and drives product decisions. For example, if we notice that users rarely tap the chat button, we might consider repositioning it to make it more visible. Instead of relying on gut feelings, we can make informed decisions backed by data.</p><p>But collecting and analyzing this behavioral data turned out to be more complex than expected. As our log volume grew, we gradually hit the limitations of our operational approach.</p><p>Before diving into those challenges, let me briefly explain how we collect user events at Karrot.</p><h4>1.1. How We Collect User Events</h4><p>As Karrot grew, so did the variety and volume of data we needed to collect. Our existing approach couldn’t scale well or stay user-friendly, so we built our own user event logging system.</p><p>Here’s a simplified overview of how user events flow from generation to becoming analyzable data:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/945/1*GoXNx0DqGP-dnQwuAG5Lrg.png\" /><figcaption>User Event Collection Pipeline (Simplified)</figcaption></figure><p>The process breaks down into three main stages: event collection, validation and processing, and storage.</p><ol><li><strong>Event Collection</strong>: When a user action occurs in the Karrot mobile app, the SDK sends data to our event server (managed by the Data team) based on specific conditions or intervals.</li><li><strong>Initial Validation and Routing</strong>: The event server performs basic validation, then forwards events to GCP Pub/Sub.</li><li><strong>Stream Processing and Transformation</strong>: GCP Dataflow handles real-time validation of key fields, short-window deduplication, and data flattening.</li><li><strong>Storage and Error Handling</strong>: Throughout the pipeline, data is stored in GCS and BigQuery. Invalid events are routed to a <em>Dead Letter Queue (DLQ)</em> Pub/Sub and stored in a separate BigQuery table for later analysis and debugging.</li><li><strong>Batch Deduplication</strong>: A subsequent batch job performs another round of time-window-based deduplication to improve data accuracy.</li><li><strong>Final Data Loading</strong>: Data is loaded into a format that team members can query directly. Common fields are stored in a flattened structure for immediate access, while event-specific parameters are stored as JSON for flexibility.</li></ol><h4>1.2. User Event Schema</h4><p>Once data reaches BigQuery, proper interpretation becomes essential for meaningful analysis.</p><p>That’s where <em>user event schemas</em> come in. A schema defines what each log means and what fields it contains — the event type, expected parameters, and data formats.</p><p>Here’s why schemas matter:</p><ol><li><strong>They identify who owns each event.<br></strong>With hundreds of events generated across the company, it can be unclear who’s responsible for each one. Without knowing who created and maintains an event, operations become difficult. So we assign an owner to each event.</li><li><strong>They enable domain-based event classification.<br></strong>As our service grew, we needed to organize events systematically. For company-wide analysis, you might want to filter events related to specific domain only. To support this, we define a domain for each event.</li><li><strong>They allow custom parameters per event.<br></strong>All events share common fields like event_name, timestamp, and event_id. But each event also has unique information — custom parameters. Without documentation of what these parameters mean and their types, writing queries becomes confusing. You end up constantly checking whether a value is a string or number, or what the exact field name is.</li></ol><p>Once you add an event schema, BigQuery automatically creates a table for that event. Custom parameters that were previously stored as JSON are now exposed as regular columns, making SQL queries much simpler:</p><pre>SELECT <br>  event_id,     -- common field<br>  event_name,   -- common field<br>  user_id,      -- common field<br>  banner_id,    -- custom parameter<br>  banner_title  -- custom parameter<br>FROM `event_dataset.event_name`</pre><p>No more complex queries to extract values from JSON — custom parameters like banner_id are directly queryable, making analysis much easier.</p><h3>2. Before: Managing Event Schemas with Git-Based Code</h3><p>User event schemas are a critical system for making collected data analyzable. They’re primarily used to define team-specific custom fields and manage ownership, beyond the common logging fields.</p><p>These schemas need to be managed easily but consistently by anyone who wants to analyze data. But at the time, Karrot managed schemas through Git-based code. Without standardized event naming conventions, we started experiencing various operational challenges.</p><h4>2.1. The Problems</h4><p>Managing schemas in code without standardized event names led to multiple challenges. The biggest issue was that adding a single schema required way too much effort.</p><blockquote><strong>Problem 1: Complexity of Code-Based Schema Management</strong></blockquote><p>Creating a schema required this multi-step process:</p><ol><li>Write a JSON schema file in the data pipeline codebase (requires coding knowledge)</li><li>Pass validation and formatting CI checks</li><li>Create a PR</li><li>Go through review cycles with the Data team</li><li>Once the PR is merged, a queryable BigQuery schema is auto-generated</li></ol><p>The schema file in step 1 had to be written manually in Spark’s StructType JSON format:</p><pre>// client_{action_type}_{service}_{object}.json<br>{<br>  &quot;type&quot;: &quot;struct&quot;,<br>  &quot;metadata&quot;: {<br>    &quot;description&quot;: &quot;Item click event&quot;,<br>    &quot;owners&quot;: [&quot;data@daangn.com&quot;],<br>    &quot;domains&quot;: [&quot;data&quot;]<br>  },<br>  &quot;fields&quot;: [<br>    {<br>      &quot;name&quot;: &quot;id&quot;,<br>      &quot;type&quot;: &quot;string&quot;,<br>      &quot;nullable&quot;: false,<br>      &quot;metadata&quot;: {<br>        &quot;comment&quot;: &quot;Event ID&quot;<br>      }<br>    }<br>  ]<br>}</pre><p>Since schemas supported nested structures, they could get quite complex:</p><pre>{<br>  &quot;name&quot;: &quot;extra&quot;,<br>  &quot;type&quot;: {<br>    &quot;type&quot;: &quot;struct&quot;,<br>    &quot;fields&quot;: [<br>      {<br>        &quot;name&quot;: &quot;random&quot;,<br>        &quot;type&quot;: {<br>          &quot;type&quot;: &quot;struct&quot;,<br>          &quot;fields&quot;: [<br>            {<br>              &quot;name&quot;: &quot;parent_item_id&quot;,<br>              &quot;type&quot;: &quot;string&quot;,<br>              &quot;nullable&quot;: true,<br>              &quot;metadata&quot;: {<br>                &quot;comment&quot;: &quot;Parent item ID&quot;<br>              }<br>            }<br>          ]<br>        }<br>      }<br>    ]<br>  }<br>}</pre><p>Step 1 was overly complicated. Even adding a simple field meant filling out metadata, nullable, type, and other attributes. Typos and formatting mistakes were common.</p><p>With deeply nested struct structures, missing a single bracket or comma would fail CI.</p><blockquote><strong>Problem 2: Long Review Cycles</strong></blockquote><p>Other teams had to write JSON and submit PRs, which required Data team review. Convention violations, type errors, insufficient descriptions — various issues would trigger revision requests, leading to back-and-forth cycles that ate up significant time.</p><blockquote><strong>Problem 3: Inconsistent Event Naming</strong></blockquote><p>Without enforced naming conventions, event names ended up in various formats:</p><p>Example 1: Same service, different casing</p><ul><li>home_feed vs homeFeed (snake_case vs camelCase)</li></ul><p>Example 2: Same action, different words</p><ul><li>show_article vs shown_article</li><li>view vs shown</li></ul><blockquote><strong>Problem 4: Screen Name Confusion and Management Difficulties</strong></blockquote><p>Different teams called the same screen by different names. Some named screens based on functionality, others based on product specs. Without a unified standard, consistency gradually broke down. Screen information was scattered across team-specific Notion pages and separate documents.</p><p>This structure affected not just engineers working directly with event schemas, but also various roles that relied on logs. Here’s a summary of the difficulties each role experienced:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/936/1*0S5UGgmSa2yLdpKXzJmJIw.png\" /></figure><p>Schemas managed in code without a unified event system slowed down the entire workflow beyond just one team’s inconvenience.</p><h4>2.2. The Solutions</h4><p>To address these challenges, the Data team set a few key directions:</p><blockquote><strong>1. Establish a standardized user event system company-wide.</strong></blockquote><p>We decided to unify the different event naming conventions across teams into a common language — not team-specific jargon, but a common language everyone could use. We believed a consistent standard was necessary before logs could become company-wide assets.</p><p>So we standardized all event names. Now when someone mentions <em>“chat button click on the fleamarket listing detail screen,” </em>there’s no ambiguity — everyone knows exactly what event that is. This reduces communication overhead and makes data discovery much faster.</p><blockquote><strong>2. Build an admin platform for defining user event schemas via UI instead of code.</strong></blockquote><p>We determined that code-based schema management, limited to certain teams and roles, had inherent limitations. So we decided to build an admin platform where anyone could define schemas directly through a UI. The system would automatically generate event names and formats according to conventions, maintaining consistency automatically.</p><p>Once you register a screen in the admin, you can see all events occurring on that screen in one place. Wondering <em>“what events exist on the fleamarket listing detail screen?”</em> Now anyone — regardless of team or role — can look it up instantly.</p><blockquote><strong>3. Create a CLI that safely converts user event schemas to typed code for each programming language.</strong></blockquote><p>Define schemas in one place — Event Center, and the CLI automatically generates platform-specific code for IOS, Android, and Webview. This catches common errors like missing fields or type mismatches at compile time.</p><h3>3. Step One: Company-Wide Event System Overhaul</h3><p>To solve these problems, we first established a company-wide consistent event system. We decided that just changing tools while leaving different team rules in place wouldn’t be a fundamental fix. To create consistency across teams, we built the following event naming convention:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/903/1*gjKed2ID3b3BkIW9CZMkqg.png\" /><figcaption>Event Naming Convention</figcaption></figure><blockquote><strong>1. User event must follow a three-level hierarchy: Service → Screen → Action (Event).</strong></blockquote><ul><li><strong>Service</strong>: The top-level unit representing the business domain.</li><li><strong>Screen</strong>: Belongs to a service. Represents each screen the user sees.</li><li><strong>Event</strong>: Belongs to a screen. Represents user actions on that screen.</li></ul><blockquote><strong>2. User event name must follow the format: client_{action}_{service}_{screen}_{object}</strong></blockquote><ul><li>Actions are defined in past tense.</li><li>Elements are separated by snake_case, and individual elements use camelCase.</li></ul><p>In practice, we also defined separate conventions for UI elements like bottomsheets and dialogs, but I’ll keep this overview focused on the core concepts.</p><p>With this naming convention, you can now tell which service and screen an event belongs to just by looking at its name.</p><h3>4. Step Two: Event Center — User Events Management Platform</h3><p>After establishing a company-wide user event system, we needed a tool that would make it easy to define events following these rules. Having standards is pointless if defining and managing events remains difficult.</p><p>So we developed a log management system for systematically managing user events. Let me walk you through each step.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*YOQRb6ZIhkXSE895pdOQcA.png\" /></figure><h4>4.1. Service Management</h4><p>You can view and manage all company services — each service represents a product domain within Karrot, like Payment or Jobs. Events are organized by service.</p><h4>4.2. Screen Management</h4><p>As mentioned earlier, different teams called the same screen by different names, and documentation was scattered, making it hard to understand what events belong to each screen. To solve this, we built functionality to register and manage screens.</p><p>Once you register a screen, you can add the events that occur on it. Now all events for that screen are visible in one place.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*5S3_0mLzvNCKrIx0piSbkw.png\" /><figcaption>Register a screen</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*KuIHkElhvxtY6o2oPr804w.png\" /><figcaption>Screen Detail</figcaption></figure><h4>4.3. Defining User Events</h4><p>Select the screen where you want to add logging, then register and manage event schemas using a consistent log structure.</p><p>Throughout this process, you don’t need to know anything about Spark StructType or JSON schemas. The system automatically handles:</p><ul><li>Applying naming conventions</li><li>Generating Spark StructType JSON-based schemas</li><li>All validation checks that used to require reviews and CI</li><li>BigQuery View Table creation</li></ul><p>Now anyone can register user event schemas with just a few clicks. Automated review processes have significantly improved time efficiency.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1022/1*grqeU1OwFzCh-ap1rHzfYA.png\" /><figcaption>Add User Event to Screen</figcaption></figure><h4>4.4. QA for User Events</h4><p>After implementing logging, developers often wonder <em>“is this actually being collected properly?”</em> In Event Center, internal team members can query logs they generated using their own user ID.</p><p>Here’s how the QA process works:</p><ol><li>Developer implements logging code and performs the action on their device.</li><li>In Event Center, search by your ID to view events you just triggered in near real-time, or check events from a specific time period.</li><li>Immediately verify whether the event was collected correctly and parameters contain expected values.</li></ol><p>No need to run BigQuery queries directly or check the app manually. Questions like <em>“is </em><em>item_id being captured correctly?&quot;</em> get instant answers.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1005/1*rKWCzy6mjQfgLIOarRCQgg.png\" /><figcaption>Event Tracking</figcaption></figure><h3>5. Type-Safe Code Generation via CLI</h3><p>Once you define an event in Event Center, developers can auto-generate type-safe code using the CLI. With help from the Mobile team, we developed CLIs for each platform:</p><ul><li><strong>iOS</strong>: Generates Swift types</li><li><strong>Android</strong>: Generates Kotlin types</li><li><strong>Webview</strong>: Generates TypeScript interfaces</li></ul><h4>Webview TypeScript Code Generation Example</h4><p>The CLI transforms Spark StructType JSON schemas into TypeScript:</p><pre>// package.json<br>{<br>  &quot;scripts&quot;: {<br>    &quot;codegen&quot;: &quot;event-center-codegen generate&quot;<br>  }<br>}<br><br>// Usage<br>pnpm codegen</pre><p><strong>Auto-generated code</strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/754/1*U1YmEBbtngpkqqipDR4r4A.png\" /></figure><p>Developers simply use the generated types. If a field name is misspelled, it triggers a compile error. Logging is now safer with IDE autocomplete and type checking.</p><h4>Wrapping Up</h4><p>I’ve introduced you to Event Center, the log management system our team built to systematically manage user events. Event Center isn’t a tool born from one team’s idea —it’s the result of collaboration across multiple teams and roles. We shared our pain points and aligned our perspectives throughout the design process.</p><p>Data analysts defined the consistent event system and helped establish standards for key screens and user events. Data engineers built reliable pipelines and ensured data quality. As a frontend engineer, I created the user-friendly admin interface and the CLI to improve developer experience.</p><p>When rolling out Event Center, we worked closely with the Mobile team and developers across teams. Together, we unified previously scattered event definitions into a single system and reorganized everything by screen. This migration brought our company-wide event system to production.”</p><p>Event Center isn’t just one team’s tool — it’s an attempt to collectively change how we handle user events at Karrot.</p><p>That said, challenges remain. While Event Center solved many problems, it’s not a perfect solution. As people started using it, we discovered new areas to improve.</p><h4>User Experience Improvements</h4><ul><li>Adding an event still requires multiple clicks and inputs. We need faster, simpler methods.</li><li>Currently, only single screens can be registered, so when UI varies based on success/failure states, each state needs its own screen. This needs improvement too.</li></ul><h4>Taking Automation Further</h4><ul><li>We still have limitations in pinpointing exactly which UI element triggered an event on a given screen.</li><li>What if we could integrate with <em>Figma</em> to define events at the design stage and auto-generate code? We want to create an environment where designers, PMs, and engineers can discuss events while looking at the same screen.</li></ul><h4><strong>Analytics Tool Extensions</strong></h4><ul><li>We’re considering automatic calculation of basic metrics like CTR, PV, and AU from logged data, and UI-based experiment metric configuration. The goal is to move beyond just collecting logs to enabling immediate decision-making.</li></ul><p>We plan to tackle these challenges one by one as Event Center continues to evolve.</p><p>This year, the Data team is taking another step toward our vision — <em>making data-driven decisions for users every day.</em> Event Center was one effort along that journey.</p><p>Our team is working to improve everything from how we collect logs to how we interpret and leverage data. Interested in this work? If you want to be part of building systems that turn data into better products and decisions, we’d love to chat. Check out our open positions below:</p><ul><li><a href=\"https://about.daangn.com/jobs/7507320003/\">Data Analytics Engineer</a></li><li><a href=\"https://about.daangn.com/jobs/4300801003/\">Software Engineer</a></li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=387c58b10530\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://medium.com/daangn/building-event-center-karrots-user-event-management-platform-387c58b10530\">Building Event Center: Karrot’s User Event Management Platform</a> was originally published in <a href=\"https://medium.com/daangn\">당근 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2026-01-12T01:50:33.000Z",
    "url": "https://medium.com/daangn/building-event-center-karrots-user-event-management-platform-387c58b10530?source=rss----4505f82a2dbd---4"
  },
  {
    "publisherId": "daangn",
    "publisherName": "당근마켓 테크",
    "specTitle": "React Native",
    "categories": [
      "mobile",
      "frontend"
    ],
    "specUrl": "https://medium.com/feed/daangn",
    "title": "당근의 사용자 행동 로그 관리 플랫폼: 이벤트센터 개발기",
    "partialText": "<h4>코드로 관리하던 사용자 행동 로그를 플랫폼으로 만든 이유</h4><p>안녕하세요. 당근 데이터가치화팀에서 프론트엔드 엔지니어로 일하고 있는 <em>미카(Mika.kang)</em>예요.</p><p>당근에서는 수많은 사용자 행동 로그가 매일 쌓이고 있어요. 이 로그들은 실험을 설계하고, 제품을 개선하고, 의사결정을 내리는 데 중요한 역할을 해요. 하지만 로그가 많아질수록 관리 방식의 중요성도 함께 커졌어요.</p><p>그래서 전사 로그 체계를 다시 정리했고, 사용자 행동 로그를 관리하는 시스템, <em>이벤트센터</em>를 새로 만들었어요. Git과 코드로 관리하던 방식을 UI 중심으로 바꾸고, 사람이 직접 처리하던 작업은 최대한 자동화했어요. 사용자 행동 로그를 더 일관되고 안전하게 다루기 위해서요.</p><p>이 글에서는 전사 로그 체계를 개편하게 된 배경부터, 이벤트센터를 어떻게 설계하고 구현했는지까지 과정을 이야기해보려고 해요. 로그가 점점 늘어나면서 관리가 부담이 되기 시작한 분들께 이 글이 작은 힌트가 되기를 바라요!</p><h3>1. 사용자 행동 로그 — 데이터 기반 의사결정의 시작점</h3><p>매일 수백만 명의 사용자가 당근 앱을 사용하며 각자 다양한 행동 데이터를 남겨요. <em>“중고거래 게시글을 봤다”, “채팅 버튼을 눌렀다”, “관심 목록에 추가했다”</em> 같은 작은 행동 하나하나가 모여 데이터가 되죠.</p><p>이 데이터는 사용자 경험을 개선하고, 제품 의사결정의 근거가 돼요. 예를 들어 <em>“게시글 상세 화면에서 채팅 버튼을 누르는 비율이 낮다면, 버튼 위치를 바꿔볼까?”</em> 같은 결정을 내릴 수 있게 되어요. 감이 아니라 데이터를 기반으로 판단할 수 있게 되는 거죠.</p><p>하지만 이러한 사용자 행동 데이터를 수집하고 분석하는 과정은 생각보다 단순하지 않았어요. 여러 가지 어려움이 많았죠. 로그의 양이 늘어날수록 점차 운영 방식의 한계를 마주하게 되었어요.</p><p>이 어려움을 더 자세히 설명하기 전에, 먼저 당근에서 사용자 행동 로그가 어떤 방식으로 수집되는지부터 간단하게 짚어보려고 해요.</p><h4>1.1. 사용자 행동 로그 수집 방식</h4><p>당근이 성장하면서 수집하는 데이터의 종류와 양도 빠르게 늘어났어요. 기존 방식으로는 확장성과 사용성을 함께 챙기기 어려웠고, 그래서 자체 사용자 행동 로그 시스템을 구축해서 사용하고 있어요.</p><p>아래는 사용자 행동 로그가 발생한 뒤, 분석 가능한 데이터로 저장되기까지의 흐름을 간단히 정리한 그림이에요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*ocL8AWQ8skqvoPD6Fhbfjg.png\" /><figcaption>사용자 행동 로그 수집 파이프라인 (간소화 버전)</figcaption></figure><p>전체 과정은 크게 이벤트 수집, 검증과 처리, 저장 단계로 나뉘어요.</p><ol><li><strong>이벤트 수집</strong> : 당근 모바일 앱에서 특정 사용자 행동이 발생하면, SDK로 특정 조건이나 주기에 따라 데이터가치화팀이 관리하는 이벤트 서버로 전송돼요.</li><li><strong>1차 검증 및 전달</strong> : 이벤트 서버는 기본적인 유효성 검사를 수행한 후, GCP Pub/Sub으로 이벤트를 전달해요.</li><li><strong>스트리밍 처리 및 정제</strong> : GCP Dataflow에서 실시간 스트리밍으로 주요 필드의 유효성을 검증하고, 짧은 시간 내 중복 제거(short window deduplication) 및 데이터 변환(flatten)을 진행해요.</li><li><strong>저장 및 에러 처리: </strong>처리 과정 전반에서 데이터는 GCS와 BigQuery에 저장돼요. 유효하지 않은 이벤트는 DLQ(Dead Letter Queue) Pub/Sub으로 보내지고, 별도의 BigQuery 테이블에 저장돼요. 이후 원인 분석이나 개선에 활용할 수 있어요.</li><li><strong>배치 중복 제거</strong> : 이후 배치 작업으로 한 번 더 <em>시간 윈도우 기반 중복 제거</em>를 진행해요. 데이터 정확도를 높이기 위한 단계예요.</li><li><strong>최종 데이터 적재</strong> : 구성원들이 바로 사용할 수 있는 형태로 데이터 적재가 완료돼요. 공통 필드는 flatten된 형태로 저장돼 바로 조회할 수 있고, 이벤트별로 다른 파라미터는 JSON 형태로 저장해 유연성을 확보했어요.</li></ol><h4>1.2. 사용자 행동 이벤트 스키마</h4><p>이벤트 파이프라인을 통해 데이터가 BigQuery에 적재되면, 이제 이 데이터를 어떻게 해석할지가 중요해지는데요. 단순히 로그가 쌓이는 것만으로는 분석이 어렵기 때문이에요.</p><p>그래서 이때 추가로 필요한 게 <em>사용자 행동 이벤트 스키마</em>예요. 이벤트 스키마는 각 로그가 어떤 의미를 가지는지, 어떤 필드로 구성되어 있는지를 정의해요. 어떤 이벤트인지, 어떤 파라미터가 들어오는지, 값은 어떤 형태인지까지 함께 정리돼 있어요.</p><p>이벤트 스키마가 필요한 이유를 아래에서 더 자세히 알려드릴게요.</p><ol><li><strong>이벤트의 관리 주체를 알 수 있어요.<br></strong>전사에서 수백 개의 이벤트가 발생하다 보니, 문제가 생겼을 때 누구에게 물어봐야 하는지 모르는 경우가 생겨요. 이 이벤트를 누가 만들었고, 누가 책임지고 관리하는지 알 수 없으면 운영이 어려워져요. 그래서 각 이벤트마다 오너를 지정해요.</li><li><strong>도메인별로 이벤트를 분류할 수 있어요.<br></strong>서비스가 커지면서 이벤트를 체계적으로 분류할 필요도 생겼어요. 전사 단위 분석을 하다 보면 중고거래와 관련된 이벤트만 모아서 보고 싶은 경우도 있어요. 이런 요구를 충족하기 위해 각 이벤트마다 도메인을 함께 정의해요.</li><li><strong>이벤트별로 커스텀한 파라미터를 정의할 수 있어요.<br></strong>모든 이벤트에는 event_name, timestamp, event_id 같은 공통 필드가 있어요. 동시에각 이벤트마다 고유한 정보(커스텀 파라미터)도 존재하죠. 이런 커스텀 파라미터가 어떤 의미를 가지는지, 타입은 무엇인지 정의돼 있지 않으면 쿼리할 때 혼란이 생겨요. 이 값이 문자열인지 숫자인지, 필드 이름이 정확히 무엇인지 매번 다시 확인해야 하거든요.</li></ol><p>이벤트 스키마를 추가하면 BigQuery에 이벤트별 테이블이 자동으로 생성돼요. 기존의 JSON 형태로 저장되던 커스텀 파라미터도 일반 컬럼처럼 펼쳐져서, SQL 쿼리로 바로 접근할 수 있어요.</p><pre>SELECT <br>  event_id,     -- 공통 필드<br>  event_name,   -- 공통 필드<br>  user_id,      -- 공통 필드<br>  banner_id     -- 커스텀 파라미터<br>  banner_title  -- 커스텀 파라미터<br>FROM `이벤트 데이터셋.이벤트명`</pre><p>JSON에서 값을 꺼내는 복잡한 쿼리 없이, 커스텀 파라미터도 banner_id처럼 바로 조회할 수 있어서 분석이 훨씬 간편해져요.</p><h3>2. 이전의 사용자 행동 이벤트 스키마 정의 방식 — Git 기반 코드로 관리</h3><p>사용자 행동 로그 스키마는 수집된 사용자 행동 데이터를 분석할 수 있도록 도와주는 중요한 시스템이에요. 주로 공통으로 로깅되는 필드외에 팀에서 사용하는 커스텀한 필드 및 오너십 관리를 위해서 정의되고 있어요.</p><p>이러한 스키마는 데이터 분석을 원하는 누구나 일관된 방식으로 쉽고 빠르게 관리할 수 있어야해요. 하지만 당시 당근에서는 <strong>이 스키마가 Git 기반 코드로 관리되고 있었어요. 이벤트 이름에 대한 컨벤션이 통일되어 있지 않다 보니, 운영하면서 여러 가지 불편함이 생기기 시작했어요.</strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*rRLWGfae-s6JZirMdKzYRQ.png\" /></figure><h4>2.1 문제인식</h4><p>스키마가 코드로 관리되고, 이벤트 이름도 통일돼 있지 않다 보니 운영 과정에서 여러 가지 어려움이 생겼어요. 그중 가장 크게 느낀 건 스키마를 한 번 더 추가하는 데 드는 비용이 너무 컸다는 점이었어요.</p><p><strong>문제 1: 코드 기반 스키마 관리의 복잡함</strong></p><p>스키마를 생성하기 위해서는 아래와 같은 복잡한 과정을 거쳐야 했어요.</p><ol><li><strong>데이터 파이프라인 코드에 json 스키마 파일 작성 (코드 지식 필요)</strong></li><li><strong>유효성 검사 및 포매팅 CI 통과</strong></li><li><strong>PR 생성</strong></li><li><strong>데이터가치화팀의 리뷰 ↔ 수정 반복</strong></li><li><strong>PR 머지하면 BigQuery 조회 가능한 스키마 자동 생성</strong></li></ol><p>1번에서 작성하는 스키마 파일은 Spark의 StructType JSON 형태로 직접 작성해야했어요.</p><pre>// client_{action_type}_{service}_{object}.json<br>{<br>  &quot;type&quot;: &quot;struct&quot;,<br>  &quot;metadata&quot;: {<br>    &quot;description&quot;: &quot;아이템 클릭 이벤트&quot;,<br>    &quot;owners&quot;: [<br>      &quot;data@daangn.com&quot;<br>    ],<br>    &quot;domains&quot;: [<br>      &quot;sample&quot;<br>    ]<br>  },<br>  &quot;fields&quot;: [<br>    {<br>      &quot;name&quot;: &quot;id&quot;,<br>      &quot;type&quot;: &quot;string&quot;,<br>      &quot;nullable&quot;: false,<br>      &quot;metadata&quot;: {<br>        &quot;comment&quot;: &quot;이벤트 id&quot;<br>      }<br>    },<br>    ...<br>  ]<br>}</pre><p>스키마는 중첩 구조를 지원하기때문에, 아래와 같이 복잡한 구조로 중첩될 수도 있어요.</p><pre>{<br>  &quot;name&quot;: &quot;extra&quot;,<br>  &quot;type&quot;: {<br>    &quot;type&quot;: &quot;struct&quot;,<br>    &quot;fields&quot;: [<br>      {<br>        &quot;name&quot;: &quot;random&quot;,<br>        &quot;type&quot;: {<br>          &quot;type&quot;: &quot;struct&quot;,<br>          &quot;fields&quot;: [<br>            {<br>              &quot;name&quot;: &quot;parent_item_id&quot;,<br>              &quot;type&quot;: &quot;string&quot;,<br>              &quot;nullable&quot;: true,<br>              &quot;metadata&quot;: {<br>                &quot;comment&quot;: &quot;부모 item  id&quot;<br>              }<br>            }<br>            ...<br>          ]<br>        }<br>      }<br>    ]<br>  }<br>}</pre><p>이 중 문제는 1번 단계의 진입장벽이 높았다는 거예요. 단순한 필드 하나를 추가하려고 해도 metadata, nullable, type 같은 속성을 전부 채워야 했고, 오타나 형식 실수도 자주 발생했어요.</p><p>게다가 스키마는 중첩 구조를 지원하다 보니, 실제로는 더 복잡한 형태를 자주 다뤄야 했어요. 예를 들어아래처럼 struct 안에 struct가 여러 번 중첩되기도 해요.</p><p>예를 들어, struct 안에 struct, 그 안에 또 fields … 하나라도 괄호나 쉼표를 빠뜨리면 CI가 실패했어요.</p><p><strong>문제 2: 긴 리뷰 사이클</strong></p><p>기존에는 다른 팀 구성원들이 JSON을 작성하고 PR을 올리려면, 저희 데이터가치화팀의 리뷰를 받아야 했어요. 컨벤션 위반이나 타입 실수, 설명이 부족한 경우 등 여러 이유로 수정 요청이 오곤 했고, 그때마다 다시 코드를 고치고, 다시 리뷰를 기다리고… 시간이 많이 소요됐죠.</p><p><strong>문제 3: 일관성 없는 이벤트 네이밍 체계</strong></p><p>이벤트 이름에 대한 컨벤션이 강제되지 않았다 보니, 다양한 형식으로 이벤트 이름이 만들어졌어요.</p><p>예시 1) 같은 서비스, 다른 표기</p><ul><li>home_feed vs homeFeed (snake_case vs camelCase)</li></ul><p>예시 2) 같은 액션, 다른 표현</p><ul><li>show_article vs shown_article</li><li>view vs shown</li></ul><p><strong>문제 4: 화면 이름의 혼란 및 관리의 어려움</strong></p><p>같은 화면을 두고도 팀마다 부르는 이름도 달랐어요. 어떤 팀은 기능을 기준으로, 어떤 팀은 기획 문서 기준으로 화면을 부르다 보니, 기준이 자연스럽게 흐려진 거예요. 화면 정보도 팀별 노션이나 별도 문서에 나뉘어 관리되고 있었고요.</p><p>이런 구조는 이벤트 스키마를 직접 다루는 엔지니어뿐 아니라, 로그를 활용하는 여러 직군에도 영향을 주고 있었어요. 실제로 각 직군에서 느끼는 어려움을 아래에 간단히 정리해봤어요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/878/1*cRo2x9D9hdGNfyteYnUPUA.png\" /></figure><p>이처럼 스키마가 코드로 관리되고, 이벤트 체계가 통일되지 않은 구조는 특정 팀의 불편을 넘어, 로그를 활용하는 전체 흐름을 느리게 만들고 있었어요.</p><h4>2.2 해결방안 도출</h4><p>사내 구성원들이 이벤트를 다루며 겪는 어려움을 해결하기 위해, 데이터가치화팀은 몇 가지 방향을 먼저 설정했어요.</p><p><strong>1. 전사 공통의 일관된 사용자 행동 로그 체계를 만들어요.<br></strong>팀마다 다르게 쓰던 이벤트 이름을 각 팀의 개별 언어가 아니라 전사 공통의 언어로 통일하기로 했어요. 로그를 전사 자산으로 활용하려면 먼저 같은 기준으로 이해할 수 있는 체계가 필요했다고 판단했기 때문이에요. 그래서 팀마다 다르게 쓰이던 이벤트 이름을 하나의 기준으로 정리했어요. 예를 들면<em> “중고거래 게시글 상세 화면의 채팅 버튼 클릭”</em>이라고 말하면, 이벤트 이름만 보고도 모두가 특정 이벤트를 떠올리는 거죠. 커뮤니케이션 비용이 줄어들고, 데이터를 찾는 시간도 단축돼요.</p><p><strong>2. 코드대신 UI로 사용자 행동 스키마를 정의할 수 있는 어드민 플랫폼을 만들어요.<br></strong>스키마로 코드를 관리하는 방식은 일부 팀, 직군에만 맡기는 방식이라 한계가 있다고 판단했어요. 그래서 사용자 스키마를 UI에서 모두 직접 정의할 수 있는 어드민 플랫폼을 만들기로 했어요. 시스템이 이벤트 이름 및 형식을 자동으로 컨벤션에 맞게 생성하는 방식이에요.. 체계가 자동으로 적용되어서 일관성이 유지돼요.</p><p>어드민에 화면을 등록하면, 해당 화면에서 발생하는 모든 이벤트를 한곳에서 확인할 수 있어요. <em>“중고거래 게시글 상세 화면에 어떤 이벤트가 있지?”</em> 궁금할 때 팀과 직군에 관계 없이 누구나 바로 조회할 수 있어요.</p><p><strong>3. 사용자 행동 스키마를 각 프로그래밍 언어의 타입으로 안전하게 변환하는 CLI를 만들어요.<br></strong>한 곳(이벤트센터)에서 스키마를 정의하면, CLI가 각 플랫폼에 맞는 코드를 자동으로 생성해줘요. 덕분에 컴파일 타임에 자주 생기는 필드 누락이나 타입 실수 같은 오류를 사전에방지할 수 있어요.</p><h3>3. 해결의 시작: 전사 이벤트 체계 개편 — 모두가 같은 규칙으로!</h3><p>문제를 해결하기 위해 먼저 전사 공통의 일관된 이벤트 체계를 정립했어요. 팀마다 다른 규칙을 그대로 둔 채 도구만 바꾸는 건 근본적인 해결이 아니라고 판단했거든요. 모두가 같은 규칙으로 말할 수 있도록 아래와 같이 이벤트 네이밍 컨벤션을 구축하기로 했죠.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*qzOluscoMhCWP7UGoMtxTw.png\" /><figcaption>이벤트 네이밍 컨벤션</figcaption></figure><p><strong>1. 사용자 행동 로그는 서비스 — 스크린 — 액션(이벤트) 3단계의 계층 구조를 따라야 해요.</strong><br>- <strong>서비스(Service)</strong>: 최상위 단위예요. 비즈니스 도메인을 의미해요.<br>- <strong>스크린(Screen)</strong>: 서비스에 종속돼요. 사용자가 보는 각각의 화면을 의미해요.<br>- <strong>이벤트(Event)</strong>: 스크린에 종속돼요. 해당 화면에서 발생하는 사용자 행동을 의미해요.</p><p><strong>2. 사용자 행동 로그 이름은 client_{action}_{service}_{screen}_{object} 형태를 따라야해요.<br>- </strong>action은 과거형으로 정의해요.<br>- 각각의 요소는 snake_case로 구분하고, 하나의 요소는 camelCase로 정의해요.</p><p>실제로는 bottomsheet, dialog 같은 UI 요소에 대한 컨벤션도 별도로 정의되어 있었어요. 다만 이 글에서는 전사 이벤트 체계의 핵심 개념만 간략하게 소개할게요.</p><p>이 기준을 적용한 뒤로는 이벤트 이름만 봐도 어느 서비스의 어떤 화면에서 발생한 이벤트인지 바로 파악할 수 있게 되었어요.</p><h3>4. 해결책: 사용자 행동 로그 관리 플랫폼 ‘이벤트센터’ — 코드 대신 UI로, 간단하게</h3><p>전사 공통의 사용자 행동 로그를 체계한 정리한 다음에는 이 체계를 쉽게 사용하면서 이벤트를 정의할 수 있는 도구가 필요하다고 판단했어요. 규칙은 존재하는데, 정의하고 관리하는 과정이 여전히 어렵다면 문제는 근본적으로 해결되지 않으니까요.</p><p>그래서 아래와 같은 플로우로 사용자 행동 로그를 체계적으로 관리할 수 있는 로그 관리 시스템을 개발했어요. 지금부터 각 단계를 더 자세히 하나씩 차근차근 설명해 볼게요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*dGoP7sjMhhLw1LLTUulHbA.png\" /></figure><p><strong>4.1 서비스 관리</strong></p><p>전사의 모든 서비스를 조회하고 관리할 수 있어요. 중고거래, 동네생활, 당근페이 등 서비스별로 분류해서 이벤트를 볼 수 있어요.</p><p><strong>4.2 스크린 관리</strong></p><p>앞서 언급한 것처럼, 같은 화면을 팀마다 다르게 부르거나 문서가 흩어져 있어서 특정 화면의 이벤트를 파악하기 어려웠어요. 이를 해결하기 위해 스크린을 등록하고 관리하는 기능을 만들었어요.</p><p>스크린을 등록하면, 해당 스크린에서 발생하는 이벤트를 추가할 수 있어요. 한 화면에 어떤 이벤트들이 있는지 한곳에서 확인할 수 있게 되었어요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*BPEr0CyHbchg9hju9PopBw.png\" /><figcaption>스크린 등록</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*vgmmhuAN5FU-1vqEIeyeSg.png\" /><figcaption>스크린 상세 조회</figcaption></figure><p><strong>4.3 사용자 행동 로그 정의</strong></p><p>사용자 행동 로그를 심을 화면을 선택하고, 일관된 로그 체계로 이벤트 스키마를 등록하고 관리할 수 있어요.</p><p>이 과정에서 Spark StructType이나 JSON 스키마를 알 필요가 전혀 없어요. 시스템이 자동으로 아래 항목을 처리해요.</p><ul><li>네이밍 컨벤션 적용</li><li>Spark StructType JSON 기반의 스키마 생성</li><li>리뷰 및 CI로 확인하던 유효성 검사가 모두 내재화</li><li>BigQuery View Table 생성</li></ul><p>누구나 손쉽게 몇 번의 클릭으로 사용자 행동 로그 스키마를 등록할 수 있게 되었어요. 또한 리뷰 프로세스가 자동화되어서 시간 효율을 높였어요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*d64wk3I8fQMjrWj3BbAvbA.png\" /><figcaption>스크린에 이벤트 추가하기</figcaption></figure><p><strong>4.4 사용자 행동 로그 QA</strong></p><p>개발자가 로깅을 심고 나서 <em>“이게 잘 쌓이고 있나?”</em> 궁금할 때가 있잖아요. 이벤트센터에서는 내부 구성원이 본인의 ID로 직접 발생시킨 로그를 조회할 수 있어요.</p><p>QA 과정은 이렇게 진행돼요.</p><ol><li>개발자가 로깅 코드를 심고, 본인 기기에서 해당 행동을 수행해요.</li><li>이벤트센터에서 본인 ID로 검색하면, 방금 발생한 이벤트를 준실시간으로 조회하거나, 특정 기간에 발생한 이벤트를 확인할 수 있어요.</li><li>이벤트가 제대로 수집되었는지, 파라미터 값이 의도한 대로 들어갔는지 바로 확인할 수 있어요.</li></ol><p>BigQuery에서 직접 쿼리를 돌리거나 앱에 직접 접속하지않아도, “item_id” 가 제대로 들어가는가?” 같은 질문에 즉시 답할 수 있어요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*uQjOcfi3_R6btOyOhqoHxg.png\" /><figcaption>이벤트 트래킹</figcaption></figure><h3>5. CLI로 타입 안전한 코드 생성</h3><p>사용자 행동 로그 관리 플랫폼인 이벤트센터에서 이벤트를 정의하면, 개발자는 CLI로 타입 안전한 코드를 자동 생성할 수 있어요. 모바일실의 도움으로 네이티브, 웹뷰 각 플랫폼에 맞는 CLI가 개발되었어요.</p><ul><li>iOS: Swift 타입 생성</li><li>Android: Kotlin 타입 생성</li><li>Webview: TypeScript 인터페이스 생성</li></ul><p><strong>Webview의 Typescript 코드 생성 예시</strong></p><p>CLI는 Spark StructType JSON 스키마를 TypeScript로 변환해서 코드를 생성해요.</p><pre># package.json에 명령어 정의<br>&quot;scripts&quot;: {<br>  &quot;codegen&quot;: &quot;event-center-codegen generate&quot;,<br>}<br><br># 명령어 사용<br>pnpm codegen</pre><p><strong>자동 생성된 코드</strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*mbJle36Do042mFyD0dUKnA.png\" /></figure><p>개발자는 생성된 타입을 그대로 사용하기만 하면 돼요. 필드명을 잘못 쓰면 컴파일 에러가 나요. IDE의 자동완성과 타입 체크를 받으며 안전하게 로깅할 수 있게 되었어요.</p><h4>마무리</h4><p>지금까지 사용자 행동 로그를 체계적으로 관리하기 위해 저희 팀에서 직접 구축한 로그 관리 시스템 이벤트센터를 소개해봤어요. 이벤트센터는 한 팀의 아이디어로 만들어진 도구라기보다, 여러 팀과 직군의 고민이 모여 완성된 결과물이에요. 각자가 겪고 있던 페인 포인트를 공유하고, 서로의 관점을 맞춰가며 설계했어요.</p><p>데이터 분석가는 일관된 이벤트 체계를 정의하고, 주요 화면과 사용자 행동 로그의 기준을 함께 정리했어요. 데이터 엔지니어는 안정적인 파이프라인을 구축하고 데이터 품질을 책임졌어요. 프론트엔드 엔지니어인 저는 사용하기 쉬운 어드민과 개발자 경험을 개선하는 CLI를 만들었고요.</p><p>이벤트센터를 실제로 전사에 적용하는 과정에서는 모바일실과 각 팀의 웹뷰 담당자들과 긴밀하게 협업했어요. 기존에 각기 다른 기준으로 정의돼 있던 이벤트를 하나의 체계로 맞추고, 화면 단위로 이벤트를 다시 정리하는 작업을 함께 진행했어요. 이 마이그레이션 과정 덕분에 전사 이벤트 체계를 실제 서비스에 안정적으로 안착시킬 수 있었어요.</p><p>이벤트센터는 특정 팀의 도구라기보다, 당근 안에서 사용자 행동 로그를 다루는 방식을 함께 바꿔보려는 시도의 결과라고 생각해요.</p><p><strong>한편으로 앞으로의 도전도 여전히 남아있어요.</strong> 이벤트센터가 많은 문제를 해결해주긴 했지만, 완벽한 솔루션은 아니에요. 실제로 사용해보면서 새로운 과제들도 분명히 보이기 시작했어요.</p><p><strong>사용성 개선</strong></p><ul><li>이벤트를 추가하기 위해 여러 번의 클릭과 입력이 필요해요. 더 빠르고 간편한 방법이 필요해요.</li><li>또 현재는 단일 스크린만 등록할 수 있어서, 같은 화면이라도 성공과 실패에 따라 UI가 달라지는 경우에는 모든 상태를 개별 스크린으로 관리해야 해요. 이 부분도 개선이 필요한 지점이에요.</li></ul><p><strong>자동화 확대</strong></p><ul><li>특정 화면에서 이벤트가 발생했을 때, 화면의 어떤 요소에서 발생했는지를 정확히 특정하는 데에는 아직 한계가 있어요.</li><li>Figma와 연동해 디자인 단계에서부터 이벤트를 정의하고, 코드까지 자동으로 생성할 수 있다면 어떨까요. 디자이너, PM, 엔지니어가 같은 화면을 보며 이벤트를 논의할 수 있는 환경을 만들고 싶어요.</li></ul><p><strong>분석 도구 확장</strong></p><ul><li>로깅된 데이터를 기반으로 CTR, PV, AU 같은 기본 지표를 자동으로 계산하거나, UI 기반으로 실험 지표를 설정하는 기능도 고민하고 있어요. 로그를 쌓는 데서 그치지 않고, 바로 의사결정으로 이어질 수 있도록요.</li></ul><p>이런 과제들을 하나씩 해결해 나가면서, 이벤트센터도 계속해서 발전시켜 나갈 예정이에요.</p><p>올해 데이터가치화팀은 이런 목표를 향해 한 걸음 더 나아가고 있어요. 매일 데이터를 통해 사용자를 위한 의사결정을 한다는 비전을 실제로 만들어가기 위해서예요. 이벤트센터도 그 과정에서 나온 하나의 시도였고요.</p><p>지금 저희 팀에서는 로그를 쌓는 방식부터, 데이터를 해석하고 활용하는 구조까지 함께 고민하고 있어요. 이 방향에 공감하고, 데이터로 제품과 조직의 의사결정을 바꾸는 일을 직접 만들어보고 싶은 분을 기다리고 있어요. 관심이 생기셨다면 아래 채용 공고를 확인해 보세요.</p><ul><li><a href=\"https://about.daangn.com/jobs/7507320003/\">Data Analytics Engineer 채용 공고</a></li><li><a href=\"https://about.daangn.com/jobs/4300801003/\">Software Engineer, Data 채용 공고</a></li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=e3c240945882\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://medium.com/daangn/%EB%8B%B9%EA%B7%BC%EC%9D%98-%EC%82%AC%EC%9A%A9%EC%9E%90-%ED%96%89%EB%8F%99-%EB%A1%9C%EA%B7%B8-%EA%B4%80%EB%A6%AC-%ED%94%8C%EB%9E%AB%ED%8F%BC-%EC%9D%B4%EB%B2%A4%ED%8A%B8%EC%84%BC%ED%84%B0-%EA%B0%9C%EB%B0%9C%EA%B8%B0-e3c240945882\">당근의 사용자 행동 로그 관리 플랫폼: 이벤트센터 개발기</a> was originally published in <a href=\"https://medium.com/daangn\">당근 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2026-01-08T09:36:40.000Z",
    "url": "https://medium.com/daangn/%EB%8B%B9%EA%B7%BC%EC%9D%98-%EC%82%AC%EC%9A%A9%EC%9E%90-%ED%96%89%EB%8F%99-%EB%A1%9C%EA%B7%B8-%EA%B4%80%EB%A6%AC-%ED%94%8C%EB%9E%AB%ED%8F%BC-%EC%9D%B4%EB%B2%A4%ED%8A%B8%EC%84%BC%ED%84%B0-%EA%B0%9C%EB%B0%9C%EA%B8%B0-e3c240945882?source=rss----4505f82a2dbd---4"
  },
  {
    "publisherId": "daangn",
    "publisherName": "당근마켓 테크",
    "specTitle": "React Native",
    "categories": [
      "mobile",
      "frontend"
    ],
    "specUrl": "https://medium.com/feed/daangn",
    "title": "Standardizing User Activation: How We Built a Shared Data Layer at Karrot",
    "partialText": "<p>Hello, I’m Pepper, a Data Analytics Engineer on the Data Team at Karrot.</p><p>Our team&#39;s vision is to &quot;make user-focused decisions through data every day.&quot; So we don&#39;t just focus on reliably collecting massive amounts of data — we also work on transforming it into trustworthy, easy-to-use formats.</p><p>In this post, I&#39;d like to share how we moved away from manually calculating Activation analysis with ad hoc queries and elevated it to a shared data layer used across the organization.</p><h3><strong>Background</strong></h3><h4>The Limits of Active User Metrics</h4><p>Like many services, Active Users (DAU, WAU, MAU) are essential metrics at Karrot. But the number of Active Users only shows &quot;what happened&quot; — it doesn&#39;t directly explain &quot;why it happened.&quot; For example, you can see that &quot;MAU increased by 10% this month,&quot; but it&#39;s hard to answer questions such as why Active Users changed or what we should do to increase them further.</p><p>To answer these questions, we need a <strong>perspective that doesn&#39;t treat Active Users as a single number but breaks them down into components with distinct characteristics</strong>. That&#39;s precisely what User Activation does.</p><h4><strong>User Activation: Activity States and State Transitions</strong></h4><p>User Activation is a framework that goes beyond simply classifying users as active or inactive. It examines users’ current <strong>activity state </strong>and how they transition between <strong>states </strong>over time.</p><ul><li><strong>Activity states</strong> indicate a user&#39;s state at a specific point in time. For example, states like New, Retained, Reactivated, and Inactive.</li><li><strong>State transitions </strong>represent how users move between activity states over time. For example, transitions like New → Retained, Retained → Inactive, or Reactivated → Inactive.</li></ul><p><strong>Activity states</strong> alone can tell you &quot;how many users are in each state right now,&quot; but they can&#39;t reveal &quot;where they came from&quot; or &quot;what paths lead to churn.&quot; By looking at <strong>state transitions</strong> together, you can understand the paths users take. Segmenting users by these transition patterns enables tailored interpretations and actions across activity levels.</p><p>For example, when the number of Active Users increases, you can use activity states to decompose and explain whether the growth came from new user acquisition or returning existing users. If retention rate drops, you can use state transitions to pinpoint which specific segment is churning more, rather than just concluding &quot;retention rate got worse.&quot;</p><h3><strong>Goals</strong></h3><h4><strong>Why We Needed a Common Layer</strong></h4><p>To analyze user behavior through the lens of User Activation, you need data that already includes each user&#39;s activity state and how that state changes over time. The challenge was that when each team defined and maintained this logic independently, it was difficult to maintain reliable data and a stable pipeline. Team-created data often lacked context about who created it, when, and with what criteria — making it hard to understand or verify results over time. Operational issues, such as failed scheduled queries or reprocessing, sometimes broke idempotency or left data without freshness guarantees. Ultimately, the data existed, but it was often difficult to use with confidence.</p><p>We decided to build an <strong>Activation Layer—a common layer that applies Activation in accordance with unified, organization-level standards</strong>. Our goal was to ensure the reliability and operational stability of results while enabling multiple teams to reuse the same standards.</p><blockquote><strong>User Activation is a framework</strong> for interpreting Active User metrics through states and transitions. The <strong>Activation Layer is a common data layer</strong> that provides per-user state and transition information needed for interpretation, following consistent standards.</blockquote><h4><strong>What We Wanted the Activation Layer to Do</strong></h4><p>After deciding to build the Activation Layer as a shared common layer, our first task was defining &quot;what this layer should provide.&quot; By organizing the recurring questions within our company, we identified the following specific information needs:</p><ul><li>Whether the current activity is New, Retained, or Reactivated (<strong>activity state</strong>)</li><li>How the state changed from the previous period to the current period (<strong>state transition</strong>)</li><li>Whether recent activity has been continuous (<strong>continuity</strong>)</li><li>How long since the last activity before returning (<strong>return interval</strong>)</li><li>How long since the previous active state (<strong>inactivity duration</strong>)</li></ul><p>For example, if a user visited on December 10, December 11, and December 20, we should provide the above information at the daily level, as shown.</p><pre>user_A (daily)<br>- 2025–12–10 NEW<br>- 2025–12–11 RETAINED (prev=2025–12–10, interval=1d)<br>- 2025–12–20 REACTIVATED (prev=2025–12–111,11interval=9d)</pre><p>While we used visits as an example here, User Activation applies not only to app visits but also to core actions such as selling used items, writing community posts, or opening push notifications.</p><h3><strong>Three Challenges We Solved While Designing the Activation Layer</strong></h3><p>Now, let me walk you through how we implemented the Activation Layer. First, here&#39;s an overview of the overall structure.</p><h4><strong>Overall Structure at a Glance</strong></h4><p>We designed the Activation Layer to sit on top of Karrot&#39;s existing DBT project data hierarchy. Instead of using raw event logs directly, we built it in the order of Base (refined) → Fact (action unit) → Activation (state/flow analysis).</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*0w14QIwG2lT219KsuSqiMw.png\" /><figcaption><em>Activation Layer placed on top of DBT project hierarchy (Base/Dimension/Fact)</em></figcaption></figure><blockquote>For more details about Karrot&#39;s data hierarchy structure, please refer to our post &quot;<a href=\"https://medium.com/daangn/dbt%EC%99%80-airflow-%EB%8F%84%EC%9E%85%ED%95%98%EB%A9%B0-%EB%A7%88%EC%A3%BC%ED%95%9C-7%EA%B0%80%EC%A7%80-%EB%AC%B8%EC%A0%9C%EB%93%A4-61250a9904ab\">7 Problems We Faced While Adopting DBT and Airflow.</a>&quot;</blockquote><p>We built the Activation Layer so that three models — FirstLast, Activation, and Activation Status — work together as a set on top of a single Fact model. I&#39;ll explain what each model contains, what role it plays, and how they connect later.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*vocvyTM-tK1ZT74P5dUBbQ.png\" /><figcaption><em>Activation Layer structure where 3 models are sequentially connected based on a Fact model</em></figcaption></figure><p>While building this structure, we faced three main challenges: <strong>reliability, cost, and productivity</strong>. Let me explain how we solved each one.</p><h4><strong>1. Reliability: Clearly Fixing the Reference Action</strong></h4><p>First, if we want to run Activation as a shared layer, we need an explicit reference action. If teams interpret the criteria differently, no one can reuse the data without revalidating it each time. We prioritized <strong>making the reference action obvious at a glance—just by looking at the model name and definition</strong>.</p><p>At first, we tried to map event logs 1:1 to Activation reference actions. But product teams usually log events at the UI level — button clicks, screen views — so a single event can represent different actions depending on its parameters. For example, one &quot;interest button click&quot; event can cover both adding and removing interest. If we used &quot;interest added&quot; as the reference action, we would have to keep filtering for the &quot;add&quot; case every time we queried it.</p><p>Instead of using event logs directly as reference actions, <strong>we should fix the reference actions themselves to be precise units.</strong> Karrot uses DBT for data modeling and manages models with a conceptual distinction called Layers.</p><p>Among them, the Fact Layer defines user actions. It expresses meaningful action units, ranging from simple actions (e.g., &quot;user sent a message&quot;) to actions that require conditions and business logic (e.g., &quot;user actively used the feed&quot;).</p><p>We decided to <strong>define reference actions as Fact models and implement the Activation Layer to use them as inputs</strong>. To make reference actions even more visible at a glance, we established a naming convention where Activation model names include the Fact model name.</p><pre># Naming convention<br>&lt;fact_name&gt;_activation_&lt;time_grain&gt;<br># fact_name: Same as Fact Layer model name (action meaning defined in Fact)<br># time_grain: daily | weekly | monthly<br># Examples<br>users_visited_app_activation_daily<br>users_opened_push_activation_daily<br>users_created_article_activation_daily</pre><p>As a result, Activation models now clearly indicate the reference action from the model name alone, reducing the room for interpretation to vary based on event parameters or filter conditions.</p><h4><strong>2. Cost: Making It Sustainable</strong></h4><p>To calculate Activation, we need to track two timestamps per user: <strong>the first occurrence and the previous occurrence</strong>. Even if users are active on the same day, their Activation state can differ depending on when they last acted. For example, someone who visits on December 20 may be classified as Retained or Reactivated, depending on whether they last visited on December 19 or December 11.</p><p>The problem is that if there&#39;s no pre-calculated table for these values, you have to scan the entire Fact model to find the previous occurrence. In a service environment with large data volumes, such as Karrot, <strong>scan range directly impacts cost and execution time — this was the most significant cost hurdle in operating Activation.</strong></p><p>Therefore, we introduced an intermediate table, FirstLast, to reduce compute costs. At the same time, the storage strategy for FirstLast significantly affects both daily run costs and backfill costs, so we compared three approaches.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*C7UBOrIzANz_XilFxs7bPA.png\" /><figcaption><em>Three candidates considered for FirstLast model implementation</em></figcaption></figure><p><strong>Candidate 1 — Calculate directly from Fact each time</strong></p><p>This approach doesn&#39;t use an intermediate table and scans the entire history each time to get User Activation. The structure is simplest, but it requires scanning the whole Fact model history on every execution, resulting in high daily costs and increased execution time. We ruled this out due to the operational burden of repeated runs.</p><p><strong>Candidate 2 — Keep only the latest value per user</strong></p><p>This approach stores the first and last occurrence in a single record per user. The first occurrence rarely changes once it&#39;s set. The most recent occurrence, however, needs daily updates. Since we only merge users who acted today, each daily run scans just one day of the Fact table. However, because it doesn&#39;t store historical last occurrences separately, backfills still require scanning the entire Fact model range.</p><p><strong>Candidate 3 — Maintain daily snapshots </strong>✅</p><p>This approach stores each user&#39;s previous occurrences as a daily snapshot. To build today&#39;s snapshot, we start from yesterday&#39;s snapshot, update users who were active today, and carry forward the previous values for users who weren&#39;t. As a result, both the intermediate table update and the Activation calculation only need one day of data. That allows us to keep the scan range fixed to a single day for both daily runs and backfills.</p><p>In conclusion, we selected <strong>Candidate 3</strong> for the FirstLast model because backfills occur periodically at Karrot, and this approach minimizes scan volume even during backfills.</p><p>Of course, the snapshot approach has trade-offs too. It increases storage costs as daily snapshots accumulate, and issues on a specific date can cascade to subsequent dates. However, because backfills only need to reload affected partitions, we found this approach more cost-effective and faster than Option 2, which requires full scans. Also, through data quality monitoring, we could detect issues before they spread and respond quickly.</p><h4><strong>3. Productivity: Creating Models for New Actions Without SQL</strong></h4><p>The next challenge we faced was &quot;how can we easily create Activation models for any action?&quot; Activation calculations involve complex logic, such as WINDOW functions, JOINs, and CASE statements. Writing SQL directly each time led to slightly different implementations, resulting in inconsistent schemas.</p><p>We encapsulated the calculation logic in DBT macros. New Activation models can now be created by just specifying the reference Fact model name.</p><p><strong>[Before] Implementing Activation logic directly in SQL</strong></p><pre>-- Partial query to get the user&#39;s first action time and previous action for the monthly activity state<br><br>WITH first_activation AS (<br>    SELECT user_id, MIN(event_date) as first_date<br>    FROM events<br>    WHERE …<br>    GROUP BY user_id<br>),<br><br>monthly_activity AS (<br>    SELECT<br>    user_id,<br>    DATE_TRUNC(&#39;month&#39;, event_date) as month,<br>    LAG(DATE_TRUNC(&#39;month&#39;, event_date)) OVER (<br>    PARTITION BY user_id ORDER BY event_date<br>    ) as prev_month<br>    FROM events<br>    WHERE …<br>),<br><br>… (window functions, joins, CASE branches, etc.)</pre><p><strong>[After] Creating models without writing SQL using DBT Macros</strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*RvO-YWSMQAPsDcSrE4wptw.png\" /><figcaption><em>Sample of implementation code for FirstLast, Activation, Activation Status models using defined DBT Macros</em></figcaption></figure><h3><strong>Final Results</strong></h3><p>To capture the information needed for Activation analysis while meeting the reliability, cost, and productivity as mentioned above, we designed the Activation Layer so that three models operate as a set based on a single Fact model.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/960/1*jA-dOB8dvGIZQIh-8WBB8g.png\" /><figcaption><em>Data flow diagram of the 3 models within the Activation Layer</em></figcaption></figure><ul><li><strong>FirstLast</strong> aggregates each user&#39;s first/last action timestamps into daily snapshots to improve cost efficiency.</li><li><strong>Activation</strong> takes the Fact model and FirstLast model as inputs, produces New/Retained/Reactivated states and return intervals for dates with activity, and returns the intervals.</li><li><strong>Activation Status</strong> includes inactive users to provide state transitions, continuity, and inactivity duration for all dates.</li></ul><p>These three models are connected sequentially to build the states and flows required for Activation analysis progressively.</p><h4><strong>Three-Model Structure and Data Examples</strong></h4><p>To quickly understand each model&#39;s data composition and how it works, let&#39;s walk through an example: User A visits for the first time on December 10 and then returns on December 11 and December 20.</p><p><strong>1. FirstLast Model</strong></p><p>FirstLast is an intermediate model that stores each user&#39;s first/last action timestamps as daily snapshots. Every day, it fetches the previous day&#39;s snapshot, updates the last active date for users with activity today, and carries forward the previous day&#39;s values for users without activity to generate snapshots for all users.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*JSRErBnJmLBXYbgWN3Di9g.png\" /><figcaption><em>Data example showing how FirstLast model is generated based on User A’s Fact data</em></figcaption></figure><p>For User A, on their first visit on December 10, we set both the <strong>first active date</strong> and <strong>last active date</strong> to December 10. When they return on December 11, we update only the <strong>last active date</strong>. From December 12 to 19, the user doesn&#39;t visit, but <strong>we still generate a daily snapshot</strong>. When they visit again on December 20, we set the <strong>last active date</strong> to that date.</p><p>Thanks to these snapshots, Activation calculations can get the previous timestamp by just referencing the previous day&#39;s snapshot.</p><p><strong>2. Activation Model</strong></p><p>This model keeps <strong>only dates with activity based on the Fact model</strong>. It references the FirstLast model to retrieve the previous activity timestamp, and based on this, calculates <strong>New/Retained/Reactivated states and return intervals</strong>. It also aggregates information, such as action counts for each date.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*D-PGiCEw96COUoCPdEbrPA.png\" /><figcaption><em>Data example showing how Activation model is generated based on User A’s Fact and FirstLast data</em></figcaption></figure><p>For User A, on December 10, there&#39;s no prior record in FirstLast, so they&#39;re classified as a new user. On December 11, it retrieves the last active date (December 10) from the December 10 snapshot in FirstLast and uses it as the previous active date. Since the <strong>return interval</strong> between the active date and the previous active date is 1 day, the user is classified as retained. From December 12 to 19, when there&#39;s no activity, no rows are generated in the Activation model.</p><p>The Activation model can be used to decompose the number of Active Users into activity-state components (New/Retained/Reactivated) and analyze month-over-month contributions.</p><p><strong>3. Activation Status Model</strong></p><p>Unlike the Activation model, this model fills in inactive periods to provide states for all dates. It provides not only the <strong>inactivity duration</strong> and <strong>consecutive active days</strong> but also <strong>transition segments</strong> that show how states changed.</p><p>Transition segments are values that further segment user flows by combining &quot;previous activity state → current activity state.&quot; For example, users in the same Retained state are distinguished as New User Retained (New → Retained), Core User Retained (Retained → Retained), or Reactivated User Retained (Reactivated → Retained). Similarly, churned users are segmented as Core User Churned (Retained → Inactive), Reactivation Failed (Reactivated → Inactive), etc.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/906/1*u87KeqoQJ_HGAMrJc06RIQ.png\" /><figcaption><em>Activation Status data example for User A</em></figcaption></figure><p>For User A, they start in the New state on December 10, become active on December 11, and transition to the Retained state; therefore, the <strong>transition segment</strong> is New User Retained. From December 12 to 19, there&#39;s no activity, but we can see the inactivity duration. On December 20, the activity state detail shows they returned after 8 days.</p><p>The Activation Status model enables more sophisticated analysis of acquisition-churn-return flows by combining activity states with previous states through transition segments.</p><h3><strong>Use Cases</strong></h3><h4><strong>1. AU Dashboard and Analysis Agent</strong></h4><p>As mentioned in the background, the number of Active Users alone doesn&#39;t immediately tell you &quot;why it increased or decreased.&quot; This chart breaks down changes in Active Users relative to the previous period into New/Retained/Reactivated <strong>contributions</strong>, enabling quick identification of the causes of change.</p><p><strong>1) AU Composition — Contribution by Activity State</strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/933/0*Xc2yanZGVkfQwTdr.png\" /><figcaption>A contribution table by activation state built with mock data (not real data)</figcaption></figure><p>For example, MAU of November is -1.20%p compared to October, mainly due to decreased Reactivated users (-0.90%p) and Retained users (-0.35%p), partially offset by New users (+0.05%p).</p><p>As shown in the example below, we quickly assess the MAU change drivers through user group contributions.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/933/0*zWTW1VBRE4lzQCNa.png\" /><figcaption><em>Slack message summarizing previous month’s MAU changes (partially blurred)</em></figcaption></figure><p><strong>2) Seeing Where Users Flowed — Transition Segment Analysis</strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/933/0*XjHraG_7F2zbof2T.png\" /><figcaption><em>Charts for Transition segment analysis created with mock data, not real data</em></figcaption></figure><p>Looking only at activity states tells us how much each segment grew or shrank this month, but it doesn&#39;t tell us how those changes happened. When Active Users move, knowing the paths they took—where they came from and where they went—helps us decide what to do next.</p><p>We use a transition segment in the Activation Status model to break down state transitions and quickly identify which flows changed, even for exact state changes.</p><p>For example, both September and November 2025 have 220 retained users (activation_status = retained). Looking only at activity states, the retained users for both months appear the same. But when broken down by transition segment, &quot;Retained New User (New → Retained)&quot; decreased from 100 in September to 50 in November. It means that while overall retained user volume is the same, new user retention is weakening—a signal we can catch. In such cases, there&#39;s a high likelihood we need to examine the onboarding funnel or early experience.</p><p>Furthermore, we also provide an analysis Agent that supplies dashboard interpretation guides as prompts. It enables team members to gain a range of insights through conversations with the Agent on our internal LLM platform.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/proxy/0*P5CrvtzTASNg0BmC.png\" /><figcaption><em>Example of analyzing with Activation analysis bot registered on internal LLM platform</em></figcaption></figure><p><strong>2. Marketing Targeting and Performance Analysis</strong></p><p>The Activation model we built is now also being used for the Marketing team&#39;s performance analysis. For example, when executing CRM actions, we define targets based on the Activation Layer. We segment audiences by inactivity duration, like users churned for 3+ months, and can now analyze campaign performance using the same criteria.</p><p><strong>3. Core Action Tracking by Service</strong></p><p>Each team can now define important core actions as Activation models and track them. Instead of just looking at DAU for that action, they can view activity state composition and day-over-day churn rate together to monitor user flows. It enables teams to identify changes that might be missed when reviewing individual experiment metrics, from the perspective of overall user composition changes within strategic decisions.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/933/0*bBAr0g1Ok8Wry-Nw.png\" /><figcaption><em>Dashboards built using models created in the Activation Layer, being used for decision-making</em></figcaption></figure><h3><strong>Conclusion</strong></h3><p>The biggest realization from building the Activation Layer was that <strong>well-structured data alone can transform team-wide productivity</strong>. Time spent writing complex SQL queries repeatedly decreased, and teams needing growth analysis can now make decisions based on the data directly.</p><p>Also, the Activation Layer wasn&#39;t just about creating a table that calculates AU—it was an attempt to <strong>establish a common language for interpreting user behavior across states and flows</strong>. Especially in today&#39;s environment, as LLM-powered analysis grows, I believe <strong>providing structured data that LLMs can understand is more important than giving massive raw datasets</strong>. We plan to continue creating such structured data in the future.</p><p>As such, Karrot&#39;s Data Team works on making data trustworthy and easy for anyone to use. Among them, Data Analytics Engineers design structures that enable analysts, engineers, and product teams to consistently leverage data without complex queries, spanning data modeling, pipeline design, and metric definition. If this post sparked your interest in data structuring and modeling, please check out the job postings below!</p><p>👉 <a href=\"https://about.daangn.com/jobs/7507320003/\">View Data Analytics Engineer Opening</a></p><p>👉 <a href=\"https://about.daangn.com/jobs/4300801003/\">View Software Engineer, Data Opening</a></p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=342ed895508f\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://medium.com/daangn/standardizing-user-activation-how-we-built-a-shared-data-layer-at-karrot-342ed895508f\">Standardizing User Activation: How We Built a Shared Data Layer at Karrot</a> was originally published in <a href=\"https://medium.com/daangn\">당근 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2026-01-02T09:42:38.000Z",
    "url": "https://medium.com/daangn/standardizing-user-activation-how-we-built-a-shared-data-layer-at-karrot-342ed895508f?source=rss----4505f82a2dbd---4"
  },
  {
    "publisherId": "daangn",
    "publisherName": "당근마켓 테크",
    "specTitle": "React Native",
    "categories": [
      "mobile",
      "frontend"
    ],
    "specUrl": "https://medium.com/feed/daangn",
    "title": "Activation을 전사 공통 레이어로 만들며 해결한 3가지: 신뢰성, 비용, 생산성",
    "partialText": "<h3>당근은 왜 User Activation을 전사 공통 데이터 레이어로 만들었을까?</h3><p>안녕하세요. 당근 데이터 가치화팀에서 Data Analytics Engineer로 일하고 있는 Pepper예요.</p><p>데이터 가치화팀은 ‘매일 데이터를 통해 사용자를 위한 의사결정을 해요’라는 비전을 위해 수많은 데이터를 안정적으로 수집하고, 더 나아가 신뢰할 수 있는 형태로 제공하는 일을 하고 있어요.</p><p>오늘 글에서는 그중 하나로, 당근에서 Activation 분석을 매번 쿼리로 직접 계산하던 방식에서 벗어나 이를 ‘전사 공통 데이터 레이어’로 끌어올린 경험을 소개해 보려고 해요.</p><h3>배경</h3><h4>Active User 지표의 한계</h4><p>많은 서비스가 그렇듯, 당근에서도 Active User 수는 중요한 지표예요. 하지만 Active User 수는 ‘무슨 일이 일어났는지’를 보여줄 뿐, ‘왜 그런 일이 일어났는지’를 직접 설명해 주지는 못해요.</p><p>예를 들어, ‘이번 달 Active User가 10% 증가했다’라는 단편적인 사실은 알 수 있지만, 왜 Active User가 늘었는지, 더 나아가 Active User를 늘리려면 무엇을 해야 하는지 같은 질문까지는 답하기 어려워요.</p><p>이런 질문에 답하려면, <strong>Active User를 하나의 숫자로 보지 않고, 서로 다른 성격의 구성 요소로 쪼개서 해석할 수 있는 관점</strong>이 필요해요. 그리고 바로 그 역할을 하는 것이 User Activation이에요.</p><h4>User Activation: 활성 상태와 상태 전이</h4><p>User Activation은 사용자의 활동을 단순히 활성과 비활성으로 보지 않고 현재 어떤 <strong>활성 상태</strong>에 있는지, 기간이 바뀌면서 어떤 상태로 이동하는지 <strong>상태 전이</strong>를 함께 해석하는 관점인데요. 아래에서 좀 더 자세히 설명해 볼게요.</p><ul><li><strong>활성 상태</strong>는 특정 시점에 사용자가 어떤 상태인지에 대한 분류예요. 예를 들어, 신규(New), 유지(Retained), 복귀(Reactivated), 이탈(Inactived) 같은 상태로 구분해요.</li><li><strong>상태 전이</strong>는 기간이 지나면서 사용자가 활성 상태 간에 어떻게 이동했는지를 의미해요. 예를 들어, 신규 → 유지, 유지 → 이탈, 복귀 → 이탈처럼 상태 간 이동을 표현해요.</li></ul><p>활성 상태만으로는 ‘지금 몇 명이 어떤 상태인지’는 알 수 있지만, ‘어디서 왔는지’, ‘어떤 경로로 이탈하는지’는 파악하기 어려워요. 상태 전이를 함께 보면 유저가 어떤 경로로 이동하는지 알 수 있고, 이 전이 패턴을 기준으로 유저를 세분화하면 활동성 수준별로 다른 해석과 액션이 가능해져요.</p><p>예를 들어, Active User가 늘었을 때 활성 상태를 활용해 Active User 증가가 신규 유입 때문인지, 아니면 기존 사용자의 복귀로 늘어난 것인지를 구성 요소로 분해해서 설명할 수 있어요. 또한 리텐션이 떨어졌다면, 상태 전이를 활용해 단순히 ‘리텐션이 나빠졌다’로 끝나는 게 아니라 어느 세그먼트에서 이탈이 늘었는지를 구체적으로 파악해 의사결정할 수 있어요.</p><h3>목표</h3><h4>왜 공통 레이어가 필요했나</h4><p>User Activation 관점으로 분석하려면 활성 상태와 상태 전이가 계산된 데이터가 필요해요. 그런데 문제는 팀마다 각자 정의하고 운영하는 방식으로는 데이터 신뢰성과 운영 안정성을 확보하기 어렵다는 점이었어요.</p><p>팀별로 만들어진 데이터는 누가, 언제, 어떤 기준으로 만들었는지에 대한 맥락이 남지 않아 시간이 지나면 결과를 이해하거나 점검하기 어려웠죠. 또 예약 쿼리 실패나 재처리 같은 운영 이슈가 발생하면 멱등성이 깨지거나 최신성을 보장하지 못한 채로 남은 경우도 있었어요. 결국 데이터는 존재했지만, 마음 놓고 쓰기 어려운 경우가 많았던 거예요.</p><p>그래서 Activation을 전사 공통 기준으로 계산하고 운영하는 <strong>공통 레이어인</strong> <strong>Activation 레이어</strong>를 만들기로 했어요. 결과의 신뢰도와 운영 안정성을 확보하고, 여러 팀이 같은 기준으로 재사용하는 것을 목표로 삼았죠.</p><blockquote><em>여기서</em><strong><em> User Activation</em></strong><em>은 Active User를 상태와 전이로 해석하는 관점이고, </em><strong><em>Activation 레이어</em></strong><em>는 그 해석에 필요한 사용자별 상태/전이 정보를 일관된 기준으로 제공하는 공통 데이터 레이어를 의미해요.</em></blockquote><h4>Activation 레이어로 무엇을 하려 했나</h4><p>Activation 레이어는 전사 공통 레이어로 만들기로 결정한 뒤, 가장 먼저 한 일은 ‘이 레이어가 무엇을 제공해야 하는지’를 정의하는 것이었어요. 사내에서 반복되던 질문을 정리하다 보니, 구체적으로는 아래와 같은 정보들이에요.</p><ul><li>이번 활동이 신규/유지/복귀 중 무엇인지(<strong>활성 상태</strong>)</li><li>직전 기간의 상태에서 이번 기간의 상태로 어떻게 바뀌었는지(<strong>상태 전이</strong>)</li><li>최근 활동이 연속적으로 이어지고 있는지(<strong>연속성</strong>)</li><li>직전 활동 이후 얼마 만에 돌아왔는지(<strong>복귀 간격</strong>)</li><li>마지막 활성 이후 얼마나 쉬고 있는지(<strong>이탈 기간)</strong></li></ul><p>예를 들어 어떤 유저가 12월 10일, 12월 11일, 12월 20일에 방문했다면, 위 정보들이 일 기준으로 아래처럼 제공되어야 해요.</p><pre>user_A (daily)<br>- 2025-12-10 NEW<br>- 2025-12-11 RETAINED (prev=2025-12-10, interval=1d)<br>- 2025-12-20 REACTIVATED (prev=2025-12-11, interval=9d)</pre><p>여기서는 방문을 예시로 들었지만, User Activation은 앱 방문뿐 아니라 중고물품 판매나 커뮤니티 글 작성, 알림 오픈처럼 코어 행동에도 적용할 수 있어요.</p><h3>Activation 레이어를 설계하며 해결한 3가지 고민</h3><p>이제부터 Activation 레이어를 어떻게 구현했는지 이야기해 볼게요. 먼저 전체 구조를 보면 다음과 같아요.</p><h4>전체 구조 한눈에 보기</h4><p>Activation 레이어는 기존 당근 DBT 프로젝트의 데이터 계층 위에 한 단계를 더 얹는 형태로 설계했어요. 원천 이벤트 로그(Raw Data)를 그대로 사용하는 대신, Base (정제) → Fact (행동 단위) → Activation (상태/흐름 분석) 순서로 쌓아 올린 구조예요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*0w14QIwG2lT219KsuSqiMw.png\" /><figcaption>DBT 프로젝트 계층 구조(Base/Dimension/Fact)에 Activation 레이어를 올려놓은 구조</figcaption></figure><blockquote><em>당근의 데이터 계층 구조를 더 자세히 알고 싶다면, </em><a href=\"https://medium.com/daangn/dbt%EC%99%80-airflow-%EB%8F%84%EC%9E%85%ED%95%98%EB%A9%B0-%EB%A7%88%EC%A3%BC%ED%95%9C-7%EA%B0%80%EC%A7%80-%EB%AC%B8%EC%A0%9C%EB%93%A4-61250a9904ab\"><em>DBT와 Airflow 도입하며 마주한 7가지 문제들</em></a><em> 글을 참고해 주세요.</em></blockquote><p>Activation 레이어는 하나의 Fact 모델을 기준으로, 3개 모델(FirstLast, Activation, Activation Status)이 한 세트로 동작하도록 구성했어요. 각 모델이 어떤 데이터를 담고, 어떤 역할을 맡는지, 그리고 어떤 구조로 서로 연결되어 있는지는 뒤에서 풀어볼게요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Rp8t7kOXRAQq6oDZEArocg.png\" /><figcaption>Fact 모델을 기준으로 3개 모델이 순차적으로 연결되는 Activation 레이어 구조</figcaption></figure><p>이 구조를 만들면서 실제로 마주한 고민은 크게 세 가지였어요. 바로 <strong>신뢰성, 비용, 생산성</strong>에 대한 문제였어요. 지금부터 어떻게 각 고민을 해결했는지를 설명해 볼게요.</p><h4>1. 신뢰성: 기준 행동을 명확하게 고정하기</h4><p>먼저 전사 공통 레이어로 운영하려면 Activation의 기준 행동이 명확해야 해요. 기준이 사람마다 다르게 해석되는 순간, 데이터는 재사용될 수 없고 매번 검증을 거쳐야만 쓸 수 있기 때문이에요. 그래서 <strong>모델만 봐도 어떤 행동을 기준으로 Activation을 계산했는지 쉽게 알아차릴 수 있게</strong> 만드는 것을 우선순위로 뒀어요.</p><p>사실 처음에는 이벤트 로그와 Activation 기준 행동을 1:1로 대응시키는 방식을 고려했어요. 하지만 보통 이벤트 로그는 UI 단위(예: 버튼 클릭, 화면 조회)로 로깅되다 보니, 하나의 이벤트 안에서도 파라미터에 따라 행동 의미가 달라지는 경우가 많았어요.</p><p>예를 들어, ‘관심 버튼 클릭’ 이벤트 하나에 관심 등록/해제가 함께 로깅 되기도 했어요. 이 경우 관심 등록을 기준 행동으로 쓰려면, 매번 관심 등록에 해당하는 케이스만 필터링한다는 조건을 반복해서 붙여야 했죠.</p><p>그래서 <strong>이벤트 로그를 그대로 기준 행동으로 삼는 게 아니라 기준 행동 자체를 명확한 단위로 고정</strong>해야겠다고 생각했어요. 당근은 dbt로 데이터 모델링을 하고 있고 모델들을 레이어(Layer)라는 개념적 구분으로 관리하고 있는데요.</p><p>그중 Fact 레이어는 사용자 행동을 정의해두는 계층이에요. 단순한 행동(예: ‘사용자가 메시지를 보냈다’)부터 조건과 비즈니스 로직이 필요한 행동(예: ‘사용자가 액티브하기 피드를 사용했다’)까지, 의미가 담긴 행동 단위로 표현되도록 운영하고 있어요.</p><p>그래서 <strong>기준 행동은 Fact 모델로 정의</strong>하고, Activation 레이어가 그 Fact 모델을 입력으로 쓰도록 구현하기로 했어요. 또한 기준 행동이 더 한눈에 드러나도록, 아래처럼 Activation 모델명에 Fact 모델 이름이 포함되도록 <strong>네이밍 컨벤션</strong>을 정했어요.</p><pre># Naming convention<br>&lt;fact_name&gt;_activation_&lt;time_grain&gt;<br><br># fact_name: Fact 레이어 모델명과 동일 (행동 의미는 Fact에서 정의)<br># time_grain: daily | weekly | monthly<br># Examples<br>users_visited_app_activation_daily<br>users_opened_push_activation_daily<br>users_created_article_activation_daily</pre><p>덕분에 Activation 모델은 모델명만 봐도 기준 행동이 명확하게 드러나고, 이벤트 파라미터나 필터 조건에 의해 해석이 흔들릴 여지 크게 줄었어요.</p><h4>2. 비용: 지속 가능하게 만들기</h4><p>Activation을 계산하려면 같은 날 활동한 유저라도 <strong>직전 활동 시점에 따라 상태가 달라지기 때문에 ‘최초 시점’과 ‘직전 시점’이 각각 필요</strong>해요. 최초 시점은 해당 행동을 처음 수행한 날짜이고, 직전 시점은 현재 날짜 기준으로 바로 이전에 그 행동을 수행한 날짜예요. 예를 들어 12월 20일에 방문했더라도 직전 방문이 12월 19일인지 12월 11일인지에 따라 유지/복귀처럼 <strong>활성 상태 분류가 달라질 수 있어요.</strong></p><p>문제는 이 값을 미리 정리해 둔 테이블이 없다면, 직전 시점을 찾기 위해 매번 Fact 모델 전체 기간을 스캔해야 한다는 점이에요. 당근처럼 데이터 규모가 큰 서비스 환경에서는 스캔 범위가 곧 비용과 수행 시간으로 이어져, 이 부분이 Activation 운영에서 가장 큰 비용 허들이었어요.</p><p>그래서 계산 비용을 줄이기 위해 유저의 첫/마지막 행동 시점을 담은 중간 테이블을 도입하기로 했어요. 그리고 이 중간 테이블은 말 그대로 First(최초)/Last(마지막)을 담고 있어서 <strong>FirstLast 모델</strong>이라고 부르기로 했어요. 다만 FirstLast 모델을 어떤 방식으로 저장하느냐에 따라 일별 실행 비용뿐 아니라 백필 비용까지 크게 달라지기 때문에, 세 가지 접근 방식을 비교해 봤어요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*q9IiVOD4MrZnmh3t33oPlw.png\" /><figcaption>FirstLast 모델 구현을 위해 고민한 세가지 후보</figcaption></figure><p><strong>후보 1 — Fact에서 매번 직접 계산</strong></p><p>중간 테이블을 두지 않고 매번 전체 기간을 스캔해서 유저별 최초 시점과 직전 시점을 구하는 방식이에요. 구조는 가장 단순하지만, 실행할 때마다 Fact 모델 전체 기간을 스캔해야 해서 일별 비용과 수행 시간이 크게 발생해요. 운영을 반복하기에 부담이 커서 제외했어요.</p><p><strong>후보 2 — 유저별 최신 값만 유지</strong></p><p>유저당 최초 시점과 마지막 시점을 한 레코드에 저장하는 방식이에요. 최초 시점은 한 번 정해지면 거의 변하지 않아요. 반면 마지막 시점은 매일 업데이트가 필요하지만, 오늘 행동한 유저만 merge 하면 되니 일별 갱신은 하루치 Fact 모델만 스캔하면 돼요. 다만 과거 날짜의 마지막 시점을 따로 쌓지 않기 때문에, 백필할 때 결국 Fact 모델 전체 범위를 스캔해야 해요.</p><p><strong>후보 3 — 날짜별 스냅샷으로 유지 ✅</strong></p><p>유저별 직전 시점을 날짜별로 쌓는 방식이에요. 오늘 스냅샷을 만들 때 전날 스냅샷을 가져와서, 오늘 활동한 유저는 업데이트하고 활동이 없는 유저는 전날 값을 그대로 이어가죠. 중간 테이블 갱신도 하루치 데이터만 보면 되고, Activation 계산 시에도 필요한 날짜의 전날 스냅샷을 쓰면 되니 일별 계산과 백필 모두 스캔 범위를 ‘하루치’로 고정할 수 있어요.</p><p>이 중 결론적으로 당근에서는 백필이 주기적으로 발생하고, 백필 상황에서도 스캔량을 최소화할 수 있는 방식 3을 선택해서 FirstLast 모델을 정의했어요.</p><p>물론 스냅샷 방식에도 trade-off는 있어요. 날짜별로 쌓아서 저장 공간이 점차 늘어나고, 특정 날짜에 문제가 생기면 이후로 영향이 이어질 수 있어요. 하지만 백필 시 영향받은 파티션만 재적재하면 되니 전체 스캔이 필요한 방식 2보다 비용과 수행 시간 측면에서 효율적이라고 판단했어요. 또 데이터 품질 모니터링을 통해 문제가 발생하더라도 영향 범위가 커지기 전에 감지해서 빠르게 대응할 수 있었어요.</p><h4>3.생산성: SQL 없이 새 행동을 모델로 만들기</h4><p>다음으로 마주한 고민은 ‘어떤 행동이든 쉽게 Activation 모델로 만들려면 어떻게 해야 할까?’였어요. Activation 계산에는 WINDOW 함수나 JOIN, CASE 같은 복잡한 로직이 많이 들어가요. 그래서 매번 SQL을 직접 작성하다 보면 구현 방식이 조금씩 달라지고, 그 과정에서 스키마가 흔들리기 쉽다는 한계가 존재했어요.</p><p>그래서 계산 로직을 DBT 매크로로 캡슐화했어요. 새 Activation 모델은 기준이 되는 Fact 모델 이름 (fact_name)만 지정하면 생성되도록 구성했죠.</p><p><strong>[Before]</strong> Activation 로직을 직접 SQL로 구현하던 방식</p><pre>-- 유저의 월별 활성 상태를 구하기 위해 유저의 첫 행동 시점과 직전 행동을 구하는 쿼리 일부<br>WITH first_activation AS (<br>  SELECT user_id, MIN(event_date) as first_date<br>  FROM events<br>  WHERE ...<br>  GROUP BY user_id<br>),<br>monthly_activity AS (<br>  SELECT<br>    user_id,<br>    DATE_TRUNC(&#39;month&#39;, event_date) as month,<br>    LAG(DATE_TRUNC(&#39;month&#39;, event_date)) OVER (<br>      PARTITION BY user_id ORDER BY event_date<br>    ) as prev_month<br>  FROM events<br>  WHERE ...<br>),<br>... (윈도우 함수, 조인, CASE 분기 등)</pre><p><strong>[After]</strong> DBT Macro를 사용해 SQL 작성 없이 모델 생성</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*RvO-YWSMQAPsDcSrE4wptw.png\" /><figcaption>정의해둔 DBT Macro를 사용해서 FirstLast, Activation, Activation Status 모델 구현 코드 예시</figcaption></figure><h3>최종 결과물</h3><p>Activation 분석을 위한 정보를 담으면서도 앞서 이야기한 <strong>신뢰성, 비용, 생산성</strong>을 모두 만족하기 위해, Activation 레이어는 하나의 Fact 모델을 기준으로 <strong>3개 모델이 한 세트로 동작</strong>하는 구조로 만들었어요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/903/1*dvjoTcFom2zX9fvKcjbM5g.png\" /><figcaption>Activation 레이어 내 3개의 모델의 데이터 흐름도</figcaption></figure><ul><li><strong>FirstLast</strong>는 비용을 고려해 유저별 첫/마지막 행동 시점을 <strong>날짜별 스냅샷으로 누적</strong>하고</li><li><strong>Activation</strong>은 Fact 모델과 FirstLast 모델을 입력으로 받아 <strong>행동이 있는 시점의 신규/유지/복귀와 복귀 간격</strong>을 제공하고</li><li><strong>Activation Status</strong>는 <strong>비활성 유저</strong>까지 포함해 <strong>상태 전이</strong>와 <strong>연속성 및 이탈 기간</strong>을 제공해요.</li></ul><p>이 세 모델이 순서대로 연결되면서 Activation 분석에 필요한 상태와 흐름을 단계적으로 만들어가죠.</p><h4>3개 모델 구조와 데이터 예시</h4><p>모델별 데이터 구성과 동작 방식을 빠르게 이해하기 위해, 유저 A가 12월 10일에 첫 방문 하고 12월 11일, 12월 20일에 재방문하는 시나리오를 예시로 살펴볼게요.</p><p><strong>1. FirstLast 모델</strong></p><p>FirstLast는 <strong>유저별 최초/마지막 행동 시점을 날짜별 스냅샷</strong>으로 저장하는 중간 모델이에요. 매일 전날 스냅샷을 가져온 뒤, 오늘 행동이 있는 유저는 마지막 활성 일자를 업데이트하고, 행동이 없는 유저는 전날 값을 그대로 유지해서 모든 유저의 스냅샷을 생성해요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*5yQUCebiD5ChC-A7X2v09g.png\" /><figcaption>유저 A의 Fact 데이터를 기반으로 FirstLast 모델이 생성되는 로직을 보여주는 데이터 예시</figcaption></figure><p>유저 A의 경우, 12월 10일 첫 방문 시 ‘<strong>최초 활성 일자</strong>’와 ‘<strong>마지막 활성 일자</strong>’가 모두 12월 10일로 생성되고, 12월 11일 방문 시에는 ‘마지막 활성 일자’만 업데이트돼요. 12월 12일부터 19일까지는 방문이 없지만 매일 스냅샷이 생성되고, 12월 20일에 방문 시 ‘마지막 활성 일자’가 12월 20일로 업데이트돼요.</p><p>이 스냅샷 덕분에 Activation 계산 시 전날 스냅샷만 참조하면 직전 시점을 가져올 수 있어요.</p><p><strong>2. Activation 모델</strong></p><p>Fact 모델을 기준으로 활동이 발생한 날짜만 남기는 모델이에요. FirstLast 모델을 참조해서 <strong>직전 활동 시점</strong>을 가져오고, 이를 기반으로 <strong>신규/유지/복귀 상태</strong>와 <strong>복귀 간격</strong>을 계산해요. 또한 해당 날짜의 행동 횟수 등 <strong>집계 정보</strong>도 함께 집계해요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Azgu5482Xux2sZ_gkciPCw.png\" /><figcaption>유저 A의 Fact 데이터와 FirstLast 데이터를 기반으로 Activation 모델이 생성되는 로직을 보여주는 데이터 예시</figcaption></figure><p>유저 A의 경우, 12월 10일에는 FirstLast에 이전 기록이 없어서 신규 유저로 판정되고, 12월 11일에는 FirstLast의 12월 10일 스냅샷에서 마지막 활성 일자인 12월 10일을 가져와 ‘직전 활성 일자’로 사용해요. 이때 ‘활성 일자’와 ‘직전 활성 일자’ 간의 차이인 ‘복귀 간격’이 1일이기 때문에 복귀 유저로 판정해요. 활동이 없는 12월 12일부터 19일까지는 Activation 모델에 row가 생성되지 않아요.</p><p>이처럼 Activation 모델은 Active User를 <strong>활성 상태(신규/유지/복귀) 구성 요소로 분해</strong>하고, <strong>전월 대비 기여도</strong>를 분석하는 데 사용될 수 있어요.</p><p><strong>3. Activation Status 모델</strong></p><p><strong>Activation 모델과 달리 비활성 구간까지 채워서 모든 날짜의 상태</strong>를 제공하는 모델이에요. ‘이탈 기간’, ‘연속 활동 일수’뿐만 아니라 상태가 어떻게 바뀌었는지를 나타내는 ‘전이 세그먼트’도 함께 제공해요.</p><p><strong>전이 세그먼트</strong>는 ‘이전 활성 상태 → 현재 활성 상태’ 조합으로 유저의 흐름을 더 세분화한 값이에요. 예를 들어, 같은 유지 유저라도 신규 유저 정착(신규 → 유지), 핵심 유저 유지 (유지 → 유지), 복귀 유저 정착(복귀 → 유지)로 구분돼요. 또한 이탈 유저도 핵심 유저 이탈(유지 → 이탈), 복귀 실패(복귀 → 이탈) 등으로 나뉘어요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/877/1*-sc3PywHH92_m6wez1lQ0w.png\" /><figcaption>유저 A의 Activation Status 데이터 예시</figcaption></figure><p>유저 A의 경우, 12월 10일에는 신규 상태로 시작해 12월 11일에 활성화되어서 유지 상태로 전환되면서 ‘전이 세그먼트’는 신규 유저 정착(New User)가 돼요. 12월 12일부터는 19일까지 활동이 없지만 ‘이탈 기간’을 알 수 있어요. 12월 20일에는 ‘활성 상태 상세’를 통해 8일 만에 복귀했음을 알 수 있어요.</p><p>이처럼 Activation Status 모델은 전이 세그먼트로 활성 상태에 직전 상태를 결합해, <strong>유입-이탈-복귀 흐름을 더 정교하게 분석</strong>할 수 있게 해줘요.</p><h3>활용 사례</h3><h4>1. AU 대시보드와 분석 Agent</h4><p>Activation 레이어를 만들고 이를 기반으로 AU 대시보드를 구성해 Active User를 단순히 ‘몇 명’으로 보지 않고 <strong>왜 변했는지</strong>를 한 흐름으로 설명할 수 있게 됐어요. AU 대시보드는 <strong>구성, 전이 </strong>그리고 <strong>지속(리텐션/부활) </strong>순서로 3단으로 나눠서 보게 구성되어 있어요. 아래는 그중 일부를 mock 데이터로 예시로 보여드릴게요.</p><p><strong>1) AU 구성 — 활성 상태별 기여도</strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*epjc5rj-KW3pIG1_I-VJyg.png\" /><figcaption>실제 데이터가 아니라 mock 데이터로 만든 활성 상태별 기여도 테이블</figcaption></figure><p>앞서 배경에서 이야기한 것처럼, Active User 수만으로는 ‘왜 늘었는지/줄었는지’를 바로 알기 어려워요. 이 차트는 직전 기간 대비 Active User 변화를 신규/유지/복귀의 <strong>기여도</strong>로 분해해, 변화 원인을 빠르게 파악할 수 있게 해줘요.</p><p>예를 들어 2025년 11월 MAU는 10월 대비 <strong>-1.20%p</strong>인데, <strong>복귀 유저(-0.90%p)와 유지 유저(-0.35%p) 감소가 주 원인</strong>이고 신규 유저(+0.05%p)는 일부 상쇄한 것으로 해석할 수 있어요.</p><p>아래 사례처럼 월초에 지난달 MAU가 나오면, 유저 그룹별 기여도로 MAU 변화 원인을 빠르게 확인해요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*gg71s6CwdYQaTccP3gBqjA.png\" /><figcaption>전월 MAU 변화 요약 슬랙 메시지(일부 블러 처리)</figcaption></figure><p><strong>2) 유저가 어디로 흘러갔는지 보기 — Transition segment 분석</strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*b2J8Owpno0gSovNzwprvVQ.png\" /><figcaption>실제 데이터가 아니라 mock 데이터로 만든 Transition segment 분석용 차트들</figcaption></figure><p>활성 상태만으로는 ‘이번 달에 각 상태가 얼마나 늘고 줄었는지’는 볼 수 있지만, 그 변화가 <strong>어떤 경로에서 만들어졌는지</strong>까지는 알기 어려워요. 그런데 Active User 수가 변했을 때는 유저가 어떤 경로로 흘러갔는지 알면 효과적인 액션을 취할 수 있어요.</p><p>그래서 이 Activation Status 모델의 transition segment를 이용해 직전 상태 → 이번 상태의 전이로 나눠보고, 같은 상태 변화라도 어떤 흐름이 바뀌었는지 빠르게 파악할 수 있게 했어요.</p><p>예를 들어 2025년 9월과 11월 모두 유지 유저(activation_status = retained) 수는 220명으로 동일해요. 활성 상태만 보면 두 달의 유지 상태 유저는 같아보여요. 하지만 transition segment로 쪼개보면, ‘Retained New User (신규 → 유지)’가 9월 100명에서 11월 50명으로 줄었다는 사실을 알 수 있어요.</p><p>즉 전체 유지 유저 규모는 유지되었지만, 그 안에서 신규 유저의 정착이 약해지고 있다는 신호를 잡아낼 수 있어요. 이런 경우 온보딩 퍼널이나 초기 경험을 점검해야 할 가능성이 높아요.</p><p>더 나아가, 대시보드 해석 가이드를 프롬프트로 제공하는 분석 Agent도 함께 제공하고 있어요. 덕분에 구성원들이 사내 LLM 플랫폼에서 Agent와 대화하며 다양한 인사이트를 얻고 있어요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/736/1*vAvcBC_lHZx2jCVphMNOyg.png\" /><figcaption>사내 LLM 플랫폼에 등록된 Activation 분석 봇과 분석하는 예시</figcaption></figure><h4>2. 마케팅 타겟팅과 성과 분석</h4><p>이렇게 만든 Activation 모델은 현재 마케팅팀의 성과 분석에도 활용되고 있어요. 예를 들어 CRM 액션을 집행할 때, Activation 레이어를 기준으로 타겟을 정의해요. 3개월 이상 이탈한 사용자처럼 이탈 기간을 기준으로 대상을 나누고, 같은 기준으로 캠페인 성과도 분석할 수 있게 됐어요.</p><h4>3. 서비스별 코어 행동 트래킹</h4><p>또 이제 각 팀에서 중요한 코어 행동을 Activation 모델로 정의해 트래킹할 수 있게 됐어요. 단순히 그 행동의 DAU만 보는 게 아니라, <strong>활성 상태 구성</strong>과 <strong>전일 대비 이탈율</strong>을 함께 보면서 유저 흐름을 확인해요. 그래서 개별 실험의 지표만으로는 놓치기 쉬운 변화도, 팀의 전략적 판단을 <strong>전체 유저 구성 변화 관점</strong>에서 점검할 수 있어요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*1y4ChSw92Uksm1Q7N-fz5Q.png\" /><figcaption>Activation 레이어에 만든 모델을 활용해 대시보드 구현하고 이를 의사결정에 활용하는 모습</figcaption></figure><h3>마치며</h3><p>Activation 레이어를 구축하면서 가장 크게 느낀 건, 데이터를 잘 구조화하는 것만으로도 팀 전체의 생산성이 달라진다는 점이었어요. 복잡한 SQL을 매번 작성하던 시간이 줄어들었고, 그로스 분석이 필요한 팀들이 직접 데이터를 보며 의사결정을 내릴 수 있게 됐어요.</p><p>또한 Activation 레이어는 ‘AU를 계산하는 테이블’ 하나를 만든 게 아니라, <strong>사용자 행동을 상태와 흐름으로 해석할 수 있는 공통 언어</strong>를 정리한 시도였어요. 특히 요즘처럼 LLM을 활용한 분석이 늘어나는 환경에서는, 방대한 원천 데이터를 주기보다 LLM이 이해할 수 있는 형태의 구조화된 데이터를 제공하는게 더 중요해지고 있다고 생각해요. 그래서 앞으로도 이런 구조화된 데이터를 만드는 일을 해나가려고 해요.</p><p>이렇듯 당근 데이터 가치화팀은 데이터를 신뢰할 수 있고 누구나 활용하기 쉬운 형태로 만드는 일을 하고 있어요. 그중에서도 Data Analytics Engineer는 데이터 모델링과 파이프라인 설계, 지표 정의 등을 넘나들며 분석가와 엔지니어, 제품팀이 복잡한 쿼리 없이도 데이터를 일관되게 활용할 수 있는 구조를 설계하고 있답니다.</p><p>만약 이 글을 읽고 데이터 구조화와 모델링에 관심이 생기셨다면, 아래 채용 공고도 함께 확인해 보세요!</p><p>👉 <a href=\"https://about.daangn.com/jobs/7507320003/\">Data Analytic Engineer 공고 보러 가기</a></p><p>👉 <a href=\"https://about.daangn.com/jobs/4300801003/\">Software Engineer, Data 공고 보러 가기</a></p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=f40d362107ff\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://medium.com/daangn/activation%EC%9D%84-%EC%A0%84%EC%82%AC-%EA%B3%B5%ED%86%B5-%EB%A0%88%EC%9D%B4%EC%96%B4%EB%A1%9C-%EB%A7%8C%EB%93%A4%EB%A9%B0-%ED%95%B4%EA%B2%B0%ED%95%9C-3%EA%B0%80%EC%A7%80-%EC%8B%A0%EB%A2%B0%EC%84%B1-%EB%B9%84%EC%9A%A9-%EC%83%9D%EC%82%B0%EC%84%B1-f40d362107ff\">Activation을 전사 공통 레이어로 만들며 해결한 3가지: 신뢰성, 비용, 생산성</a> was originally published in <a href=\"https://medium.com/daangn\">당근 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2026-01-02T02:33:17.000Z",
    "url": "https://medium.com/daangn/activation%EC%9D%84-%EC%A0%84%EC%82%AC-%EA%B3%B5%ED%86%B5-%EB%A0%88%EC%9D%B4%EC%96%B4%EB%A1%9C-%EB%A7%8C%EB%93%A4%EB%A9%B0-%ED%95%B4%EA%B2%B0%ED%95%9C-3%EA%B0%80%EC%A7%80-%EC%8B%A0%EB%A2%B0%EC%84%B1-%EB%B9%84%EC%9A%A9-%EC%83%9D%EC%82%B0%EC%84%B1-f40d362107ff?source=rss----4505f82a2dbd---4"
  },
  {
    "publisherId": "daangn",
    "publisherName": "당근마켓 테크",
    "specTitle": "React Native",
    "categories": [
      "mobile",
      "frontend"
    ],
    "specUrl": "https://medium.com/feed/daangn",
    "title": "Karrot’s Generative AI Platform",
    "partialText": "<p>When we first shared <a href=\"https://medium.com/daangn/%EB%8B%B9%EA%B7%BC%EC%97%90%EC%84%9C-llm-%ED%99%9C%EC%9A%A9%ED%95%98%EA%B8%B0-76131ecebce1\">Using LLMs at Karrot</a> in early 2024, we were just beginning our journey with large language models.</p><p>A year and a half later, the landscape has transformed dramatically. AI models have advanced beyond what we could have imagined, and Karrot has scaled to hundreds of GenAI use cases across products and data pipelines.</p><p>In this post, we’ll share the challenges we encountered while scaling GenAI adoption and the platforms we built to address them. We hope our learnings help others navigating similar paths.</p><h3>Platform Overview</h3><p>GenAI powers services across Karrot’s entire stack — from user-facing features to internal data pipelines. Behind the scenes, three core platforms enable this adoption.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*L0jFW-TABAo58z-3.png\" /><figcaption>Karrot’s GenAI Platform</figcaption></figure><p>While the architecture may seem complex at first glance, LLM Router, Prompt Studio, and KarrotChat each evolved to solve distinct problems. Let’s dive into what each platform addresses and how we built them.</p><h3>LLM Router</h3><h4>The Account Management Problem</h4><p>In the early days of LLM adoption, teams provisioned their own accounts and API keys whenever they needed AI capabilities. With models from OpenAI, Anthropic, Google, and others, accounts and keys proliferated rapidly — and so did the management overhead. Several pain points emerged:</p><p><strong>Provisioning became a bottleneck.</strong> As more teams adopted AI, the account and API key setup process itself became a friction point. With numerous keys in circulation, tracking which team used which credentials for what service became increasingly difficult, raising security concerns.</p><p><strong>Rate limits created uneven availability.</strong> AI APIs typically enforce per-account rate limits. With teams operating independently, some accounts had plenty of headroom while others hit their limits, causing request failures.</p><p><strong>Cost visibility was fragmented.</strong> As accounts and keys multiplied, aggregating usage and costs required querying multiple sources. Getting a unified view of Karrot’s total AI spend became time-consuming.</p><h4>Unifying Through an API Gateway</h4><p>We built <strong>LLM Router</strong> to solve these challenges. The core concept: funnel all AI API calls through a single gateway. API keys and accounts are managed centrally by LLM Router, while individual services authenticate with just a service ID — no separate credentials required.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*CcojDlnE9H__nPM6.png\" /></figure><p>This unlocked several improvements:</p><p><strong>Eliminated provisioning overhead.</strong> The account and API key setup process disappeared entirely. We recalled most previously issued keys (with a few exceptions), and teams can now access any supported API immediately.</p><p><strong>Centralized operations.</strong> With all traffic flowing through one point, our infrastructure team took over unified account management. Rate limit monitoring and quota adjustments became their responsibility, freeing product teams to focus on building features.</p><p><strong>Unified cost visibility.</strong> Every request through LLM Router is attributed to its originating service. This data feeds into Karrot’s infrastructure cost management platform, providing at-a-glance visibility into which services consume which models — and at what cost.</p><h4>One Interface, Every Model</h4><p>For LLM Router to serve as the universal gateway, it needed to support OpenAI, Google, Anthropic, and even models we self-host via vLLM. The challenge: each provider has different API formats and capabilities. Without abstraction, client code would need changes every time we switched models.</p><p>We standardized on the OpenAI interface. All models — regardless of provider — are accessible through the OpenAI SDK. Whether you’re calling `claude-4.5-sonnet` or `gpt-5.2`, you simply change the model name. LLM Router handles provider-specific translation internally. When new models launch, we add them to LLM Router once. Teams can immediately use them by specifying the new model name — zero code changes required.</p><pre>from openai import OpenAI<br><br>client = OpenAI(base_url=&quot;https://llm_router&quot;) # Point to LLM Router<br>completion = client.chat.completions.create(<br> model=&quot;claude-4.5-sonnet&quot;, # Any supported model<br> messages=[<br> {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello!&quot;}<br> ]<br>)</pre><h3>Prompt Studio</h3><h4>The Experimentation Bottleneck</h4><p>Early in our LLM journey, building AI-powered features always required code. Validating an idea — “Can this prompt solve this problem?” — meant first requesting engineering support. How well an approach works, how to craft the prompt, which model fits best — these vary by use case and require iterative experimentation. When every iteration required an engineer, rapid experimentation wasn’t possible.</p><h4>No-Code AI Feature Development</h4><p><strong>Prompt Studio</strong> is the web-based platform we built to solve this. Anyone can create and test AI features without writing code. Enter a prompt, select a model, click run. If results don’t match expectations, revise and run again — iterating toward the desired behavior.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*bU53EeG08BZek7WV.png\" /><figcaption>Prompt Studio</figcaption></figure><p>The platform supports all models from OpenAI, Google, and Anthropic, plus internally-hosted models. Switch freely between them to compare outputs and find the best fit. This enabled PMs and other non-engineering roles to build AI features independently, iterating as fast as they needed.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*vPLZhwk0RRKevzUa.png\" /><figcaption>Model Comparison</figcaption></figure><p>Once a prompt shows promise, it needs systematic evaluation. A few successful examples don’t guarantee consistent quality across diverse inputs. Prompt Studio’s <strong>Evaluation</strong> feature lets you upload test sets — hundreds to thousands of examples — generate results in batch, and measure performance quantitatively. This answers: “How well does this prompt perform across varied scenarios?”</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*4clCH2wz3mbZ75eo.png\" /><figcaption>Evaluation</figcaption></figure><p>When a prompt is production-ready, deployment is straightforward. Engineers integrate the Prompt Studio API only once. After that, teams ship prompt improvements directly from the UI — no code changes needed. Multiple versions live within a single project, making it easy to compare iterations and roll back if needed. Selecting which version serves production traffic is a single click.</p><p>This architecture enables anyone to own AI features end-to-end — continuously testing and improving without engineering dependencies. Features like AI Writing Assistance shipped quickly through Prompt Studio and continue to evolve.</p><p>Prompt Studio has become the repository of AI knowledge across Karrot. Teams can reference how others structure their prompts, and best practices naturally accumulate. It’s evolved into the central hub where our collective AI expertise lives.</p><h4>Building Reliable AI APIs</h4><p>One challenge we faced: ensuring high availability when depending on external AI services. Rate limits, latency spikes, and occasional service disruptions can affect any cloud API. When a critical feature depends on a single model, any service interruption impacts that feature directly.</p><p>Handling reliability per-feature is costly and inconsistent. Prompt Studio provides multiple layers of resilience:</p><p><strong>Retry</strong>: Transient failures trigger automatic retries with exponential backoff.</p><p><strong>Region Fallback</strong>: When rate limits or errors hit in one region, requests automatically retry against the same model in a different region. If `gemini-2.5-flash` in `us-central1` fails, we retry in the `global` region.</p><p><strong>Model Fallback</strong>: When all retries fail, requests fall back to a pre-configured alternative model from a different provider. If Google’s `gemini-2.5-flash` is unavailable even across regions, we route to OpenAI’s GPT-5.</p><p><strong>Circuit Breaker</strong>: During sustained outages — when a model continuously fails — the circuit breaker activates. The system blocks requests to that model immediately, routing directly to fallback. It periodically health-checks the blocked model and restores traffic when it recovers. This fail-fast pattern minimizes latency during sustained provider outages.</p><p>These layered safeguards ensure AI-powered services remain operational even when individual providers experience issues.</p><h4>Beyond Text Generation</h4><p>AI capabilities now extend well beyond text. Models like OpenAI’s GPT-Image and Sora, along with Google’s NanoBanana, generate images and video with remarkable quality. Teams use these generation models through the same Prompt Studio workflow: select a model, test prompts, deploy when ready.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*w6znDb7pXmVTsZWE.png\" /><figcaption>Image Generation</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*x4F2iVXZbFTGAzLk.png\" /><figcaption>Video Generation</figcaption></figure><p>This unified approach enables diverse GenAI applications. We rapidly prototyped and launched campaigns and features like Karrot AI Photo Studio, Dream Home, and AI Try-on through Prompt Studio.</p><h4>Agents and the MCP Ecosystem</h4><p>Interest in AI Agents — systems that use tools and execute multi-step workflows — is growing rapidly. Agents receive a task along with available tools, then autonomously select and invoke tools as needed. The capabilities are bounded only by the tools you provide.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*LcMuz7BXT4P5vOFQ.png\" /></figure><p>Building effective Agents requires two things: well-designed tools and an execution loop that orchestrates tool calls and AI reasoning until the task completes. Prompt Studio provides both:</p><p><strong>MCP Hub</strong>: A registry for discovering and sharing internally-developed MCPs (Model Context Protocol tools). Register a useful MCP, and anyone at Karrot can find and use it. The hub hosts tools for querying internal data, fetching documents, and more.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*NN2tBBG0nQ4P8oUQ.png\" /><figcaption>MCP Hub</figcaption></figure><p><strong>Agent Builder</strong>: Combine tools from the MCP Hub to create Agents without code. Write task instructions, select a model and MCPs, and you’re done. Prompt Studio handles the orchestration loop automatically and captures every Agent execution as a Trace — enabling step-by-step debugging: “Why did the LLM call this tool?” “What was the tool response?”</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*4nJF1PGn5wbXelSp.png\" /><figcaption>Agent builder</figcaption></figure><p>Agents you build in Prompt Studio become immediately available in KarrotChat.</p><h3>KarrotChat</h3><h4>Our Internal Agent Platform</h4><p>Prompt Studio is where you build AI features and Agents — <strong>KarrotChat</strong> is where you use them.</p><p>Through KarrotChat, teams can discover and interact with Agents from Prompt Studio. Users can also select any supported model for direct conversation, and enabling MCPs from the hub requires just a toggle. Useful conversations can be shared across teams.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*YcaSTKSFg5Wgfwq9.png\" /><figcaption>Discovering Agents</figcaption></figure><h4>Case Study: DANA — Data Analysis Agent</h4><p>What happens when tools that access internal data meet capable AI and domain expertise? Karrot accumulates rich analytical data in BigQuery. But actually performing analysis was challenging — you needed to know which tables hold what information, what columns mean, which joins to perform, and how to write BigQuery SQL. This knowledge lived with a small group of specialists.</p><p>Prompt Studio let us connect MCPs with AI and capture data analysis expertise in Agent instructions. Now anyone can ask questions in KarrotChat and perform sophisticated analysis.</p><p><strong>DANA</strong> — Data Analyst of NA Product team — exemplifies this transformation. It combines the BigQuery MCP, detailed documentation of the data model, and carefully crafted prompts. Team members now get answers and insights without understanding the underlying schema.</p><p>Ask “Give me daily post counts for the past week,” and DANA finds the right table, runs the query, and returns the answer. For deeper questions like “Which category was the most popular over the past 10 days?” it joins tables, aggregates data, and surfaces insights.</p><p>No SQL knowledge required. No schema expertise needed. Since launch, DANA has become part of the team’s daily workflow — helping everyone make faster, more confident data-driven decisions.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*iDFMG7xwjVrhhFkn579srw.png\" /><figcaption>DANA in KarrotChat</figcaption></figure><p>Internal Agents like DANA are multiplying. Knowledge that once lived with specialists now spreads across the organization through Agents — measurably boosting productivity across teams.</p><h4>Wrapping Up</h4><p>Karrot has embraced AI across operations and services. Throughout 2025, we’ve built numerous AI features and internal Agents, all running on this platform. With multiple services depending on shared infrastructure, we invest heavily in reliability, observability, and security.</p><p>Our GenAI platform evolved in alignment with Karrot’s core values: autonomy, rapid experimentation, and transparent knowledge sharing. Teams adopt AI independently while the platform provides company-wide visibility and governance. Effective prompts and Agents naturally propagate across the organization. This cultural foundation has enabled Karrot to adapt quickly to the GenAI era.</p><p>As adoption grows, so does responsibility. The platform now handles hundreds of millions of requests — stability and security have never been more critical. AI technology advances daily, with new models and capabilities emerging constantly.</p><p>The LLM Infrastructure team work to bring these advances to the platform first — so every product team at Karrot can build on them. We’re hiring engineers to help shape the future of AI infrastructure here. If that sounds interesting, we’d love to talk.</p><ul><li><a href=\"https://about.daangn.com/jobs/7498021003/\">Senior Software Engineer — ML Infra (Seoul, Korea)</a></li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=5cf6e813838e\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://medium.com/daangn/karrots-genai-platform-5cf6e813838e\">Karrot’s Generative AI Platform</a> was originally published in <a href=\"https://medium.com/daangn\">당근 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2025-12-22T08:42:15.000Z",
    "url": "https://medium.com/daangn/karrots-genai-platform-5cf6e813838e?source=rss----4505f82a2dbd---4"
  },
  {
    "publisherId": "daangn",
    "publisherName": "당근마켓 테크",
    "specTitle": "React Native",
    "categories": [
      "mobile",
      "frontend"
    ],
    "specUrl": "https://medium.com/feed/daangn",
    "title": "당근의 GenAI 플랫폼",
    "partialText": "<p>안녕하세요, 당근 Tech Core의 ML Applications팀과 LLM Infra TF에서 일하고 있는 Tommy예요. 저희 팀은 ‘AI 활용에 가장 앞선 당근’이라는 비전 아래 여러 제품 팀이 AI를 더 잘 활용할 수 있도록 돕고 있어요. 2024년 초에는 <a href=\"https://medium.com/daangn/%EB%8B%B9%EA%B7%BC%EC%97%90%EC%84%9C-llm-%ED%99%9C%EC%9A%A9%ED%95%98%EA%B8%B0-76131ecebce1\">당근에서 LLM 활용하기</a>라는 글로 당근이 LLM 활용을 시작했던 몇 가지 사례와 그 과정에서 무엇이 필요했는지 공유했었는데요.</p><p>그로부터 1년 반이 지난 지금, AI 모델은 당시와 비교할 수 없을 만큼 발전했고 당근에서 GenAI를 활용하는 사례는 수백가지로 다양해졌어요. 이 글에서는 당근이 GenAI를 적극적으로 활용해오면서 마주한 문제들을 짚어두고 이를 해결하기 위해 어떤 플랫폼들을 구축해왔는지 소개하려고 해요. 비슷한 고민을 하고 있는 분들이 시행착오를 줄이고 인사이트를 얻어가셨으면 좋겠어요.</p><h3>당근의 GenAI 플랫폼</h3><p>당근의 많은 서비스들과 데이터 파이프라인 전반에서 GenAI를 활용하고 있어요. 그 뒤에는 GenAI 활용을 돕는 몇 가지 플랫폼들이 자리잡고 있어요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*ZVk-D6ZItzHcbGzMd8m8aQ.png\" /><figcaption>당근의 GenAI 플랫폼</figcaption></figure><p>조금 복잡해 보일 수 있지만 LLM Router, Prompt Studio, KarrotChat은 각각 서로 다른 문제에 집중하며 발전해왔어요. 이 플랫폼들이 어떤 문제를 해결하려고 했고, 어떤 방식으로 구축됐는지 하나씩 살펴볼게요.</p><h3>LLM Router</h3><h4>LLM 도입 초기 계정 관리의 문제</h4><p>LLM을 처음 도입하던 시기에는 AI API 호출이 필요할 때마다 각 팀에서 직접 계정을 만들고 API 키를 발급했어요. OpenAI, Anthropic, Google 등 여러 제공사의 모델을 쓰다 보니 계정과 키가 자연스럽게 늘어났고, 그만큼 관리해야 할 것들도 많아졌죠. 이 과정에서 여러 문제가 드러나기 시작했어요.</p><ul><li>AI를 사용하려는 조직이 많아지면서 계정과 API키 발급 자체가 병목이 되었어요. 발급한 API 키가 많아지면서 어느 팀이 어떤 서비스를 위해 계정과 키를 사용하는지 관리하기 어려워졌고 보안에 대한 우려도 커졌어요.</li><li>AI API는 보통 계정별로 사용량 제한(Rate Limit)이 걸려있어요. 여러 계정을 각자 사용하다 보니 어떤 계정은 여유가 남아있는데, 다른 계정은 이미 한도에 도달해 호출이 실패하는 상황이 발생했어요.</li><li>전체 비용과 사용량을 파악하기도 쉽지 않았어요. 계정과 API 키가 많아지면서 호출수와 비용을 확인하려면 여러 곳을 조회해야 했고, 당근 전체의 AI API 비용을 집계하는 데도 시간이 많이 들었어요.</li></ul><h4>AI Gateway로 통합하기</h4><p>이런 문제를 해결하기 위해 <strong>LLM Router</strong>를 도입했어요. 핵심 아이디어는 모든 AI API 호출을 하나의 관문으로 통과하게끔 모으는 거예요. API 키와 계정은 LLM Router에서만 통합 관리하고, 각 서비스들은 별도의 키나 계정 없이 서비스ID 만으로 LLM Router를 통해 AI API를 사용할 수 있도록 했어요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*oyB-F4TNd_25s5XEUMmJXA.png\" /></figure><p>LLM Router를 도입한 이후로 여러가지가 달라졌어요.</p><ul><li>계정과 API 키 발급 프로세스가 사라졌어요. 기존에 발급했던 키도 일부 예외적인 경우를 제외하고 대부분 회수할 수 있었어요. 사용하는 팀 역시 번거로운 절차 없이 원하는 API를 바로 사용할 수 있게 되었어요.</li><li>모든 호출을 한 곳으로 모으면서 계정 관리를 인프라 담당 조직에서 통합해서 맡을 수 있게 됐어요. 사용량 제한을 모니터링하고 필요한 경우 한도를 조정하는 일도 인프라 조직이 직접 담당하게 되면서, 각 서비스 팀은 운영 부담에서 벗어나 기능과 서비스에 더 집중할 수 있게 되었어요.</li><li>사용량과 비용을 파악하는 것도 훨씬 쉬워졌어요. LLM Router로 들어오는 모든 호출은 어느 서비스에서 요청했는지 추적할 수 있고, 이 정보는 당근의 인프라 비용 관리 플랫폼과 연동돼, 이제 어떤 서비스가 어떤 모델을 얼마나 쓰고 있는지 한눈에 파악할 수 있게 되었어요.</li></ul><h4>하나의 인터페이스로 모든 모델 지원</h4><p>LLM Router가 모든 AI API 호출의 관문 역할을 하려면 OpenAI, Google, Anthropic은 물론, vLLM으로 직접 서빙하는 모델까지 모두 지원해야 했어요. 문제는 각 제공사마다 API 형태와 지원하는 기능이 모두 다르다는 점이었어요. 그대로 두면 사용하는 모델에 따라 클라이언트 코드도 함께 바뀔 수밖에 없었어요. 이 문제를 해결하기 위해 LLM Router로 호출하는 클라이언트는 모델을 바꿀 때 마다 코드를 변경할 필요가 없도록 설계했어요. 제공사에 관계없이 모두 동일한 인터페이스를 제공하기 위해서 OpenAI 인터페이스를 표준으로 정하고 OpenAI SDK를 통해서 모든 모델의 기능을 사용할 수 있도록 했어요. 예를 들어 ‘claude-4.5-sonnet’을 쓰든, ‘gpt-5.2’을 쓰든, 같은 코드에서 모델 이름만 바꿔요청하면 LLM Router가 내부적으로 해당 모델에 맞는 방식으로 호출을 처리해요.</p><p>이제 새로운 모델이 출시되더라도 LLM Router에만 빠르게 추가하면 돼요. 각 팀은 별도의 구현 없이 새 모델 이름을 지정하는 것만으로 바로 사용할 수 있게 되었어요.</p><pre>from openai import OpenAI<br>client = OpenAI(base_url=&quot;https://llm_router&quot;) # base_url 변경<br><br>completion = client.chat.completions.create(<br>  model=&quot;claude-4.5-sonnet&quot;,  # 모든 모델 지원<br>  messages=[<br>    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello!&quot;}<br>  ]<br>)</pre><h3>Prompt Studio</h3><h4>AI 기능을 만들 때의 문제</h4><p>LLM 도입 초기에는 AI로 새로운 기능을 만들어보려면 매번 코드가 필요했어요. ‘이 프롬프트로 이 문제를 해결할 수 있을지 해볼까?’ 라는 아이디어를 검증하려면 먼저 엔지니어에게 코드를 요청을 해야 했어요. 아이디어가 실제로 얼마나 잘 동작하는지, 프롬프트를 어떻게 써야 하는지, 어떤 모델이 적합하고 효율적인지는 문제마다 달라요. 그래서 실제로 호출해보고 확인하는 과정을 여러 번 반복해야 했어요. 그때마다 엔지니어에게 요청하거나 코드를 수정해야 하는 구조에서는, 빠르게 실험하고 검증하기가 쉽지 않았어요.</p><h4>누구나 코드 없이 AI 기능을 만드는 곳</h4><p><strong>Prompt Studio</strong>는 이런 문제를 해결하기 위해 만든 웹 기반 AI 플랫폼이에요. 코드를 몰라도 누구나 AI 기능을 만들고 테스트할 수 있어요. 프롬프트를 입력하고 모델을 고른 후 실행 버튼만 누르면 돼요. 결과가 기대와 다르면 프롬프트를 바로 수정해 다시 실행하면서 점점 개선해나갈 수 있어요. OpenAI, Google, Anthropic 은 물론, 사내에서 서빙하는 다양한 모델까지 모두 지원해요. 원하는 모델을 자유롭게 바꿔가며 결과를 비교할 수 있고, 문제에 가장 잘 맞는 선택지를 찾을 수 있어요. 덕분에 PM 등 비개발자 직군에서도 엔지니어에 의존하지 않고도 많은 AI 기능을 개발하고, 원하는 만큼 빠르게 이터레이션을 돌릴 수 있게 되었어요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*2GBQd53gn_zNLnz0F7s5lw.png\" /><figcaption>Prompt Studio</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*6DZmBgfpyzm-2QW-ey1MfQ.png\" /><figcaption>Prompt Studio에서 지원하는 다양한 모델 비교</figcaption></figure><p>프롬프트가 어느 정도 완성되면 이제는 체계적으로 평가해볼 필요가 있어요. 몇 가지 예시에서는 잘 동작하는 것처럼 보여도, 실제로는 다양한 입력에 대해서 일관된 품질이 나오지 않는 경우도 있어요. Prompt Studio는 이런 상황을 위해 수백에서 수천 개의 테스트셋을 업로드해, 한 번에 결과를 생성하고 평가하는 Evaluation 기능을 제공해요. 이를 통해 ‘이 프롬프트가 다양한 상황에서 얼마나 잘 동작하는가’를 정량적으로 측정할 수 있어요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*rbYmybEdjAPqiu9AumQbuA.png\" /><figcaption>Prompt Studio의 Evaluation 기능</figcaption></figure><p>프롬프트가 충분히 잘 동작한다면 바로 적용해볼 수도 있어요. 엔지니어는 해당 기능을 위해 Prompt Studio API 연동을 한번만 해두면 돼요. 이후에는 코드 변경 없이, Prompt Studio에서 직접 프롬프트를 개선하고 바로 적용할 수 있어요. 하나의 프로젝트 안에서 여러 버전을 함께 관리할 수 있어서, 프롬프트나 모델을 바꿀 때 각 변경 사항을 서로 비교하며 쉽게 오갈 수 있어요. Prompt Studio API 호출 시 어떤 배포 버전을 사용할지 UI에서 바로 지정할 수 있어서, 실제 반영도 클릭 한 번이면 가능해요.</p><p>이 구조 덕분에 엔지니어의 도움 없이도 누구나 오너십을 가지고 AI 기능을 지속적으로 테스트하고 개선할 수 있게 됐어요. AI 글쓰기와 같은 기능도 Prompt Studio를 통해 빠르게 적용할 수 있었고 지속적으로 개선해 오고 있어요.</p><p>Prompt Studio에는 회사 전반에서 사용되는 수많은 프롬프트가 모여 있어요. 다른 팀이 어떤 방식으로 프롬프트를 구성했는지 참고할 수도 있고, 자연스럽게 조직 전체의 AI 활용 노하우가 쌓여가죠. Prompt Studio는 당근 안에서 AI 활용 경험치가 축적되는 허브 역할을 하고 있어요.</p><h4>안정적인 AI API를 위해</h4><p>AI API를 서비스에 적용하면서 겪는 어려움 중 하나는 API가 생각보다 불안정하다는 점이에요. 사용량 제한에 걸려 오류가 발생하는 일은 아주 흔하고, 모델 제공사 측 장애로 응답이 느려지거나 특정 모델이 일정 시간 동안 아예 작동하지 않는 경우도 있어요. 예를 들어 사용자 기능에 GPT-5 모델을 사용하고 있는데, OpenAI에 장애가 발생해 모든 요청이 실패한다면 해당 기능도 같이 멈추게 돼요. 이런 안정성 문제를 기능마다 개별적으로 대응하려면 번거롭고, 구현과 운영에 드는 비용도 커져요. <strong>Prompt Studio는 이런</strong> 문제를 해결하기 위해 여러 단계의 안전 장치를 제공하고 있어요.</p><ul><li><strong>Retry</strong>: 우선 모델이 일시적인 실패를 하는 경우 재시도 가능한 오류라면 자동으로 재시도 해요.</li><li><strong>Region Fallback</strong>: 특정 리전에서 사용량 제한이나 오류가 발생하면, 다른 리전의 같은 모델로 자동으로 재시도 해요. 예를 들어 us-central1의 gemini-2.5-flash에서 사용량 제한 오류가 발생하면, global 리전의 gemini-2.5-flash 모델로 같은 요청을 다시 시도하는 방식이에요.</li><li><strong>Model Fallback</strong>: 모든 재시도도 실패하고 장애가 나는 경우에는 다른 제공사의 모델로 폴백하는 기능도 제공해요. 만약 Google의 gemini-2.5-flash가 Region Fallback에서도 오류를 내면, OpenAI의 GPT-5 같은 미리 지정해둔 다른 모델로 대신 호출해주는 방식이에요. 이를 통해서 특정 모델에 장애가 발생하더라도 서비스 영향을 최소화 할 수 있어요.</li><li><strong>Model Circuit breaker</strong>: 특정 모델이 일정 시간동안 지속적으로 오류를 발생시키는 전면 장애 상황에서는 Circuit breaker가 발동돼요. 이 경우 해당 모델로의 요청 자체를 차단하고 바로 Model Fallback으로 처리해요. 차단된 동안에는 모델의 상태를 자동으로 점검하고, 정상으로 돌아오면 다시 복구돼요. 특정 모델이 긴 시간동안 전면 장애가 발생하는 경우 Retry에 들어가는 지연 시간을 최소화 하기 위한 장치예요.</li></ul><p>이러한 다양한 단계의 안전장치를 통해 AI API를 사용하는 서비스들이 최대한 안정적으로 동작하도록 대비하고 있어요.</p><h4>이미지와 비디오 생성까지 모든 종류의 GenAI 지원</h4><p>최근에는 OpenAI의 GPT-Image와 Sora, Google의 NanoBanana처럼 이미지와 비디오를 생성하는 AI도 빠르게 발전하고 있어요. 당근에서는 Prompt Studio를 통해 텍스트 생성뿐 아니라 이미지와 비디오 생성 모델도 바로 사용할 수 있어요. 텍스트 생성 AI와 동일하게 원하는 모델을 선택해 프롬프트를 테스트하고, 검증이 끝나면 바로 배포할 수 있어요.</p><p>이런 구조 덕분에 텍스트 생성 뿐 아니라 이미지와 비디오 생성까지 다양한 Gen AI 활용이 가능해졌어요. 당근 AI 사진관, 꿈의 집, AI Try-on 같은 다양한 이미지 생성 캠페인과 기능들도 Prompt Studio를 기반으로 빠르게 실험하고 운영할 수 있었어요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*aPaJzJg72cGC8Wc6NTQDyw.png\" /><figcaption>Prompt Studio의 이미지 생성 기능</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*26bCeYXfpQiXRn6N2qwgiA.png\" /><figcaption>Prompt Studio의 비디오 생성 기능</figcaption></figure><h4>당근의 Agent와 MCP 생태계</h4><p>AI가 도구를 사용하며 여러 단계에 걸친 작업을 수행할 수 있는 <strong>Agent</strong>에 대한 관심과 수요가 빠르게 늘고 있어요. Agent는 AI에게 작업을 요청할 때 사용할 수 있는 도구 목록을 함께 전달하고, AI가 상황에 따라 적절한 도구를 선택해 호출하도록 하는 방식이에요. 어떤 도구를 주느냐에 따라서 Agent가 할 수 있는 일은 무궁무진하죠. 유용한 Agent를 만들기 위해서는 먼저 잘 설계된 도구들이 충분히 준비되어 있어야 하고, 문제가 해결될 때까지 도구 호출과 AI 호출을 반복하는 Agent 루프도 필요해요. 이렇게 도구와 실행 흐름이 함께 갖춰질 때, Agent는 단순한 응답을 넘어 실제 작업을 수행할 수 있게 돼요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*JHzMUqyjyPYlhMjQ12vLBw.png\" /></figure><p><strong>Prompt Studio</strong>는 Agent를 쉽게 구성할 수 있도록 다음 기능들을 제공하고 있어요.</p><ul><li>MCP 허브: 사내에서 개발된 다양한 <strong>MCP</strong>들을 등록하고 탐색할 수 있는 MCP 허브를 제공해요. 유용한 MCP를 발견하거나 새로 만들었다면 이곳에 등록하면 돼요. 그러면 당근 구성원 누구나 쉽게 찾아보고 사용할 수 있어요. 사내 데이터를 조회하는 도구나 문서를 읽어오는 도구 등 다양한 MCP들이 이 허브를 통해 공유되고 있어요.</li><li>Agent 만들기: MCP 허브에 등록된 도구들을 조합해 누구나 Agent를 만들 수 있어요. 수행할 작업에 대한 지시사항을 작성하고 사용할 모델과 MCP를 선택하면 바로 완성이에요. 도구 호출과 AI 호출을 반복하는 Agent 루프는 Prompt Studio에서 자동으로 처리해요. Agent가 실행되는 전체 과정은 Trace로 기록되어서, 문제가 생겼을 때 “LLM이 왜 이 도구를 호출했지?”, “도구 실행 결과가 뭐였지?”를 단계별로 확인하며 디버깅할 수 있어요.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*75zNCxtHu4FUuB48U-ue5A.png\" /><figcaption>Prompt Studio의 MCP 허브</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*bOp-PUwfqMOSGsPGRR-91Q.png\" /><figcaption>Prompt Studio의 Agent 생성 기능</figcaption></figure><p>이렇게 만든 Agent는 <strong>KarrotChat</strong>에서 누구나 바로 사용할 수 있어요.</p><h3>KarrotChat</h3><h4>당근 사내 AI/Agent 채팅 플랫폼</h4><p>Prompt Studio가 AI 기능과 Agent를 만드는 곳이라면, <strong>KarrotChat</strong>은 만들어진 Agent를 직접 사용하는 채팅 플랫폼이에요. 사내 Agent용 ChatGPT라고 보면 이해하기 쉬워요. KarrotChat에서는 Prompt Studio에서 구성해둔 Agent들을 탐색하고 바로 사용할 수 있어요. Agent뿐만 아니라 원하는 모델을 직접 선택해서 대화할 수 있고, MCP 허브에 등록된 MCP도 간단히 켜서 사용할 수 있어요. 유용한 대화는 동료들과 서로 공유할 수도 있어요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*ocGWq7phABHwIjcFj5JiNg.png\" /><figcaption>KarrotChat에서 Agent 탐색하기</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*vZUpHYcS2RXRB470uq3zGQ.png\" /><figcaption>KarrotChat에서 Agent와 대화하기</figcaption></figure><h4>당근알바팀의 데이터 분석 Agent 사례</h4><p>사내 데이터에 접근할 수 있는 도구, 똑똑한 AI, 그리고 동료들의 노하우가 만나면 어떤 일이 가능할까요? 당근은 다양한 분석을 할 수 있는 데이터를 빅쿼리에 많이 쌓고 있어요. 하지만 실제로 이를 활용해서 분석하는 일은 쉽지 않았어요. 어떤 테이블에 어떤 정보가 있는지, 각 칼럼들은 어떤 의미인지, 원하는 정보를 보기 위해서 어떤 테이블을 조인해야 하는지, 그리고 무엇보다 빅쿼리 SQL을 작성할 수 있는지까지. 이런 지식들이 있어야만 데이터 분석이 가능했어요.</p><p>Prompt Studio에서 MCP와 AI를 연결하고, 데이터 분석 노하우를 지시사항으로 담은 Agent를 구성할 수 있게 되면서 상황이 달라졌어요. 이제는 누구나 KarrotChat에서 원하는 정보를 물어보고 깊이있는 데이터 분석을 할 수 있게 되었어요.</p><p>예를 들어, 당근알바팀의 ‘데이터캣’은 이런 변화를 잘 보여주는 사례예요. 데이터캣은 빅쿼리 MCP와 당근알바 빅쿼리 데이터 구조에 대한 상세한 가이드, 그리고 프롬프트 엔지니어링을 결합해서 만든 Agent예요. 당근알바 팀원들은 데이터 구조에 대한 배경 지식 없이도 데이터캣을 통해서 다양한 정보를 얻고 분석할 수 있게 되었어요. 뿐만 아니라 데이터캣은 팀원들이 최근에 사용한 쿼리들을 기억하고, 도메인 지식을 학습하면서 사용할수록 점점 개인에게 맞게 똑똑해지는 기능도 가지고 있어요.</p><p>예를 들어 “어제 게시된 당근알바 공고는 몇 개야?” 와 같은 간단한 질문에 바로 답할 수 있어요. 데이터캣이 알아서 적절한 테이블을 찾고, 쿼리를 만들고, 실행해서 결과를 알려줘요. “최근 열흘 동안 특별히 인기 있었던 공고들의 제목은 뭐야?” 같은 분석 요청도 가능해요. 여러 테이블을 조인하고, 집계하고, 결과를 분석해 패턴을 찾아 인사이트를 제공해요. SQL을 몰라도, 테이블 구조를 몰라도 누구나 데이터 기반의 의사결정을 할 수 있는 환경이 만들어진 거예요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*92-iA64M-18LIu5LjE03Fg.png\" /><figcaption>KarrotChat에서 데이터캣과 대화</figcaption></figure><p>데이터캣처럼 당근 동료들이 매일 사용하는 사내 Agent들도 점점 늘어나고 있어요. 이전에는 소수의 사람만 가지고 있던 지식이나 노하우가 Agent를 통해 회사 전체로 전파되고, 결과적으로 모두의 생산성도 눈에 띄게 향상되고 있어요.</p><h3>마치며</h3><p>당근은 AI를 업무와 서비스 전반에서 적극적으로 활용해오고 있어요. 2025년 한 해 동안에도 많은 AI 기능과 사내Agent들이 만들어졌고, 지금도 이 플랫폼 위에서 운영되고 있어요. 여러 서비스가 공통 플랫폼에 의존하는 만큼 안정성과 가시성과 보안을 확보하는 데에도 많은 노력을 기울이고 있답니다.</p><p>당근 GenAI 플랫폼은 자율, 빠른 실험, 투명한 공유라는 당근의 핵심 문화와도 잘 맞는 방향으로도 발전해왔어요. 각 팀은 자율적으로 AI를 활용하되, 플랫폼을 통해 전사적인 가시성과 거버넌스를 함께 확보해요. 빠르게 실험하고 배포할 수 있는 환경이 갖춰져 있고 좋은 프롬프트와 Agent는 자연스럽게 공유되어요. 이런 문화적 기반 위에서 당근은 GenAI 활용에 빠르게 적응하는 회사로 성장할 수 있었어요.</p><p>플랫폼 위에 올라가는 기능이 많아질수록 책임도 함께 커지고 있어요. 이제는 수억번의 호출이 처리되는 인프라가 되었고, 그만큼 안정성과 보안의 중요성도 더 커졌어요. AI 기술은 빠르게 발전하고 있고, 그에 맞춘 새로운 모델과 기능도 매일같이 등장하고 있으니까요.</p><p>ML 인프라팀과 ML Applications팀은 당근의 모든 제품 팀이 이런 변화를 빠르게 활용하고 지렛대로 삼을 수 있도록 플랫폼 차원에서 가장 먼저 제공하려고 해요. 지금은 당근의 AI 플랫폼을 함께 만들어갈 동료도 찾고 있어요. 관심 있다면 아래 링크를 참고해 주세요.</p><ul><li><a href=\"https://about.daangn.com/jobs/7498021003/\">Senior Software Engineer, Machine Learning — ML 인프라</a></li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=ee2ac8953046\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://medium.com/daangn/%EB%8B%B9%EA%B7%BC%EC%9D%98-genai-%ED%94%8C%EB%9E%AB%ED%8F%BC-ee2ac8953046\">당근의 GenAI 플랫폼</a> was originally published in <a href=\"https://medium.com/daangn\">당근 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2025-12-19T10:28:14.000Z",
    "url": "https://medium.com/daangn/%EB%8B%B9%EA%B7%BC%EC%9D%98-genai-%ED%94%8C%EB%9E%AB%ED%8F%BC-ee2ac8953046?source=rss----4505f82a2dbd---4"
  },
  {
    "publisherId": "daangn",
    "publisherName": "당근마켓 테크",
    "specTitle": "React Native",
    "categories": [
      "mobile",
      "frontend"
    ],
    "specUrl": "https://medium.com/feed/daangn",
    "title": "Running Elasticsearch on Kubernetes the Easy Way, Part 2 — Data Node Warm-Up",
    "partialText": "<h3>Running Elasticsearch on Kubernetes the Easy Way, Part 2 — Data Node Warm-Up</h3><p>Hi, we’re Ellie and Jarry from the Search Platform team at Karrot. Our team is responsible for handling the massive search traffic generated across Karrot’s various services-quickly and reliably-while building a platform that enables new search experiences. In <a href=\"https://medium.com/daangn/%EB%8B%B9%EA%B7%BC%EB%A7%88%EC%BC%93-%EA%B2%80%EC%83%89-%EC%97%94%EC%A7%84-%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4%EB%A1%9C-%EC%89%BD%EA%B2%8C-%EC%9A%B4%EC%98%81%ED%95%98%EA%B8%B0-bdf2688df267\">Part 1</a>, we shared our journey of migrating our search infrastructure to Kubernetes (ECK), achieving deployment automation and reducing deployment time. What once took 5 hours was cut down to 90 minutes, and anyone could now safely deploy to our search clusters.</p><p>At the end of Part 1, we mentioned the following:</p><blockquote><em>“When deploying during peak traffic times, we observed spikes in CPU usage and latency. (…) Since there are short-term solutions like simply avoiding peak hours for deployments, we decided to proceed while accepting this as a non-issue.”</em></blockquote><p>Back then, we thought, “Just avoid peak hours-no big deal.” But over time, we realized that <strong>the constraint of having to avoid peak hours was itself the problem</strong>. Operators still had to constantly watch the clock, and once a deployment started, they still had to nervously monitor dashboards. In this article, we’ll explain why we came to see this as a problem and how we solved it.</p><h3>1. Challenges Remaining After ECK Adoption</h3><h4>1.1. How Much Has Our Search Infrastructure Grown in Two Years?</h4><p>When we wrote Part 1, we had a single search cluster handling about 1,000 queries per second (1K QPS) at peak.</p><p>Two years later, Karrot has grown and so has our search infrastructure. We now operate four clusters, each serving different purposes, with peak traffic like this:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*UiBiUdOOWlKvvfq5efy7Gw.png\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*PXh-9Jo2X31bDgSZQexLvw.png\" /></figure><p>As we explained in Part 1, our ECK-based search clusters operate using the following architecture: we define Elasticsearch Custom Resources in a Kubernetes environment and run them as StatefulSets.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/884/1*DIEwUBuI9oJCq7zgJRjm5g.png\" /><figcaption>ECK-based Search Cluster Architecture</figcaption></figure><p>It wasn’t just traffic that increased. With four clusters now in operation, the operational burden grew as well. As covered in Part 1, deploying a single cluster took roughly 90 minutes. With four clusters, total deployment time stretched beyond 6 hours, and someone had to monitor the entire process.</p><h4>1.2. The Limits of “Just Deploy Outside Peak Hours”</h4><p>In Part 1, we said we achieved deployment automation with ECK-but there was an important caveat: <strong>“as long as we avoid peak hours.”</strong></p><p>At first, this didn’t seem like a big deal. We could just deploy in the early morning or late at night. But as we scaled to four clusters and deployments became more frequent, the practical issues became clear.</p><p>First, <strong>the available deployment windows kept shrinking</strong>. After avoiding peak hours, lunch breaks, and the times right before and after work, only a few hours each day were left for deployments. Situations arose where urgent patches were blocked because “it’s peak time right now.”</p><p>Second, <strong>deployments started feeling like “big events.”</strong> Before clicking the ArgoCD sync button, we had to check: “Is traffic okay right now? Is it safe to deploy at this hour?” Even during deployment, we had to keep watching the latency graphs. We wondered: if we’ve automated deployments, why does it still feel so stressful?</p><p>Ultimately, the real problem we needed to solve was this:</p><blockquote><em>“Let’s create a state where we can deploy with peace of mind, whether it’s peak time or not.”</em></blockquote><p><strong>So why were we so afraid of peak hours?</strong></p><p>It wasn’t just because traffic was high. The real issue was the <strong>latency spikes that occurred during rolling restarts</strong>. Let’s dig into the root causes.</p><h3>2. The Real Reason Rolling Restarts Were Scary</h3><p>A Kubernetes StatefulSet rolling restart updates Pods one at a time, in order. As soon as a Pod becomes Ready, it moves on to the next.</p><p>The problem is that for systems like Elasticsearch that <strong>rely heavily on caches</strong>, this approach isn’t safe. A Pod being Ready doesn’t mean it’s actually ready to handle traffic — frequently accessed data must be loaded into memory (page cache, query cache, etc.) before the node can respond quickly.</p><p>At Karrot, we actually experienced a major outage due to this issue during an ECK rolling restart. That incident became the starting point for building our warm-up system.</p><h4>2.1. A Real Incident Story</h4><p>One day, an Elastic Operator version issue triggered a rolling restart across all Elasticsearch StatefulSets. For a typical Kubernetes service, Pods would go down and come back up one by one without much trouble.</p><p>But Elasticsearch was different. As the rolling restart progressed, the next Pod restarted as soon as the previous one became Ready, but from Elasticsearch’s perspective, it wasn’t actually ready. The restarted nodes had completely empty caches and had to serve traffic in a severely degraded state. During this process, some shards had both their primary and replica affected in succession, degrading availability, and ultimately causing a major outage across the search service.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*SpAUOhMUMu22a0ybBalrWA.png\" /><figcaption>[Rolling Restart Incident] Search API error rate at 60%, latency spiking to 3s</figcaption></figure><p>This experience taught us that the expectation ‘Kubernetes will handle rolling restarts safely’ does not apply to Elasticsearch.</p><h4>2.2. What Happens When a Data Node Restarts</h4><p>When a data node restarts, several things happen simultaneously inside Elasticsearch.</p><p>First, the restarted data node joins the Elasticsearch cluster with a completely empty file system cache. In this state, queries must read data from disk, significantly increasing search latency.</p><p>Second, while the data node is down, the load on that shard is concentrated on other replica shards.</p><p>The moment these two issues overlap is when the cluster is most unstable.</p><p><strong>The Problem with Cache — Cold New Nodes</strong></p><p>Elasticsearch uses multiple levels of caching — page cache, query cache, field data cache, request cache, and more. But when a data node starts fresh, all these caches are empty. Every cache miss requires reading segments from disk, and as this delay accumulates, requests start piling up in the search thread pool queue. The result: p50 and p90 latency can spike to several times their normal values.</p><p><strong>The Problem of Load Concentration on Remaining Nodes</strong></p><p>When a data node goes down, the replica shards it held become Unassigned. The ES cluster transitions to a yellow state, meaning “all primary shards are alive, but some replicas are unassigned.” The service doesn’t stop immediately, but two problems emerge:</p><ul><li>The remaining replica shards must handle all requests, increasing their load.</li><li>Shards without replicas become a single point of failure. If the node holding that primary also dies, the cluster goes red — unable to process search or indexing requests.</li></ul><p>In summary, request volume stays the same while the number of nodes available to handle it decreases, concentrating load on the remaining nodes. Then, when a cache-cold node rejoins, latency spikes for requests routed to it.</p><p>When both of these problems occur together, rolling restarts in Elasticsearch become particularly scary.</p><h3>3. Defining Goals and Solution Strategy</h3><p>After analyzing the problem, we defined our target state:</p><blockquote><em>“Create a state where clicking the Elasticsearch deploy button at any time won’t bring down the search service.”</em></blockquote><p>Specifically, we wanted three things:</p><ul><li>No need for humans to monitor and adjust timing during deployment</li><li>Search p99 latency stays under 1s even during rolling restarts</li><li>The system handles unexpected node restarts automatically</li></ul><h4>3.1. Why Kubernetes Native Mechanisms Weren’t Enough</h4><p>You might wonder: “Can’t we just tweak readinessProbe or add a postStart hook for warm-up?” But due to how Elasticsearch works, these approaches don’t help.</p><p>The key is <strong>when Elasticsearch data node joins the cluster</strong>. As soon as a data node Pod enters Running state, it joins the Elasticsearch cluster. This happens completely independently of Kubernetes readinessProbe or postStart hooks. The moment the Elasticsearch process starts, it tells the master node “I’m ready,” and the master immediately begins assigning shards to this node.</p><p>Even before the readinessProbe passes, the node is already part of the Elasticsearch cluster. Being removed from the Kubernetes Service’s Endpoints doesn’t matter — Elasticsearch uses its own node discovery and routing, sending requests directly to the node within the cluster, bypassing the Kubernetes Service. postStart hooks are similar — the ES process can join the cluster before the hook completes; it doesn’t wait.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*4CBPaSD7jH0QaQsb0sVe_w.png\" /></figure><p>Fundamentally, neither Kubernetes nor Elasticsearch settings alone can automate the state of “don’t receive traffic until warm-up is complete.” So our solution strategy boils down to one line:</p><blockquote><em>“Let nodes restart freely, but don’t let them receive search traffic until warm-up is complete.”</em></blockquote><p>The implementation of this idea is our warm-up system, with <strong>search-coordinator</strong> as its core component. We’ll explain how it works in detail in the next section.</p><h3>4. search-coordinator Proxy Architecture</h3><p>Now let’s look at how we made it possible to click the Elasticsearch deploy button without worry.</p><p>The core idea is simple: we placed a proxy called <strong>search-coordinator</strong> between our servers and Elasticsearch, creating a structure where only warmed-up data nodes participate in search. Thanks to this architecture, even when data nodes restart, search traffic always flows only to nodes that have completed warm-up.</p><h4>4.1. Architecture Overview</h4><p>Previously, services connected directly to Elasticsearch, giving us no control over traffic. Now, all requests go through search-coordinator, giving us traffic control. We operate one ECK cluster and one search-coordinator per namespace in a 1:1 structure. We added the search-coordinator module to the existing ECK-only architecture as shown below:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Sv6HKVdPsbWtQN5JcM6WwQ.png\" /><figcaption>[Before] ECK-based Search Cluster</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Zl82b_mDxbarGSMNHnc8vw.png\" /><figcaption>[After] ECK-based Search Cluster with Search Coordinator</figcaption></figure><p>search-coordinator serves two roles.</p><p>First, it’s an <strong>HTTP proxy</strong>. It receives search/indexing requests and forwards them to ES. Since it communicates via internal DNS within the same Kubernetes cluster, additional latency is negligible.</p><p>Second, it’s a <strong>warm-up orchestrator</strong>. It determines which nodes can participate in search and manages that state. Nodes receiving termination signals are immediately removed from search targets, and newly started nodes are only added to search targets after warm-up is complete.</p><h4>4.2. Controlling Search Target Nodes with prefer_nodes</h4><p>The list of data nodes eligible for search is managed through Central Dogma.</p><iframe src=\"\" width=\"0\" height=\"0\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/dde6600cbb634293fe6606d58f44bf08/href\">https://medium.com/media/dde6600cbb634293fe6606d58f44bf08/href</a></iframe><p>prefer_nodes is the list of data nodes currently eligible for search. Newly started nodes are not included until they pass warm-up. The warmup section defines criteria for warm-up evaluation - QPS, latency thresholds, minimum/maximum duration - which can be configured differently per cluster.</p><p>When search-coordinator receives a search request, it only sends it to Elasticsearch data nodes registered in Central Dogma. This enabled us to build a structure where search traffic doesn’t flow to nodes that are still warming up.</p><h4>4.3. search-coordinator as the Single State Manager</h4><p>There’s a clear reason we limited Central Dogma reads and writes to search-coordinator alone.</p><p>First, we wanted to maintain a <strong>Single Source of Truth</strong> for node routing state. We wanted to keep “which nodes are search-serving targets” in one place. If multiple servers each queried Elasticsearch to determine “which nodes are currently usable,” states would diverge based on polling timing, and debugging points would multiply exponentially.</p><p>Second, we wanted to <strong>fully encapsulate routing policy in one component</strong>. If decisions like including/excluding data nodes from search targets, warm-up success/failure, and exception handling all happen within search-coordinator, other modules don’t need to know ES’s internal state. Conversely, if applications or batch scripts directly modify the node list, tracking “who changed what, when, and why” becomes difficult.</p><h3>5. search-coordinator Warm-Up Orchestration Architecture</h3><p>Let’s look in more detail at the process from when a node goes down to when it rejoins. Elasticsearch data nodes run as Pods in a Kubernetes StatefulSet. search-coordinator operates in sync with the lifecycle of these data node Pods.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*LfN4WQHC5Nqjog1yW-yxwg.png\" /><figcaption>Data Node Lifecycle (<strong>prestop</strong> → <strong>exclude</strong> → <strong>warmup</strong> → <strong>warmup pass</strong> → <strong>include</strong> → <strong>serve traffic</strong>)</figcaption></figure><h4>5.1. When a Node Goes Down: prestop &amp; exclude Phases</h4><p>Phases (1) prestop and (2) exclude in the diagram above are the process of safely removing a data node from serving.</p><p>When a data node goes down, search-coordinator performs two main tasks. Just before the ES data node Pod terminates, a preStop script runs and sends information about the soon-to-terminate node to search-coordinator. Then search-coordinator first removes (excludes) that node from prefer_nodes in Central Dogma to stop search traffic from flowing to it. Next, it adds the same node to a warm-up queue based on a Redis Sorted Set. We use timestamps as scores so we can later dequeue the oldest nodes first.</p><p><strong>Fallback for preStop Hook Failures</strong></p><p>preStop hooks can fail or not be called at all. To handle this, we have a search-coordinator-controller module that subscribes to Elasticsearch data node Pod events via a Kubernetes Informer. If preStop wasn’t called but the Pod enters Terminating state, the Informer detects this and the controller performs the same tasks. This provides a safety net that doesn’t rely solely on preStop hooks but also validates against the Pod’s actual lifecycle.</p><h4>5.2. Real Traffic-Based Warm-Up: warmup Phase</h4><p>Phase (3) warmup in the diagram is the process of populating the cache for a cache-cold node.</p><p>When a node comes back up, warm-up begins in earnest. However, if multiple search-coordinator Pods warm up the same node simultaneously, it can cause problems, so we first need to determine “who will warm up this node.”</p><p><strong>Using Redis Distributed Locks to Assign Warm-Up Responsibility</strong></p><p>We designed warm-up so that exactly one search-coordinator Pod handles it. If multiple Pods simultaneously attempt warm-up on the same data node, duplicate queries hit the same shards, creating unnecessary load and in some cases, ES might return 429 Too Many Requests errors. Conversely, a single Pod can generate sufficient QPS for warm-up.</p><p>So we use a Redis distributed lock to decide “who is responsible for this node’s warm-up.” All warm-up workers poll the Redis warm-up queue, and when they detect the same node, only the Pod that acquires the lock first proceeds with warm-up. Other Pods skip immediately if they’re not the lock owner, guaranteeing single search-coordinator warm-up per node. Lock tokens are formatted as podIP/podName-timestamp-randomHex for easy tracking of which Pod holds the lock.</p><p><strong>Collecting Warm-Up Queries</strong></p><p>We decided to use production traffic patterns directly for warm-up queries. We stream all search request logs to a Kafka topic, and the search-coordinator worker responsible for warm-up consumes this topic in real-time to build a query pool. When warm-up starts, it pulls requests from this pool and sends them concentrated to the warm-up target node.</p><p>Queries dequeued aren’t used just once and discarded — <strong>they’re reused up to 5 times</strong>. When Elasticsearch builds query caches, it applies a <a href=\"https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=There%20is%20also%20a%20condition%20for%20the%20minimum%20frequency%20to%20be%20eligible%20for%20caching%2C%20so%20that%20a%20single%20invocation%20will%20not%20result%20in%20the%20cache%20being%20filled\">minimum frequency condition</a>, so a single request isn’t enough to create a cache entry.</p><p>Looking at Lucene’s <a href=\"https://github.com/apache/lucene/blob/683f59f66b9f8d48c8f28840b9d7722b6f079b86/lucene/core/src/java/org/apache/lucene/search/UsageTrackingQueryCachingPolicy.java#L116C3-L138C4\">minFrequencyToCache</a>() method used by Elasticsearch, the same query needs to come in at least 2 times (or 5 times depending on conditions) to become a caching candidate. If we sent every query just once, we&#39;d increase disk I/O without actually building caches. So we force cache creation with a &quot;real traffic + repeated identical queries&quot; combination.</p><h4>5.3. Warm-Up Completion and Traffic Serving: warmup pass &amp; include &amp; serve traffic Phases</h4><p>Phases (4) warmup pass, (5) include, and (6) serve traffic in the diagram are the process of evaluating whether warm-up is complete for a node, and if passed, adding it to prefer_nodes to receive actual search traffic.</p><p>Query send rate follows the QPS (Queries Per Second) setting defined in Central Dogma. Response latency is tracked by storing the most recent N requests in a Circular Buffer and calculating p50 and p90 latency at configured intervals to check if they meet the criteria.</p><p>Warm-up success requires three conditions: total request count meets the minimum threshold, minimum execution time has elapsed, and recent response p50 and p90 latency are both within thresholds. When all conditions are met, warm-up is judged successful, the node is removed from the Redis warm-up queue, and added to prefer_nodes in Central Dogma to receive search traffic.</p><p><strong>Warm-Up Failure and Retry</strong></p><p>If maximum execution time is reached without meeting criteria, warm-up is judged as failed. In this case, the node is not removed from the warm-up queue. The worker releases the lock and exits. Another search-coordinator Pod then acquires the lock and retries warm-up. Even with temporary network delays or Kafka lag, the system can recover through self-retry.</p><h4>5.4. Safeguards to Prevent Shard Shortage</h4><p>To warm up a data node, we first need to exclude it from search targets. The problem is that if this is applied to multiple nodes simultaneously, situations can arise where “both primary and replica for this shard are warming up, making search completely impossible.” So we added safeguards with the goal of “warm up, but never create a situation where shards become unavailable.”</p><p><strong>Limiting the Number of Nodes That Can Be Excluded from Search</strong></p><p>We limited simultaneous warm-up to a maximum of 2 nodes — meaning at most 2 nodes can be excluded from search targets at once. This isn’t an arbitrary number but calculated based on our shard replication policy. Our indexing system enforces at least 2 replica shards per shard. So each shard consists of 1 primary and 2 replicas. Limiting excluded nodes to 2 ensures that even in the worst case, at least 1 node holding that shard always remains available.</p><p>To enforce this limit, we periodically check the warm-up queue. If 3 or more nodes are queued, we stop warm-up for the oldest node (by timestamp) and immediately return it to the prefer_nodes search target set. In this case, warm-up isn&#39;t 100% complete, but since caches warm up quickly once real traffic starts, latency stabilizes soon.</p><h3>6. Operational Results</h3><p>In actual operation, we achieved results meeting all three criteria we set during project goal-setting.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*7qPFhzkAN2AW3iJhMy9ncA.png\" /></figure><h4>6.1. No Need for Humans to Monitor and Adjust Timing During Deployment</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*0CmPE7T6W_dpLqrpf9u9Mg.png\" /></figure><p>Previously, one person could only handle one cluster at a time, so deploying all four took nearly half a day. Now, we can run rolling restarts on each cluster simultaneously, and search-coordinator handles the exclude → warmup → include process automatically, enabling total deployment completion in 1–2 hours.</p><p>The biggest change is the significant reduction in psychological burden around deployments. Before, we had to steel ourselves: ‘Today I need to mentally prepare for a deployment.’ Now it’s something we can do whenever needed. It’s no longer a tense operation that requires picking a specific late-night window — we can run rolling restarts regardless of whether it’s peak time or not.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*vKoQq5QBKngOo4wgdjNmmA.png\" /><figcaption>First case of Elasticsearch data node warm-up</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Vg_UOftSan5xSTnfRCfigw.png\" /></figure><h4>6.2. Search p99 Latency Stays Under 1s Even During Rolling Restarts</h4><p>Before introducing the warm-up system, p90 latency would spike to 3–5x normal levels when rolling restarts began. After introduction, latency stays stable at normal levels even during rolling restarts. Notably, p99 latency also remains servable under 1s.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*dj2epnhulWtBFRXlDVuy0w.png\" /><figcaption>[Before] Rolling Restart Latency Without Warm-Up</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*12JSkqEj1T0qxdJWsUVu1w.png\" /><figcaption>[After] Rolling Restart Latency With Warm-Up</figcaption></figure><h4>6.3. The System Handles Unexpected Node Restarts Automatically</h4><p>Another important change is handling unexpected situations. The figure below shows a case where we arbitrarily restarted a data node and the exclude → warmup → include process completed successfully.</p><p>Before, when an ES data node restarted due to infrastructure issues, all we could do was watch and wait for “when the cache refills and latency returns to normal.” Now, the moment a node goes down, it’s automatically excluded from search targets, and after coming back up, it only receives traffic after passing warm-up. Thanks to this, we now have the confidence that unexpected restarts won’t immediately cascade into full-blown outages.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*0KHRdl22H4MPYpku_-EZzA.png\" /><figcaption>Successful warm-up notification for data node 17 after restart</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*_QgiVcdkt9l6FT9s.png\" /><figcaption>Metrics showing automatic warm-up progress for data node 17 after restart</figcaption></figure><h3>7. Limitations and Next Steps</h3><p>In this project, our goal was to ensure that even if nodes are temporarily excluded from search targets during warm-up, specific shards never become completely unsearchable. This significantly improved stability during node restarts, but some areas remain unsolved.</p><p>For example, if the entire ES cluster becomes unavailable or network issues prevent access to ES itself, search-coordinator’s intervention capability is very limited. Also, when search query DSL structures change significantly, there can be a gap between query patterns accumulated in Kafka and actual traffic, potentially reducing warm-up effectiveness.</p><p>Currently, our warm-up system focuses on data node restart scenarios. Going forward, we plan to expand our coverage to handle full cluster failures and other unpredictable situations without severely impacting search.</p><p>Another next step is extensibility. While this system was built for Karrot’s internal environment, we’re also considering how to package it so other teams or companies using ECK can easily adopt it.</p><h3>Conclusion</h3><p>In summary, here’s the problem we solved: after adopting ECK, latency spikes during rolling restarts meant we had to avoid deploying during peak hours. By placing search-coordinator in front of Elasticsearch and controlling traffic so only warmed-up nodes receive search requests, everything changed. Now, clicking the ArgoCD sync button triggers the system to complete deployment safely on its own, regardless of whether it’s peak time or not.</p><p>As a result, the Search Platform team can spend time building better search experiences instead of worrying about “when should we deploy?”</p><h3>Join Us</h3><p>The Karrot Search Platform team will continue improving how we operate our Kubernetes-based search engine. We’re working to build a robust platform that can reliably handle massive traffic while delivering better search results. If you’d like to join us in solving these challenges, check out the job posting below.</p><p>🥕 <a href=\"https://about.daangn.com/jobs/6653346003/\">Software Engineer, Backend — Search Platform</a></p><p>Thanks for reading!</p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=0d81d433c5c1\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://medium.com/daangn/running-elasticsearch-on-kubernetes-the-easy-way-part-2-data-node-warm-up-0d81d433c5c1\">Running Elasticsearch on Kubernetes the Easy Way, Part 2 — Data Node Warm-Up</a> was originally published in <a href=\"https://medium.com/daangn\">당근 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2025-12-16T07:03:54.000Z",
    "url": "https://medium.com/daangn/running-elasticsearch-on-kubernetes-the-easy-way-part-2-data-node-warm-up-0d81d433c5c1?source=rss----4505f82a2dbd---4"
  },
  {
    "publisherId": "daangn",
    "publisherName": "당근마켓 테크",
    "specTitle": "React Native",
    "categories": [
      "mobile",
      "frontend"
    ],
    "specUrl": "https://medium.com/feed/daangn",
    "title": "당근 검색 엔진, 쿠버네티스로 쉽게 운영하기 2편 — 데이터 노드 웜업 적용",
    "partialText": "<h3>당근 검색 엔진, 쿠버네티스로 쉽게 운영하기 2편 — 데이터 노드 웜업 적용</h3><p>안녕하세요, 당근 검색 플랫폼팀 Ellie, Jarry예요. 검색플랫폼팀은 당근의 여러 서비스에서 발생하는 방대한 검색 트래픽을 빠르고 안정적으로 처리하고, 더 나아가 새로운 검색 경험을 가능하게 하는 플랫폼을 만드는 팀이에요. 지난 글인 <a href=\"https://medium.com/daangn/%EB%8B%B9%EA%B7%BC%EB%A7%88%EC%BC%93-%EA%B2%80%EC%83%89-%EC%97%94%EC%A7%84-%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4%EB%A1%9C-%EC%89%BD%EA%B2%8C-%EC%9A%B4%EC%98%81%ED%95%98%EA%B8%B0-bdf2688df267\">1편</a>에서는 저희가 검색 인프라를 쿠버네티스(ECK)로 이관하면서 배포 자동화와 배포 시간 단축을 이뤘던 이야기를 공유했어요. 5시간 걸리던 배포가 90분으로 줄었고, 누구나 안전하게 검색 클러스터를 배포할 수 있게 됐죠.</p><p>그리고 1편을 마무리할 때 이런 이야기를 했는데요.</p><blockquote><em>“피크 타임 트래픽일 때 배포하면 CPU 사용률과 레이턴시가 튀는 현상이 발생하는 것을 확인할 수 있었어요. (…) 피크 타임을 피해서 배포하는 등의 단기적으로 쉽게 해결할 수 있는 방안도 있기 때문에, 이 문제는 논이슈로 감안하고 진행하기로 했어요.”</em></blockquote><p>당시만 해도 “피크 타임만 피하면 되지”라고 생각했어요. 하지만 시간이 지나면서, <strong>“피크 타임을 피해야 한다”는 제약 자체가 문제</strong>라는 걸 깨달았어요. 운영자가 배포 시간을 계속 신경 써야 했고, 배포가 시작되면 여전히 긴장하며 지켜봐야 했으니까요. 이번 글에서는 왜 이걸 문제라고 생각하게 되었는지, 그리고 어떻게 해결했는지 이야기해 볼게요.</p><h3>1. ECK 도입 후에도 남은 과제</h3><h4>1.1. 검색 인프라, 2년 만에 얼마나 커졌을까</h4><p>1편을 쓸 당시에는 검색 클러스터가 하나였고, 피크 타임 트래픽은 초당 약 1,000건(1K QPS) 정도였어요.</p><p>2년이 지난 지금은 어떨까요? 당근이 성장하면서 검색 인프라도 함께 커졌어요. 지금은 목적에 따라 네 개의 클러스터를 운영하고 있고, 각 클러스터가 받는 피크 타임 트래픽도 아래처럼 크게 달라졌어요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*bnLzt8X_mNZQVtXqPiFMkA.png\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*AtiGCKJRLD1MjVHxv2GYSg.png\" /></figure><p>1편에서 말했듯이, ECK 기반 검색 클러스터는 다음과 같은 구조로 동작하고 있어요. 쿠버네티스 환경에서 Elasticsearch Custom Resource를 정의하고, 이를 기반으로 StatefulSet으로 운영하는 구조예요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/884/1*DIEwUBuI9oJCq7zgJRjm5g.png\" /><figcaption>ECK 기반 검색 클러스터 구성도</figcaption></figure><p>트래픽만 늘어난 게 아니에요. 클러스터가 네 개로 늘어나면서 운영 부담도 함께 커졌어요. 1편에서 다뤘던 것처럼, 한 클러스터를 배포하는 데는 대략 90분 정도가 필요했어요. 그런데 클러스터가 네 개로 늘어나면서 전체 배포에 6시간 이상이 걸리게 됐고, 그 긴 시간 동안 담당자가 계속 붙어서 모니터링해야 했죠.</p><h4>1.2. “피크 타임을 피해서 배포하세요”의 한계</h4><p>1편에서 우리는 ECK를 도입해 배포 자동화를 이뤘다고 말했지만, 한 가지 중요한 포인트가 있었어요. 바로 “<strong>피크 타임만 피하면</strong>” 이라는 전제 조건이에요.</p><p>처음에는 이게 큰 문제처럼 느껴지지 않았어요. 새벽이나 오전 시간대에 배포하면 되니까요. 그런데 클러스터가 네 개로 늘어나고, 배포할 일이 잦아지면서 현실적인 문제가 드러났어요.</p><p>첫째, <strong>배포 가능한 시간이 점점 줄었어요</strong>. 피크 타임을 피하고, 점심시간도 피하고, 퇴근 전후도 피하다 보면 배포할 수 있는 시간이 하루에 몇 시간 되지 않았어요. 긴급 패치가 필요할 때 “지금은 피크 타임이라 못 해요”라고 말해야 하는 상황이 생겼어요.</p><p>둘째, <strong>배포가 점점 “큰 이벤트”처럼 느껴지기 시작했어요</strong>. ArgoCD sync 버튼을 누르기 전에 “지금 트래픽 괜찮지?”, “이 시간에 해도 되지?”를 확인해야 했고, 배포 중에도 레이턴시 그래프를 계속 지켜봐야 했어요. 배포 자동화를 했는데도 왜 이렇게 아직도 긴장하면서 배포해야 할까?라는 의문이 들기 시작했죠.</p><p>결국, 우리가 진짜 풀어야 할 문제는 이거였어요.</p><blockquote><strong><em>“피크 타임이든 아니든, 언제든 마음 편하게 배포할 수 있는 상태를 만들자.”</em></strong></blockquote><p><strong>그렇다면 왜 우리는 피크 타임을 그렇게 두려워했을까요?</strong></p><p>단순히 트래픽이 많아서만은 아니었어요. 진짜 문제는 배포 과정, 그중에서도 <strong>롤링 리스타트 중에 레이턴시가 급증하는 현상</strong> 때문이었어요. 그럼, 이제 롤링 리스타트 중에 왜 레이턴시가 올라갔는지, 그 근본 원인을 하나씩 파헤쳐 볼게요.</p><h3>2. 롤링 리스타트가 무서웠던 진짜 이유</h3><p>쿠버네티스 StatefulSet 롤링 리스타트는 Pod를 하나씩 차례대로 업데이트하는 기능이에요. Pod가 Ready 상태가 되면 바로 다음 Pod를 업데이트하죠.</p><p>하지만 여기서 문제는 Elasticsearch처럼 캐시에 크게 의존하는 시스템에서는 이 방식이 안전하지 않다는 거예요. Pod가 Ready 상태가 됐다고 해서 바로 트래픽을 처리할 수 있는 게 아니고, 자주 조회되는 데이터가 메모리(page cache, query cache 등)에 올라와야 비로소 빠른 응답이 가능하거든요.</p><p>당근도 실제로 ECK의 Rolling Restart 과정에서 이 문제로 큰 장애를 겪었어요. 그 경험이 웜업 시스템을 만들게 된 출발점이 됐죠.</p><h3>2.1. 실제 장애 이야기</h3><p>어느 날, Elastic Operator 버전 이슈로 모든 Elasticsearch StatefulSet이 Rolling Restart 되는 상황이 생겼어요. 보통의 쿠버네티스 서비스라면 Pod가 한 대씩 내려갔다가 올라오면서 큰 문제없이 진행됐을 거예요.</p><p>하지만 Elasticsearch의 현실은 달랐어요. Rolling Restart가 진행되면서 Pod가 Ready 상태가 되자마자 다음 Pod가 재시작됐는데, ES 입장에서는 아직 준비가 안 된 상태였어요. 재시작된 노드들은 캐시가 완전히 비어 있었고, 쿼리 성능이 크게 저하된 상태로 곧바로 트래픽을 받아야 했죠. 이 과정에서 일부 샤드는 primary와 replica가 연달아 영향을 받으면서 가용성까지 떨어졌고, 결국 검색 서비스 전반에 큰 장애가 발생했어요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*SpAUOhMUMu22a0ybBalrWA.png\" /><figcaption>[Rolling Restart 장애 시점] 검색 API 전체 에러율 60%, 레이턴시 3s까지 치솟던 상황</figcaption></figure><p>이 경험을 통해 “롤링 리스타트는 쿠버네티스가 알아서 안전하게 처리해 줄 거야”라는 기대가, 적어도 Elasticsearch에서는 통하지 않는다는 사실을 확실히 배웠어요.</p><h4>2.2. 데이터 노드 재시작 시 벌어지는 일</h4><p>데이터 노드가 재시작될 때 Elasticsearch 내부에서는 몇 가지 일이 동시에 일어나요.</p><p>첫째, 재시작된 데이터 노드는 file system cache가 전부 비어 있는 상태로 Elasticsearch 클러스터에 합류해요. 이 상태에서 쿼리를 받으면 디스크에서 데이터를 읽어야 하므로 검색 latency가 크게 증가해요.</p><p>둘째, 데이터 노드가 내려가 있는 동안 해당 샤드의 부하가 다른 복사본 샤드로 집중돼요. 이 두 가지가 겹치는 순간이 클러스터가 가장 불안정한 상태예요.</p><p><strong>캐시가 비어 있는 새 노드의 문제</strong></p><p>Elasticsearch는 page cache 외에도 query cache, field data cache, request cache 등 여러 레벨의 캐시를 활용해요. 하지만 데이터 노드가 새로 뜨면 이 캐시들이 전부 비어 있는 상태로 시작해요. Cache miss가 발생할 때마다 디스크에서 segment를 읽어야 하고, 이 지연이 쌓이면서 search thread pool 큐에 요청이 밀리기 시작해요. 결과적으로 p50, p90 latency가 평소보다 몇 배씩 튀게 되죠.</p><p><strong>남은 노드로 부하가 집중되는 문제</strong></p><p>데이터 노드 하나가 내려가면 그 노드가 들고 있던 replica 샤드는 Unassigned 상태가 돼요. 이때 ES 클러스터는 yellow 상태로 전환되는데, 이건 “primary 샤드는 모두 살아있지만, 일부 replica는 할당되지 않은 상태”를 뜻해요. 당장 서비스가 멈추진 않지만, 두 가지 문제가 생겨요.</p><ul><li>남은 replica 샤드들이 모든 요청을 처리해야 해서 부하가 가중돼요.</li><li>replica가 없는 샤드는 single point of failure가 돼요. 이 상태에서 해당 primary를 가진 노드마저 죽으면 red 상태, 즉 검색/색인 요청을 처리할 수 없는 상태가 돼요.</li></ul><p>정리하자면, 요청량은 그대로인데 처리할 노드 수가 줄어들어 남은 노드에 부하가 집중되는 거예요. 이후 cold cache 상태의 노드가 다시 join하면, 캐시가 비어 있는 노드로 라우팅 된 요청의 latency가 급증하기 시작하죠. 그리고 이 두 가지 문제가 겹치는 순간, Elasticsearch에서 롤링 리스타트가 유난히 무섭게 느껴져요.</p><h3>3. 목표와 해결 전략 정하기</h3><p>위처럼 문제를 분석하고 나서, 저희는 도달하고자 하는 목표 상태를 정했어요.</p><blockquote><em>“언제든 Elasticsearch 배포 버튼을 눌러도, 검색 서비스가 무너지지 않는 상태를 만들자.”</em></blockquote><p>구체적으로는 세 가지를 원했어요.</p><ul><li>배포할 때 사람이 모니터링하면서 타이밍을 조절할 필요가 없을 것</li><li>Rolling Restart 중에도 검색 p99 latency 1s 이내일 것</li><li>예기치 못한 노드 재시작에도 시스템이 알아서 대응할 것</li></ul><h4>3.1. 쿠버네티스 기본 메커니즘으로는 왜 해결하지 못할까?</h4><p>“쿠버네티스 readinessProbe를 조절하거나, postStart hook으로 웜업하면 되지 않나요?”라는 의문이 들 수도 있어요. 하지만 Elasticsearch의 동작 방식 때문에 이 방법은 통하지 않아요.</p><p>핵심은 <strong>Elasticsearch가 클러스터에 join하는 시점</strong>이에요. 데이터 노드 Pod가 Running 상태가 되면, 곧바로 Elasticsearch 클러스터에 join해요. 이건 쿠버네티스의 readinessProbe나 postStart hook과는 완전히 별개의 일이에요. Elasticsearch 프로세스가 뜨자마자 마스터 노드에 “나 준비됐어”라고 알리고, 마스터 노드는 바로 이 노드에 샤드를 배치하기 시작해요.</p><p>readinessProbe 통과 전이라고 하더라도 Elasticsearch 클러스터 관점에서는 이미 데이터 노드로 편입된 상태예요. 쿠버네티스 Service의 Endpoints에서 빠져 있어도 소용 없어요. Elasticsearch는 자체 노드 디스커버리와 라우팅을 사용하기 때문에, 쿠버네티스 Service를 거치지 않고 클러스터 내부에서 직접 해당 노드로 요청을 보내요. postStart hook도 마찬가지예요. hook이 완료되기 전에 ES 프로세스는 이미 클러스터에 join할 수 있어요. hook 완료를 기다려주지 않죠.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*8SoPE6Icw8X6nVyNi89e2Q.png\" /></figure><p>근본적으로 쿠버네티스나 Elasticsearch 설정만으로는 “웜업이 끝날 때까지 트래픽을 받지 않는” 상태를 자동화하기 어려워요. 그래서 해결 전략은 한 줄로 정리할 수 있어요.</p><blockquote><em>“노드는 마음껏 재시작하되, 웜업이 끝나기 전까지는 검색 트래픽을 받지 않게 하자.”</em></blockquote><p>이 아이디어를 실제로 구현한 것이 바로 웜업 시스템이고, 그 중심에 있는 핵심 컴포넌트가 search-coordinator예요. 다음 섹션에서 어떻게 동작하는지 자세히 설명할게요.</p><h3>4. search-coordinator Proxy 아키텍처</h3><p>이제 어떻게 하면 안심하고 Elasticsearch 배포 버튼을 누를 수 있게 되었는지 방법을 살펴볼게요.</p><p>핵심 아이디어는 간단해요. 서버와 Elasticsearch 사이에 search-coordinator라는 프록시를 두고, 웜업이 끝난 데이터 노드만 검색에 참여시키는 구조를 만든 거예요. 이 구조 덕분에 데이터 노드가 재시작되더라도 검색 트래픽은 항상 웜업이 완료된 노드로만 흘러가게 됐어요.</p><h4>4.1. 아키텍처 개요</h4><p>기존에는 서비스가 Elasticsearch에 직접 연결되어 있어서, 트래픽을 통제할 권한이 없었어요. 현재는 모든 요청이 search-coordinator를 거쳐 가면서 트래픽 제어권이 생겼어요. 네임스페이스 하나당 ECK 클러스터 하나, search-coordinator 하나를 1:1 구조로 운영하고 있죠. 아래와 같이 ECK 클러스터만 존재하던 구조에 search-coordinator 모듈을 새롭게 추가했어요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Sv6HKVdPsbWtQN5JcM6WwQ.png\" /><figcaption>[Before] ECK 기반 검색 클러스터</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Zl82b_mDxbarGSMNHnc8vw.png\" /><figcaption>[After] ECK 기반 검색 클러스터 with Search Coordinator</figcaption></figure><p>search-coordinator는 두 가지 역할을 해요.</p><p>첫째는 <strong>HTTP 프록시</strong>예요. 검색/색인 요청을 받아서 ES로 전달하는데, 같은 쿠버네티스 클러스터에서 내부 DNS로 통신하기 때문에 추가 지연은 거의 없어요.</p><p>둘째는 <strong>웜업 오케스트레이터</strong>예요. 어떤 노드가 검색에 참여할 수 있는지를 판단하고 그 상태를 관리해요. 종료 시그널을 받은 노드는 즉시 검색 대상에서 제외하고, 새로 올라온 노드는 웜업이 끝난 뒤에만 검색 대상에 추가해요.</p><h4>4.2. prefer_nodes로 검색 대상 노드 제어하기</h4><p>검색에 참여할 수 있는 데이터 노드 목록은 Central Dogma로 관리해요.</p><iframe src=\"\" width=\"0\" height=\"0\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/ef2740661882b28b22cc61d288771eb8/href\">https://medium.com/media/ef2740661882b28b22cc61d288771eb8/href</a></iframe><p>prefer_nodes는 “현재 검색 대상이 되는 데이터 노드 목록”이에요. 새로 뜬 노드는 웜업을 통과하기 전까지 이 목록에 포함되지 않아요. warmup 섹션에는 QPS, latency 임계값, 최소/최대 시간처럼 웜업 판단에 필요한 기준을 정의하고, 클러스터별로 다른 값을 설정할 수 있어요.</p><p>search-coordinator는 검색 요청을 받으면 Central Dogma에 등록된 Elasticsearch 데이터 노드로만 검색 요청을 보내요. 덕분에 웜업 중인 노드로는 검색 트래픽이 흐르지 않는 구조를 만들 수 있었어요.</p><h4>4.3. 단일 상태 관리자로서의 search-coordinator</h4><p>Central Dogma를 읽고 쓰는 주체를 search-coordinator 하나로만 제한한 데에는 분명한 이유가 있어요.</p><p>첫째, 노드 라우팅 상태의 Single Source of Truth를 유지하고 싶었어요. “어떤 노드가 검색 서빙 대상인지”에 대한 정보를 한 곳에만 두고 싶었거든요. 여러 서버가 각자 Elasticsearch 상태를 조회해서 “지금 쓸 수 있는 노드”를 판단하기 시작하면 폴링 타이밍마다 상태가 어긋나고, 디버깅 포인트도 기하급수적으로 늘어나요.</p><p>둘째, 라우팅 정책을 한 컴포넌트에 온전히 캡슐화하고 싶었어요. 검색 대상 데이터노드 포함/제외, 웜업 성공 여부, 예외 처리 같은 결정이 search-coordinator 안에서만 이루어지면, 다른 모듈은 ES 내부 상태를 알 필요가 없어요. 반대로 애플리케이션이나 배치 스크립트가 직접 노드 목록을 수정하게 되면 “누가 언제 어떤 이유로 데이터 노드를 검색 대상에서 제외하거나 추가했는지” 추적하기 어려워지거든요.</p><h3>5. search-coordinator 웜업 오케스트레이션 아키텍처</h3><p>이제 노드 한 대가 내려갔다가 다시 합류할 때까지의 과정을 조금 더 상세히 살펴볼게요. Elasticsearch 데이터 노드는 쿠버네티스 StatefulSet의 Pod로 운영돼요. search-coordinator는 이 데이터 노드 Pod의 라이프사이클에 맞춰 동작해요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*LfN4WQHC5Nqjog1yW-yxwg.png\" /><figcaption>데이터노드 라이프사이클 (<strong>prestop</strong> → <strong>exclude</strong> → <strong>warmup</strong> → <strong>warmup pass </strong>→ <strong>include</strong> → <strong>serve traffic</strong>)</figcaption></figure><h4>5.1. 노드가 내려갈 때: prestop &amp; exclude 단계</h4><p>위 도식의 (1)prestop, (2)exclude 단계는 데이터 노드가 안전하게 서빙에서 제외되는 과정이에요.</p><p>데이터 노드가 내려갈 때 search-coordinator는 크게 두 가지 작업을 수행해요. ES 데이터 노드 Pod가 종료되기 직전에 preStop 스크립트가 실행되면서 종료 예정인 노드 정보가 search-coordinator로 전달돼요. 그러면 search-coordinator는 먼저 Central Dogma의 prefer_nodes에서 해당 노드를 제거(exclude)해서 검색 트래픽이 더 이상 흐르지 않게 만들어요. 그다음 같은 노드를 Redis Sorted Set 기반의 웜업 대기열에 추가해요. score로 타임스탬프를 사용해서 나중에 가장 오래된 노드부터 순서대로 꺼낼 수 있게 했어요.</p><p><strong>preStop hook 실패에 대비한 Fallback</strong></p><p>preStop hook이 실패하거나 아예 호출되지 않는 경우도 있어요. 이런 상황을 대비해 search-coordinator-controller 모듈을 두고, 쿠버네티스 Informer로 Elasticsearch 데이터 노드 Pod 이벤트를 구독하고 있어요. preStop이 호출되지 않았는데 Pod가 Terminating으로 진입하면 Informer가 이를 감지하고, controller가 동일한 작업을 대신 수행해요. preStop hook만 의존하지 않고 Pod의 실제 라이프사이클을 기준으로 한 번 더 검증하는 안전망이에요.</p><h4>5.2. 실 트래픽 기반 웜업: warmup 단계</h4><p>위 도식의 (3)warmup 단계는 cold cache 상태의 노드에 대해 캐시를 채워주는 과정이에요.</p><p>노드가 다시 올라오면 본격적인 웜업이 시작돼요. 다만 여러 search-coordinator Pod가 동시에 같은 노드를 웜업하면 오히려 문제가 생길 수 있어서, 먼저 “누가 이 노드를 웜업할지”를 정하는 단계가 필요했어요.</p><p><strong>Redis 분산 락으로 웜업 담당자 정하기</strong></p><p>웜업은 여러 search-coordinator Pod 중 딱 하나의 Pod만 담당하도록 했어요. 동일한 데이터 노드에 여러 Pod가 동시에 웜업을 시도하면, 같은 샤드로 중복 쿼리가 몰리면서 불필요한 부하가 생기고, 경우에 따라 오히려 ES에서 429 Too Many Requests가 발생해 요청이 거부될 수 있거든요. 반대로 하나의 Pod만 붙여도 웜업에 필요한 QPS는 충분히 만들 수 있었어요.</p><p>그래서 “이 노드 웜업은 누가 담당하는지”를 결정하기 위해 Redis 분산 락을 사용했어요. 모든 웜업 워커가 Redis 웜업 대기열을 폴링하다가 동일한 노드를 감지하면, 가장 먼저 락을 획득한 Pod만 해당 노드 웜업을 진행해요. 나머지 Pod들은 락의 주인이 아니면 바로 스킵해서, 한 노드에 대해 항상 단일 search-coordinator만 웜업하도록 보장해요. 락 토큰은 podIP/podName-timestamp-randomHex 형식으로 만들어, 어떤 Pod가 락을 잡았는지 쉽게 추적할 수 있게 했어요.</p><p><strong>웜업 쿼리 수집</strong></p><p>저희는 웜업 쿼리로 운영 트래픽 패턴을 그대로 사용하기로 했어요. 모든 검색 요청 로그를 Kafka 토픽에 쌓고 있어서, 웜업을 담당하는 search-coordinator 워커가 이 토픽을 실시간으로 consume해서 쿼리 풀을 만들어요. 웜업이 시작되면 이 풀에서 요청을 꺼내 웜업 대상 노드로 집중해서 보내요.</p><p>이때 큐에서 꺼낸 요청을 한 번만 쓰고 버리지는 않아요. <strong>최대 5회까지 재사용</strong>해요. Elasticsearch는 쿼리 캐시를 만들 때 <a href=\"https://www.elastic.co/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time#:~:text=There%20is%20also%20a%20condition%20for%20the%20minimum%20frequency%20to%20be%20eligible%20for%20caching%2C%20so%20that%20a%20single%20invocation%20will%20not%20result%20in%20the%20cache%20being%20filled\">최소 빈도 조건</a>을 적용해서, 단 한 번의 요청만으로는 캐시가 생성되지 않아요.</p><p>실제로 Elasticsearch에서 사용하는 Lucene 코드의 <a href=\"https://github.com/apache/lucene/blob/683f59f66b9f8d48c8f28840b9d7722b6f079b86/lucene/core/src/java/org/apache/lucene/search/UsageTrackingQueryCachingPolicy.java#L116C3-L138C4\">minFrequencyToCache(</a>) 메서드를 보면 동일한 쿼리가 최소 2회(혹은 조건에 따라 5회) 이상 들어와야 캐싱 대상이 돼요. 모든 쿼리를 한 번씩만 보내면 disk I/O만 늘고 캐시는 거의 쌓이지 않는 상태가 되는 거죠. 그래서 저희는 &quot;실제 트래픽 + 동일 쿼리 반복&quot; 조합으로 캐시가 실제로 만들어지도록 강제했어요.</p><h4>5.3 웜업 완료 판정 및 트래픽 서빙: warmup pass &amp; include &amp; serve traffic 단계</h4><p>위 도식의 (4)warmup pass, (5)include, (6)server traffic 단계는 웜업이 완료된 노드에 대해 웜업 통과 여부를 판단하고 통과한 노드를 prefer_nodes에 추가해 실제 검색 트래픽을 받게 되는 과정이에요.</p><p>쿼리를 보내는 속도는 Central Dogma에 정의된 QPS(Query Per Second) 설정을 따라요. 응답 Latency는 최근 N개의 요청을 Circular Buffer에 적재하고, 설정한 주기마다 p50, p90 Latency를 계산해서 기준을 만족하는지 확인해요.</p><p>웜업 성공 조건은 세 가지예요. 총요청 수가 최소 개수 기준을 충족하고, 최소 실행 시간 이상 경과했으며, 최근 응답의 p50, p90 Latency가 모두 임계값 이내여야 해요. 이 조건을 모두 만족하면 웜업을 성공으로 판정하고, Redis 웜업 대기열에서 해당 노드를 제거한 뒤 Central Dogma의 prefer_nodes에 추가해 검색 트래픽을 받도록 해요.</p><p><strong>웜업 실패와 재시도</strong></p><p>웜업 최대 실행 시간을 채웠는데도 기준을 만족하지 못하면 웜업 실패로 판단해요. 이때는 웜업 대기열에서 노드를 제거하지 않고, 해당 워커는 락을 해제한 뒤 종료해요. 그러면 다른 search-coordinator Pod가 다시 락을 잡고 웜업을 재시도해요. 일시적인 네트워크 지연이나 Kafka 지연이 있더라도 시스템이 스스로 재시도하면서 복구할 수 있도록 구조를 설계했어요.</p><h4>5.4. 샤드 부족을 막기 위한 안전장치</h4><p>데이터 노드를 웜업하려면 일단 검색 대상에서 제외해야 해요. 문제는 이걸 여러 노드에 동시에 적용하면 이 샤드는 primary도, replica도 전부 웜업 중이라서 검색이 아예 안 되는 상황이 생길 수 있다는 점이에요. 그래서 “웜업은 하되, 샤드가 부족해지는 상황은 절대 만들지 않는다”를 목표로 안전장치를 넣었어요.</p><p><strong>검색 대상에서 빠질 수 있는 노드 수 제한</strong></p><p>동시에 웜업 가능한 노드를 최대 2개로 제한했어요. 즉, 검색 대상에서 동시에 빠질 수 있는 노드를 최대 2개로 제한했어요. 이 값은 임의로 정한 게 아니라 샤드 복제본 정책에 맞춰 계산한 값이에요. 색인 시스템에서는 모든 인덱스가 샤드 당 replica 샤드를 최소 2개를 갖도록 강제하고 있어요. 그래서 하나의 샤드는 primary 1개와 replica 2개로 구성돼요. 검색 대상에서 빠지는 노드를 최대 2개로 제한하면, 최악의 상황에도 해당 샤드를 가진 노드가 최소 1개는 항상 남게 돼요.</p><p>그리고 이 제한을 지키기 위해 웜업 대기열을 주기적으로 확인해요. 대기열에 노드가 3개 이상 쌓이면 timestamp 기준으로 가장 오래된 노드의 웜업을 중단하고 바로 검색 대상 집합인 prefer_nodes로 복귀시켜요. 이 경우 웜업이 100% 완료된 상태는 아니지만, 실 트래픽을 받기 시작하면 캐시가 빠르게 워밍되기 때문에 latency도 금방 안정돼요.</p><h3>6. 운영 결과</h3><p>실제 운영 결과, 프로젝트 목표 설정 시 잡았던 세 가지 기준에 모두 부합하는 성과를 이루었어요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*acJXHXPlmjmXfMnD2hXg8A.png\" /></figure><h4>6.1. 배포할 때 사람이 모니터링하면서 타이밍을 조절할 필요가 없을 것</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*sIWKif1GldbKWyvBY5nSMA.png\" /></figure><p>이전에는 한 사람이 한 번에 한 클러스터만 맡을 수 있어서, 클러스터 4개를 모두 배포하려면 거의 반나절을 써야 했어요. 지금은 각 클러스터를 동시에 Rolling Restart로 돌릴 수 있고, search-coordinator가 노드 제외 → 웜업 → 복귀 과정을 알아서 처리해 줘서 전체 배포를 1~2시간 안에 끝낼 수 있는 구조가 됐어요.</p><p>무엇보다 큰 변화는 배포에 대한 심리적 부담이 크게 줄었다는 점이에요. 예전에는 “오늘은 마음 단단히 먹고 배포 한번 해야겠다”라고 준비해야 했다면, 이제는 필요할 때 언제든 진행할 수 있는 작업이 됐어요. 특정 새벽 시간대를 잡아서 긴장하며 진행해야 하는 작업이 아니라, 피크 타임이든 아니든 시간에 관계없이 Rolling Restart를 진행할 수 있어요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*1qZCAyhpXj6-sLsBp07DwQ.png\" /><figcaption>elasticsearch 데이터노드 웜업 첫 사례</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*pcFrC3uXWRzcapmWVXYFdA.png\" /></figure><h4>6.2. Rolling Restart 중에도 검색 p99 latency 1s 이내일 것</h4><p>웜업 시스템을 도입하기 전에는 Rolling Restart가 시작되면 p90 레이턴시가 평소의 3~5배까지 치솟았어요. 도입 후에는 Rolling Restart 중에도 평소 수준을 안정적으로 유지하게 됐어요. 특히 p99 레이턴시 또한 1s 이내로 서빙 가능해요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*dj2epnhulWtBFRXlDVuy0w.png\" /><figcaption>[Before] 웜업 적용 전 Rolling Restart 레이턴시</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*12JSkqEj1T0qxdJWsUVu1w.png\" /><figcaption>[After] 웜업 적용 후 Rolling Restart 레이턴시</figcaption></figure><h4>6.3. 예기치 못한 노드 재시작에도 시스템이 알아서 대응할 것</h4><p>또 하나의 중요한 변화는 예기치 못한 상황에 대한 대응이에요. 아래 그림은 데이터 노드 한 대를 임의로 재시작했을 때, exclude → warmup → include 과정이 성공적으로 진행된 상황을 보여줘요.</p><p>예전에는 ES 데이터 노드가 인프라 문제로 재시작되면 “언제 캐시가 다시 차서 latency가 정상으로 돌아오나”를 지켜보는 수밖에 없었어요. 지금은 노드가 내려가는 순간 자동으로 검색 대상에서 제외되고, 다시 올라온 뒤에는 웜업을 거쳐 충분히 준비된 상태에서만 트래픽을 받아요. 그 덕분에 예기치 못한 재시작이 발생해도 곧바로 전면 장애로 이어지지 않는다는 안정감을 갖게 됐어요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*0KHRdl22H4MPYpku_-EZzA.png\" /><figcaption>17번 데이터노드 재시작 시 성공적으로 웜업 완료된 Notification</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*vd9NhRvIJAXKs_Xn8XpQOw.png\" /><figcaption>17번 데이터노드 재시작 시 자동으로 웜업 진행된 메트릭</figcaption></figure><h3>7. 한계와 다음 스텝</h3><p>이번 프로젝트에서는 웜업 과정에서 일시적으로 노드를 검색 대상에서 제외하더라도, 특정 샤드가 완전히 검색 불가능한 상태가 되지 않도록 만드는 것을 목표로 했어요. 그 덕분에 노드 재시작 상황에서는 안정성을 크게 끌어올릴 수 있었지만, 여전히 해결하지 못한 영역도 남아 있어요.예를 들어, ES 클러스터 전체가 불능 상태가 되거나 네트워크 장애로 ES 자체에 접근할 수 없는 경우에는 <strong>search-coordinator</strong>가 개입할 수 있는 범위가 매우 제한적이에요. 또 검색 쿼리 DSL 구조가 크게 바뀌는 상황에서는 Kafka에 축적된 기존 쿼리 패턴과 실제 트래픽 사이에 괴리가 생겨 웜업 효과가 충분히 발휘되지 않을 가능성도 있어요.</p><p>현재 웜업 시스템은 데이터 노드 재시작 상황에 초점을 맞추고 있어요. 앞으로는 클러스터 전체 장애나 예측하기 어려운 상황에서도 검색이 크게 흔들리지 않도록 대응 범위를 넓혀갈 예정이에요. 또 하나의 다음 스텝은 확장성이에요. 지금은 당근 내부 환경에 맞춰 만들어진 시스템이지만, ECK를 사용하는 다른 팀이나 회사에서도 쉽게 적용할 수 있도록 패키징하는 방안도 고민하고 있어요.</p><h3>마무리</h3><p>정리하면, 저희는 이런 문제를 해결했어요. ECK를 도입했지만, 롤링 리스타트 시 레이턴시 스파이크가 발생해, 피크 타임에는 배포를 피해야 했어요. search-coordinator를 Elasticsearch 앞에 두고 웜업이 끝난 노드만 검색 트래픽을 받도록 제어하면서 상황이 달라졌어요. 이제는 ArgoCD sync 버튼을 누르면 시스템이 알아서 안전하게 배포를 완료해줘요. 피크 타임이든 아니든 상관없이요.</p><p>그 결과, 검색 플랫폼팀은 “배포 언제 하지?”라는 고민 대신, 더 좋은 검색 경험을 만드는 데 시간을 쓸 수 있게 됐어요.</p><h3>함께해요</h3><p>당근 검색 플랫폼 팀은 앞으로도 쿠버네티스 기반의 검색 엔진을 더 효율적으로 운영하기 위해 끊임없이 개선해 나갈 예정이에요. 수많은 트래픽을 안정적으로 소화하면서, 더 좋은 검색 결과를 제공할 수 있는 튼튼한 플랫폼을 만들기 위해 노력하고 있고요. 이런 문제를 해결해 나가는 과정에 함께하고 싶으시다면, 아래 공고를 함께 살펴보세요.</p><p>🥕 <a href=\"https://about.daangn.com/jobs/6653346003/\">Software Engineer, Backend — 검색 플랫폼</a></p><p>읽어주셔서 감사해요!</p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=f687a6c2c00a\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://medium.com/daangn/%EB%8B%B9%EA%B7%BC-%EA%B2%80%EC%83%89-%EC%97%94%EC%A7%84-%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4%EB%A1%9C-%EC%89%BD%EA%B2%8C-%EC%9A%B4%EC%98%81%ED%95%98%EA%B8%B0-2%ED%8E%B8-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%85%B8%EB%93%9C-%EC%9B%9C%EC%97%85-%EC%A0%81%EC%9A%A9-f687a6c2c00a\">당근 검색 엔진, 쿠버네티스로 쉽게 운영하기 2편 — 데이터 노드 웜업 적용</a> was originally published in <a href=\"https://medium.com/daangn\">당근 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2025-12-15T05:42:56.000Z",
    "url": "https://medium.com/daangn/%EB%8B%B9%EA%B7%BC-%EA%B2%80%EC%83%89-%EC%97%94%EC%A7%84-%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4%EB%A1%9C-%EC%89%BD%EA%B2%8C-%EC%9A%B4%EC%98%81%ED%95%98%EA%B8%B0-2%ED%8E%B8-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%85%B8%EB%93%9C-%EC%9B%9C%EC%97%85-%EC%A0%81%EC%9A%A9-f687a6c2c00a?source=rss----4505f82a2dbd---4"
  }
]