[
  {
    "publisherId": "velog",
    "publisherName": "Velog",
    "specTitle": "개발자 블로그",
    "categories": [
      "_all_"
    ],
    "specUrl": "https://v2.velog.io/rss/",
    "title": "SSRF 취약점",
    "partialText": "<p>Server-Side Request Forgery - 서버측 요청 위조</p>\n<p>워게임 문제 중 서버측에서 요청을 위조해서 로컬의 파일을 읽어드리는 문제</p>\n<p>flag가 /flag.txt에 위치해 있을때 로컬 코드 중 fetch를 사용하거나 요청을 보낼 수 있는 함수를 사용한다면 아래와 같이 시도해볼 수 있다.</p>\n<pre><code>file:///flag.txt\nfile://localhost/flag.txt</code></pre><p>이 방법을 변형해서 다양하게 사용가능하다.</p>",
    "date": "2026-02-15T01:52:50.000Z",
    "url": "https://velog.io/@j-iwon/SSRF-%EC%B7%A8%EC%95%BD%EC%A0%90"
  },
  {
    "publisherId": "velog",
    "publisherName": "Velog",
    "specTitle": "개발자 블로그",
    "categories": [
      "_all_"
    ],
    "specUrl": "https://v2.velog.io/rss/",
    "title": "1. MySQL의 역사, 라이선스, 그리고 우리가 사용하는 이유",
    "partialText": "<p>지금은 너무나 당연하게 사용하고 있는 오픈소스 데이터베이스 <strong>MySQL</strong>. 하지만 처음부터 지금의 모습은 아니었다. MySQL의 탄생부터 오라클 인수 후의 변화, 그리고 수많은 DBMS 중 왜 MySQL을 선택해야 하는지에 대해 정리해 본다.</p>\n<h2 id=\"1-mysql의-역사와-라이선스-변화\">1. MySQL의 역사와 라이선스 변화</h2>\n<h3 id=\"탄생과-성장\">탄생과 성장</h3>\n<ul>\n<li><strong>1979년:</strong> 스웨덴의 TcX(텍스트에는 TeX로 표기됨)라는 회사의 터미널 인터페이스 라이브러리인 <code>UNIREG</code>로부터 시작되었다.</li>\n<li><strong>1994년:</strong> 웹 시스템의 데이터베이스로 사용되면서 MySQL 버전 1.0이 완성되었으나 사내에서만 사용되었다.</li>\n<li><strong>1996년:</strong> 드디어 일반인에게 공개되었다.</li>\n<li><strong>2000년:</strong> 핵심 개발자인 몬티와 데이빗이 <strong>MySQL AB</strong>라는 회사로 독립하며 GPL(Free Public License) 정책을 도입했다.</li>\n<li><strong>2006년:</strong> 현재와 같은 <strong>이중 라이선스(Dual License)</strong> 정책을 확립했다.</li>\n</ul>\n<h3 id=\"현재의-라이선스-정책-커뮤니티-vs-엔터프라이즈\">현재의 라이선스 정책 (커뮤니티 vs 엔터프라이즈)</h3>\n<p>MySQL은 썬마이크로시스템즈를 거쳐 오라클에 인수되었지만, 라이선스 정책의 큰 틀은 유지되고 있다. <strong>결론적으로 MySQL은 100% 무료는 아니다.</strong></p>\n<table>\n<thead>\n<tr>\n<th>구분</th>\n<th>MySQL 커뮤니티 에디션</th>\n<th>MySQL 엔터프라이즈 에디션</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>대상</strong></td>\n<td>일반 사용자 (별도 계약 없음)</td>\n<td>라이선스 계약을 맺은 기업/사용자</td>\n</tr>\n<tr>\n<td><strong>비용</strong></td>\n<td>무료</td>\n<td>유료</td>\n</tr>\n<tr>\n<td><strong>소스코드</strong></td>\n<td>공개</td>\n<td><strong>비공개</strong> (5.5 GA 버전 이후)</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Note:</strong> 과거에는 두 에디션의 차이가 패치 주기 정도였고 소스코드도 모두 공개되었으나, <strong>2011년 MySQL 5.5 GA 버전부터 엔터프라이즈 에디션의 소스코드는 비공개</strong>로 전환되었다. (커뮤니티 에디션은 여전히 공개)</p>\n</blockquote>\n<h2 id=\"2-오라클-인수-우려와-반전\">2. 오라클 인수, 우려와 반전</h2>\n<p>오라클이 MySQL을 인수했을 때, 시장에서는 &quot;MySQL은 이제 사라질 것&quot;이라는 우려가 컸다. 하지만 이는 기우에 불과했다. 오라클은 오히려 MySQL을 더욱 강력하게 변화시켰다.</p>\n<ul>\n<li><strong>초기:</strong> 소스코드 레벨부터 리팩토링 진행</li>\n<li><strong>5.5 ~ 5.7 버전:</strong> 안정성과 성능 개선에 집중</li>\n<li><strong>8.0 버전 이후:</strong> 상용 DBMS 수준의 고급 기능 탑재 시작</li>\n</ul>\n<p>오라클 인수 후 지난 10여 년은 <strong>MySQL 역사상 가장 큰 변화와 발전의 시기</strong>였다고 평가받는다.</p>\n<h2 id=\"3-왜-여전히-mysql인가-경쟁력\">3. 왜 여전히 MySQL인가? (경쟁력)</h2>\n<p>다른 DBMS, 특히 상용 데이터베이스인 오라클 RDBMS와 비교했을 때 MySQL의 가장 큰 무기는 <strong>비용 효율성</strong>과 <strong>범용성</strong>이다.</p>\n<h3 id=\"데이터-폭증의-시대\">데이터 폭증의 시대</h3>\n<p>과거 금융권이나 대형 시스템은 오라클 DB가 필수였지만, 이제는 상황이 달라졌다.</p>\n<ul>\n<li>국내 유명 포털의 빌링 시스템, 대형 은행 시스템 등에서도 MySQL을 도입하여 사용 중이다.</li>\n<li>폭발적으로 늘어나는 데이터를 모두 고가의 상용 DBMS에 저장하는 것은 비용적으로 불가능에 가깝다.</li>\n</ul>\n<blockquote>\n<p><strong>페이스북 DBA의 한마디:</strong>\n&quot;페이스북이 가진 데이터를 모두 오라클 RDBMS에 저장하면 페이스북은 망할 것이다.&quot;</p>\n</blockquote>\n<p>앞으로 데이터가 수백, 수천 배로 늘어날 미래에는 <strong>MySQL(또는 오픈소스 DB) 외에는 대안이 없을지도 모른다.</strong></p>\n<h2 id=\"4-좋은-dbms를-선택하는-기준\">4. 좋은 DBMS를 선택하는 기준</h2>\n<p>&quot;어떤 DBMS가 가장 좋은가요?&quot;라는 질문에 대한 정답은 <strong>&quot;자기가 가장 잘 활용할 수 있는 DBMS&quot;</strong>다. 하지만 여전히 고민된다면 다음 순서로 고려해 보자.</p>\n<ol>\n<li><strong>안정성 (Stability):</strong> 가장 중요하다. 성능은 돈과 노력으로 해결되지만, 안정성이 무너지면 개발자는 잠을 잘 수 없다.</li>\n<li><strong>성능과 기능 (Performance &amp; Features)</strong></li>\n<li><strong>커뮤니티와 인지도 (Community &amp; Popularity)</strong></li>\n</ol>\n<h3 id=\"커뮤니티가-중요한-이유\">커뮤니티가 중요한 이유</h3>\n<p>다음은 <a href=\"https://db-engines.com\">DB-Engines</a>에서 발표한 2026년 2월 기준 DBMS 랭킹이다.</p>\n<table>\n<thead>\n<tr>\n<th>Rank</th>\n<th>DBMS</th>\n<th>Database Model</th>\n<th>Score</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>1</strong></td>\n<td>Oracle</td>\n<td>Relational, Multi-model</td>\n<td>1203.51</td>\n</tr>\n<tr>\n<td><strong>2</strong></td>\n<td><strong>MySQL</strong></td>\n<td><strong>Relational, Multi-model</strong></td>\n<td><strong>868.22</strong></td>\n</tr>\n<tr>\n<td><strong>3</strong></td>\n<td>Microsoft SQL Server</td>\n<td>Relational, Multi-model</td>\n<td>708.14</td>\n</tr>\n<tr>\n<td><strong>4</strong></td>\n<td>PostgreSQL</td>\n<td>Relational, Multi-model</td>\n<td>672.03</td>\n</tr>\n<tr>\n<td><strong>5</strong></td>\n<td>MongoDB</td>\n<td>Document, Multi-model</td>\n<td>378.73</td>\n</tr>\n<tr>\n<td><strong>6</strong></td>\n<td>Snowflake</td>\n<td>Relational</td>\n<td>208.14</td>\n</tr>\n<tr>\n<td><strong>7</strong></td>\n<td>Redis</td>\n<td>Key-value, Multi-model</td>\n<td>147.04</td>\n</tr>\n<tr>\n<td><strong>8</strong></td>\n<td>Databricks</td>\n<td>Multi-model</td>\n<td>144.51</td>\n</tr>\n<tr>\n<td><strong>9</strong></td>\n<td>IBM Db2</td>\n<td>Relational, Multi-model</td>\n<td>111.22</td>\n</tr>\n<tr>\n<td><strong>10</strong></td>\n<td>Elasticsearch</td>\n<td>Multi-model</td>\n<td>106.46</td>\n</tr>\n</tbody></table>\n<p>MySQL은 여전히 <strong>전체 랭킹 2위</strong>를 굳건히 지키고 있으며, 오픈소스 RDBMS 중에서는 독보적인 위치를 차지하고 있다. 이 랭킹은 단순 성능이 아니라 웹 언급 횟수, 기술 토론 빈도, 구인 정보 등을 종합한 <strong>&#39;활용도&#39;</strong>를 나타낸다.</p>\n<ul>\n<li>인지도가 낮은 DBMS는 문제 발생 시 해결책(지식)을 찾기 어렵다.</li>\n<li>무엇보다 해당 DBMS를 관리할 <strong>전문가를 구하기 어렵다는 치명적인 단점</strong>이 있다.</li>\n</ul>\n<h2 id=\"마무리\">마무리</h2>\n<p>MySQL은 강력한 커뮤니티, 검증된 안정성, 그리고 오픈소스라는 비용적 이점을 모두 갖춘 매력적인 선택지다. 오라클의 기술력이 더해져 상용 DBMS 못지않은 기능을 제공하는 지금, MySQL은 여전히 최고의 선택 중 하나다.</p>",
    "date": "2026-02-15T01:51:42.000Z",
    "url": "https://velog.io/@hhyukk/MySQL%EC%9D%98-%EC%97%AD%EC%82%AC-%EB%9D%BC%EC%9D%B4%EC%84%A0%EC%8A%A4-%EA%B7%B8%EB%A6%AC%EA%B3%A0-%EC%9A%B0%EB%A6%AC%EA%B0%80-%EC%82%AC%EC%9A%A9%ED%95%98%EB%8A%94-%EC%9D%B4%EC%9C%A0"
  },
  {
    "publisherId": "velog",
    "publisherName": "Velog",
    "specTitle": "개발자 블로그",
    "categories": [
      "_all_"
    ],
    "specUrl": "https://v2.velog.io/rss/",
    "title": "(Unity)004. 코루틴 개념 보충 : 제어권 분할과 시분할 협업",
    "partialText": "<h2 id=\"1-코루틴의-본질-메인-스레드-점유의-분산\">1. 코루틴의 본질: 메인 스레드 점유의 분산</h2>\n<blockquote>\n</blockquote>\n<p>유니티는 단일 스레드(Main Thread) 방식으로 동작함. 코루틴은 이 한정된 자원을 효율적으로 쓰기 위해 제어권을 능동적으로 분할하는 기술적 장치임.</p>\n<h2 id=\"2-협업의-대상-유니티-메인-루프-main-loop\">2. 협업의 대상: 유니티 메인 루프 (Main Loop)</h2>\n<blockquote>\n</blockquote>\n<p>코루틴은 독립적인 개체가 아님. 유니티 엔진의 핵심 실행 주기 내에서 메인 루프와 상호작용하며 동작함.</p>\n<p><strong>Update 함수와의 관계 :</strong> Update가 매 프레임 즉각적인 상태 변경을 수행한다면, 코루틴은 그 사이의 빈틈을 활용해 긴 작업을 처리함.</p>\n<h2 id=\"3-제어권-분할-control-flow-split\">3. 제어권 분할 (Control Flow Split)</h2>\n<p>일반 함수와 코루틴의 가장 큰 차이는 CPU 제어권의 점유 방식임.</p>\n<p>*<em>함수 독점의 위험 : *</em>일반 함수는 로직이 끝날 때까지 제어권을 안 놓음. 연산이 길어지면 렌더링이 밀려서 화면이 굳는 프리징 현상이 발생함.</p>\n<p>*<em>능동적 제어권 포기 : *</em>코루틴은 yield return을 만나는 즉시 연산 상태를 메모리에 보존하고 제어권을 엔진에 반환함.</p>\n<h2 id=\"4-시분할-협업-time-sharing-collaboration\">4. 시분할 협업 (Time-Sharing Collaboration)</h2>\n<blockquote>\n</blockquote>\n<p>단일 스레드 환경에서 코루틴은 시간축을 잘게 쪼개는 방식으로 병렬 처리와 유사한 효과를 냄.</p>\n<p><strong>프레임 단위 배분 :</strong> 한 프레임 내에서 Update 연산이 끝나면, 엔진은 대기 중이던 코루틴을 깨워 남는 가용 시간 동안 작업을 수행하게 함.</p>\n<p><strong>비동기적 가시성 :</strong> 이 시분할 처리를 통해 복잡한 로직을 수행하면서도 화면 갱신이 중단되지 않는 환경을 구축할 수 있음.</p>\n<h2 id=\"5-요약\">5. 요약</h2>\n<table>\n<thead>\n<tr>\n<th>구분</th>\n<th>일반 함수 (독점 모델)</th>\n<th>코루틴 (협업 모델)</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>제어권 확보</td>\n<td>종료 시까지 CPU 점유 유지</td>\n<td>yield를 통해 능동적으로 반환</td>\n</tr>\n<tr>\n<td>실행 단위</td>\n<td>단일 프레임 내 완결 원칙</td>\n<td>여러 프레임에 걸친 시분할 실행</td>\n</tr>\n<tr>\n<td>상태 보존</td>\n<td>함수 종료 시 소멸</td>\n<td>복귀를 위해 메모리에 상태 보존</td>\n</tr>\n<tr>\n<td>주요 목적</td>\n<td>즉각적인 결과 도출</td>\n<td>프레임 드랍 방지 및 로직 분산</td>\n</tr>\n</tbody></table>\n<h2 id=\"6-결론\">6. 결론</h2>\n<blockquote>\n</blockquote>\n<p>코루틴의 yield return은 <strong>&quot;메인 스레드 부하를 막기 위해 엔진과 실행 시간을 나누어 쓰겠다&quot;</strong>는 기술적 목적을 가짐. 이를 통해 단일 스레드의 한계를 극복하고 효율적인 자원 분배를 달성함.</p>",
    "date": "2026-02-15T01:45:44.000Z",
    "url": "https://velog.io/@thrinia63/Unity004.-%EC%BD%94%EB%A3%A8%ED%8B%B4-%EA%B0%9C%EB%85%90-%EB%B3%B4%EC%B6%A9-%EC%A0%9C%EC%96%B4%EA%B6%8C-%EB%B6%84%ED%95%A0%EA%B3%BC-%EC%8B%9C%EB%B6%84%ED%95%A0-%ED%98%91%EC%97%85"
  },
  {
    "publisherId": "velog",
    "publisherName": "Velog",
    "specTitle": "개발자 블로그",
    "categories": [
      "_all_"
    ],
    "specUrl": "https://v2.velog.io/rss/",
    "title": "내가 기획자라면 어떤 게임을",
    "partialText": "<h3 id=\"저는-원신처럼-방대한-세계를-여행하면서도-캐릭터들이-sdsuper-deformed-스타일로-표현된-귀엽지만-묵직한-오픈월드-rpg를-만들고-샆습니다\"><strong>저는 원신처럼 방대한 세계를 여행하면서도, 캐릭터들이 SD(Super Deformed) 스타일로 표현된 귀엽지만 묵직한 오픈월드 RPG를 만들고 샆습니다.</strong></h3>\n<p>세계관: 모든 것이 완벽하게 태어나는 세상이 아닌, 조금씩 &#39;결함&#39;을 가진 캐릭터들이 모여 사는 대륙입니다. 주인공 역시 처음엔 아주 미약한 능력을 갖췄지만, 세상을 탐험하며 자신의 한계를 인정하고(메타인지) 조금씩 성장해 나가는 과정을 담고 싶습니다.</p>\n<p>비주얼: 짜리몽땅하고 귀여운 SD 캐릭터들이 화려한 스킬을 쓰고, 거대한 오픈월드의 자연경관 속을 누비는 반전 매력을 강조하고 싶습니다.</p>\n<h3 id=\"게임의-핵심-재미-요소\">게임의 핵심 재미 요소</h3>\n<ol>\n<li>실패가 곧 &#39;성장 스택&#39;이 되는 시스템\n죽으면 끝이거나 페널티가 아니라 경험치가 쌓여 새로운 공략법을 제안\n유저가 포기하지 않고 다시 도전할 때 캐릭터가 조금씩 &#39;끈기의 가치&#39;를 게임으로 느끼게 하기</li>\n</ol>\n<p>2.스킬 조합\n캐릭터가 자신의 상태를 얼마나 정확히 파악하고 있느냐에 따라 스킬의 위력이 달라지는 시스템. 무조건 강한 기술만 쓰는 게 아니라, 현재 상황을 보고 최적의 판단을 내리는 재미를 주고 싶습니다.</p>",
    "date": "2026-02-15T01:45:30.000Z",
    "url": "https://velog.io/@dldbcks/%EB%82%B4%EA%B0%80-%EA%B8%B0%ED%9A%8D%EC%9E%90%EB%9D%BC%EB%A9%B4-%EC%96%B4%EB%96%A4-%EA%B2%8C%EC%9E%84%EC%9D%84"
  },
  {
    "publisherId": "velog",
    "publisherName": "Velog",
    "specTitle": "개발자 블로그",
    "categories": [
      "_all_"
    ],
    "specUrl": "https://v2.velog.io/rss/",
    "title": "[Java] BOJ 5639번 - 이진 검색 트리",
    "partialText": "<p><a href=\"https://www.acmicpc.net/problem/5639\">5639번: 이진 검색 트리</a></p>\n<hr>\n<h2 id=\"문제\">문제</h2>\n<p>이진 검색 트리는 다음과 같은 세 가지 조건을 만족하는 이진 트리이다.</p>\n<ul>\n<li>노드의 왼쪽 서브트리에 있는 모든 노드의 키는 노드의 키보다 작다.</li>\n<li>노드의 오른쪽 서브트리에 있는 모든 노드의 키는 노드의 키보다 크다.</li>\n<li>왼쪽, 오른쪽 서브트리도 이진 검색 트리이다.</li>\n</ul>\n<p><img src=\"https://velog.velcdn.com/images/gyeongjun09/post/193b7cf8-24c0-43ce-b1ef-ccd1a04d543c/image.png\" alt=\"\"></p>\n<p>전위 순회 (루트-왼쪽-오른쪽)은 루트를 방문하고, 왼쪽 서브트리, 오른쪽 서브 트리를 순서대로 방문하면서 노드의 키를 출력한다. 후위 순회 (왼쪽-오른쪽-루트)는 왼쪽 서브트리, 오른쪽 서브트리, 루트 노드 순서대로 키를 출력한다. 예를 들어, 위의 이진 검색 트리의 전위 순회 결과는 50 30 24 5 28 45 98 52 60 이고, 후위 순회 결과는 5 28 24 45 30 60 52 98 50 이다.</p>\n<p>이진 검색 트리를 전위 순회한 결과가 주어졌을 때, 이 트리를 후위 순회한 결과를 구하는 프로그램을 작성하시오.</p>\n<hr>\n<h2 id=\"입력\">입력</h2>\n<p>트리를 전위 순회한 결과가 주어진다. 노드에 들어있는 키의 값은 10<sup>6</sup>보다 작은 양의 정수이다. 모든 값은 한 줄에 하나씩 주어지며, 노드의 수는 10,000개 이하이다. 같은 키를 가지는 노드는 없다.</p>\n<hr>\n<h2 id=\"출력\">출력</h2>\n<p>입력으로 주어진 이진 검색 트리를 후위 순회한 결과를 한 줄에 하나씩 출력한다.</p>\n<hr>\n<h2 id=\"알고리즘-분류\">알고리즘 분류</h2>\n<ul>\n<li>그래프 이론(Graph Theory)</li>\n<li>그래프 탐색(Graph Traversal)</li>\n<li>트리(Tree)</li>\n<li>재귀(Recursion)</li>\n</ul>\n<hr>\n<h2 id=\"아이디어-및-코드\">아이디어 및 코드</h2>\n<h3 id=\"방법-1-트리-구성\">방법 1: 트리 구성</h3>\n<blockquote>\n<p>아이디어</p>\n<ul>\n<li>전위 순회를 입력 받아서 직접 이진 트리를 구성</li>\n<li>왼쪽 서브트리 → 오른쪽 서브트리 → 루트 순으로 후위 순회 출력</li>\n</ul>\n<ol>\n<li>전위 순회가 입력되므로 첫 번째 줄에 들어온 입력을 <code>root</code>로 한다.</li>\n<li>두 번째 줄부터 들어온 입력을 <code>root</code>에 붙인다.<ul>\n<li>그 값이 더 작으면 왼쪽 서브트리에 추가</li>\n<li>그 값이 더 크면 오른쪽 서브트리에 추가</li>\n</ul>\n</li>\n<li>왼쪽 서브트리 → 오른쪽 서브트리 → 루트 순으로 후위 순회를 출력한다.</li>\n</ol>\n</blockquote>\n<pre><code class=\"language-java\">import java.io.*;\n\npublic class Main {\n    static StringBuilder sb = new StringBuilder();\n\n    static class Node {\n        int val;\n        Node left, right;\n\n        Node(int val) {\n            this.val = val;\n        }\n\n        void insert(int n) {\n            if(n &lt; this.val) {\n                if(left == null) left = new Node(n);\n                else             left.insert(n);\n            } else {\n                if(right == null) right = new Node(n);\n                else              right.insert(n);\n            }\n        }\n    }\n\n    static void postorder(Node node) {\n        if(node == null) return;\n        postorder(node.left);\n        postorder(node.right);\n        sb.append(node.val).append(&quot;\\n&quot;);\n    }\n\n    public static void main(String[] args) throws IOException {\n        BufferedReader br = new BufferedReader(new InputStreamReader(System.in));\n\n        String s = br.readLine();\n        Node root = new Node(Integer.parseInt(s));\n        while((s = br.readLine()) != null) {\n            root.insert(Integer.parseInt(s));\n        }\n\n        postorder(root);\n        System.out.print(sb);\n    }\n}</code></pre>\n<h3 id=\"방법-2-재귀\">방법 2: 재귀</h3>\n<blockquote>\n<p>아이디어</p>\n<ul>\n<li>전위 순회는 루트 → 왼쪽 서브트리 → 오른쪽 서브트리로 주어지고, 이진 트리는 왼쪽 서브트리의 값이 무조건 루트보다 작거나 같다는 성질 이용</li>\n<li>루트보다 크거나 같은 값을 찾아서 왼쪽 서브트리와 오른쪽 서브트리를 구분하여 재귀적으로 후위 순회(왼쪽 서브트리 → 오른쪽 서브트리 → 루트)</li>\n</ul>\n<ol>\n<li>들어오는 모든 입력을 <code>ArrayList&lt;Integer&gt; list</code>에 저장한다.</li>\n<li><code>0</code>번 원소부터 <code>list.size() - 1</code>번 원소까지 <code>postorder()</code> 메서드를 수행한다.</li>\n<li><code>root</code>는 <code>start</code>번 원소로 설정한 다음 <code>root</code>보다 크거나 같은 첫 번째 원소의 인덱스를 <code>pivot</code>으로 설정한다. 그런 원소가 없으면 <code>pivot = end</code>이다.</li>\n<li><code>start + 1</code>부터 <code>pivot</code>까지 <code>postorder()</code> 메서드를, <code>pivot</code>부터 <code>end</code>까지 <code>postorder()</code> 메서드를 수행하고, 루트를 출력한다. (후위 순회)</li>\n</ol>\n</blockquote>\n<pre><code class=\"language-java\">import java.io.*;\nimport java.util.*;\n\npublic class Main {\n    static List&lt;Integer&gt; list = new ArrayList&lt;&gt;();\n    static StringBuilder sb = new StringBuilder();\n\n    static void postorder(int start, int end) {\n        if(start &gt;= end) return;\n\n        int root = list.get(start);\n        int pivot = end;\n        for(int i = start + 1; i &lt; end; i++) {\n            if(list.get(i) &gt; root) {\n                pivot = i;\n                break;\n            }\n        }\n        postorder(start + 1, pivot);\n        postorder(pivot, end);\n        sb.append(root).append(&quot;\\n&quot;);\n    }\n\n    public static void main(String[] args) throws IOException {\n        BufferedReader br = new BufferedReader(new InputStreamReader(System.in));\n\n        String s;\n        while((s = br.readLine()) != null) {\n            list.add(Integer.parseInt(s));\n        }\n\n        postorder(0, list.size());\n        System.out.print(sb);\n    }\n}</code></pre>\n<hr>\n<h2 id=\"복잡도\">복잡도</h2>\n<h3 id=\"방법-1\">방법 1</h3>\n<ul>\n<li>시간 복잡도: 최악 $O(N^2)$, 평균 $O(N \\log N)$</li>\n<li>공간 복잡도: $O(N)$</li>\n</ul>\n<h3 id=\"방법-2\">방법 2</h3>\n<ul>\n<li>시간 복잡도: 최악 $O(N^2)$, 평균 $O(N \\log N)$</li>\n<li>공간 복잡도: $O(N)$</li>\n</ul>\n<hr>\n<h2 id=\"배운-점\">배운 점</h2>\n<h3 id=\"트리를-arraylist로-관리\">트리를 <code>ArrayList</code>로 관리</h3>\n<p>방법 1에서는 참조를 이용하여 전통적인 트리 구현 방식을 사용했다. 그러나 방법 2에서는 <strong>리스트 내 인덱스 조절만으로</strong> 논리적인 트리 구조를 다뤘다.</p>\n<p>오히려 방법 1과 다르게 방법 2에서는 <code>Node</code> 객체와 같이 메모리를 사용하는 코드가 거의 없기 때문에 메모리 효율성이 높아진다.</p>\n<p>또, <code>ArrayList</code>로 관리할 수 있었던 이유는 전위 순회 결과에서 <strong>루트보다 큰 값이 처음 나오는 지점이 오른쪽 서브트리의 시작점</strong>이라는 큰 특징이 있었기 때문이다. 이를 <code>pivot</code>이라는 값으로 저장하여 <code>Node</code> 객체 생성 없이도 후위 순회를 구현할 수 있었다.</p>\n<hr>\n<h2 id=\"추가-문제gemini-추천\">추가 문제(Gemini 추천)</h2>\n<h3 id=\"비슷한-유형\">비슷한 유형</h3>\n<ul>\n<li><a href=\"https://www.acmicpc.net/problem/1991\">1991번: 트리 순회</a><ul>\n<li><a href=\"https://velog.io/@gyeongjun09/Java-BOJ-1991%EB%B2%88-%ED%8A%B8%EB%A6%AC-%EC%88%9C%ED%9A%8C\">풀이</a></li>\n</ul>\n</li>\n<li><a href=\"https://www.acmicpc.net/problem/2263\">2263번: 트리의 순회</a></li>\n<li><a href=\"https://www.acmicpc.net/problem/4256\">4256번: 트리</a></li>\n</ul>\n<h3 id=\"높은-난이도-유형\">높은 난이도 유형</h3>\n<ul>\n<li><a href=\"https://www.acmicpc.net/problem/1202\">1202번: 보석 도둑</a></li>\n<li><a href=\"https://www.acmicpc.net/problem/1539\">1539번: 이진 검색 트리</a></li>\n<li><a href=\"https://www.acmicpc.net/problem/2957\">2957번: 이진 탐색 트리</a></li>\n</ul>",
    "date": "2026-02-15T01:42:46.000Z",
    "url": "https://velog.io/@gyeongjun09/Java-BOJ-5639%EB%B2%88-%EC%9D%B4%EC%A7%84-%EA%B2%80%EC%83%89-%ED%8A%B8%EB%A6%AC"
  },
  {
    "publisherId": "velog",
    "publisherName": "Velog",
    "specTitle": "개발자 블로그",
    "categories": [
      "_all_"
    ],
    "specUrl": "https://v2.velog.io/rss/",
    "title": "[Andrew Ng] 5-2.Parameters vs Hyperparameter",
    "partialText": "<h3 id=\"parameter\">Parameter</h3>\n<ul>\n<li>신경망에서 학습 가능한 W와 b를 뜻한다.</li>\n</ul>\n<h3 id=\"hyperparameter\">Hyperparameter</h3>\n<ul>\n<li>Hyperparameter의 종류.<ul>\n<li>학습률(learning rate, \\alpha<em>α</em> )</li>\n<li>반복횟수(numbers of iteration)</li>\n<li>은닉층의 갯수(numbers of hidden layer, L)</li>\n<li>은닉유닛의 갯수(numbers of hidden units)</li>\n<li>활성화 함수의 선택(choice of activation function)</li>\n<li>모멘텀항(momentum term)</li>\n<li>미니배치 크기(mini batch size)</li>\n<li>etc...</li>\n</ul>\n</li>\n<li>Hyperparameter는 결정 된것이 없으며, 여러번의 시도를 통해 적합한 Hyperparameter를 찾아야한다.</li>\n</ul>\n<blockquote>\n<p>출처 및 참고 자료 </p>\n<ul>\n<li>Andrew Ng, Improving Deep Neural Network, DeepLearningAI</li>\n</ul>\n</blockquote>",
    "date": "2026-02-15T01:36:40.000Z",
    "url": "https://velog.io/@hojin0155/Andrew-Ng-5-2.Parameters-vs-Hyperparameter"
  },
  {
    "publisherId": "velog",
    "publisherName": "Velog",
    "specTitle": "개발자 블로그",
    "categories": [
      "_all_"
    ],
    "specUrl": "https://v2.velog.io/rss/",
    "title": "(Unity)003. 코루틴(Coroutine). 양보 구문.",
    "partialText": "<h2 id=\"1-양보-구문yield-return의-정의\">1. 양보 구문(Yield Return)의 정의</h2>\n<p>유니티 코루틴에서 사용하는 yield return 문구는 제어권 반환을 의미</p>\n<ul>\n<li><p>yield: 현재 실행 중인 코루틴의 상태를 저장하고 실행을 일시 정지함. (양보 하겠다)</p>\n</li>\n<li><p>return: 호출자인 유니티 엔진 스케줄러에게 프로그램 주도권을 넘김. (주도권을 유니티 메인 루프에게)</p>\n</li>\n<li><p>작동 원리: 지정된 조건이 충족되면 저장된 상태 이후의 코드부터 다시 실행을 재개함.</p>\n</li>\n</ul>\n<h2 id=\"2-코루틴-사용-목적-프레임-점유-방지\">2. 코루틴 사용 목적: 프레임 점유 방지</h2>\n<p>게임 엔진은 매 프레임(약 0.016초)마다 연산과 렌더링을 반복 </p>\n<ul>\n<li><p>일반 함수의 문제점: 루프 처리가 긴 함수는 해당 연산이 끝날 때까지 CPU를 점유함. 결과적으로 다음 프레임의 렌더링이 지연되어 프리징 현상이 발생함.</p>\n</li>\n<li><p>코루틴의 해결법: 연산을 여러 프레임에 걸쳐 분산 처리함. 매 프레임 허용된 시간 내에서만 코드를 실행하고 제어권을 반환하여 전체 프로그램의 흐름을 유지함.</p>\n</li>\n</ul>\n<h2 id=\"3-코드-구조-분석\">3. 코드 구조 분석</h2>\n<h3 id=\"a-일반-함수-프레임-점유\">A. 일반 함수 (프레임 점유)</h3>\n<p>이 구조는 1만 번의 루프가 한 프레임 안에 완료되어야 하므로 성능 저하를 유발</p>\n<pre><code class=\"language-cs\">void CreateTenThousandObjects()\n{\n    for (int i = 0; i &lt; 10000; i++)\n    {\n        // 1만 번의 연산이 완료될 때까지 메인 스레드가 정지됨\n        CreateObject(i);\n    }\n}</code></pre>\n<h3 id=\"b-코루틴-제어권-분산\">B. 코루틴 (제어권 분산)</h3>\n<p>일정 주기마다 yield return을 호출하여 엔진이 다른 작업을 수행할 수 있도록 함</p>\n<pre><code class=\"language-cs\">IEnumerator CreateObjectsWithCoroutine()\n{\n    for (int i = 0; i &lt; 10000; i++)\n    {\n        CreateObject(i);\n\n        // 100회 연산마다 제어권을 유니티 엔진에 반환\n        if (i % 100 == 0)\n        {\n            // 다음 프레임의 업데이트 이후 복귀하도록 설정\n            yield return null; \n        }\n    }\n}</code></pre>\n<h2 id=\"4-주요-양보-구문-종류-및-동작\">4. 주요 양보 구문 종류 및 동작</h2>\n<p>반환하는 값의 종류에 따라 복귀 시점이 결정</p>\n<ul>\n<li><p>yield return null: 다음 프레임의 Update 함수 호출 이후 복귀.</p>\n</li>\n<li><p>yield return new WaitForSeconds(float): 지정된 초(Seconds)가 경과한 후 복귀.</p>\n</li>\n<li><p>yield return new WaitForFixedUpdate(): 다음 물리 연산(FixedUpdate) 주기 이후 복귀.</p>\n</li>\n<li><p>yield return new WaitUntil(System.Func<bool>): 전달된 조건식이 true가 될 때까지 매 프레임 체크 후 복귀.</p>\n</li>\n<li><p>yield break: 코루틴의 루프를 중단하고 해당 코루틴을 완전히 종료.</p>\n</li>\n</ul>",
    "date": "2026-02-15T01:34:54.000Z",
    "url": "https://velog.io/@thrinia63/Unity003.-%EC%BD%94%EB%A3%A8%ED%8B%B4Coroutine.-%EC%96%91%EB%B3%B4-%EA%B5%AC%EB%AC%B8"
  },
  {
    "publisherId": "velog",
    "publisherName": "Velog",
    "specTitle": "개발자 블로그",
    "categories": [
      "_all_"
    ],
    "specUrl": "https://v2.velog.io/rss/",
    "title": "방이동노래방알바",
    "partialText": "<p>방이동노래방알바 방이동노래방알바 방이동노래방알바 카톡상담:knmy486 방이동노래방알바 방이동노래방알바 방이동노래방알바 카톡상담:knmy486방이동노래방알바 방이동노래방알바 방이동노래방알바 카톡상담:knmy486방이동노래방알바 방이동노래방알바 방이동노래방알바 카톡상담:knmy486<img src=\"https://velog.velcdn.com/images/fdsd80439680/post/7e2a21bd-29e5-4586-be82-41a4659a2215/image.jpg\" alt=\"\"></p>",
    "date": "2026-02-15T01:28:58.000Z",
    "url": "https://velog.io/@fdsd80439680/%EB%B0%A9%EC%9D%B4%EB%8F%99%EB%85%B8%EB%9E%98%EB%B0%A9%EC%95%8C%EB%B0%94"
  },
  {
    "publisherId": "velog",
    "publisherName": "Velog",
    "specTitle": "개발자 블로그",
    "categories": [
      "_all_"
    ],
    "specUrl": "https://v2.velog.io/rss/",
    "title": "남양주노래방알바",
    "partialText": "<p>남양주노래방알바 남양주노래방알바 남양주노래방알바 카톡상담:knmy486남양주노래방알바 남양주노래방알바 남양주노래방알바 카톡상담:knmy486남양주노래방알바 남양주노래방알바 남양주노래방알바 카톡상담:knmy486남양주노래방알바 남양주노래방알바 남양주노래방알바 카톡상담:knmy486남양주노래방알바 남양주노래방알바 남양주노래방알바 카톡상담:knmy486남양주노래방알바 남양주노래방알바 남양주노래방알바 카톡상담:knmy486남양주노래방알바 남양주노래방알바 남양주노래방알바 카톡상담:knmy486남양주노래방알바 남양주노래방알바 남양주노래방알바 카톡상담:knmy486<img src=\"https://velog.velcdn.com/images/fdsd80439680/post/7b659b8a-bf1c-48b2-95e2-e11786efd95b/image.jpg\" alt=\"\"></p>",
    "date": "2026-02-15T01:25:35.000Z",
    "url": "https://velog.io/@fdsd80439680/%EB%82%A8%EC%96%91%EC%A3%BC%EB%85%B8%EB%9E%98%EB%B0%A9%EC%95%8C%EB%B0%94"
  },
  {
    "publisherId": "velog",
    "publisherName": "Velog",
    "specTitle": "개발자 블로그",
    "categories": [
      "_all_"
    ],
    "specUrl": "https://v2.velog.io/rss/",
    "title": "[Andrew Ng] 5-1.Why Deep Representations?",
    "partialText": "<h3 id=\"intuition-about-deep-representation\">Intuition about deep representation</h3>\n<p><img src=\"https://velog.velcdn.com/images/hojin0155/post/7a59b87f-4478-4115-bab2-ba3ff6cc078d/image.png\" alt=\"\"></p>\n<ul>\n<li>첫 번째 층에서는 모서리 탐지, 두 번째 층에서는 눈•코•귀 탐지, 세 번째 층에서는 얼굴 전반 탐지를 함</li>\n<li>이 처럼 작은 영역에서 더 넓은 영역으로 탐지를 확장해감.</li>\n</ul>\n<h3 id=\"circuit-theory-and-deep-learning\">Circuit theory and deep learning</h3>\n<p><img src=\"https://velog.velcdn.com/images/hojin0155/post/5f1367db-2104-4cc9-ad91-f6a559b35068/image.png\" alt=\"\"></p>\n<ul>\n<li>Circuit theory에 따르면, 상대적으로 hidden layer의 개수가 작지만 DNN에서 계산할 수 있는 함수가 있다. 충분한 hidden layer가 없다면 기하급수적으로 많은 은닉 유닛이 필요하다.</li>\n<li>깊은 신경망은 각 층에서 점차적으로 더 복잡한 특징을 추출하고, 이를 결합하여 복잡한 패턴을 학습할 수 있다.</li>\n<li>반면, 얕은 네트워크(층이 적고 유닛이 많은 네트워크)는 한 번에 복잡한 특징을 추출하려고 하므로 복잡한 함수를 학습하기 위해 많은 유닛이 필요하고, 계산량이 커진다.</li>\n</ul>\n<blockquote>\n<p>출처 및 참고 자료 </p>\n<ul>\n<li>Andrew Ng, Improving Deep Neural Network, DeepLearningAI</li>\n</ul>\n</blockquote>",
    "date": "2026-02-15T01:25:19.000Z",
    "url": "https://velog.io/@hojin0155/Andrew-Ng-5-1.Why-Deep-Representations"
  },
  {
    "publisherId": "velog",
    "publisherName": "Velog",
    "specTitle": "개발자 블로그",
    "categories": [
      "_all_"
    ],
    "specUrl": "https://v2.velog.io/rss/",
    "title": "구리노래방알바",
    "partialText": "<p>구리노래방알바 구리노래방알바  구리노래방알바 카톡상담:knmy486\n구리노래방알바 구리노래방알바  구리노래방알바 카톡상담:knmy486\n구리노래방알바 구리노래방알바  구리노래방알바 카톡상담:knmy486\n구리노래방알바 구리노래방알바  구리노래방알바 카톡상담:knmy486\n구리노래방알바 구리노래방알바  구리노래방알바 카톡상담:knmy486\n구리노래방알바 구리노래방알바  구리노래방알바 카톡상담:knmy486<img src=\"https://velog.velcdn.com/images/fdsd80439680/post/e9624ae5-d928-4fa9-9373-5eb7f1574d5a/image.jpg\" alt=\"\"></p>",
    "date": "2026-02-15T01:23:55.000Z",
    "url": "https://velog.io/@fdsd80439680/%EA%B5%AC%EB%A6%AC%EB%85%B8%EB%9E%98%EB%B0%A9%EC%95%8C%EB%B0%94"
  },
  {
    "publisherId": "velog",
    "publisherName": "Velog",
    "specTitle": "개발자 블로그",
    "categories": [
      "_all_"
    ],
    "specUrl": "https://v2.velog.io/rss/",
    "title": "AI프로그램 효과적이게 활용하기",
    "partialText": "<p>AI프로그램 활용 종류와 방식 총정리, 실무와 일상에서 어떻게 쓰일까?\n최근 몇 년 사이 인공지능 기술은 단순한 트렌드를 넘어 실제 업무와 일상 전반에 깊숙이 자리 잡았습니다. 과거에는 전문가 영역으로 여겨졌던 AI가 이제는 일반 사용자도 쉽게 활용할 수 있는 프로그램 형태로 제공되면서 생산성 향상과 비용 절감, 시간 단축이라는 실질적인 효과를 만들어내고 있습니다. 이번 글에서는 AI프로그램의 주요 종류와 활용 방식에 대해 정리해보겠습니다. <a href=\"https://pgmb.kr/\">폰테크</a> </p>\n<p>생성형 AI 프로그램 활용 방식\n가장 널리 사용되는 유형은 텍스트, 이미지, 영상 등을 생성해주는 생성형 AI입니다. 대표적으로 OpenAI의 ChatGPT는 글 작성, 아이디어 기획, 요약, 번역, 코드 작성 등 다양한 작업에 활용되고 있습니다. 또한 Google의 Gemini 역시 문서 작성과 데이터 분석, 검색 보조 기능에 특화되어 있습니다. 이러한 생성형 AI는 블로그 글 작성, 마케팅 카피 제작, 보고서 초안 작성, 고객 상담 자동화 등 콘텐츠 기반 업무에 특히 유용합니다. 활용 방식은 보통 질문이나 지시문을 입력하고 결과를 수정·보완하는 구조로 이루어집니다.<a href=\"https://pgmb.kr/\">폰테크</a> </p>\n<p>이미지 및 디자인 AI 프로그램\n디자인 분야에서는 이미지 생성 AI와 편집 AI가 빠르게 확산되고 있습니다. OpenAI의 DALL·E나 Midjourney의 Midjourney는 텍스트 설명만으로 원하는 이미지를 제작할 수 있습니다. 또한 Adobe의 Adobe Firefly는 기존 디자인 작업에 AI 기능을 접목해 배경 제거, 색상 보정, 자동 레이아웃 구성 등을 지원합니다. 활용 방식은 키워드 기반 이미지 생성, 기존 이미지 업스케일링, SNS 콘텐츠 제작 등으로 다양합니다. 특히 마케팅, 쇼핑몰 운영, 유튜브 썸네일 제작 등에서 활용도가 높습니다.<a href=\"https://pgmb.kr/\">폰테크</a> </p>\n<p>영상 및 음성 AI 프로그램\n영상 제작과 음성 합성 분야에서도 AI의 영향력은 점점 커지고 있습니다. 예를 들어 Runway는 텍스트 기반 영상 생성과 편집 기능을 제공하며, ElevenLabs는 자연스러운 음성 합성 기술로 콘텐츠 제작 시간을 단축시켜 줍니다. 활용 방식은 홍보 영상 제작, 교육 콘텐츠 녹음, 오디오북 제작, 더빙 자동화 등으로 확장되고 있습니다. 과거에는 전문 장비와 인력이 필요했던 작업을 AI가 대체하거나 보조하는 구조입니다.</p>\n<p>데이터 분석 및 업무 자동화 AI\n기업 환경에서는 데이터 분석과 업무 자동화가 핵심 활용 분야입니다. Microsoft의 Copilot는 엑셀 데이터 분석, 보고서 자동 작성, 이메일 정리 등을 지원합니다. 또한 CRM, ERP 시스템과 연동된 AI는 고객 패턴 분석, 매출 예측, 재고 관리 자동화를 수행합니다. 활용 방식은 기존 업무 시스템에 AI를 접목해 반복 작업을 줄이고 의사결정을 지원하는 형태로 이루어집니다. 특히 중소기업에서도 구독형 AI 서비스를 통해 쉽게 도입할 수 있다는 점이 특징입니다.</p>\n<p>개인 생산성 향상을 위한 AI 활용\n일상에서는 일정 관리, 공부 보조, 외국어 학습, 자기계발 등 다양한 분야에서 AI가 사용됩니다. AI 챗봇을 통해 학습 계획을 세우거나, 음성 인식 기반 메모 앱으로 회의 내용을 자동 정리할 수 있습니다. 또한 주식, 부동산, 창업 아이디어 분석 등 정보 탐색에도 AI가 보조 역할을 합니다. 활용 방식은 단순 질의응답을 넘어, 사용자가 목표를 설정하면 AI가 단계별 실행 계획을 제안하는 형태로 발전하고 있습니다.\nAI프로그램 활용 시 주의할 점\nAI는 매우 편리하지만 결과물을 그대로 사용하는 것은 위험할 수 있습니다. 정보의 정확성 검증, 저작권 문제 확인, 개인정보 보호 등은 반드시 고려해야 합니다. 또한 AI는 보조 도구일 뿐 최종 판단은 사용자의 책임이라는 점을 인식하는 것이 중요합니다.\n마무리\nAI프로그램은 이제 특정 전문가만의 도구가 아니라 누구나 활용할 수 있는 생산성 도구로 자리 잡았습니다. 텍스트 생성, 이미지 제작, 영상 편집, 데이터 분석 등 분야별로 적절한 AI를 선택해 활용한다면 시간과 비용을 크게 절감할 수 있습니다. 앞으로는 단순 사용을 넘어, 자신의 업무 구조에 맞게 AI를 설계하고 결합하는 능력이 경쟁력이 될 것입니다.</p>",
    "date": "2026-02-15T01:09:54.000Z",
    "url": "https://velog.io/@jiwonavi/AI%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%A8-%ED%9A%A8%EA%B3%BC%EC%A0%81%EC%9D%B4%EA%B2%8C-%ED%99%9C%EC%9A%A9%ED%95%98%EA%B8%B0"
  },
  {
    "publisherId": "velog",
    "publisherName": "Velog",
    "specTitle": "개발자 블로그",
    "categories": [
      "_all_"
    ],
    "specUrl": "https://v2.velog.io/rss/",
    "title": "[Andrew Ng] 4-4.Random Initialization",
    "partialText": "<h3 id=\"what-happens-if-you-initialize-weights-to-zero\">What happens if you initialize weights to zero?</h3>\n<p><img src=\"https://velog.velcdn.com/images/hojin0155/post/41901554-e8fc-4279-975f-0539e1fdb00b/image.png\" alt=\"\"></p>\n<ul>\n<li>가중치를 0으로 다 초기화 해버리면, 뉴런들이 같은 결과값을 가지게 되고 업데이트도 똑같이 된다.<ul>\n<li>back propagation을 해도 똑같은 값을 빼고 더하기 때문</li>\n</ul>\n</li>\n<li>결국 layer를 많이 쌓아도 symmetric해져, perceptron과 같게 된다.</li>\n</ul>\n<h3 id=\"random-initialization\">Random initialization</h3>\n<p><img src=\"https://velog.velcdn.com/images/hojin0155/post/08a818e4-073a-43f2-9ed0-f5ba757788d3/image.png\" alt=\"\"></p>\n<ul>\n<li>np.random.rand()를 사용하여 랜덤한 값을 사용한다.</li>\n<li>가중치의 초기값은 작아야 한다.<ul>\n<li>가중치의 초기값이 너무 크다면 activation 경사의 기울기가 낮기 때문에 학습이 느려진다.</li>\n</ul>\n</li>\n</ul>\n<blockquote>\n<p>출처 및 참고 자료 </p>\n<ul>\n<li>Andrew Ng, Improving Deep Neural Network, DeepLearningAI</li>\n</ul>\n</blockquote>",
    "date": "2026-02-15T01:04:25.000Z",
    "url": "https://velog.io/@hojin0155/Andrew-Ng-4-4.Random-Initialization"
  },
  {
    "publisherId": "velog",
    "publisherName": "Velog",
    "specTitle": "개발자 블로그",
    "categories": [
      "_all_"
    ],
    "specUrl": "https://v2.velog.io/rss/",
    "title": "cloud flare 1014 우회",
    "partialText": "<div align=center>\n<img src=https://velog.velcdn.com/images/jihwankim128/post/4f16102b-2998-4287-a97f-c10cb39ed191/image.png width=300/></div>\n\n<h2 id=\"상황\">상황</h2>\n<p>Busan CMC 1st 활동 중 진행하게 된 Ondo 프로젝트에서 빠른 마케팅과 SEO 노출을 목적으로 Domain을 구매했고 적용하려고 했다.</p>\n<p><img src=\"https://velog.velcdn.com/images/jihwankim128/post/368f0432-01a4-4d9c-b6f3-a9e534350cf6/image.png\" alt=\"\"></p>\n<p>하지만 우리는 서비스를 Serverless로 운영하면서 DB를 Sass인 Supabase로 선택했는데, Supabase에 CName Record 설정을 하던 중 CF 1014 문제가 발생했다.</p>\n<hr>\n<h2 id=\"문제-분석\">문제 분석</h2>\n<p><a href=\"https://developers.cloudflare.com/support/troubleshooting/http-status-codes/cloudflare-1xxx-errors/error-1014/\">CF 1014 Trouble Shooting Docs</a>에서 어떤 에러인지 부터 확인했다.</p>\n<blockquote>\n<p>Error 1014: CNAME Cross-User Banned\nThis error indicates that a CNAME record between domains in different Cloudflare accounts is prohibited.</p>\n</blockquote>\n<p>해당 에러는 Cloudflare 서로 다른 계정의 도메인에 대해 CNAME을 설정할 수 없다는 내용이다. (Supabase가 Cloudflare로 배포하고 있나보다..)</p>\n<p>CF 입장에서 크게 두가지 측면에서 CNAME Record 설정을 막고 있다.</p>\n<div align=center>\n<img src=https://velog.velcdn.com/images/jihwankim128/post/31be65a8-dd04-44ac-b2d6-7a5448c8c76a/image.png width=300/></div>\n\n<ol>\n<li>도메인 하이재킹 방지\nCF를 이용중인 Client A의 Domain 정보를 활용해 악성 코드가 포함된 피싱사이트를 제작하거나 쿠키등을 탈취할 수도 있다. 이것을 CF는 방지해주는 것이 목적으로 보인다.\n도메인 하이재킹에 대한 설명은 <a href=\"https://www.cloudflare.com/ko-kr/learning/dns/what-is-domain-hijacking/\">CF Learning Docs</a>에 잘 정리되어있다.</li>\n<li>경제적/인프라 측면\nCF를 이용중인 악의적인 Client가 CF를 이용중인 다른 Client들의 정보들을 무단으로 사용하면서 트래픽을 발생시킨다. CF는 계정 별로 요금을 책정하는데 다른 Client들은 악의적인 Client로 인해 말도 안되는 요금을 납부해야된다.\n이랬을 때 CF 입장에서 책임을 묻기도 힘들고... 너무 복잡해지니까 막아버린 것으로 추측된다.</li>\n</ol>\n<hr>\n<h2 id=\"문제-해결-방안\">문제 해결 방안</h2>\n<p>문제 해결 방안은 크게 2가지가 있는데 <strong>Supabase 유료 플랜 사용</strong>과 <strong>CloudFlare Workers</strong>를 활용하는 것이다. 두가지 각 각 장단점이 있지만 최종적으로 CloudFlare Workers를 선택했다.</p>\n<p>각 각에 대해 한 번 알아보고 어떤 이유로 CloudFlare Workers를 선택했는지 알아보자.</p>\n<h3 id=\"supabase-유료-플랜\">Supabase 유료 플랜</h3>\n<p><img src=\"https://velog.velcdn.com/images/jihwankim128/post/eddf2b18-25e8-4a08-9346-7e1f29df2883/image.png\" alt=\"\"></p>\n<p>Supabase 유료 플랜은 Custom Domain에 대한 기능을 제공하지만 달달이 돈을 내야한다. 이거 하나면 해결이 된다!</p>\n<p>CloudFlare Workers를 선택하면서 이후 프로세스에 대해 자세히는 모르겠지만, 아마도 CF를 사용하는 대표적인 Sass인 Vercel과 같이 Cloudflare for SaaS를 통해 Custom Domain에 대한 승인을 통해 1014를 해결해 줄 것으로 예상된다.</p>\n<p>정리하자면 장점은 <strong>간단하다는 것</strong>이고 단점은 <strong>유료</strong>라는 것이다.</p>\n<h3 id=\"cloudflare-workers\">CloudFlare Workers</h3>\n<p>다음으로 Worker를 활용하는 방식은 CF에서 DNS 설정이 된 Web Server(Vercel)와 Supabase 간에 Proxy를 하나 두는 것이다.</p>\n<p><img src=\"https://velog.velcdn.com/images/jihwankim128/post/0890b2a7-fe24-4559-ba1d-d77682549b2e/image.png\" alt=\"\"></p>\n<p>그림과 같이 보안 처리, 요청 가공, 캐싱 등 중간에 필요한 정보들을 Worker에서 처리하는 방법이다. 이 방법에도 장/단점이 존재한다.</p>\n<blockquote>\n<p><strong>장점</strong></p>\n</blockquote>\n<ul>\n<li>Supabase 유료 플랜에서 벗어나 무료로 서비스를 제공 할 수 있다.</li>\n<li>Supabase 관련 정보를 front에서 은닉할 수 있다.<ul>\n<li>CSR과 ServerLess기반 BackEnd로 명확한 관심사 분리</li>\n</ul>\n</li>\n<li>요청/응답에 따른 필요한 처리를 커스터마이징 할 수 있다. </li>\n</ul>\n<blockquote>\n<p><strong>단점</strong></p>\n</blockquote>\n<ul>\n<li>Worker는 하루에 10만 건의 요청까지만 무료로 제공하기 때문에 서비스가 커지면, 유료 요금제로 전환을 하거나 아키텍처 변경이 필수 동반된다.</li>\n<li>Worker에 대해 작업하는 추가 비용이 발생한다.</li>\n</ul>\n<h3 id=\"worker를-선택한-이유\">Worker를 선택한 이유</h3>\n<p>각 각의 장단점을 비교 했을 때 핵심은 <strong>비용 vs 복잡도</strong>로 좁힐 수 있다.\n프로젝트의 MVP 관점에서 바라봤을 때 <strong>비용 최소화</strong>가 가장 중요하게 다가왔다. 복잡도도 간단하면 좋겠지만, 복잡도를 낮추는 것은 MVP 관점이 아닌 유지보수 관점에서 바라봐야 한다고 생각했기 때문에 Worker를 선택했다.</p>\n<p><img src=\"https://velog.velcdn.com/images/jihwankim128/post/9baafe24-6170-4248-8870-099761edf1a2/image.png\" alt=\"\"></p>\n<p>Worker에 대한 설정 방법은 사진에서 보이는 것과 같이 Worker Page에서 <code>Create application</code> -&gt; <code>Start with Hello World</code>를 통해 index.js를 직접 작성할 수 있다.</p>\n<pre><code class=\"language-js\">export default {\n  async fetch(request, env) {\n    const SUPABASE_URL = &#39;https://project-id.supabase.co&#39;;\n    const SUPABASE_KEY = &#39;supabase-anon-key&#39;;\n\n    const targetUrl = `${SUPABASE_URL}/rest/v1/store?select=*`;\n\n    try {\n      const response = await fetch(targetUrl, {\n        method: &#39;GET&#39;,\n        headers: {\n          &#39;apikey&#39;: SUPABASE_KEY,\n          &#39;Authorization&#39;: `Bearer ${SUPABASE_KEY}`,\n          &#39;Content-Type&#39;: &#39;application/json&#39;,\n        },\n      });\n\n      const data = await response.json();\n\n      return new Response(JSON.stringify(data, null, 2), {\n        headers: {\n          &#39;content-type&#39;: &#39;application/json;charset=UTF-8&#39;,\n          &#39;Access-Control-Allow-Origin&#39;: &#39;https://ondoguide.com&#39;,\n        },\n      });\n\n    } catch (error) {\n      return new Response(JSON.stringify({ error: error.message }), { \n        status: 500,\n        headers: { &#39;content-type&#39;: &#39;application/json&#39; }\n      });\n    }\n  },\n};</code></pre>\n<p>코드까지 모두 작성을 마치면 Custom Domain 설정만 하면 CF에서 알아서 DNS 설정까지 마무리해준다.</p>\n<p><img src=\"https://velog.velcdn.com/images/jihwankim128/post/d5a1452e-4219-4687-a39f-33da4c3a0412/image.png\" alt=\"\"></p>\n<p>배포된 Worker를 선택해서 <code>Settings</code> -&gt; <code>Domains &amp; Routes</code> -&gt; <code>Add</code> -&gt; <code>Custom Domain</code>에서 구매한 도메인 TLD를 작성하면 된다.</p>\n<hr>\n<h2 id=\"마치며\">마치며</h2>\n<p>Serverless 기반 프로젝트를 경험하며 CloudFlare의 정책에 대해 일부 알게돼서 의미있었다. 이 정책이 어떤 이유로 생겼을지도 고민해보고, 이 정책으로 발생한 문제점을 해결할 방법들을 고민하면서 인프라 지식이 한단계 더 레벨업 할 수 있었던 것 같다.</p>\n<p>결국 인프라의 제약 사항을 이해하는 것은 단순히 에러를 고치는 과정을 넘어, 서비스의 확장성과 비용 효율성을 동시에 고려하는 설계 능력을 기르는 과정임을 다시 한번 느끼게 됐다.</p>",
    "date": "2026-02-15T01:01:08.000Z",
    "url": "https://velog.io/@jihwankim128/cloud-flare-1014-%EC%9A%B0%ED%9A%8C"
  },
  {
    "publisherId": "velog",
    "publisherName": "Velog",
    "specTitle": "개발자 블로그",
    "categories": [
      "_all_"
    ],
    "specUrl": "https://v2.velog.io/rss/",
    "title": "15.02.2026",
    "partialText": "<h1 id=\"뇌과학-코딩의-종말-그리고-다시-쓰는-일기\">뇌과학, 코딩의 종말, 그리고 다시 쓰는 일기</h1>\n<p>오늘 우연히 뇌과학에 관한 영상을 접했다. 뇌는 언제 성장하고, 또 언제 퇴화하는가. 그 질문 끝에 닿은 것은 <strong>&#39;인지적 지구력(Cognitive Endurance)&#39;</strong>이라는 단어였다.</p>\n<h3 id=\"인지적-지구력과-밀도-높은-글쓰기\">인지적 지구력과 밀도 높은 글쓰기</h3>\n<p>영상에서는 수녀님들을 대상으로 한 유명한 연구(The Nun Study)가 소개되었다. 평생을 규칙적으로 사신 수녀님들 중, 사후 뇌 부검 결과 알츠하이머의 병변이 심각했음에도 생전에는 전혀 치매 증상을 보이지 않았던 분들이 계셨다.</p>\n<p>그 비결은 <strong>&#39;글쓰기&#39;</strong>에 있었다.</p>\n<blockquote>\n<p>20대 시절, 밋밋하고 단순한 글을 썼던 그룹은 치매 발병률이 높았던 반면, <strong>밀도 높고 풍부한 어휘로 글을 남겼던 분들은 뇌의 물리적 손상마저 이겨냈다.</strong></p>\n</blockquote>\n<p>뇌 안의 후각 정보, 해마, 편도체, 전두엽까지를 연결시키는 거대한 다리가 놓인 것이다. 서울대 이인아 교수님은 뇌를 &#39;서랍&#39;이 아닌 <strong>&#39;거미줄&#39;</strong>에 비유하셨다. 그 구석구석을 어떻게 연결할지는 매 순간 나의 선택에 달려있다.</p>\n<p>아무리 피곤하더라도 다시 일기를 써야겠다고 다짐한 이유가 여기에 있다. 뇌를 단단하게 만드는 것은 결국 밀도 높은 생각과 그것을 정리하는 행위니까.</p>\n<h3 id=\"아인슈타인의-바이올린-그리고-외국어\">아인슈타인의 바이올린, 그리고 외국어</h3>\n<p>아인슈타인은 물리학 난제에 부딪힐 때마다 바이올린을 켰다고 한다. 전혀 다른 영역의 자극이 뇌의 새로운 연결을 도왔을 것이다.</p>\n<p>나에게는 그것이 <strong>영어와 독일어</strong>다. 아직은 단어와 기초 문법을 헤매는, 미숙하다 못해 우스운 수준일지 모른다. 하지만 이 또한 내 뇌의 거미줄을 넓히는 과정이라 믿으며 남은 시간 동안 꾸준히 부딪쳐보기로 한다.</p>\n<h3 id=\"코딩은-사라질-것이다라는-말-앞에서\">&quot;코딩은 사라질 것이다&quot;라는 말 앞에서</h3>\n<p>최근 일론 머스크가 &quot;곧 코딩이라는 단어가 사라질 것&quot;이라 예견했다.\n생각해 보면 소스코드(C, Python, Java 등)는 인간이 기계를 이해하고, 이해시키기 위해 만든 도구다. 하지만 AI가 기계와 기계 사이의 소통을 완벽히 중개하는 시스템이 된다면? 굳이 인간이 작성하는 코드가 필요 없을지도 모른다. 컴파일이라는 과정 자체가 역사 속으로 사라질 수도 있다.</p>\n<p>이 거대한 변화의 흐름 속에서 나는 역설적으로 <strong>기본(Basic)</strong>을 다시 본다.\nCS(컴퓨터 공학) 지식과 임베디드 시스템의 가장 기초적인 부분들. 화려한 기술보다 그 밑바닥에 있는 원리를 탐구하는 중이다.</p>\n<h3 id=\"성장과-정체-사이\">성장과 정체 사이</h3>\n<p>학업적으로도 새로운 변화가 생겼다. <strong>방송통신대 프라임칼리지 3학년으로 편입</strong>하게 되었다. 내년까지 잘 마무리하면 학사 학위라는 결실을 맺을 것이다.</p>\n<p>솔직히 말하면, 지금 당장은 내가 성장하고 있는지 잘 느껴지지 않는다. 여전히 제자리걸음인 것 같고 미약하게만 느껴진다. 하지만 뇌과학이 알려준 대로, <strong>&#39;순간의 선택&#39;</strong>들이 모여 나를 만든다는 것을 기억하려 한다.</p>\n<p>앞으로는 루틴을 단순화한다.</p>\n<ul>\n<li><strong>밤:</strong> 뇌의 연결을 위해 밀도 있는 일기 쓰기</li>\n<li><strong>아침:</strong> 마음과 몸을 깨우는 명상과 운동</li>\n</ul>\n<p>오늘의 기록이 훗날 내 머릿속 거미줄을 지탱하는 단단한 실 한 가닥이 되기를 바란다.</p>",
    "date": "2026-02-15T00:43:00.000Z",
    "url": "https://velog.io/@hyunahn1/15.02.2026"
  },
  {
    "publisherId": "velog",
    "publisherName": "Velog",
    "specTitle": "개발자 블로그",
    "categories": [
      "_all_"
    ],
    "specUrl": "https://v2.velog.io/rss/",
    "title": "[Unity] Coroutine, IEnumerator",
    "partialText": "<h2 id=\"ienumerator-변수의-코루틴\">[IEnumerator 변수의 코루틴]</h2>\n<pre><code>IEnumerator myCoroutine;\n\nmyCoroutine = MyCoroutine(1.0f);\nStartCoroutine(myCoroutine);\nStopCoroutine(myCoroutine);</code></pre><p>✔ 특징</p>\n<ul>\n<li>MyCoroutine()이 반환하는 IEnumerator 객체 자체를 저장\nStartCoroutine(IEnumerator routine) 방식 사용\n같은 IEnumerator 인스턴스를 StopCoroutine()에 전달해서 중지</li>\n<li>바로 시작을 안하고 객체를 저장할 수 있어 원하는 타이밍에\n코루틴을 돌릴 수 있다.</li>\n</ul>\n<h2 id=\"coroutine-변수의-코루틴\">[Coroutine 변수의 코루틴]</h2>\n<pre><code>Coroutine myCoroutine;\n\nmyCoroutine = StartCoroutine(MyCoroutine(1.0f));\nStopCoroutine(myCoroutine);</code></pre><p>✔ 특징</p>\n<ul>\n<li>StartCoroutine()의 반환값인 Coroutine 객체의 주소를 저장\nUnity가 내부적으로 관리하는 실행 핸들(handle)</li>\n<li>실무에서 더 자주 쓰이는 방식</li>\n</ul>\n<p>✔ 동작 원리</p>\n<ul>\n<li>StartCoroutine()이 실행과 동시에 Coroutine 참조 객체를 반환\n그 핸들을 통해 정확히 해당 실행 인스턴스를 중지하고\n다시 같은 코루틴을 재사용할 수 있다.</li>\n</ul>\n<h2 id=\"코루틴-함수-모르는-부분-정리\">[코루틴 함수 모르는 부분 정리]</h2>\n<pre><code>yield return new WaitUntil()</code></pre><ul>\n<li>조건식을 넣어주고 결과값이 true가 되면 다음 구문을 실행한다.</li>\n</ul>\n<pre><code>yield return new WaitWhile()</code></pre><ul>\n<li>조건식을 넣어주고 결과값이 false가 되면 다음 구문을 실행한다.</li>\n</ul>",
    "date": "2026-02-15T00:40:13.000Z",
    "url": "https://velog.io/@100norhozhoroski/Unity-Coroutine-IEnumerator-IEnumerable"
  },
  {
    "publisherId": "velog",
    "publisherName": "Velog",
    "specTitle": "개발자 블로그",
    "categories": [
      "_all_"
    ],
    "specUrl": "https://v2.velog.io/rss/",
    "title": "Evidence-Pooled Presence Supervision (EPPS) for Semi-Supervised 3D Medical Segmentation",
    "partialText": "<h2 id=\"1-problem-statement--motivation\">1. Problem Statement &amp; Motivation</h2>\n<p>Training promptable segmentation models (like Segment Anything) for 3D medical imaging requires expensive voxel-level annotations. While we have limited labeled data (ReXGroundingCT), we have massive amounts of unlabeled data paired with radiology reports (CT-RATE).</p>\n<p><strong>The Core Challenge:</strong>\nStandard semi-supervised methods fail in this setting:</p>\n<ol>\n<li><strong>Teacher-Student Pseudo-labeling:</strong> Fails because the teacher model, trained on limited data, often hallucinates findings (high False Positives) or misses tiny lesions (False Negatives).</li>\n<li><strong>Global Alignment (CLIP-style):</strong> Training an encoder to match images to text globally () creates a &quot;shortcut.&quot; The model learns to predict the presence of a disease based on global context (e.g., scan metadata, artifacts) without actually localizing the lesion.</li>\n</ol>\n<p><strong>Research Gap:</strong> We need a way to utilize report-level supervision (&quot;This scan contains pneumonia&quot;) that forces the model to learn <em>dense, pixel-level</em> features rather than global shortcuts.</p>\n<h2 id=\"2-core-hypothesis\">2. Core Hypothesis</h2>\n<p><strong>&quot;Presence implies Spatial Evidence.&quot;</strong>\nWe hypothesize that a model should only predict a finding is &quot;present&quot; if it can point to specific high-activation regions in the segmentation map. By forcing the model to derive its &quot;presence score&quot; by pooling the segmentation logits (rather than using a global vector), we can train the segmentation head using only report-level labels.</p>\n<h2 id=\"3-methodology\">3. Methodology</h2>\n<p>We propose <strong>Evidence-Pooled Presence Supervision (EPPS)</strong>. We will extend the SAT (Segment Anything Text) architecture to support semi-supervised training with a two-stream approach.</p>\n<h3 id=\"31-the-architecture-comparison\">3.1. The Architecture Comparison</h3>\n<p>We will compare two distinct ways of handling unlabeled data:</p>\n<ul>\n<li><strong>Baseline A: Global Alignment (The Control)</strong>\nThe model predicts presence using a separate MLP head on the encoder&#39;s global output.</li>\n</ul>\n<p><em>Critique:</em> This decouples presence from localization, allowing the model to cheat.</p>\n<ul>\n<li><strong>Proposed Method: Evidence Pooling (EPPS)</strong>\nThe model predicts presence by pooling the final segmentation logits (voxel evidence).</li>\n</ul>\n<p><em>Advantage:</em> To predict  (present), the model <em>must</em> activate specific voxels in the segmentation map.</p>\n<h3 id=\"32-evidence-pooling-strategies\">3.2. Evidence Pooling Strategies</h3>\n<p>Since medical findings vary wildly in size (tiny nodules vs. diffuse edema), we will evaluate adaptive pooling operators on the flattened logits:</p>\n<ul>\n<li><strong>LSEPool (Log-Sum-Exp):</strong> A smooth approximation of MaxPool. Good for focal lesions.</li>\n<li><strong>GeMPool (Generalized Mean):</strong> Adaptive pooling that can learn to interpolate between Max and Average.</li>\n</ul>\n<h3 id=\"33-training-objective\">3.3. Training Objective</h3>\n<p>The model is trained on mixed batches of Labeled () and Unlabeled () data:</p>\n<p><strong>1. Supervised Stream (Labeled Data):</strong>\nStandard Dice + Cross-Entropy loss on ground truth masks.</p>\n<p><strong>2. Unsupervised Stream (Unlabeled Data + Reports):</strong>\nWe utilize three loss components to prevent the &quot;False Positive Explosion&quot; common in medical AI:</p>\n<ul>\n<li><strong>Presence Alignment Loss:</strong> .</li>\n<li><em>Positive Sampling ():</em> Prompts extracted from the patient&#39;s report.</li>\n<li><em>Negative Sampling ():</em> Synthetic prompts <em>not</em> in the report (crucial to prevent the model from predicting &quot;Yes&quot; to everything).</li>\n</ul>\n<ul>\n<li><strong>Area Penalty:</strong> .</li>\n<li>Penalizes the model for highlighting the entire lung volume; encourages sparsity.</li>\n</ul>\n<ul>\n<li><strong>Consistency Loss:</strong> .</li>\n<li>Enforces that the predicted presence score remains stable under image augmentations.</li>\n</ul>\n<h2 id=\"4-experimental-design\">4. Experimental Design</h2>\n<p><strong>Datasets:</strong></p>\n<ul>\n<li><strong>Labeled:</strong> ReXGroundingCT (small, high-quality masks).</li>\n<li><strong>Unlabeled:</strong> CT-RATE (large, image-report pairs).</li>\n</ul>\n<p><strong>Baselines to Compare:</strong></p>\n<ol>\n<li><strong>Supervised Only:</strong> Trained only on ReXGroundingCT.</li>\n<li><strong>Global Encoder MLP:</strong> The standard CLIP-like approach for weak supervision.</li>\n<li><strong>EPPS (Ours):</strong> The proposed logit-pooling approach.</li>\n</ol>\n<p><strong>Key Metrics:</strong></p>\n<ul>\n<li><strong>Dice Score:</strong> Segmentation accuracy on held-out labeled data.</li>\n<li><strong>False Positive Volume:</strong> Does the model hallucinate masks on healthy scans?</li>\n<li><strong>Presence AUC:</strong> Can the model correctly classify findings based on the report?</li>\n</ul>\n<h2 id=\"5-expected-contribution-the-eccv-story\">5. Expected Contribution (The ECCV &quot;Story&quot;)</h2>\n<p>We aim to demonstrate that <strong>Global Alignment is insufficient for 3D grounding</strong>. We show that tying presence prediction directly to spatial evidence via <strong>Evidence Pooling</strong>  allows for scalable learning from radiology reports, significantly improving recall on small lesions while controlling false positives through negative sampling and area constraints.</p>\n<hr>\n<blockquote>\n<p>아래는 제미나이 피셜 possible 문제점</p>\n</blockquote>\n<h3 id=\"1-incremental-novelty-the-its-just-pooling-critique\">1. &quot;Incremental Novelty&quot; (The &quot;It&#39;s Just Pooling&quot; Critique)</h3>\n<ul>\n<li></li>\n<li><em>The Critique:*</em> Reviewers might argue that replacing a global <code>[CLS]</code> token with <code>Max/Avg/LSE</code> pooling on feature maps is a standard engineering trick, not a research contribution. MIL (Multiple Instance Learning) has used &quot;bag-of-features&quot; pooling for decades. If the core novelty is just &quot;we applied LSE pooling to segmentation logits,&quot; it looks like a hyper-parameter search masquerading as a method.</li>\n</ul>\n<ul>\n<li><strong>The Fix:</strong> You must reframe the narrative. The contribution isn&#39;t <em>pooling</em>; the contribution is <strong>solving the semantic gap in semi-supervised 3D grounding</strong>. You are proving that <em>global alignment objectives</em> (like CLIP) fundamentally fail for dense prediction tasks because they decouple presence from localization. Your method enforces &quot;evidence-based consistency&quot; where a model is <em>not allowed</em> to predict presence unless it can point to the voxels. The pooling is just the mechanism to enforce this constraint.</li>\n</ul>\n<h3 id=\"2-the-naive-negatives-problem\">2. The &quot;Naive Negatives&quot; Problem</h3>\n<ul>\n<li><strong>The Critique:</strong> Your dataset (radiology reports) contains mostly positive findings (&quot;Pneumonia is present&quot;). You propose generating synthetic negatives by sampling prompts <em>not</em> in the report. A reviewer will immediately ask: &quot;How do you know &#39;not mentioned&#39; means &#39;absent&#39;?&quot;.</li>\n</ul>\n<ul>\n<li>In radiology, omitting a finding often means it&#39;s normal or irrelevant, but not necessarily &quot;absolutely zero evidence.&quot;</li>\n<li>If your &quot;negative&quot; sampling teaches the model to suppress features that are actually present (but just not mentioned), you hurt recall.</li>\n</ul>\n<ul>\n<li>Conversely, if you don&#39;t have enough <em>hard</em> negatives, the model might just learn to predict  for everything to minimize loss.</li>\n</ul>\n<ul>\n<li><strong>The Fix:</strong> You need a <strong>&quot;Reliability Check&quot;</strong> or <strong>&quot;Soft Negative&quot;</strong> strategy.</li>\n<li>Acknowledge that &quot;not mentioned&quot; is a weak negative.</li>\n</ul>\n<ul>\n<li>Use a lower loss weight for these synthetic negatives compared to the positives.</li>\n</ul>\n<ul>\n<li>Or, if possible, use an explicit &quot;Normal&quot; or &quot;No acute findings&quot; category as a <em>hard</em> negative.</li>\n</ul>\n<ul>\n<li>Show in your ablation that your negative sampling strategy is robust to label noise.</li>\n</ul>\n<h3 id=\"3-weak-theoretical-grounding-for-pooling-choices\">3. Weak Theoretical Grounding for Pooling Choices</h3>\n<ul>\n<li><strong>The Critique:</strong> Why <code>LSEPool</code>? Why <code>GeMPool</code>?. The proposal lists them as things to try, but doesn&#39;t offer a theoretical reason why one is better for <em>this specific problem</em>. It feels like &quot;we threw the kitchen sink at it.&quot;</li>\n</ul>\n<ul>\n<li></li>\n<li><em>The Fix:*</em> Tie the pooling choice to the <strong>medical reality</strong> of the data.</li>\n</ul>\n<ul>\n<li><em>Hypothesis:</em> <code>MaxPool</code> works for tiny nodules (1-2 voxels drive the signal). <code>AvgPool</code> works for diffuse pneumonia (large area drives signal).</li>\n</ul>\n<ul>\n<li></li>\n<li>Method:* Therefore, a learnable pooling parameter (like <code>r</code> in GeM or <code>temperature</code> in LSE) is not just a tweak—it&#39;s <strong>necessary</strong> to handle the scale variance of medical lesions.</li>\n</ul>\n<ul>\n<li></li>\n<li>Experiments:* Show that learning this parameter per-class improves performance on <em>both</em> tiny and large lesions, whereas fixed pooling fails on one or the other.</li>\n</ul>\n<h3 id=\"4-the-where-is-the-teacher-confusion\">4. The &quot;Where is the Teacher?&quot; Confusion</h3>\n<ul>\n<li><strong>The Critique:</strong> You start by motivating &quot;limited data,&quot; but standard semi-supervised benchmarks use strong teacher-student pseudo-labeling. Your proposal pivots to &quot;weak supervision via reports.&quot; A reviewer might ask: &quot;Why didn&#39;t you just use a better pseudo-labeling filter (like uncertainty estimation) on the teacher?&quot;. You need to show that your method is <em>complementary</em> to or <em>better than</em> just filtering pseudo-labels.</li>\n</ul>\n<ul>\n<li><strong>The Fix:</strong></li>\n<li>Position your method as the <strong>&quot;Warm-up&quot; or &quot;Stabilizer&quot;</strong> for the teacher.</li>\n</ul>\n<ul>\n<li>The teacher fails because it hallucinates. Your &quot;Evidence-Pooled&quot; objective acts as a <strong>False Positive Brake</strong>.</li>\n</ul>\n<ul>\n<li>Explicitly compare against a baseline of &quot;Teacher-Student with Confidence Thresholding&quot; to show that your method adds value beyond standard SSL.</li>\n</ul>\n<h3 id=\"summary-is-it-fatal\">Summary: Is it fatal?</h3>\n<p><strong>No.</strong> The core idea (enforcing spatial evidence for weak supervision) is sound and addresses a real bottleneck in medical AI.</p>\n<p><strong>To ensure ECCV acceptance:</strong></p>\n<ol>\n<li></li>\n</ol>\n<p><strong>Don&#39;t sell &quot;Pooling.&quot;</strong> Sell <strong>&quot;Grounded Weak Supervision.&quot;</strong> </p>\n<ol start=\"2\">\n<li></li>\n</ol>\n<p><strong>Defend your negatives.</strong> Explain why your synthetic negative strategy is valid and robust.</p>\n<ol start=\"3\">\n<li></li>\n</ol>\n<p><strong>Justify the adaptive pooling.</strong> It&#39;s the solution to the &quot;multi-scale lesion&quot; problem.</p>\n<ol start=\"4\">\n<li></li>\n</ol>\n<p><strong>Show the failure cases.</strong> Include the &quot;Encoder MLP&quot; baseline to prove that global alignment fails.</p>\n<p>If you frame it as &quot;Solving the False Positive problem in Semi-Supervised Medical Grounding via Evidence constraints,&quot; it is a strong paper. If you frame it as &quot;We tried LSE pooling,&quot; it is a workshop paper.</p>",
    "date": "2026-02-15T00:32:59.000Z",
    "url": "https://velog.io/@treeboy2762/Evidence-Pooled-Presence-Supervision-EPPS-for-Semi-Supervised-3D-Medical-Segmentation"
  },
  {
    "publisherId": "velog",
    "publisherName": "Velog",
    "specTitle": "개발자 블로그",
    "categories": [
      "_all_"
    ],
    "specUrl": "https://v2.velog.io/rss/",
    "title": "kubesrapy로 k8s offline 설치 - kubesrapy-offline 도구",
    "partialText": "<blockquote>\n<h2 id=\"kubespray-offline-도구를-사용해서-외부망에서-필요한-파일을-모두-내려받고-폐쇄망-내부에-로컬-레포지토리와-레지스트리를-구성한-뒤-클러스터를-배포하는-전체-과정을-정리했다\"><code>kubespray-offline</code> 도구를 사용해서 외부망에서 필요한 파일을 모두 내려받고, 폐쇄망 내부에 로컬 레포지토리와 레지스트리를 구성한 뒤 클러스터를 배포하는 전체 과정을 정리했다.</h2>\n</blockquote>\n<hr>\n<h2 id=\"작업-구조\">작업 구조</h2>\n<p>크게 두 단계로 나뉜다.</p>\n<ul>\n<li><strong>외부망(Online)</strong>: 필요한 리소스를 모두 다운로드</li>\n<li><strong>폐쇄망(Offline)</strong>: 내부 서버 구성 후 클러스터 배포</li>\n</ul>\n<p><img src=\"https://velog.velcdn.com/images/bytebliss/post/12836302-c7db-4eb6-a003-aca6704e0922/image.png\" alt=\"\"></p>\n<hr>\n<h2 id=\"사전-요구-사항\">사전 요구 사항</h2>\n<h3 id=\"지원-os\">지원 OS</h3>\n<table>\n<thead>\n<tr>\n<th>구분</th>\n<th>버전</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>RHEL / AlmaLinux / Rocky Linux</td>\n<td>9.x</td>\n</tr>\n<tr>\n<td>Ubuntu</td>\n<td>22.04, 24.04</td>\n</tr>\n</tbody></table>\n<p>주의할 점은 Online Node와 Offline Target Node의 OS 종류와 버전이 반드시 같아야 한다는 것이다. 다르면 패키지 의존성 문제가 생긴다.</p>\n<blockquote>\n<p>RHEL 8은 Kubespray 2.29.0부터 지원이 중단됐다.</p>\n</blockquote>\n<h3 id=\"하드웨어-권장-사양\">하드웨어 권장 사양</h3>\n<table>\n<thead>\n<tr>\n<th>구분</th>\n<th>최소 사양</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Installer Node</td>\n<td>RAM 4GB, Disk 50GB 이상</td>\n</tr>\n<tr>\n<td>Target Nodes</td>\n<td>RAM 2GB, vCPU 2개 이상</td>\n</tr>\n</tbody></table>\n<hr>\n<h2 id=\"phase-1---외부망-리소스-다운로드\">Phase 1 - 외부망: 리소스 다운로드</h2>\n<p>인터넷이 되는 리눅스 서버에서 진행한다.</p>\n<h3 id=\"configsh-수정\">config.sh 수정</h3>\n<p>먼저 <code>config.sh</code>를 열어 버전과 런타임 설정을 확인한다.</p>\n<pre><code class=\"language-bash\"># config.sh\n\n# 설치할 Kubespray 버전\nKUBESPRAY_VERSION=${KUBESPRAY_VERSION:-2.30.0}\n\n# 컨테이너 런타임 (RHEL 계열은 podman, Ubuntu는 docker 권장)\ndocker=${docker:-podman}</code></pre>\n<h3 id=\"전체-다운로드-실행\">전체 다운로드 실행</h3>\n<pre><code class=\"language-bash\">$ ./download-all.sh</code></pre>\n<p>내부적으로 아래 순서로 동작한다.</p>\n<ol>\n<li><code>prepare-pkgs.sh</code> - pip, podman 등 필요한 도구 설치</li>\n<li><code>get-kubespray.sh</code> - 지정 버전의 Kubespray 소스코드 다운로드</li>\n<li><code>pypi-mirror.sh</code> - Python 라이브러리(.whl) 다운로드</li>\n<li><code>download-kubespray-files.sh</code> - 컨테이너 이미지 및 바이너리(kubectl, cni 등) 다운로드</li>\n<li><code>create-repo.sh</code> - OS 패키지(RPM/Deb) 다운로드 및 로컬 레포 메타데이터 생성</li>\n</ol>\n<p>완료되면 <code>outputs/</code> 디렉토리에 모든 파일이 쌓인다.</p>\n<hr>\n<h2 id=\"phase-2---파일-이관\">Phase 2 - 파일 이관</h2>\n<p><code>outputs/</code> 디렉토리를 압축해서 폐쇄망 Installer Node로 옮긴다.</p>\n<pre><code class=\"language-bash\"># 압축\n$ tar czf kubespray-offline-outputs.tar.gz outputs/\n\n# Installer Node에서 압축 해제\n$ tar xzf kubespray-offline-outputs.tar.gz</code></pre>\n<p>USB나 망연계 솔루션을 통해 이동시키면 된다.</p>\n<hr>\n<h2 id=\"phase-3---폐쇄망-인프라-구성-및-배포\">Phase 3 - 폐쇄망: 인프라 구성 및 배포</h2>\n<p>이제부터는 폐쇄망 Installer Node에서 진행한다.</p>\n<h3 id=\"로컬-인프라-구축\">로컬 인프라 구축</h3>\n<pre><code class=\"language-bash\">$ cd outputs\n$ ./setup-all.sh</code></pre>\n<p>이 스크립트가 하는 일은 다음과 같다.</p>\n<ol>\n<li><code>setup-container.sh</code> - containerd 설치, Nginx와 Registry 이미지 로드</li>\n<li><code>start-nginx.sh</code> - 80번 포트로 Nginx 실행 (패키지 파일 서버)</li>\n<li><code>setup-offline.sh</code> - Installer Node가 로컬 Nginx를 바라보도록 repo 설정 변경</li>\n<li><code>start-registry.sh</code> - 35000번 포트로 Docker Registry 실행</li>\n<li><code>load-push-all-images.sh</code> - 이미지를 containerd에 로드 후 로컬 Registry에 푸시</li>\n</ol>\n<h3 id=\"kubespray-환경-구성\">Kubespray 환경 구성</h3>\n<pre><code class=\"language-bash\"># Kubespray 소스 압축 해제\n$ ./extract-kubespray.sh\n$ cd kubespray-{version}\n\n# Python 가상환경 생성 및 활성화\n$ source ../venv.sh\n\n# 라이브러리 설치 (오프라인 PyPI 미러 사용)\n$ pip install -r requirements.txt</code></pre>\n<h3 id=\"인벤토리-및-오프라인-설정\">인벤토리 및 오프라인 설정</h3>\n<p>인벤토리를 만들고 오프라인 설정을 적용한다.</p>\n<pre><code class=\"language-bash\"># 인벤토리 생성\n$ cp -rfp inventory/sample inventory/mycluster\n$ declare -a IPS=(10.10.1.3 10.10.1.4 10.10.1.5)\n$ CONFIG_FILE=inventory/mycluster/hosts.yaml \\\n  python3 contrib/inventory_builder/inventory.py ${IPS[@]}</code></pre>\n<p><code>outputs/offline.yml</code>을 <code>inventory/mycluster/group_vars/all/offline.yml</code>로 복사한 뒤 Installer Node IP를 수정한다.</p>\n<pre><code class=\"language-yaml\"># inventory/mycluster/group_vars/all/offline.yml\n\n# YOUR_HOST를 Installer Node IP로 변경\nhttp_server: &quot;http://192.168.1.100&quot;\nregistry_host: &quot;192.168.1.100:35000&quot;\n\n# 로컬 레지스트리 미러 설정 (중요)\ncontainerd_registries_mirrors:\n  - prefix: &quot;{{ registry_host }}&quot;\n    mirrors:\n      - host: &quot;http://{{ registry_host }}&quot;\n        capabilities: [&quot;pull&quot;, &quot;resolve&quot;]\n        skip_verify: true</code></pre>\n<h3 id=\"클러스터-배포\">클러스터 배포</h3>\n<p><strong>Step 1. 타겟 노드 레포지토리 설정</strong></p>\n<p>타겟 노드들이 Installer Node의 Nginx에서 패키지를 받도록 설정한다.</p>\n<pre><code class=\"language-bash\">$ cp -r ../playbook/* .\n$ ansible-playbook -i inventory/mycluster/hosts.yaml --become offline-repo.yml</code></pre>\n<p><strong>Step 2. 클러스터 설치</strong></p>\n<pre><code class=\"language-bash\">$ ansible-playbook -i inventory/mycluster/hosts.yaml \\\n  --become --become-user=root cluster.yml</code></pre>\n<hr>\n<h2 id=\"트러블슈팅\">트러블슈팅</h2>\n<p><strong>Python 버전 문제</strong>\nUbuntu 24.04는 Python 3.12를 쓴다. <code>prepare-pkgs.sh</code> 실행 시 호환성 문제가 생길 수 있는데, <code>target-scripts/pyver.sh</code>에서 자동 감지하도록 되어 있어서 대부분 자동으로 처리된다.</p>\n<p><strong>방화벽</strong>\nInstaller Node의 80번(Nginx)과 35000번(Registry) 포트가 타겟 노드들에서 접근 가능한지 반드시 확인한다.</p>\n<p><strong>디스크 용량</strong>\n<code>outputs/</code> 디렉토리는 수 GB가 된다. Installer Node에 여유 공간이 충분한지 미리 확인해둔다.</p>\n<hr>\n<h2 id=\"마무리\">마무리</h2>\n<p>처음에는 설정 파일이 많아서 복잡해 보이지만, 결국 흐름은 단순하다.</p>\n<pre><code>다운로드 → 이관 → 서버 구성 → 배포</code></pre><p><code>kubespray-offline</code>이 대부분의 번거로운 작업을 자동화해줘서 직접 처리할 부분은 IP 설정과 인벤토리 구성 정도다.</p>",
    "date": "2026-02-15T00:30:39.000Z",
    "url": "https://velog.io/@bytebliss/kubesrapy%EB%A1%9C-k8s-offline-2"
  },
  {
    "publisherId": "velog",
    "publisherName": "Velog",
    "specTitle": "개발자 블로그",
    "categories": [
      "_all_"
    ],
    "specUrl": "https://v2.velog.io/rss/",
    "title": "[Andrew Ng] 4-3.Derivatives of Activation Functions",
    "partialText": "<h3 id=\"sigmoid-activation-function\">Sigmoid activation function</h3>\n<p><img src=\"https://velog.velcdn.com/images/hojin0155/post/d63f3bca-5f56-47a7-8d86-c0fe4eca08cd/image.png\" alt=\"\"></p>\n<ul>\n<li>Sigmoid 함수 값 즉 a값을 구했다면 빠르게 $$g$$&#39;값을 구할 수 있는 것이 장점이다.</li>\n</ul>\n<h3 id=\"proof-derivative-of-sigmoid\">Proof Derivative of Sigmoid</h3>\n<ul>\n<li>[Andrew Ng] 2-5.Logistic Regression Gradient Descent에서 다룸.</li>\n</ul>\n<h3 id=\"tanh-activation-function\">Tanh activation function</h3>\n<p><img src=\"https://velog.velcdn.com/images/hojin0155/post/672ecd1b-aa23-4aff-a4e6-995ae20a7ce5/image.png\" alt=\"\"></p>\n<ul>\n<li>Tanh 함수 값 즉 a값을 구했다면 빠르게 $$g$$&#39;값을 구할 수 있는 것이 장점이다.</li>\n</ul>\n<h3 id=\"proof-derivative-of-tanh\">Proof Derivative of Tanh</h3>\n<ul>\n<li><p>$$\\tanh(x)$$\n$$\n\\tanh(x) = \\frac{\\sinh(x)}{\\cosh(x)}\n$$</p>\n</li>\n<li><p>$$f(x)$$와 $$g(x)$$의 미분\n$$\nf(x) = e^x - e^{-x}, \\quad g(x) = e^x + e^{-x}\n$$\n$$\nf&#39;(x) = e^x + e^{-x}, \\quad g&#39;(x) = e^x - e^{-x}\n$$</p>\n</li>\n<li><p>몫의 미분법\n$$\n\\frac{d}{dx} \\tanh(x) = \n\\frac{d}{dx} \\left( \\frac{f(x)}{g(x)} \\right) = \\frac{f&#39;(x)g(x) - f(x)g&#39;(x)}{(g(x))^2} = \\frac{(e^x + e^{-x})(e^x + e^{-x}) - (e^x - e^{-x})(e^x - e^{-x})}{(e^x + e^{-x})^2}\n$$</p>\n</li>\n</ul>\n<ul>\n<li><p>전개 및 정리\n$$\n(e^x + e^{-x})^2 = e^{2x} + 2 + e^{-2x}\n$$\n$$\n(e^x - e^{-x})^2 = e^{2x} - 2 + e^{-2x}\n$$\n$$\n(e^x + e^{-x})^2 - (e^x - e^{-x})^2 = 4\n$$</p>\n</li>\n<li><p>최종 결과\n$$\n\\frac{d}{dx} \\tanh(x) = \\frac{1}{\\cosh^2(x)}\n$$\n또는\n$$\n\\frac{d}{dx} \\tanh(x) = 1 - \\tanh^2(x)\n$$</p>\n<h3 id=\"relu-and-leak-relu\">ReLU and Leak ReLU</h3>\n<p><img src=\"https://velog.velcdn.com/images/hojin0155/post/a21ff0ca-5de3-4c25-a91f-ccc20e6d46d1/image.png\" alt=\"\"></p>\n</li>\n<li><p>ReLU는 기울기가 0인 영역이 있지만, 실제로 z = 0인 경우는 드물고, $$g$$&#39;(0) = 0 이여도 큰 영향을 주지 않는다.</p>\n</li>\n</ul>\n<h3 id=\"graph-of-activation-functions\">Graph of Activation functions</h3>\n<p><img src=\"https://velog.velcdn.com/images/hojin0155/post/5062174e-be70-441d-a968-95907707d904/image.png\" alt=\"\"></p>\n<blockquote>\n<p>출처 및 참고 자료 </p>\n<ul>\n<li>Andrew Ng, Improving Deep Neural Network, DeepLearningAI</li>\n</ul>\n</blockquote>",
    "date": "2026-02-15T00:25:08.000Z",
    "url": "https://velog.io/@hojin0155/Andrew-Ng-4-3.Derivatives-of-Activation-Functions"
  },
  {
    "publisherId": "velog",
    "publisherName": "Velog",
    "specTitle": "개발자 블로그",
    "categories": [
      "_all_"
    ],
    "specUrl": "https://v2.velog.io/rss/",
    "title": "[MySQL] 프로그래머스 'SUM, MAX, MIN' 오답노트",
    "partialText": "<h3 id=\"프로그래머스-물고기-종류-별-대어-찾기\">[프로그래머스: 물고기 종류 별 대어 찾기]</h3>\n<pre><code class=\"language-sql\">SELECT I.ID, N.FISH_NAME, I.LENGTH\nFROM FISH_INFO I \nJOIN FISH_NAME_INFO N ON I.FISH_TYPE = N.FISH_TYPE\nWHERE (I.FISH_TYPE, I.LENGTH) IN (\n    -- [핵심] 종류별 최대 길이를 먼저 구함\n    SELECT FISH_TYPE, MAX(LENGTH)\n    FROM FISH_INFO\n    GROUP BY FISH_TYPE\n)\nORDER BY I.ID;</code></pre>\n<br/>\n<br/>\n\n<h3 id=\"프로그래머스-연도별-대장균-크기의-편차-구하기-\">[프로그래머스: 연도별 대장균 크기의 편차 구하기 ]</h3>\n<pre><code class=\"language-sql\">-- 코드를 작성해주세요\n-- 분화된 연도(YEAR), 분화된 연도별 대장균 크기의 편차(YEAR_DEV), 대장균 개체의 ID(ID) 를 출력하는 SQL 문을 작성해주세요. 분화된 연도별 대장균 크기의 편차는 분화된 연도별 가장 큰 대장균의 크기 - 각 대장균의 크기로 구하며 결과는 연도에 대해 오름차순으로 정렬하고 같은 연도에 대해서는 대장균 크기의 편차에 대해 오름차순으로 정렬해주세요.\n\nSELECT YEAR(DIFFERENTIATION_DATE) AS YEAR,\n       (MAX(SIZE_OF_COLONY) OVER (PARTITION BY YEAR(DIFFERENTIATION_DATE)) - SIZE_OF_COLONY) AS YEAR_DEV,\n       ID\nFROM ECOLI_DATA\nORDER BY YEAR, YEAR_DEV\n\n\nSELECT YEAR(A.DIFFERENTIATION_DATE) AS YEAR,\n       (\n           (SELECT MAX(SIZE_OF_COLONY) \n            FROM ECOLI_DATA B \n            WHERE YEAR(B.DIFFERENTIATION_DATE) = YEAR(A.DIFFERENTIATION_DATE) \n           ) - A.SIZE_OF_COLONY\n       ) AS YEAR_DEV,\n       A.ID\nFROM ECOLI_DATA A \nORDER BY YEAR, YEAR_DEV</code></pre>\n<ul>\n<li>MySQL 8.0(프로그래머스 환경)에서는 윈도우 함수(OVER)를 쓰는 게 훨씬 빠르고 코드도 짧다.</li>\n</ul>",
    "date": "2026-02-15T00:19:47.000Z",
    "url": "https://velog.io/@wisdxx/MySQL-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%A8%B8%EC%8A%A4-SUM-MAX-MIN-%EC%98%A4%EB%8B%B5%EB%85%B8%ED%8A%B8"
  }
]