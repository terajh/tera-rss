[
  {
    "publisherId": "levelup",
    "publisherName": "Level Up Coding",
    "specTitle": "ì½”ë”© íŠœí† ë¦¬ì–¼",
    "categories": [
      "frontend"
    ],
    "specUrl": "https://levelup.gitconnected.com/feed",
    "title": "I replaced my entire QA team with Claude and Agentic Workflow",
    "partialText": "<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://levelup.gitconnected.com/i-replaced-my-entire-qa-team-with-claude-and-agentic-workflow-aed22dfb2a65?source=rss----5517fd7b58a6---4\"><img src=\"https://cdn-images-1.medium.com/max/1200/1*yjjotfF4UGz19-TmgO-7lg.png\" width=\"1200\"></a></p><p class=\"medium-feed-snippet\">An Open-Source Experiment with Claude, Python, and Playwright</p><p class=\"medium-feed-link\"><a href=\"https://levelup.gitconnected.com/i-replaced-my-entire-qa-team-with-claude-and-agentic-workflow-aed22dfb2a65?source=rss----5517fd7b58a6---4\">Continue reading on Level Up Coding Â»</a></p></div>",
    "date": "2026-02-23T17:35:22.000Z",
    "url": "https://levelup.gitconnected.com/i-replaced-my-entire-qa-team-with-claude-and-agentic-workflow-aed22dfb2a65?source=rss----5517fd7b58a6---4"
  },
  {
    "publisherId": "levelup",
    "publisherName": "Level Up Coding",
    "specTitle": "ì½”ë”© íŠœí† ë¦¬ì–¼",
    "categories": [
      "frontend"
    ],
    "specUrl": "https://levelup.gitconnected.com/feed",
    "title": "Can AI Models Learn From Synthetic Data Without Collapsing?",
    "partialText": "<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://levelup.gitconnected.com/can-ai-models-learn-from-synthetic-data-without-collapsing-d8ab1e83e962?source=rss----5517fd7b58a6---4\"><img src=\"https://cdn-images-1.medium.com/max/2240/1*hd3u-CvmW468jScwm0tcNg.jpeg\" width=\"2240\"></a></p><p class=\"medium-feed-snippet\">Model Collapse, Data Scarcity, and the Limits of Recursive Training in Large Language Models</p><p class=\"medium-feed-link\"><a href=\"https://levelup.gitconnected.com/can-ai-models-learn-from-synthetic-data-without-collapsing-d8ab1e83e962?source=rss----5517fd7b58a6---4\">Continue reading on Level Up Coding Â»</a></p></div>",
    "date": "2026-02-23T17:35:14.000Z",
    "url": "https://levelup.gitconnected.com/can-ai-models-learn-from-synthetic-data-without-collapsing-d8ab1e83e962?source=rss----5517fd7b58a6---4"
  },
  {
    "publisherId": "levelup",
    "publisherName": "Level Up Coding",
    "specTitle": "ì½”ë”© íŠœí† ë¦¬ì–¼",
    "categories": [
      "frontend"
    ],
    "specUrl": "https://levelup.gitconnected.com/feed",
    "title": "CPU-Driven Circular Buffer",
    "partialText": "<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://levelup.gitconnected.com/cpu-driven-circular-buffer-7bc0cfe29cc3?source=rss----5517fd7b58a6---4\"><img src=\"https://cdn-images-1.medium.com/max/1198/1*PPq4h-QuebBAuSJJxLPJnQ.png\" width=\"1198\"></a></p><p class=\"medium-feed-snippet\">Did you know that you can delegate the wrap-around logic of a circular buffer to the hardware?</p><p class=\"medium-feed-link\"><a href=\"https://levelup.gitconnected.com/cpu-driven-circular-buffer-7bc0cfe29cc3?source=rss----5517fd7b58a6---4\">Continue reading on Level Up Coding Â»</a></p></div>",
    "date": "2026-02-23T17:35:05.000Z",
    "url": "https://levelup.gitconnected.com/cpu-driven-circular-buffer-7bc0cfe29cc3?source=rss----5517fd7b58a6---4"
  },
  {
    "publisherId": "levelup",
    "publisherName": "Level Up Coding",
    "specTitle": "ì½”ë”© íŠœí† ë¦¬ì–¼",
    "categories": [
      "frontend"
    ],
    "specUrl": "https://levelup.gitconnected.com/feed",
    "title": "The End of Prompt Engineering as We Know It (and the LLM Feels Fine)",
    "partialText": "<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://levelup.gitconnected.com/the-end-of-prompt-engineering-as-we-know-it-and-the-llm-feels-fine-e89d35ab996b?source=rss----5517fd7b58a6---4\"><img src=\"https://cdn-images-1.medium.com/max/2183/1*UVudmvTnz8b9swMyIaSkPQ.png\" width=\"2183\"></a></p><p class=\"medium-feed-snippet\">How a new paper suggests we&#x2019;ve been overcomplicating LLM prompting</p><p class=\"medium-feed-link\"><a href=\"https://levelup.gitconnected.com/the-end-of-prompt-engineering-as-we-know-it-and-the-llm-feels-fine-e89d35ab996b?source=rss----5517fd7b58a6---4\">Continue reading on Level Up Coding Â»</a></p></div>",
    "date": "2026-02-23T17:34:58.000Z",
    "url": "https://levelup.gitconnected.com/the-end-of-prompt-engineering-as-we-know-it-and-the-llm-feels-fine-e89d35ab996b?source=rss----5517fd7b58a6---4"
  },
  {
    "publisherId": "levelup",
    "publisherName": "Level Up Coding",
    "specTitle": "ì½”ë”© íŠœí† ë¦¬ì–¼",
    "categories": [
      "frontend"
    ],
    "specUrl": "https://levelup.gitconnected.com/feed",
    "title": "How I Cut AI Coding Costs by 80% on a Large Project",
    "partialText": "<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://levelup.gitconnected.com/how-i-cut-ai-coding-costs-by-80-on-a-large-project-8744016d13a8?source=rss----5517fd7b58a6---4\"><img src=\"https://cdn-images-1.medium.com/max/1200/1*-REYRVMyOx3uOojs0HbIiw.png\" width=\"1200\"></a></p><p class=\"medium-feed-snippet\">A detective story about $100/day in AI credits, three guilty culprits, and the investigation that solved the case</p><p class=\"medium-feed-link\"><a href=\"https://levelup.gitconnected.com/how-i-cut-ai-coding-costs-by-80-on-a-large-project-8744016d13a8?source=rss----5517fd7b58a6---4\">Continue reading on Level Up Coding Â»</a></p></div>",
    "date": "2026-02-23T17:34:39.000Z",
    "url": "https://levelup.gitconnected.com/how-i-cut-ai-coding-costs-by-80-on-a-large-project-8744016d13a8?source=rss----5517fd7b58a6---4"
  },
  {
    "publisherId": "levelup",
    "publisherName": "Level Up Coding",
    "specTitle": "ì½”ë”© íŠœí† ë¦¬ì–¼",
    "categories": [
      "frontend"
    ],
    "specUrl": "https://levelup.gitconnected.com/feed",
    "title": "Why Your C# AI Agents Will Fail in Production (And How to Fix It)",
    "partialText": "<p>The transition from a cool AI prototype running in a Jupyter Notebook to a production-grade, scalable microservice is where most projects hit a wall. You have a working model, maybe even a slick UI, but when you try to deploy it into a real cloud environment, it crashes, hangs, or costs aÂ fortune.</p><p>Why? Because standard microservice architecture treats AI agents like stateless â€œCashiers,â€ while in reality, they are stateful â€œProject Managers.â€</p><p>To build robust, enterprise-ready AI systems using C# and Kubernetes, you need to rethink your architectural foundation. Letâ€™s break down the operational shift required to containerize these complex entities effectively.</p><h3>The Stateful Nature of AIÂ Agents</h3><p>To understand the operational challenge, we must dissect the lifecycle of an AI agent. Unlike a stateless function, an agent is a persistent entity.</p><ul><li><strong>The Cashier (Traditional Microservice):</strong> Receives an order, processes it, and immediately forgets the customer. The interaction is transactional and ephemeral.</li><li><strong>The Project Manager (AI Agent):</strong> Retains context. They remember the projectâ€™s history, ongoing tasks, dependencies, and the personalities of team members. If the Project Manager goes home for the night (pod shutdown) and returns the next morning (pod restart), they must resume work without losing the thread of conversation.</li></ul><p>In C#, state is typically held in memory within object instances. However, containers are inherently ephemeral. If a Kubernetes node reboots or a pod crashes, the in-memory state of the agent is lost. Therefore, the theoretical foundation of cloud-native AI agents relies on twoÂ pillars:</p><ol><li><strong>Externalized State:</strong> Persisting the agentâ€™s â€œmemoryâ€ (conversation history, tool execution logs, and plan steps) to a durable store (e.g., Redis, PostgreSQL, or Azure Cosmos DB) rather than relying solely on List&lt;T&gt; or Dictionary&lt;TKey, TValue&gt; inÂ memory.</li><li><strong>Process Continuity:</strong> Ensuring the C# process itself can restart and hydrate its state from the external store, effectively â€œwaking upâ€ with full recollection.</li></ol><h3>The Microservices Boundary forÂ Agents</h3><p>We treat an agent not as a single object, but as a <strong>bounded context</strong>â€Šâ€”â€Ša microservice. This service encapsulates:</p><ul><li><strong>The Orchestrator:</strong> The C# logic managing the agentâ€™s decision loop (planning, reflection).</li><li><strong>The Inference Client:</strong> The interface communicating with LLMs (OpenAI, Azure OpenAI, or localÂ models).</li><li><strong>The Memory Store:</strong> The vector database interface (e.g., Pinecone, Milvus) for semanticÂ recall.</li></ul><p><strong>The Analogy:</strong> Think of a <strong>Restaurant Kitchen</strong>. The agent is the entire kitchen station, not just the chef. The station includes the prep area (memory retrieval), the stove (inference), and the plating area (response formatting). If the stove is overwhelmed (high inference load), we donâ€™t necessarily need a bigger kitchen; we need more stoves (horizontal scaling) or faster chefs (optimized models).</p><h3>Containerizing the AgentÂ Runtime</h3><p>Containerization in C# is typically handled via Docker andÂ .NETâ€™s cross-platform runtime. However, AI agents have specific runtime requirements that differ from standard webÂ APIs.</p><ol><li><strong>Dependency Management:</strong> AI agents rely heavily on external SDKs (e.g., Microsoft.SemanticKernel, OpenAI.SDK, Azure.Identity). These dependencies must be locked down in the container image to ensure reproducibility.</li><li><strong>Long-Running Processes:</strong> Standard web containers are designed to handle requests and return. Agents often run background loops (e.g., â€œReActâ€ loops: Reasoning and Acting). The container entry point (ENTRYPOINT in Docker) must execute a long-running BackgroundService inÂ C#.</li><li><strong>Resource Constraints:</strong> LLM inference is memory-hungry. A container requesting 2GiB of RAM might crash if the agent loads a large local model (like a 4-bit quantized Llama).</li></ol><p><strong>The Code Concept (Theoretical):</strong><br>In a standard web app, the Program.cs might look likeÂ this:</p><pre>var builder = WebApplication.CreateBuilder(args);<br>var app = builder.Build();<br>app.MapGet(&quot;/&quot;, () =&gt; &quot;Hello World!&quot;);<br>app.Run();</pre><p>For an AI Agent, the container entry point is a persistent service:</p><pre>using Microsoft.Extensions.Hosting;<br><br>public class AgentService : BackgroundService<br>{<br>    protected override async Task ExecuteAsync(CancellationToken stoppingToken)<br>    {<br>        while (!stoppingToken.IsCancellationRequested)<br>        {<br>            // The Agent&#39;s Reasoning Loop<br>            await Task.Delay(1000, stoppingToken);<br>        }<br>    }<br>}</pre><p>This distinction is vital: the container is not just hosting an API; it is hosting a <strong>livingÂ process</strong>.</p><h3>Orchestration: Kubernetes as the Operating System</h3><p>Once containerized, the agent needs an environment to run in. Kubernetes (K8s) acts as the operating system for these distributed agents. The theoretical challenge here is managing <strong>StatefulSets</strong> versus <strong>Deployments</strong>.</p><ul><li><strong>Deployments (Stateless):</strong> Ideal for the â€œCashierâ€ analogy. Pods are interchangeable.</li><li><strong>StatefulSets (Stateful):</strong> Required if the agent has a unique identity or requires stableÂ storage.</li></ul><p>However, most AI agents are hybrid. They are stateless in compute (the reasoning logic) but stateful in data (the memory). Therefore, we typically use <strong>Deployments</strong> for the agent pods and rely on external services (Redis, SQL) forÂ state.</p><p><strong>The Scaling Challenge:</strong><br>Scaling a standard web app is trivial: more requests = more replicas. Scaling an AI agent is complex because inference is expensive.</p><ul><li><strong>Vertical Scaling:</strong> Giving the pod more CPU/GPU (e.g., using GPU nodes inÂ K8s).</li><li><strong>Horizontal Scaling:</strong> Spinning up more agent replicas.</li></ul><p>This is where <strong>Kubernetes-native patterns</strong> come in. We use the <strong>Sidecar Pattern</strong>. The main container runs the agent logic, while a sidecar container handles telemetry, logging, or proxying requests to theÂ LLM.</p><h3>Inference Workload Management</h3><p>The heaviest load on an AI agent is the inference call to the LLM. This is the â€œstoveâ€ in our kitchen analogy. We must manage this workload carefully to avoid bottlenecks and excessive costs.</p><p><strong>The Batching Strategy:</strong><br>LLMs perform best when processing inputs in batches. A single agent might process one user query, but the underlying infrastructure should ideally batch multiple requests to the GPU to maximize throughput.<br>In C#, we can use System.Threading.Channels or TPL Dataflow to create internal buffers. Instead of sending a request to the LLM immediately, the agent queues the request. A background processor flushes the queue every 100ms or when the batch size reachesÂ 32.</p><p><strong>The Routing Strategy:</strong><br>In a multi-model environment (e.g., using GPT-4 for complex reasoning and a smaller model like GPT-3.5 for simple classification), the agent needs a routingÂ logic.</p><ul><li><strong>Concept:</strong> The <strong>StrategyÂ Pattern</strong>.</li><li><strong>Implementation:</strong> An IInferenceStrategy interface with implementations Gpt4Strategy and LocalLlamaStrategy.</li><li><strong>K8s Integration:</strong> We can deploy different model servers as separate Kubernetes services. The agent pod selects the appropriate service URL based on the complexity of theÂ task.</li></ul><h3>Event-Driven Communication</h3><p>Agents rarely exist in isolation. They collaborate. This requires communication patterns that are resilient and decoupled.</p><p><strong>Synchronous vs. Asynchronous:</strong></p><ul><li><strong>Synchronous (HTTP/gRPC):</strong> User asks Agent A. Agent A asks Agent B. Agent A waits. This creates tight coupling and potential deadlocks if Agent B isÂ slow.</li><li><strong>Asynchronous (Message Bus):</strong> User asks Agent A. Agent A publishes an event: â€œTaskAssignedâ€. Agent B subscribes, processes, and publishes â€œTaskCompletedâ€. Agent A reacts to the completion event.</li></ul><p><strong>The Why:</strong> Asynchronous patterns prevent the â€œthundering herdâ€ problem where a spike in user traffic cascades through the agent network, overwhelming the inference layer.</p><p><strong>C# and Cloud Events:</strong><br>In C#, we utilize libraries like Azure.Messaging.ServiceBus or MassTransit to abstract the message broker. The agent logic becomes event-driven:</p><pre>// Theoretical Event Handler<br>public async Task Handle(PlanStepGeneratedEvent evt)<br>{<br>    // The agent decides to use a tool<br>    var result = await _toolExecutor.Execute(evt.ToolName, evt.Arguments);<br>    // Publish result for the next step in the loop<br>    await _eventBus.PublishAsync(new ToolExecutionResultEvent(result));<br>}</pre><p>This aligns with the <strong>Actor Model</strong> concepts from previous books but scales horizontally across pods. If an agent pod crashes, the message remains in the queue (if using a durable broker like Azure Service Bus), ensuring no dataÂ loss.</p><h3>Resilience and Fault Tolerance</h3><p>AI models are non-deterministic. They can hallucinate, fail to format JSON correctly, or time out. The infrastructure must be resilient.</p><p><strong>Retry Policies:</strong><br>In C#, we use libraries like Polly to define retry strategies. However, retrying an LLM call is different from retrying a databaseÂ call.</p><ul><li><strong>Transient Errors (Network):</strong> Retry immediately.</li><li><strong>Rate Limits (HTTP 429):</strong> Retry with exponential backoff.</li><li><strong>Content Policy Violations:</strong> Do NOT retry; these are permanent failures.</li></ul><p><strong>Circuit Breakers:</strong><br>If the LLM API is down or error-prone, the agent should â€œbreak the circuitâ€ and switch to a fallback mode (e.g., a cached response or a simpler rule-based logic). This prevents the agent from flooding a failingÂ service.</p><h3>A Resilient, Message-Driven C# Implementation</h3><p>Here is a self-contained C# example demonstrating a resilient, message-driven AI Agent microservice using modernÂ .NET features.</p><pre>using System.Text.Json;<br>using System.Threading.Channels;<br>using Microsoft.Extensions.Hosting;<br>using Microsoft.Extensions.Logging;<br><br>// ==================================================================<br>// 1. Domain Models: Defines the structure of communication.<br>// ==================================================================<br>public record AgentMessage(string AgentId, string Input, DateTime Timestamp);<br>public record AgentResult(string AgentId, string Response, DateTime Timestamp);<br>// ==================================================================<br>// 2. The Agent Logic: Simulates an AI Inference Task.<br>// ==================================================================<br>public class AiInferenceEngine<br>{<br>    private readonly ILogger&lt;AiInferenceEngine&gt; _logger;<br>    public AiInferenceEngine(ILogger&lt;AiInferenceEngine&gt; logger)<br>    {<br>        _logger = logger;<br>    }<br>    // Simulates a CPU/GPU intensive inference call (e.g., LLM prompt processing)<br>    public async Task&lt;AgentResult&gt; ProcessPromptAsync(AgentMessage message, CancellationToken ct)<br>    {<br>        _logger.LogInformation(&quot;Agent {Id}: Received input &#39;{Input}&#39;&quot;, message.AgentId, message.Input);<br>        // Simulate network latency and model processing time<br>        await Task.Delay(new Random().Next(500, 1500), ct);<br>        // Simple mock logic for the &quot;AI&quot; response<br>        var response = $&quot;Processed &#39;{message.Input}&#39; -&gt; Logical Conclusion generated.&quot;;<br>        _logger.LogInformation(&quot;Agent {Id}: Inference complete.&quot;, message.AgentId);<br>        return new AgentResult(message.AgentId, response, DateTime.UtcNow);<br>    }<br>}<br>// ==================================================================<br>// 3. The Microservice Host: Orchestrates the Agent&#39;s lifecycle.<br>// ==================================================================<br>public class AgentWorkerService : BackgroundService<br>{<br>    private readonly ILogger&lt;AgentWorkerService&gt; _logger;<br>    private readonly AiInferenceEngine _engine;<br>    // Channel&lt;T&gt; provides efficient, thread-safe producer/consumer queues.<br>    // This decouples message ingestion from message processing.<br>    private readonly Channel&lt;AgentMessage&gt; _inbox;<br>    public AgentWorkerService(ILogger&lt;AgentWorkerService&gt; logger, AiInferenceEngine engine)<br>    {<br>        _logger = logger;<br>        _engine = engine;<br>        // Bounded channel prevents memory overflow if traffic spikes.<br>        // FullMode.Wait blocks the sender when capacity is reached (backpressure).<br>        _inbox = Channel.CreateBounded&lt;AgentMessage&gt;(new BoundedChannelOptions(capacity: 10)<br>        {<br>            FullMode = BoundedChannelFullMode.Wait<br>        });<br>    }<br>    // ------------------------------------------------------------------<br>    // Ingestion Point: Simulates an external event (e.g., HTTP Request or Queue Message)<br>    // ------------------------------------------------------------------<br>    public async Task EnqueueAsync(AgentMessage message)<br>    {<br>        // WriteAsync respects the cancellation token and handles backpressure automatically<br>        await _inbox.Writer.WriteAsync(message);<br>        _logger.LogDebug(&quot;Message queued for Agent {Id}&quot;, message.AgentId);<br>    }<br>    // ------------------------------------------------------------------<br>    // Processing Loop: The heart of the containerized agent<br>    // ------------------------------------------------------------------<br>    protected override async Task ExecuteAsync(CancellationToken stoppingToken)<br>    {<br>        _logger.LogInformation(&quot;Agent Worker Service started. Waiting for messages...&quot;);<br>        // We consume from the channel using &#39;await foreach&#39;<br>        // This allows the loop to pause efficiently when no messages exist.<br>        await foreach (var message in _inbox.Reader.ReadAllAsync(stoppingToken))<br>        {<br>            try<br>            {<br>                // Process the message using the injected engine<br>                var result = await _engine.ProcessPromptAsync(message, stoppingToken);<br>                // In a real scenario, this would publish to an Event Bus (e.g., RabbitMQ, Azure Service Bus)<br>                // or update a database.<br>                _logger.LogInformation(&quot;Result published: {Response}&quot;, result.Response);<br>            }<br>            catch (OperationCanceledException)<br>            {<br>                // Graceful shutdown requested<br>                _logger.LogWarning(&quot;Processing interrupted due to shutdown signal.&quot;);<br>                break;<br>            }<br>            catch (Exception ex)<br>            {<br>                // CRITICAL: Never let the worker loop die due to a single bad message.<br>                // Log the error and move on (or move to a Dead Letter Queue).<br>                _logger.LogError(ex, &quot;Error processing message from Agent {Id}&quot;, message.AgentId);<br>            }<br>        }<br>    }<br>}<br>// ==================================================================<br>// 4. Main Entry Point: Wiring up Dependency Injection and Execution<br>// ==================================================================<br>public class Program<br>{<br>    public static async Task Main(string[] args)<br>    {<br>        var host = Host.CreateDefaultBuilder(args)<br>            .ConfigureServices(services =&gt;<br>            {<br>                // Register the Engine as a Singleton (stateless logic)<br>                services.AddSingleton&lt;AiInferenceEngine&gt;();<br>                // Register the Worker as a Hosted Service (runs continuously)<br>                services.AddHostedService&lt;AgentWorkerService&gt;();<br>            })<br>            .ConfigureLogging(logging =&gt; <br>            {<br>                logging.ClearProviders();<br>                logging.AddConsole();<br>            })<br>            .Build();<br>        // Start the background service<br>        await host.StartAsync();<br>        // SIMULATION: Inject traffic into the agent to demonstrate the flow<br>        var agentService = host.Services.GetRequiredService&lt;AgentWorkerService&gt;();<br>        Console.WriteLine(&quot;--- Injecting Simulation Traffic ---&quot;);<br>        // Fire and forget 5 messages to simulate concurrent requests<br>        var tasks = new List&lt;Task&gt;();<br>        for (int i = 1; i &lt;= 5; i++)<br>        {<br>            var msg = new AgentMessage($&quot;Agent-{i}&quot;, $&quot;Query #{i}&quot;, DateTime.UtcNow);<br>            tasks.Add(agentService.EnqueueAsync(msg));<br>        }<br>        // Wait for ingestion to complete<br>        await Task.WhenAll(tasks);<br>        // Keep the app running long enough to process the queue<br>        await Task.Delay(5000); <br>        // Graceful shutdown<br>        await host.StopAsync();<br>    }<br>}</pre><h3>Key Architectural Concepts in theÂ Code</h3><ul><li><strong>Channel&lt;T&gt; for Backpressure:</strong> We use Channel.CreateBounded to set a capacity. If the agent receives 100 requests per second but can only process 5, the queue fills up. Once full, WriteAsync will pause the caller. This prevents the container from crashing due to Out-Of-Memory (OOM)Â errors.</li><li><strong>BackgroundService:</strong> This is the entry point for the container. It runs on a separate thread when the host starts, allowing the agent to process tasks continuously rather than waiting for an HTTPÂ request.</li><li><strong>await foreach:</strong> This modern C# feature allows the loop to iterate over the channel as data becomes available. If the channel is empty, the loop pauses efficiently (yielding the thread) until a messageÂ arrives.</li><li><strong>Exception Handling:</strong> The try/catch block inside the loop is vital. If one message causes a crash, the entire container restarts. By catching exceptions here, we ensure the worker stays alive to process the nextÂ message.</li></ul><h3>Common Pitfalls toÂ Avoid</h3><p><strong>1. Blocking the Ingestion Path</strong><br>A common mistake is performing heavy work directly inside the method that receives the request (e.g., the Controller action).</p><ul><li><strong>Bad:</strong> public IActionResult Post([FromBody] string input) { HeavyInference(input); return Ok();Â }</li><li><strong>Why it fails:</strong> The HTTP request holds open a connection (and potentially a thread) until the inference finishes. If you get 50 requests, you might exhaust the thread pool or connection limit, causing the app toÂ hang.</li><li><strong>Correct:</strong> Use the Channel pattern. The EnqueueAsync method returns almost instantly, while the ExecuteAsync loop handles the heavy lifting asynchronously in the background.</li></ul><p><strong>2. Unbounded Queues</strong><br>Using a standard List or Queue without size limits to buffer incoming requests.</p><ul><li><strong>The Risk:</strong> If the AI inference engine is slow (e.g., waiting for a GPU), and traffic spikes, the memory usage of that list will grow indefinitely.</li><li><strong>The Result:</strong> The container hits its memory limit (MemoryLimit in Kubernetes), gets OOMKilled (Out of Memory Killed), and restarts.</li><li><strong>The Fix:</strong> Always use Channel.CreateBounded to define a hard limit. When the limit is reached, apply backpressure (slow down the clients) rather than crashing.</li></ul><h3>Summary</h3><p>By containerizing AI agents in C#, we gain portability and isolation. By orchestrating them in Kubernetes, we gain scalability and resilience. However, the â€œmagicâ€ lies in the internal architecture of the C#Â code:</p><ol><li><strong>Interfaces over Implementations:</strong> Using IChatClient or IMemoryStore allows us to swap infrastructure without changing the agent&#39;s coreÂ logic.</li><li><strong>Asynchronous Streams:</strong> Using IAsyncEnumerable&lt;T&gt; allows the agent to stream responses from the LLM to the user in real-time, rather than waiting for the full generation, improving the perceived latency.</li><li><strong>Dependency Injection:</strong>Â .NETâ€™s DI container is used to wire up the complex dependencies (Strategies, Buffers, Policies) at startup, ensuring the agent pod initializes correctly every time it scalesÂ up.</li></ol><p>This theoretical foundation moves the AI agent from a prototype running in a Jupyter Notebook to a production-grade, scalable microservice capable of handling enterprise workloads.</p><h3>Letâ€™s Discuss</h3><ol><li>In your experience, is the â€œActor Modelâ€ (like Orleans) overkill for AI agents, or is it the perfect fit for managing their statefulÂ nature?</li><li>How do you currently handle the â€œThundering Herdâ€ problem when your AI agents trigger expensive API calls? Do you rely on Kubernetes scaling or application-level buffering (like the Channel pattern shownÂ above)?</li></ol><p>The concepts and code demonstrated here are drawn directly from the comprehensive roadmap laid out in the ebook<br><strong>Cloud-Native AI &amp; Microservices. Containerizing Agents and Scaling Inference</strong>.<br><a href=\"http://youtube.com/@csharpmasterclass\">Free lessons on Youtube</a>.<br>You can find it here: <a href=\"https://leanpub.com/CloudNativeAICSharp\">Leanpub.com</a>.<br>Check all the other programming ebooks on python, typescript, c#: <a href=\"https://leanpub.com/u/edgarmilvus\">Leanpub.com</a>.<br>If you prefer you can find almost all of them onÂ <a href=\"https://www.amazon.com/stores/Edgar-Milvus/author/B0G2BS9V5N\">Amazon</a>.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*pHjrMooIIEWeA-1xmaU4fA.jpeg\" /></figure><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=a67dfe0c6341\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://levelup.gitconnected.com/why-your-c-ai-agents-will-fail-in-production-and-how-to-fix-it-a67dfe0c6341\">Why Your C# AI Agents Will Fail in Production (And How to Fix It)</a> was originally published in <a href=\"https://levelup.gitconnected.com\">Level Up Coding</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2026-02-23T17:34:31.000Z",
    "url": "https://levelup.gitconnected.com/why-your-c-ai-agents-will-fail-in-production-and-how-to-fix-it-a67dfe0c6341?source=rss----5517fd7b58a6---4"
  },
  {
    "publisherId": "levelup",
    "publisherName": "Level Up Coding",
    "specTitle": "ì½”ë”© íŠœí† ë¦¬ì–¼",
    "categories": [
      "frontend"
    ],
    "specUrl": "https://levelup.gitconnected.com/feed",
    "title": "10 Tcl Commands Only a Few Bash Programmers Know",
    "partialText": "<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://levelup.gitconnected.com/10-tcl-commands-for-productive-bashless-shell-scripting-1a10c09c21cc?source=rss----5517fd7b58a6---4\"><img src=\"https://cdn-images-1.medium.com/max/1600/1*T5ExJfbVNLD5DxNdQEIxng.png\" width=\"1600\"></a></p><p class=\"medium-feed-snippet\">Never deal with confusing Bash syntax or external commands by practicing these Tcl commands</p><p class=\"medium-feed-link\"><a href=\"https://levelup.gitconnected.com/10-tcl-commands-for-productive-bashless-shell-scripting-1a10c09c21cc?source=rss----5517fd7b58a6---4\">Continue reading on Level Up Coding Â»</a></p></div>",
    "date": "2026-02-23T17:34:23.000Z",
    "url": "https://levelup.gitconnected.com/10-tcl-commands-for-productive-bashless-shell-scripting-1a10c09c21cc?source=rss----5517fd7b58a6---4"
  },
  {
    "publisherId": "levelup",
    "publisherName": "Level Up Coding",
    "specTitle": "ì½”ë”© íŠœí† ë¦¬ì–¼",
    "categories": [
      "frontend"
    ],
    "specUrl": "https://levelup.gitconnected.com/feed",
    "title": "The Curse of Dimensionality: A Geometric Horror Story",
    "partialText": "<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://levelup.gitconnected.com/the-curse-of-dimensionality-a-geometric-horror-story-abe1a6bf0a75?source=rss----5517fd7b58a6---4\"><img src=\"https://cdn-images-1.medium.com/max/822/1*fJHrCnQdTIh0mHzskUAS-w.png\" width=\"822\"></a></p><p class=\"medium-feed-snippet\">You think 100 dimensions is &#x201C;10 times more complex&#x201D; than 10. You&#x2019;re wrong. It&#x2019;s a universe more vast and almost completely empty.</p><p class=\"medium-feed-link\"><a href=\"https://levelup.gitconnected.com/the-curse-of-dimensionality-a-geometric-horror-story-abe1a6bf0a75?source=rss----5517fd7b58a6---4\">Continue reading on Level Up Coding Â»</a></p></div>",
    "date": "2026-02-23T17:34:16.000Z",
    "url": "https://levelup.gitconnected.com/the-curse-of-dimensionality-a-geometric-horror-story-abe1a6bf0a75?source=rss----5517fd7b58a6---4"
  },
  {
    "publisherId": "levelup",
    "publisherName": "Level Up Coding",
    "specTitle": "ì½”ë”© íŠœí† ë¦¬ì–¼",
    "categories": [
      "frontend"
    ],
    "specUrl": "https://levelup.gitconnected.com/feed",
    "title": "Building a Ray Tracer from Scratch in C++ Part 1: Mathematical Foundations",
    "partialText": "<p>Graphics APIs and game engines make rendering look easy, but they hide most of the interesting details. I wanted to understand what actually happens under the hood, so I decided to build a small 3D renderer from scratch usingÂ C++.</p><p>By the end of this article, youâ€™ll understand the core ideas behind ray tracing and be able to build a simple renderer yourself.</p><p>Weâ€™ll finish by rendering the image shown below, without using any graphics libraries or engines but with C++ andÂ Maths.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/800/1*uC-DlpR4SdBkzSbZsfIQ8A.gif\" /></figure><h3>Why RayÂ tracing</h3><p>In computer graphics, there are two main rendering techniques: <strong>rasterization</strong> and <strong>rayÂ tracing</strong>.</p><p>You might ask, what exactly is rendering? In simple terms, rendering is the process of generating a 2D image or video from a 3D model or scene. Itâ€™s considered the final stage of a 3DÂ engine.</p><p>While rasterization is fast and used in real-time applications like games, ray tracing simulates how light behaves in the real world to produce highly realistic images, shadows, and reflections. It traces the path of light rays as they interact with objects in a 3D scene, calculating reflections, refractions, and accurate lightingÂ effects.</p><p>Ray tracing involves some basic mathematics. Oops, I just mentioned our worst nightmare ğŸ˜Ÿ Donâ€™t worry though, itâ€™s not as scary as it sounds. Iâ€™ve got you. So without any further ado, letâ€™s getÂ started.</p><blockquote>One drawback of ray tracing is performance. However, there are optimization techniques we can use to improve speed, which weâ€™ll touch on otherÂ part.</blockquote><p>The below image is generated using ray tracing algorithm</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*kA2OIotuYbnCAGmOqz7VjA.png\" /><figcaption>Ray traced image (source: Wikipedia)</figcaption></figure><h3>How Ray TracingÂ Works</h3><p>Ray tracing simulates how light travels. <strong>Rays</strong> are cast from a single point in 3D space which is the camera into the scene through an imaginary <strong>viewport</strong>. Each ray corresponds to a pixel on the screen. When a ray intersects an object (like a sphere or triangle), we compute the closest intersection point to determine the final color of thatÂ pixel.</p><p>This process is repeated for every pixel, creating a complete, realistic image.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*bWC45w0nku7UpOs_4UbDiQ.png\" /></figure><p>we have prepared a pipeline to render a simple shape, we will improve it as we go deeper in theÂ subject.</p><ol><li>Camera â†’Â rays</li><li>Ray â†’ Object intersection</li><li>Drawing a pixel on theÂ screen</li></ol><h3>Letâ€™s shoot some rays from theÂ camera</h3><p>A <strong>ray</strong> is similar to a line but with an important difference a line extends infinitely in both directions, while a ray starts at a specific point and extends infinitely in one direction.</p><p>Mathematically, a ray can be represented using a <strong>parametric equation</strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/131/1*sgs8pwAmV36Qp6WEWE7GAg.png\" /></figure><p><strong>Where:</strong></p><ul><li><strong><em>P</em></strong> is any point along theÂ ray</li><li><strong><em>O</em></strong> is the rayâ€™s origin (starting point)</li><li><strong><em>d</em></strong> is the direction vector</li><li><strong><em>t</em></strong> is a scalar parameter</li></ul><p>If t = 0, then P = O.<br>If t = 1, then P = O +Â d.</p><p>Increasing t moves the point along the ray indefinitely.</p><p>letâ€™s say we have two points in a space â€œpoint Aâ€ and â€œpoint Bâ€, letâ€™s use 2D for now to better understand the aboveÂ formula.</p><p>A = (0, 0) and B = (4,Â 4)</p><blockquote>I will use a platform called <strong>desmos </strong>for plotting points, you can search itÂ online</blockquote><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1019/1*coq44LwtcEqTU9cvt-WH-A.png\" /><figcaption>Two points in 2DÂ space</figcaption></figure><p>As we can see in the graph, we have two points, and we want to draw a line segment or a ray between them. A line is defined as an infinite set of points, so how can we represent the line that goes through points A and B? We use the parametric equation of a line. Before writing that equation, however, we need to determine the direction in which the line or ray is pointing. We can find this direction by subtracting point A from point B. The result is a vector, and this vector becomes the direction vector <strong>d</strong> in the parametric equation</p><p>Example:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/263/1*eCvMyjUmZpNRcSsIz5vgUg.png\" /></figure><p>now we have the direction, if you look closely the vector <strong>d</strong> is the same as the point B, this is when the origin starts from 0, but if it was another point in the space it would be different.</p><p>letâ€™s plug the direction in the equation and draw our line, but there is one missing piece, the â€œ<strong>tâ€</strong> right? donâ€™t worry we donâ€™t have to do anything for â€˜tâ€™ it has to start from 0.0 and increase it infinitly</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/156/1*JFB1J-vaosDe3KYbekW6Nw.png\" /></figure><p>we repeat this process and increase the value of â€œtâ€ until we reach B orÂ exceed.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/792/1*fuaTCE-oHMSrzb998gB6MQ.png\" /><figcaption>Line from A toÂ B</figcaption></figure><p>as you can see here by using the equation we draw a line from A to B, here you can see that when â€œ<em>t</em>â€ starts from 0 and reaches 1 it ends at B, this is called a line segment, but we need a ray, and to do that its very simple we set â€œtâ€ to infinity or a large number would work, now we have a ray and next image showsÂ that.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1017/1*sAISfD-O75gbtZ11mKFfJg.png\" /></figure><p>here we can see that the line exceeded the point B or the direction, now this is what we call a ray, but we donâ€™t want to shoot a single ray, we will need to cast/shoot many rays, right? so to do that we need what we call a viewport, letâ€™s go right intoÂ it.</p><h3>What is Viewport??</h3><p>A viewport is a 2D rectangular virtual window that represents the final image plane through which the camera â€œseesâ€ the 3D scene. It acts as a canvas or image plane and is usually divided into pixels. Rays are traced from the camera through each pixel on the viewport to determine the final color of theÂ scene.</p><p>A viewport is defined by its center point, width and height (aspect ratio), and its distance from the camera. This distance determines the field of view (FOV). If itâ€™s hard to visualize, you can think of the viewport as a plane placed between the camera and the 3DÂ scene.</p><p>Earlier, we drew a line from point A to point B and extended it beyond B. In that example, you can think of point B as representing the viewport or image plane. Of course, a viewport is not a single point, but a rectangular area with width and height. This simplification just helps with visualization.</p><p>The viewportâ€™s main purpose is to act as a bridge between 3D scene space and 2D image pixels. Rays are cast from the camera through the pixels on this plane to find intersections with 3D objects located beyondÂ it.</p><p>To help you illustrate it take a look at the below image. Letâ€™s â€œpoint Aâ€ be the camera and all â€œPoint Bsâ€ the viewport, beyond it, is the 3DÂ scene.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*cLknuI9-kxUqoFqBkItJiw.png\" /><figcaption>Ray casted from A along the direction of B and intersecting with 3DÂ objects</figcaption></figure><p>As shown in the image above, multiple rays are cast from the camera, or point A, through the viewport in the direction of point B. These rays travel into the 3D scene and intersect with objects along theirÂ paths.</p><p>For each ray, we check whether it intersects any object in the scene. If an intersection occurs, we compute the exact intersection point and use it to determine the final color of thatÂ pixel.</p><p>In our case, we will start with spheres, since they are the simplest geometric primitives to workÂ with.</p><h3>Sphere Equation and Ray Intersection</h3><p>A sphere can be thought of as a circle extended into 3D space. To simplify the explanation, weâ€™ll first work in 2D using a circle, then extend the same idea to a sphere when we move to implementation. A circle or sphere is defined by two things, itâ€™s center andÂ radius.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/119/1*RsvVJ_HuFeIrcFpCiB915w.png\" /><figcaption>if the center is at theÂ origin</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/260/1*SfmZpQ9gSYZqlzXjjUmFNA.png\" /><figcaption>when changing the origin of the circle orÂ sphere</figcaption></figure><p><strong>where</strong></p><ul><li><em>x</em> and <em>y</em> are the point on theÂ surface</li><li><em>r</em> is the distance from the center of the circle to itsÂ surface</li><li><em>Cx</em> is the <em>x</em> component center of theÂ circle</li><li><em>Cy</em> is the <em>y</em> component center of theÂ circle</li></ul><p>This equation represents a circle. It means that any point (x,y)(x, y)(x,y) whose distance from the center equals the radius <em>r</em> lies on the surface of theÂ circle.</p><p>To make this easier to work with, letâ€™s simplify the equation.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/313/1*fefmmsm7UzEPXweB5KLsNg.png\" /></figure><p>Or</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/122/1*GZ5NveqPICRZ-3ZJ1HH9qQ.png\" /></figure><p>We can interpret this equation as the length of the vector <strong>D</strong> from point <strong>P</strong> to point <strong>C</strong>, where <strong>P</strong> lies on the surface of the circle and <strong>C</strong> is the center of the circle. Subtracting these two points gives us the vector <strong>D</strong>, and the magnitude of this vector is equal to the radius of theÂ circle.</p><p>Going a step further, this expression can also be written as the dot product of vector <strong>D</strong> with itself, which givesÂ us</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/88/1*K5GQXKU2NbMb04V8OQwJsw.png\" /></figure><p>Now letâ€™s expand the dotÂ product.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/168/1*tjNp26zjd415CuwaaQdKMg.png\" /><figcaption>this is the expanded dotÂ product</figcaption></figure><p>This can be simplified asÂ well.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/71/1*PMsEnwGwhEUp7go_8qlM2g.png\" /></figure><p>Do you notice something? Itâ€™s similar to the equation of a circle, right? Exactly! That means the dot product of vector â€˜Dâ€™ behaves just like a circle equation. Now we have a simplified equation thatâ€™s much easier to workÂ with.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/211/1*amFuTThwvUrg73TnQhKMgw.png\" /></figure><p>You might be wondering why we needed to simplify this equation. Well, itâ€™s so we can more easily integrate it with the ray equation. In the simplified version, we have â€˜Pâ€™, which represents a point on the surface of the circle. So, if we can find a â€˜Pâ€™ that satisfies this equation, that means weâ€™ve found the circle, right? But how do we actually find â€˜Pâ€™? If you rememberâ€¦</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/131/1*zWSfwGPClG6nh10JAHI38g.png\" /></figure><p>This was our ray equation, right? Do you see something here? Yes, we can use the ray equation to find the point â€˜Pâ€™ that satisfies this condition. That means the circle equation nowÂ becomesâ€¦</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/315/1*c2SwdtIR4aJo0_ZWbZi5aw.png\" /></figure><p>As you can see, weâ€™ve combined the ray equation with the sphere equation. You might be wondering why we need to mix these two. The reason is simple, we want to find the intersection between the ray we cast and the sphere. I hope youâ€™re following so far, so the next step is to simplify the combined equation.</p><p>if we separate â€œ<em>td</em>â€ weÂ get</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/384/1*Eoqj87-3QG05y0R3bk9agw.png\" /></figure><p>Now letâ€™s expand the dot product. WeÂ get</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/466/1*18t5lk051-zJhuqBoL9W3Q.png\" /></figure><p>Letâ€™s subtract rÂ² from both sides. WeÂ get</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/504/1*gYx0ZKuaQDPcjLcz3NE11A.png\" /></figure><p>Now, if we take a closer look, the vectors and the radius are known because the radius â€˜râ€™ is constant and the vectors are reduced to scalar values through their dot products. The only unknowns are â€˜tâ€™ and â€˜tÂ²â€™, which means this equation is quadratic. This also means we can solve it using the quadratic formula for equations of the form axÂ² + bx + c =Â 0.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/204/1*kyrFGFV_sTiZ6nvWSc2VYQ.png\" /></figure><p>Now, letâ€™s match our final ray-sphere equation to the familiar quadratic equation.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/258/1*QQvLXMjBJXhD8Q2g9A0S8Q.png\" /></figure><p>Using the quadratic formula, we can solve for <em>t</em>. The square root term, known as the discriminant, can be positive, negative, or zero. A positive discriminant means there are two solutions, zero means there is exactly one solution, and a negative value means there is no solution at all. This discriminant tells us whether the ray intersects the sphere, but not where the intersection occurs, since it only indicates the existence of a solution. At this stage, we can already render a basic sphere on the screen. However, to fully utilize the equation, we compute the actual value of <em>t</em>. Once <em>t</em> is known, we substitute it back into the ray equation to obtain the exact intersection point along theÂ ray.</p><p>In the next part we will focus on writing code and render our first 3DÂ object.</p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=8d778512120c\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://levelup.gitconnected.com/building-a-ray-tracer-from-scratch-in-c-part-1-mathematical-foundations-8d778512120c\">Building a Ray Tracer from Scratch in C++ Part 1: Mathematical Foundations</a> was originally published in <a href=\"https://levelup.gitconnected.com\">Level Up Coding</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2026-02-23T17:34:08.000Z",
    "url": "https://levelup.gitconnected.com/building-a-ray-tracer-from-scratch-in-c-part-1-mathematical-foundations-8d778512120c?source=rss----5517fd7b58a6---4"
  },
  {
    "publisherId": "levelup",
    "publisherName": "Level Up Coding",
    "specTitle": "ì½”ë”© íŠœí† ë¦¬ì–¼",
    "categories": [
      "frontend"
    ],
    "specUrl": "https://levelup.gitconnected.com/feed",
    "title": "Are We Ready for the â€œCountry of Geniusesâ€?- Anthropic CEOâ€™s Vision of the AI Future",
    "partialText": "<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://levelup.gitconnected.com/are-we-ready-for-the-country-of-geniuses-anthropic-ceos-vision-of-the-ai-future-d574f19c409e?source=rss----5517fd7b58a6---4\"><img src=\"https://cdn-images-1.medium.com/max/2600/0*FquvphNxpwLPQr17\" width=\"4843\"></a></p><p class=\"medium-feed-snippet\">Dario Amodei, Anthropic CEO, published a blueprint for humanity&#x2019;s survival in 2026. It should be a required reading for every technologist&#x2026;</p><p class=\"medium-feed-link\"><a href=\"https://levelup.gitconnected.com/are-we-ready-for-the-country-of-geniuses-anthropic-ceos-vision-of-the-ai-future-d574f19c409e?source=rss----5517fd7b58a6---4\">Continue reading on Level Up Coding Â»</a></p></div>",
    "date": "2026-02-23T17:33:58.000Z",
    "url": "https://levelup.gitconnected.com/are-we-ready-for-the-country-of-geniuses-anthropic-ceos-vision-of-the-ai-future-d574f19c409e?source=rss----5517fd7b58a6---4"
  }
]