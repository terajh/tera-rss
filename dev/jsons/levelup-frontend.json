[
  {
    "publisherId": "levelup",
    "publisherName": "Level Up Coding",
    "specTitle": "코딩 튜토리얼",
    "categories": [
      "frontend"
    ],
    "specUrl": "https://levelup.gitconnected.com/feed",
    "title": "Your ML Evaluation Pipeline Has a Scoring Bug (You Just Haven’t Found It Yet)",
    "partialText": "<div class=\"medium-feed-item\"><p class=\"medium-feed-snippet\">I&#x2019;ve been running calibration experiments on language models using Apple&#x2019;s MLX framework. Six models in total: Mistral 7B, Llama 3.1 8B&#x2026;</p><p class=\"medium-feed-link\"><a href=\"https://levelup.gitconnected.com/your-ml-evaluation-pipeline-has-a-scoring-bug-you-just-havent-found-it-yet-19a3b9357ddf?source=rss----5517fd7b58a6---4\">Continue reading on Level Up Coding »</a></p></div>",
    "date": "2026-02-27T15:35:37.000Z",
    "url": "https://levelup.gitconnected.com/your-ml-evaluation-pipeline-has-a-scoring-bug-you-just-havent-found-it-yet-19a3b9357ddf?source=rss----5517fd7b58a6---4"
  },
  {
    "publisherId": "levelup",
    "publisherName": "Level Up Coding",
    "specTitle": "코딩 튜토리얼",
    "categories": [
      "frontend"
    ],
    "specUrl": "https://levelup.gitconnected.com/feed",
    "title": "The Anatomy of an AI Agent: Planning, Memory, and Tool Use",
    "partialText": "<p><em>Understanding the core components that transform large language models into autonomous agents</em></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*YHNzQne0k81VqFHKyQ-4CQ.png\" /></figure><p><em>Part 2 of my series on Agentic AI. Last time, we explored </em><a href=\"https://medium.com/gitconnected/from-chatbots-to-co-workers-understanding-the-agentic-ai-revolution-03f59ae90227\"><em>the shift from chatbots to co-worker</em></a><em>s — how AI evolved from reactive assistants to autonomous agents. This time: the three core capabilities that make agents work: planning, memory, and tool use. Follow along for more deep dives into building AI systems that act autonomously.</em></p><p>Picture a software developer debugging a production outage at 3 AM. They don’t just stare at error logs — they form hypotheses, check multiple systems, remember similar incidents from months ago, run diagnostic commands, and iterate through solutions until the problem is fixed. This cycle of perceiving, reasoning, planning, and acting is what separates problem-solving from pattern-matching.</p><p>Now imagine an AI system that operates the same way. Not just answering questions when prompted, but autonomously pursuing goals through multi-step workflows. Breaking down complex objectives into subtasks. Remembering what worked last time. Orchestrating dozens of tools to accomplish what it sets out to do. This is agentic AI — and it’s fundamentally different from the conversational AI most people know.</p><p>As the agentic AI market explodes from $5.25 billion in 2024 to a projected $199 billion by 2034, understanding what makes these systems tick has never been more important. What transforms a language model from an impressive conversationalist into an autonomous agent? The answer lies in three core capabilities: planning, memory, and tool use.</p><p>Let’s dissect the anatomy of an AI agent and explore the three core capabilities that separate autonomous agents from their conversational cousins: planning, memory, and tool use.</p><h3>The Agent Loop: Perception, Reasoning, Planning, Action</h3><p>At its heart, every AI agent operates on a continuous cycle that mirrors how humans approach complex tasks:</p><p><strong>1. Perception</strong>: The agent observes its environment — reading user input, checking system state, or monitoring data streams.</p><p><strong>2. Reasoning</strong>: It interprets what it perceives, understanding context and identifying what matters.</p><p><strong>3. Planning</strong>: Based on its understanding, the agent formulates a strategy to achieve its goal.</p><p><strong>4. Action</strong>: It executes the plan, using available tools and capabilities.</p><p><strong>5. Observation</strong>: It evaluates the results and loops back to perception.</p><p>This cycle repeats until the agent achieves its objective or determines it cannot proceed. Unlike a simple chatbot that executes once per prompt, an agent can iterate through this loop dozens or hundreds of times to accomplish a single high-level goal.</p><p>Consider a research agent tasked with “Analyze the competitive landscape for electric vehicle batteries.” A chatbot might generate a single response based on its training data. An agent, however, would:</p><ul><li><strong>Perceive</strong>: Understand the request requires current market data</li><li><strong>Reason</strong>: Identify that it needs to search for recent reports, patents, and company announcements</li><li><strong>Plan</strong>: Create a multi-step research strategy (search for key players, gather financial data, analyze patents, synthesize findings)</li><li><strong>Act</strong>: Execute web searches, scrape relevant pages, extract data</li><li><strong>Observe</strong>: Evaluate if the gathered information is sufficient or if more research is needed</li></ul><p>This loop continues until the agent has compiled a comprehensive analysis.</p><h3>Planning: From Goals to Actionable Steps</h3><p>Planning is what transforms a language model from a sophisticated autocomplete into an autonomous problem-solver. Modern agents employ several planning strategies:</p><h3>Decomposition Planning</h3><p>The agent breaks down complex goals into manageable subtasks. This is similar to how a project manager creates a work breakdown structure.</p><pre>Goal: &quot;Book a vacation to Japan&quot;<br>↓<br>Subtasks:<br>1. Research destinations in Japan<br>2. Check flight availability and prices<br>3. Find accommodation options<br>4. Create itinerary<br>5. Make reservations<br>6. Arrange travel insurance</pre><p>Each subtask can be further decomposed until the agent reaches atomic actions it can execute directly.</p><h3>Reactive Planning</h3><p>Rather than planning everything upfront, the agent makes decisions based on the current state and adjusts as it goes. This approach is more flexible when dealing with uncertainty.</p><p>For example, a customer service agent might:</p><ol><li>Classify the customer’s issue</li><li>Based on classification, decide next action (search knowledge base, check order status, escalate to human)</li><li>Execute action and observe result</li><li>Adjust approach based on what it learns</li></ol><h3>Hierarchical Planning</h3><p>Sophisticated agents combine both approaches — creating high-level plans while remaining reactive at the execution level. This mirrors how humans work: we have a general strategy but adapt tactics as we encounter obstacles.</p><h3>Chain-of-Thought and Tree-of-Thought</h3><p>Modern agents leverage reasoning techniques that make their planning process more robust:</p><ul><li><strong>Chain-of-Thought</strong>: The agent explicitly reasons through problems step-by-step, improving accuracy on complex tasks</li><li><strong>Tree-of-Thought</strong>: The agent explores multiple reasoning paths simultaneously, evaluating different approaches before committing to one</li></ul><p>These techniques dramatically improve agent performance on tasks requiring multi-step reasoning.</p><h3>Memory: The Foundation of Context and Learning</h3><p>If planning is the agent’s executive function, memory is its knowledge base. Without memory, an agent is perpetually starting from scratch — unable to learn from experience or maintain context across interactions.</p><h3>Short-Term Memory: Working Context</h3><p>Short-term memory is what the agent actively holds in its “mind” during a task. In practice, this is the context window of the underlying language model — typically ranging from 4,000 to 200,000 tokens depending on the model.</p><p>This memory includes:</p><ul><li>The current conversation or task context</li><li>Recent observations and actions</li><li>Intermediate results and reasoning steps</li></ul><p>The challenge: context windows are finite. As tasks grow complex, agents must decide what to keep in active memory and what to offload.</p><h3>Long-Term Memory: Persistent Knowledge</h3><p>Long-term memory allows agents to remember across sessions and learn from past experiences. This is typically implemented using external storage systems:</p><p><strong>Episodic Memory</strong>: Records of past interactions and experiences</p><ul><li>“Last time this user asked about pricing, they were interested in the enterprise tier”</li><li>“When I tried approach A for this type of problem, it failed; approach B worked better”</li></ul><p><strong>Semantic Memory</strong>: Factual knowledge and learned concepts</p><ul><li>Domain-specific information</li><li>User preferences and profile data</li><li>Organizational knowledge and procedures</li></ul><p><strong>Procedural Memory</strong>: Learned skills and strategies</p><ul><li>Successful problem-solving patterns</li><li>Optimized tool usage sequences</li><li>Refined decision-making heuristics</li></ul><h3>Memory Architecture Patterns</h3><p>Modern agent systems employ sophisticated memory architectures:</p><p><strong>Vector Databases</strong>: Store memories as embeddings, enabling semantic search</p><ul><li>When facing a new problem, the agent retrieves similar past experiences</li><li>Memories are ranked by relevance, not just recency</li></ul><p><strong>Memory Consolidation</strong>: Like human memory, agent memories can be processed and refined</p><ul><li>Frequent patterns become generalized knowledge</li><li>Redundant memories are merged</li><li>Less relevant memories fade (controlled forgetting)</li></ul><p><strong>Hierarchical Memory</strong>: Different memory systems for different timescales</p><ul><li>Immediate: Current task context (seconds to minutes)</li><li>Session: Current conversation or workflow (minutes to hours)</li><li>Long-term: Cross-session knowledge (days to months)</li><li>Permanent: Core knowledge and capabilities (persistent)</li></ul><p>Consider a DevOps agent managing infrastructure. Its memory systems might include:</p><ul><li><strong>Short-term</strong>: Current deployment status, active alerts, recent log entries</li><li><strong>Episodic</strong>: History of past incidents and how they were resolved</li><li><strong>Semantic</strong>: Infrastructure topology, service dependencies, runbook procedures</li><li><strong>Procedural</strong>: Learned patterns for diagnosing common issues</li></ul><h3>Tool Use: Extending Agent Capabilities</h3><p>Language models are powerful reasoning engines, but they’re limited to generating text. Tools transform agents from thinkers into doers — enabling them to interact with the world.</p><h3>The Tool Abstraction</h3><p>From an agent’s perspective, a tool is any capability it can invoke to perform an action or gather information. Tools are typically defined with:</p><p><strong>Name</strong>: Identifier for the tool (e.g., “web_search”, “send_email”, “query_database”)</p><p><strong>Description</strong>: What the tool does and when to use it</p><p><strong>Parameters</strong>: Required and optional inputs with types and constraints</p><p><strong>Return Schema</strong>: What the tool returns after execution</p><p>Example tool definition:</p><pre>{<br>  &quot;name&quot;: &quot;web_search&quot;,<br>  &quot;description&quot;: &quot;Search the web for current information on a topic&quot;,<br>  &quot;parameters&quot;: {<br>    &quot;query&quot;: {<br>      &quot;type&quot;: &quot;string&quot;,<br>      &quot;description&quot;: &quot;Search query&quot;,<br>      &quot;required&quot;: true<br>    },<br>    &quot;num_results&quot;: {<br>      &quot;type&quot;: &quot;integer&quot;,<br>      &quot;description&quot;: &quot;Number of results to return&quot;,<br>      &quot;default&quot;: 5<br>    }<br>  },<br>  &quot;returns&quot;: {<br>    &quot;type&quot;: &quot;array&quot;,<br>    &quot;items&quot;: {<br>      &quot;title&quot;: &quot;string&quot;,<br>      &quot;url&quot;: &quot;string&quot;,<br>      &quot;snippet&quot;: &quot;string&quot;<br>    }<br>  }<br>}</pre><h3>Tool Selection and Orchestration</h3><p>The agent must decide which tools to use and in what sequence. This involves:</p><p><strong>Tool Discovery</strong>: Understanding what tools are available</p><ul><li>Agents are typically provided a tool catalog at initialization</li><li>Some advanced systems allow agents to discover tools dynamically</li></ul><p><strong>Tool Selection</strong>: Choosing the right tool for the task</p><ul><li>Based on the current goal and context</li><li>Considering tool capabilities and constraints</li><li>Evaluating cost and latency tradeoffs</li></ul><p><strong>Parameter Generation</strong>: Constructing valid tool calls</p><ul><li>Extracting required information from context</li><li>Formatting parameters correctly</li><li>Handling optional parameters intelligently</li></ul><p><strong>Error Handling</strong>: Dealing with tool failures</p><ul><li>Retrying with adjusted parameters</li><li>Falling back to alternative tools</li><li>Escalating to human intervention when necessary</li></ul><h3>Common Tool Categories</h3><p><strong>Information Retrieval</strong>:</p><ul><li>Web search engines</li><li>Database queries</li><li>API calls to external services</li><li>Document retrieval systems</li></ul><p><strong>Communication</strong>:</p><ul><li>Email and messaging</li><li>Notifications and alerts</li><li>Report generation</li></ul><p><strong>Data Processing</strong>:</p><ul><li>File operations (read, write, transform)</li><li>Data analysis and computation</li><li>Format conversion</li></ul><p><strong>External Actions</strong>:</p><ul><li>Creating tickets or work items</li><li>Triggering workflows</li><li>Controlling physical systems (IoT, robotics)</li></ul><p><strong>Meta-Tools</strong>:</p><ul><li>Code execution environments</li><li>Other AI models (vision, speech, specialized reasoning)</li><li>Human-in-the-loop interfaces</li></ul><h3>Tool Composition: Chaining and Parallelization</h3><p>Sophisticated agents don’t just use tools in isolation — they compose them into workflows:</p><p><strong>Sequential Chaining</strong>: Output of one tool feeds into another</p><pre>web_search(&quot;AI agent frameworks&quot;) <br>  → extract_urls(results) <br>  → fetch_content(urls) <br>  → summarize(content)</pre><p><strong>Parallel Execution</strong>: Multiple tools run simultaneously</p><pre>Parallel:<br>  - web_search(&quot;company financials&quot;)<br>  - web_search(&quot;company news&quot;)<br>  - web_search(&quot;competitor analysis&quot;)<br>→ synthesize(all_results)</pre><p><strong>Conditional Branching</strong>: Tool selection based on results</p><pre>classify_email(email)<br>  → if &quot;complaint&quot;: escalate_to_human()<br>  → if &quot;question&quot;: search_knowledge_base()<br>  → if &quot;feedback&quot;: log_to_database()</pre><h3>Putting It All Together: A Real-World Example</h3><p>Let’s see how planning, memory, and tool use work together in a practical scenario. Imagine a financial analysis agent tasked with: “Evaluate whether we should invest in Company X.”</p><h3>Planning Phase</h3><p>The agent decomposes this into subtasks:</p><ol><li>Gather financial data (revenue, profit, growth)</li><li>Analyze market position and competitors</li><li>Assess risks and opportunities</li><li>Compare to investment criteria</li><li>Generate recommendation with supporting evidence</li></ol><h3>Memory in Action</h3><p><strong>Short-term memory</strong> holds:</p><ul><li>The current subtask being executed</li><li>Recently gathered data points</li><li>Intermediate analysis results</li></ul><p><strong>Long-term memory</strong> provides:</p><ul><li>Investment criteria and thresholds from past decisions</li><li>Similar companies analyzed previously</li><li>Successful and unsuccessful investment patterns</li><li>User’s risk tolerance and preferences</li></ul><h3>Tool Orchestration</h3><p>The agent executes its plan using multiple tools:</p><pre>1. web_search(&quot;Company X financial results 2024&quot;)<br>2. extract_financial_data(search_results)<br>3. query_database(&quot;SELECT * FROM competitors WHERE sector = &#39;X&#39;&quot;)<br>4. calculate_financial_ratios(company_data, competitor_data)<br>5. web_search(&quot;Company X risks challenges&quot;)<br>6. sentiment_analysis(risk_articles)<br>7. compare_to_criteria(analysis, investment_criteria)<br>8. generate_report(all_findings)</pre><p>Throughout execution, the agent:</p><ul><li><strong>Observes</strong> results from each tool</li><li><strong>Reasons</strong> about whether it has sufficient information</li><li><strong>Adjusts</strong> its plan if needed (e.g., if financial data is incomplete, search alternative sources)</li><li><strong>Remembers</strong> key findings for the final synthesis</li></ul><p>The result: a comprehensive investment analysis that would have taken a human analyst hours or days, completed in minutes with consistent methodology.</p><h3>The Challenges Ahead</h3><p>While the anatomy of AI agents is well-understood, significant challenges remain:</p><p><strong>Planning Reliability</strong>: Agents can still generate invalid plans or get stuck in loops. Ensuring robust planning under uncertainty is an active research area.</p><p><strong>Memory Management</strong>: Deciding what to remember and what to forget is non-trivial. Poor memory management leads to either context overload or loss of critical information.</p><p><strong>Tool Reliability</strong>: Agents are only as reliable as their tools. Tool failures, rate limits, and unexpected responses can derail agent execution.</p><p><strong>Cost and Latency</strong>: Each planning step and tool invocation adds cost and time. Optimizing agent efficiency while maintaining capability is a key engineering challenge.</p><p><strong>Security and Control</strong>: Giving agents tool access creates security risks. Ensuring agents use tools appropriately and within authorized boundaries is critical for production deployment.</p><h3>Conclusion</h3><p>Understanding the anatomy of AI agents — their planning mechanisms, memory systems, and tool orchestration capabilities — is essential as these systems move from research labs to production environments. The combination of goal-directed planning, persistent memory, and tool use transforms language models from impressive conversationalists into autonomous workers capable of complex, multi-step tasks.</p><p>As 79% of organizations adopt agentic AI and the market races toward $199 billion by 2034, the agents that succeed will be those that master this trinity of capabilities. They’ll plan intelligently, remember effectively, and use tools reliably — all while remaining aligned with human goals and operating within appropriate boundaries.</p><p>The age of AI agents isn’t coming — it’s here. And now you understand what makes them tick.</p><h3>Series Navigation</h3><p><strong>Previous Article</strong>: <a href=\"https://medium.com/gitconnected/from-chatbots-to-co-workers-understanding-the-agentic-ai-revolution-03f59ae90227\"><em>From Chatbots to Co-Workers: Understanding the Agentic AI Revolution</em></a><em> (Part 1)</em></p><p><strong>Next Article</strong>: <em>Multi-Agent Systems: When AI Agents Collaborate</em> <em>(Coming soon!)</em></p><p><strong>Coming Up</strong>: Multi-agent collaboration, building your first agent, Promise/Work orchestration, memory architectures</p><p><strong>About the Author</strong>: Daniel Stauffer is an Enterprise Architect specializing in AI systems and platform engineering. He’s passionate about building systems that augment human capability without destroying the planet.</p><p><strong>Sources</strong>:</p><ul><li>Emergen Research: Agentic AI Market Analysis 2024–2034</li><li>Industry adoption surveys and enterprise case studies</li><li>Academic research on agent architectures and planning systems</li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=f8dcbc4351af\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://levelup.gitconnected.com/the-anatomy-of-an-ai-agent-planning-memory-and-tool-use-f8dcbc4351af\">The Anatomy of an AI Agent: Planning, Memory, and Tool Use</a> was originally published in <a href=\"https://levelup.gitconnected.com\">Level Up Coding</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2026-02-27T15:35:19.000Z",
    "url": "https://levelup.gitconnected.com/the-anatomy-of-an-ai-agent-planning-memory-and-tool-use-f8dcbc4351af?source=rss----5517fd7b58a6---4"
  },
  {
    "publisherId": "levelup",
    "publisherName": "Level Up Coding",
    "specTitle": "코딩 튜토리얼",
    "categories": [
      "frontend"
    ],
    "specUrl": "https://levelup.gitconnected.com/feed",
    "title": "Native Random Values in CSS",
    "partialText": "<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://levelup.gitconnected.com/native-random-values-in-css-3f81457bc81b?source=rss----5517fd7b58a6---4\"><img src=\"https://cdn-images-1.medium.com/max/2600/0*ULZXWwcAuxn_RWPP\" width=\"3558\"></a></p><p class=\"medium-feed-snippet\">The CSS Working Group has published the Values and Units Module Level 5, which introduces native mechanisms for generating random content&#x2026;</p><p class=\"medium-feed-link\"><a href=\"https://levelup.gitconnected.com/native-random-values-in-css-3f81457bc81b?source=rss----5517fd7b58a6---4\">Continue reading on Level Up Coding »</a></p></div>",
    "date": "2026-02-27T15:35:03.000Z",
    "url": "https://levelup.gitconnected.com/native-random-values-in-css-3f81457bc81b?source=rss----5517fd7b58a6---4"
  },
  {
    "publisherId": "levelup",
    "publisherName": "Level Up Coding",
    "specTitle": "코딩 튜토리얼",
    "categories": [
      "frontend"
    ],
    "specUrl": "https://levelup.gitconnected.com/feed",
    "title": "5 Python One-Liners That Made Me Feel Like a Senior Developer Overnight",
    "partialText": "<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://levelup.gitconnected.com/5-python-one-liners-that-made-me-feel-like-a-senior-developer-overnight-467209dec776?source=rss----5517fd7b58a6---4\"><img src=\"https://cdn-images-1.medium.com/max/2600/0*w6lS-_rHInq1eDDe\" width=\"6336\"></a></p><p class=\"medium-feed-snippet\">The tiny lines of code that quietly automated hours of my life</p><p class=\"medium-feed-link\"><a href=\"https://levelup.gitconnected.com/5-python-one-liners-that-made-me-feel-like-a-senior-developer-overnight-467209dec776?source=rss----5517fd7b58a6---4\">Continue reading on Level Up Coding »</a></p></div>",
    "date": "2026-02-27T15:34:48.000Z",
    "url": "https://levelup.gitconnected.com/5-python-one-liners-that-made-me-feel-like-a-senior-developer-overnight-467209dec776?source=rss----5517fd7b58a6---4"
  },
  {
    "publisherId": "levelup",
    "publisherName": "Level Up Coding",
    "specTitle": "코딩 튜토리얼",
    "categories": [
      "frontend"
    ],
    "specUrl": "https://levelup.gitconnected.com/feed",
    "title": "Global Setup in Playwright TypeScript for API Testing",
    "partialText": "<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://levelup.gitconnected.com/global-setup-in-playwright-typescript-for-api-testing-ce7abe0173cf?source=rss----5517fd7b58a6---4\"><img src=\"https://cdn-images-1.medium.com/max/1920/1*kxhFal2TLOU38RJvUb64TA.png\" width=\"1920\"></a></p><p class=\"medium-feed-snippet\">Learn how to use Global Setup in Playwright TS to create test data, seed the database, and prepare test environments before running tests.</p><p class=\"medium-feed-link\"><a href=\"https://levelup.gitconnected.com/global-setup-in-playwright-typescript-for-api-testing-ce7abe0173cf?source=rss----5517fd7b58a6---4\">Continue reading on Level Up Coding »</a></p></div>",
    "date": "2026-02-27T15:34:32.000Z",
    "url": "https://levelup.gitconnected.com/global-setup-in-playwright-typescript-for-api-testing-ce7abe0173cf?source=rss----5517fd7b58a6---4"
  },
  {
    "publisherId": "levelup",
    "publisherName": "Level Up Coding",
    "specTitle": "코딩 튜토리얼",
    "categories": [
      "frontend"
    ],
    "specUrl": "https://levelup.gitconnected.com/feed",
    "title": "Delete 80% of AGENTS.md. It is making LLM 3% Stupider and 20% Costlier",
    "partialText": "<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://levelup.gitconnected.com/delete-80-of-agents-md-it-is-making-llm-3-stupider-and-20-costlier-722a43244830?source=rss----5517fd7b58a6---4\"><img src=\"https://cdn-images-1.medium.com/max/1264/0*F8OcAhWMK8oBIHH3.jpeg\" width=\"1264\"></a></p><p class=\"medium-feed-snippet\">New ETH Zurich research reveals the &#x201C;Dirty Secret&#x201D; of Context Engineering: You might be better off deleting most of the Agents.md</p><p class=\"medium-feed-link\"><a href=\"https://levelup.gitconnected.com/delete-80-of-agents-md-it-is-making-llm-3-stupider-and-20-costlier-722a43244830?source=rss----5517fd7b58a6---4\">Continue reading on Level Up Coding »</a></p></div>",
    "date": "2026-02-27T15:34:15.000Z",
    "url": "https://levelup.gitconnected.com/delete-80-of-agents-md-it-is-making-llm-3-stupider-and-20-costlier-722a43244830?source=rss----5517fd7b58a6---4"
  },
  {
    "publisherId": "levelup",
    "publisherName": "Level Up Coding",
    "specTitle": "코딩 튜토리얼",
    "categories": [
      "frontend"
    ],
    "specUrl": "https://levelup.gitconnected.com/feed",
    "title": "Understanding Microsoft Entra Agent ID",
    "partialText": "<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://levelup.gitconnected.com/understanding-microsoft-entra-agent-id-c437e5629a32?source=rss----5517fd7b58a6---4\"><img src=\"https://cdn-images-1.medium.com/max/1000/0*R77nQ35DFBWFUZBN.png\" width=\"1000\"></a></p><p class=\"medium-feed-snippet\">As agents become more capable of making decisions, they require own identities to ensure proper governance, security, and accountability&#x2026;</p><p class=\"medium-feed-link\"><a href=\"https://levelup.gitconnected.com/understanding-microsoft-entra-agent-id-c437e5629a32?source=rss----5517fd7b58a6---4\">Continue reading on Level Up Coding »</a></p></div>",
    "date": "2026-02-27T15:34:00.000Z",
    "url": "https://levelup.gitconnected.com/understanding-microsoft-entra-agent-id-c437e5629a32?source=rss----5517fd7b58a6---4"
  },
  {
    "publisherId": "levelup",
    "publisherName": "Level Up Coding",
    "specTitle": "코딩 튜토리얼",
    "categories": [
      "frontend"
    ],
    "specUrl": "https://levelup.gitconnected.com/feed",
    "title": "7 Advanced Python Library Moves I Thought Only Core Developers Knew",
    "partialText": "<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://levelup.gitconnected.com/7-advanced-python-library-moves-i-thought-only-core-developers-knew-08a17f63e326?source=rss----5517fd7b58a6---4\"><img src=\"https://cdn-images-1.medium.com/max/2600/0*mM4sLPbc5CwdwNuD\" width=\"8400\"></a></p><p class=\"medium-feed-snippet\">The automation tricks that quietly 10x&#x2019;d my output.</p><p class=\"medium-feed-link\"><a href=\"https://levelup.gitconnected.com/7-advanced-python-library-moves-i-thought-only-core-developers-knew-08a17f63e326?source=rss----5517fd7b58a6---4\">Continue reading on Level Up Coding »</a></p></div>",
    "date": "2026-02-27T15:33:44.000Z",
    "url": "https://levelup.gitconnected.com/7-advanced-python-library-moves-i-thought-only-core-developers-knew-08a17f63e326?source=rss----5517fd7b58a6---4"
  },
  {
    "publisherId": "levelup",
    "publisherName": "Level Up Coding",
    "specTitle": "코딩 튜토리얼",
    "categories": [
      "frontend"
    ],
    "specUrl": "https://levelup.gitconnected.com/feed",
    "title": "8 Python Library Shortcuts I Stole From Open-Source Maintainers",
    "partialText": "<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://levelup.gitconnected.com/8-python-library-shortcuts-i-stole-from-open-source-maintainers-cb86fce68fe6?source=rss----5517fd7b58a6---4\"><img src=\"https://cdn-images-1.medium.com/max/2600/0*7ctm63YUAcNl_Ag6\" width=\"6000\"></a></p><p class=\"medium-feed-snippet\">The automation tricks I wish someone had told me 4 years ago.</p><p class=\"medium-feed-link\"><a href=\"https://levelup.gitconnected.com/8-python-library-shortcuts-i-stole-from-open-source-maintainers-cb86fce68fe6?source=rss----5517fd7b58a6---4\">Continue reading on Level Up Coding »</a></p></div>",
    "date": "2026-02-27T15:33:27.000Z",
    "url": "https://levelup.gitconnected.com/8-python-library-shortcuts-i-stole-from-open-source-maintainers-cb86fce68fe6?source=rss----5517fd7b58a6---4"
  },
  {
    "publisherId": "levelup",
    "publisherName": "Level Up Coding",
    "specTitle": "코딩 튜토리얼",
    "categories": [
      "frontend"
    ],
    "specUrl": "https://levelup.gitconnected.com/feed",
    "title": "Claude Code + MCP + Cowork: The Agentic Stack That’s Quietly Rewriting Work",
    "partialText": "<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://levelup.gitconnected.com/claude-code-mcp-cowork-the-agentic-stack-thats-quietly-rewriting-work-d838a125d632?source=rss----5517fd7b58a6---4\"><img src=\"https://cdn-images-1.medium.com/max/1404/1*0aOGVtjxs6K-oLR2ofs11A.jpeg\" width=\"1404\"></a></p><p class=\"medium-feed-snippet\">Claude&#x2019;s models got smarter. The ecosystem got dangerous (and useful).</p><p class=\"medium-feed-link\"><a href=\"https://levelup.gitconnected.com/claude-code-mcp-cowork-the-agentic-stack-thats-quietly-rewriting-work-d838a125d632?source=rss----5517fd7b58a6---4\">Continue reading on Level Up Coding »</a></p></div>",
    "date": "2026-02-27T15:33:11.000Z",
    "url": "https://levelup.gitconnected.com/claude-code-mcp-cowork-the-agentic-stack-thats-quietly-rewriting-work-d838a125d632?source=rss----5517fd7b58a6---4"
  }
]