[
  {
    "publisherId": "musinsa",
    "publisherName": "무신사 테크블로그",
    "specTitle": "e커머스 개발",
    "categories": [
      "backend"
    ],
    "specUrl": "https://medium.com/feed/musinsa-tech",
    "title": "“스케줄이 또 안 돌았어요” — 우리가 Temporal을 선택한 이유",
    "partialText": "<h3>“스케줄이 또 안 돌았어요” — 우리가 Temporal을 선택한 이유</h3><p>어느 날 아침, 슬랙 알림이 울렸습니다. <br>“출고지시 스케줄이 실행 안 된 것 같은데 확인 부탁드려요.”</p><p>Jenkins 콘솔을 열어보니 job이 멈춰있었고, 모니터링 job마저 함께 멈춰있었습니다. 급하게 수동으로 출고지시를 트리거하고 나서야 물류센터 작업이 시작될 수 있었습니다. 이런 일이 반복되면서 우리는 고민하게 되었습니다.</p><p><strong>“스케줄 하나 도는 게 왜 이렇게 불안할까?”</strong></p><h3>출고지시, 그리고 우리가 마주한 문제들</h3><p>무신사 풀필먼트의 OMS는 주문부터 출고까지 물류 전반을 책임지는 시스템입니다. 그 중에서도 <strong>출고지시는 물류센터의 하루를 시작하는 신호</strong>와도 같습니다. 정해진 시간에 출고지시가 생성되지 않으면 물류센터 작업이 지연되고, 그것은 곧 배송 지연으로 이어집니다.</p><p>초기에는 Jenkins crontab으로 충분했습니다. 정해진 시간에 실행하기만 하면 됐습니다. 하지만 화주사가 늘고 출고 물량이 커지면서, 이 구조의 한계가 하나둘 보이기 시작했습니다.</p><h3>1. 실패를 놓치는 순간들</h3><p>Jenkins 기반 스케줄은 job이 멈춰도 알려주지 않았습니다. 그래서 우리는 별도의 모니터링 job을 만들어 실행했습니다. <strong>“스케줄이 실행됐는지 확인하는 스케줄”</strong>을 또 만드는 거죠.</p><p>문제는 이 모니터링 job도 언제든 멈출 수 있다는 것이었습니다. 실제로 Jenkins 자체에 문제가 생기면 스케줄과 모니터링이 함께 멈췄고, 우리는 뒤늦게야 알게 되곤 했습니다. 모니터링을 위한 모니터링을 또 만들 수는 없었고, 이 구조 자체가 근본적인 한계를 가지고 있다는 걸 깨달았습니다.</p><h3>2. 로그 속에서 원인 찾기</h3><p>출고지시에 문제가 생기면, 저희는 Jenkins 콘솔 로그를 시작으로 애플리케이션 로그, DB 이력을 차례로 확인해야 했습니다.</p><p>“이번엔 어디서 실패한 거지?” <br>“입력값은 뭐였지?” <br>“결과는 어떻게 됐지?”</p><p>실행 이력을 한눈에 볼 수 있는 방법이 없었고, <strong>문제를 분석하는 것보다 로그를 따라가는 데 더 많은 시간</strong>이 들었습니다. 빠른 대응이 필요한 순간일수록, 이런 가시성 부족은 운영 리스크를 키우는 요인이 되었습니다.</p><h3>3. “다시 눌러주세요”</h3><p>스케줄이 실패하면 저희가 직접 재실행해야 했습니다. 단순히 일시적인 네트워크 오류로 실패한 경우에도, 원인을 확인하고 수동으로 재실행하는 과정에서 시간이 소요되었습니다.</p><p>대응이 조금만 늦어도 출고 SLA에 영향을 주는 경우가 생겼고, 담당자의 부담은 자연스럽게 커질 수밖에 없었습니다. 실제로는 단순 재시도만으로 해결될 수 있는 케이스도 많았지만, 원인을 확인하는 절차 자체가 출고 지연으로 이어지는 경우가 반복되었습니다.</p><p>결국 이러한 구조에서는 안정적인 운영을 기대하기 어려워졌습니다.</p><h3>4. 이벤트 기반으로의 확장</h3><p>출고 도메인에서는 정해진 스케줄 외에도, 특정 이벤트를 기점으로 Workflow를 실행해야 하는 요구가 늘어나고 있었습니다. 하지만 Jenkins는 cron 기반 실행에 최적화되어 있었고, 이벤트 기반 트리거를 자연스럽게 처리하기에는 구조적인 한계가 있었습니다.</p><p>결국 저희는 깨달았습니다. <br><strong>“출고 물량과 요구사항이 늘어날수록, 기존 구조로는 안정적인 운영을 기대하기 어렵다.”</strong></p><p>구조 자체를 다시 고민해야 할 시점이었습니다.</p><h3>대안을 찾아서</h3><p>저희는 여러가지 가능성을 열어두고 대안을 비교해보기 시작했습니다.</p><h4>Jenkins + 모니터링 Job 개선</h4><p>이미 운영 중인 구조라 리스크는 적었지만, 근본적인 한계를 해결하기는 어려웠습니다. 모니터링을 아무리 촘촘하게 만들어도, Jenkins 자체의 고가용성 문제는 해결되지 않았습니다.</p><h4>Spring Batch + Quartz</h4><p>Spring Batch + Quartz는 배치 처리에 최적화된 구조였고, 팀에서도 익숙한 스택이었습니다. 하지만 Batch Job 실행 이력은 확인할 수 있어도, “주문이 어디서 멈췄고, 왜 실패했는지”와 같은 비즈니스 흐름은 보이지 않았습니다. 재시도 로직 구현은 가능했지만, “이 조건이면 재시도, 저 조건이면 스킵” 같은 의사결정 로직이 코드 곳곳에 흩어지면서 전체 워크플로우를 파악하기 어려워졌습니다. 결국 “배치 Job”이 아닌 “비즈니스 워크플로우” 단위로 실행과 상태를 추적하고 싶었습니다.</p><h4>Temporal</h4><p>Temporal은 장기 실행되는 비즈니스 프로세스를 코드로 표현하고, 실패·재시도·상태 관리를 플랫폼 레벨에서 보장해주는 Workflow Engine입니다. Uber에서 만든 Cadence를 기반으로 개발되었으며, 서버 장애가 발생해도 중단된 지점부터 자동 복구됩니다.</p><p>생소한 이름이었습니다. 러닝 커브가 높다는 것도 부담이었습니다. 하지만 회의실에서 Temporal 문서를 보며 이야기를 나누다 보니, 저희가 원하던 것들이 하나하나 눈에 들어왔습니다.</p><ul><li>스케줄 기반 실행</li><li>Workflow 전체 흐름에 대한 가시성</li><li>자동 재시도와 복구</li><li>이벤트 기반 트리거</li></ul><p>어느 순간 팀 모두가 적합해 보인다고 생각했고, <strong>단순히 스케줄을 실행하는 기능을 넘어, 출고 도메인 전반의 흐름을 안정적으로 오케스트레이션할 수 있는 플랫폼</strong>이 될 수 있겠다고 판단했습니다.</p><h3>설계하면서 고민한 것들</h3><h4>무엇을 목표로 설계하는가</h4><p>기존 Jenkins crontab 기반 스케줄링 방식은 운영 안정성, 실행 가시성, 복구 가능성 측면에서 여러 한계를 갖고 있었습니다.</p><p>이에 따라 스케줄 실행 방식을 보다 안정적이고 자동화된 구조로 전환하고, 운영자가 수행하던 수동 확인과 재실행 작업을 최소화하는 것을 목표로 했습니다.</p><h4>Workflow와 Activity, 어떻게 나눌 것인가</h4><p>Temporal 공식 문서는 이렇게 말합니다.</p><blockquote><em>Workflow는 전체 비즈니스 프로세스의 오케스트레이션을 담당하고, Activity는 외부 시스템과의 상호작용이나 단위 작업을 수행한다.</em></blockquote><p>Workflow와 Activity의 경계를 정하는 데 가장 어려웠던 점은, 단순히 “외부 시스템을 호출하는가”가 아니라 “이 분기가 비즈니스 정책인가, 실행 세부사항인가”를 판단하는 일이었습니다. 예를 들어 “중복 주문이면 스킵한다”는 비즈니스 정책이므로 Workflow에서 분기하고, “DB에서 중복 여부를 조회한다”는 실행 세부사항이므로 Activity로 분리했습니다.</p><p>논의 끝에 저희가 세운 기준은 이렇습니다:</p><ul><li>Workflow: 비즈니스 정책에 따른 분기와 흐름 제어</li><li>Activity: 멱등성이 보장되는 단위 작업, 외부 시스템 호출</li></ul><p>출고지시의 경우, Workflow는 “정책 조회 → 중복 체크 → 차수 생성 → 파이프라인 트리거” 흐름을 조율하고, 각 단계의 실제 작업은 Activity가 수행합니다. 이 구분이 명확할수록 향후 출고 파이프라인 전체를 Workflow로 확장할 때도 일관성 있게 설계할 수 있을 거라 생각했습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*iO5YSi38Zj2O5Ue3f43rbQ.png\" /></figure><ul><li>앞서 정의한 기준에 따라, Workflow는 출고지시 트리거의 전체 흐름과 분기·의사결정을 조율하고 Activity는 정책 조회, 중복 체크, 차수 생성 등 실제 작업을 수행합니다.</li><li>Temporal 내 정의된 스케줄을 기반으로 Workflow가 실행되며, 각 단계는 Activity로 위임되어 상태를 명확히 관리하고 출고지시 흐름을 조율합니다.</li></ul><h3>출고지시 Workflow 구현</h3><p>최종적으로 <strong>1개의 Workflow</strong>와 <strong>5개의 Activity</strong>로 구성했습니다. (아래는 간략화된 코드입니다.)</p><pre>@WorkflowImplement<br>class CutOffTriggerWorkflowImpl : CutOffTriggerWorkflow {<br>    override fun run() {<br>      <br>        // 출고지시 정책 조회<br>        val policies = getCutOffPolicies.get(now)<br><br>        policies.forEach { policy -&gt;<br>            // 출고지시 차수 생성<br>            val cutSequence = createCutSequence.create(policy)<br><br>            // 파이프라인 트리거<br>            triggerPipeline.trigger(cutSequence, now)<br>        }<br>    }<br>}</pre><h3>29CM 주문수집도 자동화하다</h3><p>출고지시 트리거를 Temporal로 전환하고 나니, 또 다른 수동 작업이 눈에 들어왔습니다. <strong>29CM 주문수집</strong>이었습니다.</p><p>담당자가 MOMS 화면에서 버튼을 눌러 수동으로 주문을 수집하고 있었는데, 물량이 늘면서 이 방식도 한계가 드러나기 시작했습니다. 버튼 클릭을 누락하는 경우도 있었고, 담당자 부재 시 주문 수집이 지연되기도 했습니다.</p><p>“출고지시와 비슷한 문제잖아?”</p><p>팀 내에서 자연스럽게 이러한 논의가 이어졌고, 29CM 주문수집도 Temporal Workflow로 자동화하기로 했습니다.</p><h3>개인정보 보호를 고려한 설계</h3><p>하지만 여기서 중요한 고민이 하나 있었습니다. 우리는 Temporal Cloud를 사용할 계획이므로 무신사 고객의 개인정보를 Temporal에 전달하는 것은 부적절했습니다.</p><p>회의실에서 여러 방안을 논의했고, 결국 다음과 같이 설계했습니다:</p><ol><li>29CM에서 받은 API Payload를 MOMS DB에 저장</li><li>Payload ID만 Temporal Workflow에 전달</li><li>Activity에서 Payload ID로 DB 조회 후 처리</li></ol><p><strong>즉, 개인정보는 우리 인프라 안에 머물고, Temporal에는 ID만 전달되는 구조</strong>입니다.</p><h3>주문수집 Workflow 시나리오</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*3ZllJ7Z8IUJJ-n4sSJFbYQ.png\" /></figure><ul><li>29CM API에서 주문을 조회해서 DB에 저장(ORDER_COLLECTED)합니다.</li><li>성공한 건에 대해 29CM에 상품준비중 상태 변경을 요청한 뒤, 상태를 ORDER_ACCEPTED로 변경하는 플로우입니다.</li></ul><h3>주문수집 Workflow 구현</h3><p><strong>1개의 Workflow</strong>와 <strong>4개의 Activity</strong>로 구성했습니다.</p><pre>@WorkflowImplement<br>class AddStandardOrderWorkflowImpl : AddStandardOrderWorkflow {<br>    override fun addOrders(payloadId: Long) {<br>        // 1. 주문 수집<br>        val upsertResults = addStandardOrderActivity.addOrders(payloadId)<br>        val successOrders = upsertResults.filter { it.success }<br>        if (successOrders.isEmpty()) return<br><br>        // 2. 상품 준비중 API 요청<br>        val shippingResults = requestPrepareShippingActivity.request(successOrders)<br><br>        // 3. 주문 상태를 ORDER_ACCEPTED로 변경<br>        if (shippingResults.items.isNotEmpty()) {<br>            val request = convertActivity.convert(shippingResults)<br>            changeStatusActivity.updateToAccepted(request)<br>        }<br>    }<br>}</pre><p>주문 수집 → 29CM API 호출 → 상태 변경까지의 흐름이 하나의 Workflow로 표현됩니다. 출고지시 Workflow와 비슷한 구조지만, 도메인의 특성에 맞게 Activity를 구성했습니다.</p><h3>운영하면서 느낀 것들</h3><h4>좋았던 점들</h4><h4>1. 장애 대응이 ‘케이스 바이 케이스’에서 ‘시스템’으로</h4><p>가장 먼저 체감한 변화는 <strong>자동 재시도</strong>였습니다. Activity에 정의한 Retry/Backoff/Timeout 규칙에 따라 자동으로 재시도되는 걸 보면서, “아, 이제 Spring Batch에 복잡하게 구현하지 않아도 되겠구나”라는 생각이 들었습니다.</p><p>실제로 운영 중 일시적인 네트워크 오류로 출고지시가 실패한 적이 있었는데, Temporal UI를 보니 자동으로 3번 재시도하고 성공한 걸 확인할 수 있었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*xRR-OkSmY4zf8tIl_XvT1A.png\" /><figcaption>EventID 12 : 재시도 후 성공한 케이스</figcaption></figure><h4>2. Workflow 단위로 보이는 실행 이력</h4><p>이전에는 Jenkins 로그, 애플리케이션 로그를 모두 열어봐야 했지만, <strong>Temporal UI에서 타임라인을 한눈에 확인</strong>할 수 있게 되었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*GbkPp4FK89-3N4aff2Xllg.png\" /><figcaption>하단부터 시간순 타임라인</figcaption></figure><p>특히 Activity 단위로 input, output을 빠르게 확인할 수 있어 원인 파악이 훨씬 쉬워졌습니다. “이 시점에 어떤 정책이 들어왔고, 어떤 결과가 나왔는지”를 클릭 몇 번으로 확인할 수 있게 되니, 장애 대응 시간이 크게 줄었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*nynJLox02b6lW5mbMBDJvg.png\" /><figcaption>특정 Activity의 Input, Output</figcaption></figure><h4>3. 부분 도입만으로도 체감된 변화</h4><p>출고지시 전체 파이프라인이 아닌 <strong>“트리거 + 특정 화주 주문수집”만 Temporal로 옮겼는데도</strong>, 해당 구간의 장애 대응과 모니터링 편의성은 즉시 체감할 수 있었습니다.</p><p>또한, 동일 도메인을 Spring Batch + Jenkins와 Temporal 두 체계에서 비교해보면서, 어떤 유형의 작업이 Temporal에 더 적합한지 기준을 잡는 데 도움이 되었습니다.</p><h4>고려해봐야 할 것들</h4><h4>1. Workflow·Activity 경계 설정의 어려움</h4><p>“무엇을 하나의 Workflow로 보고, 어느 단위를 Activity로 분리할 것인가”에 대한 기준을 잡는 게 쉽지 않았습니다. 팀 내에서도 의견이 엇갈릴 때가 많았고, 결국 “실제로 만들어보고 조정하자”는 방식으로 진행했습니다.</p><p>이번에는 일부에만 적용했지만, 향후 출고 전체 파이프라인으로 확장하려면 <strong>더 명확한 설계 원칙</strong>이 필요할 것 같습니다.</p><h4>2. 디버깅 포인트의 증가</h4><p>Temporal을 도입하면서 애플리케이션 로그 외에 Temporal History, Worker 메트릭까지 함께 봐야 해서 디버깅 지점이 늘어난 것은 사실입니다. 하지만 이는 단순히 복잡도가 증가했다기보다, 실행 상태를 구조적으로 관측할 수 있게 된 결과라고 느끼고 있습니다.</p><p>다만 이 장점을 살리기 위해서는, 로그·메트릭·Workflow History를 어떤 순서로 확인할지에 대한 팀 차원의 디버깅 가이드가 반드시 필요하다는 점도 함께 깨달았습니다. 현재는 이슈 대응 시 “애플리케이션 로그 → Temporal History → Worker 메트릭” 순으로 확인하는 기준을 정리 중이며, Datadog/Slack 알림 임계값도 함께 다듬어가고 있습니다.</p><h4>3. Batch와 Temporal의 공존</h4><p>Batch와 Temporal이 공존하는 현재 상태는 운영 부담이 분명 존재합니다. “이 배치는 Jenkins에서 보고, 저 워크플로우는 Temporal에서 본다”는 식으로 운영하다 보니 온콜 대응 가이드도 두 체계로 작성해야 했습니다.</p><p>하지만 이 공존은 모든 파이프라인을 한 번에 전환하지 않기 위한 의도적인 과도기이기도 합니다. 이 기간 동안 동일 도메인을 두 체계에서 비교해보면서, “장기 실행·재시도·이력 추적이 중요한 작업”은 Temporal에, “단순 반복 처리”는 Batch에 적합하다는 기준을 점점 명확히 하고 있습니다. 이러한 기준이 쌓이면 전환 시점에 대한 판단도 훨씬 명확해질 것으로 기대하고 있습니다.</p><h3>다음 여정: 출고지시 파이프라인 전체를 Temporal로</h3><p>이제 저희는 더 큰 그림을 그리고 있습니다. 출고지시 트리거와 주문수집을 Temporal로 전환하면서, 다음 단계가 분명해졌습니다.</p><p><strong>출고지시 파이프라인 전체를 Workflow로 전환하는 것.</strong></p><p>현재 출고지시는 대용량 처리 시 약 30분이 소요됩니다 (2만 건 기준). 이를 Workflow 기반 병렬 처리 구조로 전환하면 <strong>평균 90% 이상 단축</strong>할 수 있을 것으로 예상하고 있습니다.</p><p>또한 출고 전 구간의 상태, 처리 속도, 실패 지점을 실시간으로 가시화하여 문제의 원인과 영향 범위를 신속하게 파악할 수 있는 Observability 체계를 구축하려 합니다.</p><p>지금은 Child Workflow, Signal 기반 접근 방식 등 다양한 방법을 테스트하고 있습니다. 만만치 않은 도전이겠지만, 트리거와 주문수집을 통해 얻은 경험이 큰 자산이 되고 있습니다.</p><h4>AS-IS</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*UWukKCCNJBhQrh_sCo_aMw.png\" /></figure><h4>TO-BE</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*5BuNX8-EiwvfJ1Pn_BVhsw.png\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*1q4EV4qdgzZjN1HD2ClhOg.png\" /></figure><h3>마치며</h3><p>“스케줄이 또 안 돌았어요”라는 알림에서 시작된 이 여정은, 단순히 기술 스택을 바꾸는 것 이상의 의미를 가졌습니다.</p><p>저희는 <strong>“실패하지 않는 시스템”을 만드는 게 아니라, “실패해도 스스로 복구되는 시스템”</strong>을 만들고 있습니다. Temporal을 도입하면서 가장 크게 느낀 건, 기술 선택이 단순히 “어떤 라이브러리를 쓸 것인가”가 아니라 <strong>“우리가 어떻게 운영할 것인가”</strong>를 결정한다는 점이었습니다.</p><p>물론 아직 갈 길이 멉니다. Workflow 설계 기준도 계속 다듬어야 하고, 모니터링 체계도 개선해야 합니다. 출고 파이프라인 전체를 Workflow로 전환하는 것도 쉽지 않은 도전이 될 것입니다.</p><p>하지만 새벽에 출고지시 알림을 받고 급하게 수동 실행하던 날들이 조금씩 줄어들고 있습니다. 그리고 그 시간에 저희는 더 중요한 문제를 고민할 수 있게 되었습니다.</p><p>긴 글 읽어주셔서 감사합니다. <br>저희의 경험이 비슷한 고민을 하고 계신 분들께 조금이나마 도움이 되었으면 좋겠습니다.</p><h3>Platform Business Operation 조직 및 팀 소개</h3><blockquote>무신사 플랫폼 비즈니스 오퍼레이션 조직은 국내외 물류 서비스, 재고 관리, 스토어 운영을 위한 물류 프로덕트를 구축하고 다양한 오프라인 비즈니스 모델에 맞춘 스토어 관리 시스템을 개발·고도화하고 있습니다.<br>또한, 무배당발 서비스를 포함한 무신사의 차별화된 고객 경험을 브랜딩하고 확장할 수 있는 멤버십 구조를 설계하며, 온·오프라인을 넘나드는 통합 커머스 경험을 기술로 실현하고 있습니다.</blockquote><blockquote>저희 팀은 OMS(주문관리시스템)를 기반으로 온라인 주문부터 재고·출고·배송·정산에 이르는 전 과정을 유기적으로 연결하고, 무신사의 다양한 오프라인 스토어를 효과적으로 운영할 수 있는 관리 시스템을 구축하여 고객이 온라인(무신사 스토어, 29CM 등)과 오프라인(무신사 스탠다드, 편집숍 등)에서 끊김 없는 쇼핑 경험을 누릴 수 있도록 지원합니다.</blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/pbo\">🚀 Platform Business Operation 한걸음 더 알아보기</a></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/home\">🚀 팀 무신사 채용 페이지</a> (무신사/29CM 전체 포지션 확인이 가능해요)</blockquote><blockquote>🚀 <a href=\"https://kr.linkedin.com/company/musinsacom\">팀 무신사 테크 소식을 받아보는 링크드인</a></blockquote><blockquote>🚀 <a href=\"https://newsroom.musinsa.com/\">팀 무신사 뉴스룸</a></blockquote><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=f491e79a0f8f\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://techblog.musinsa.com/%EC%8A%A4%EC%BC%80%EC%A4%84%EC%9D%B4-%EB%98%90-%EC%95%88-%EB%8F%8C%EC%95%98%EC%96%B4%EC%9A%94-%EC%9A%B0%EB%A6%AC%EA%B0%80-temporal%EC%9D%84-%EC%84%A0%ED%83%9D%ED%95%9C-%EC%9D%B4%EC%9C%A0-f491e79a0f8f\">“스케줄이 또 안 돌았어요” — 우리가 Temporal을 선택한 이유</a> was originally published in <a href=\"https://techblog.musinsa.com\">MUSINSA techblog — 무신사 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2026-02-05T02:17:35.000Z",
    "url": "https://techblog.musinsa.com/%EC%8A%A4%EC%BC%80%EC%A4%84%EC%9D%B4-%EB%98%90-%EC%95%88-%EB%8F%8C%EC%95%98%EC%96%B4%EC%9A%94-%EC%9A%B0%EB%A6%AC%EA%B0%80-temporal%EC%9D%84-%EC%84%A0%ED%83%9D%ED%95%9C-%EC%9D%B4%EC%9C%A0-f491e79a0f8f?source=rss----f107b03c406e---4"
  },
  {
    "publisherId": "musinsa",
    "publisherName": "무신사 테크블로그",
    "specTitle": "e커머스 개발",
    "categories": [
      "backend"
    ],
    "specUrl": "https://medium.com/feed/musinsa-tech",
    "title": "“이번 달도 밤샘 정산입니다.” — 더 이상 밤샘하지 않아도 됩니다 (운영편)",
    "partialText": "<h3>“이번 달도 밤샘 정산입니다.” — 더 이상 밤샘하지 않아도 됩니다 (운영편)</h3><p>“이번 달도 밤샘 정산입니다.” 시리즈</p><ol><li><a href=\"https://techblog.musinsa.com/%EC%9D%B4%EB%B2%88-%EB%8B%AC%EB%8F%84-%EB%B0%A4%EC%83%98-%EC%A0%95%EC%82%B0%EC%9E%85%EB%8B%88%EB%8B%A4-%EC%A0%95%EC%82%B0-%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%80-%EC%96%B4%EB%96%BB%EA%B2%8C-%EB%A7%8C%EB%93%A4%EC%97%88%EC%9D%84%EA%B9%8C-%EC%8B%A4%EC%A0%84%ED%8E%B8-74d8a5d22ba1\">정산 시스템은 어떻게 만들었을까 (실전편)</a></li><li><a href=\"https://techblog.musinsa.com/%EC%9D%B4%EB%B2%88-%EB%8B%AC%EB%8F%84-%EB%B0%A4%EC%83%98-%EC%A0%95%EC%82%B0%EC%9E%85%EB%8B%88%EB%8B%A4-%EC%A0%95%EC%82%B0-%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%80-%EC%96%B4%EB%96%BB%EA%B2%8C-%EB%A7%8C%EB%93%A4%EC%97%88%EC%9D%84%EA%B9%8C-%EC%8B%A4%EC%A0%84%ED%8E%B8-74d8a5d22ba1\">정산 시스템은 왜 필요했을까 (설계편)</a></li><li><a href=\"https://techblog.musinsa.com/이번-달도-밤샘-정산입니다-더-이상-밤샘하지-않아도-됩니다-운영편-4f09ae3bdf5d\"><strong>더 이상 밤샘하지 않아도 됩니다 (운영편)</strong></a></li></ol><h3>들어가며</h3><p>앞선 두 편에서는 정산 시스템이 왜 어려운 문제인지, 그리고 그 문제를 어떤 구조와 기술로 풀어냈는지를 다뤘습니다. <br>마지막 글에서는 MASS 정산 시스템을 실제 운영 환경에 단계적으로 오픈하며 어떤 변화와 성과를 만들어냈는지를 정리합니다.</p><h3>단계적 오픈 전략</h3><p>정산 시스템은 한 번에 완성해서 오픈하기에는 리스크가 너무 큰 시스템입니다.<br>그래서 MASS는 기능이 아닌 <strong>데이터를 기준으로 단계적 오픈 전략</strong>을 선택했습니다.</p><ol><li><strong>원천 데이터 적재 모듈 선배포<br></strong>a. 실제 운영 환경에서 발생하는 모든 케이스를 먼저 수집<br>b. 수집 과정에서 드러난 데이터 품질 이슈와 처리 오류를 사전에 식별/수정<br>c. 정산 정책 결정이 필요한 엣지 케이스들을 정리하고 기준을 확정<br>ㅤi. 예외 데이터 처리 기준<br>ㅤii. 경계 조건에서의 금액 산정 방식 등</li><li><strong>실데이터 기반 QA/시뮬레이션<br></strong>a. 실제 데이터를 기준으로 정산 배치를 반복 실행하며 리허설</li><li><strong>검증 완료 후 전체 정산 오픈<br></strong>a. 한 달 단위 정산을 처음부터 끝까지 무결하게 수행</li></ol><p>이 전략 덕분에 시스템 오픈과 동시에 실제 정산을 안정적으로 마칠 수 있었습니다.</p><h4>단계적 오픈 전략 (데이터 적재 → QA/시뮬레이션 → 전체 오픈)</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Pcq6TxN82czZdu5eoZYe-w.png\" /></figure><h4>실데이터 기반 QA / 시뮬레이션</h4><p>정산 시스템은 실제 데이터로 검증하지 않으면, 오픈 이후에 반드시 예상하지 못한 불일치가 발생합니다.<br>그래서 MASS는 <strong>실제 운영 데이터를 기준으로 한 리허설</strong>에 집중했습니다.</p><blockquote>리허설 환경 구성</blockquote><p>QA 및 시뮬레이션은 <strong>운영 환경과 동일한 스키마를 가진 개발 환경</strong>에서 수행되었습니다.<br>운영 DB를 직접 사용하는 방식이 아니라,</p><ul><li>8월부터 10월까지 발생한 <strong>실제 원천 데이터를 개발 환경으로 마이그레이션</strong></li><li>정산 로직, 배치 설정, 기준 데이터는 운영과 동일하게 유지</li><li>운영과 분리된 환경에서 반복 실행이 가능하도록 구성</li></ul><p>이를 통해 운영 데이터의 현실적인 복잡성을 그대로 가져오면서도, 정산 배치를 <strong>수차례 재실행할 수 있는 안전한 실험 환경</strong>을 확보했습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*X28LQEXpzlOIiBpF0JzJhA.png\" /></figure><blockquote>검증 방식: 수기 정산 결과와의 비교</blockquote><p>정산 결과 검증은 <strong>수기 정산 결과와의 직접 비교</strong>를 기준으로 진행했습니다.</p><ul><li>기존 수기 정산으로 확정된 결과를 기준 데이터로 사용</li><li>동일 기간, 동일 조건으로 MASS 정산 배치를 반복 실행</li><li>업체별·항목별 금액을 단위까지 대조하며 결과 비교</li></ul><p>초기 단계에서는 일부 수동 대조가 필요했지만, 반복되는 검증 구간에 대해서는 <strong>리포트 형태로 검증을 자동화</strong>해 불일치 여부를 빠르게 식별할 수 있도록 했습니다.</p><blockquote>리허설 범위와 데이터 규모</blockquote><p>리허설은 <strong>단일 케이스가 아닌, 수개월치 실데이터</strong>를 대상으로 수행되었습니다.</p><ul><li><strong>8월 ~ 10월, 총 3개월치 실제 원천 데이터</strong></li><li>일 정산, 월 정산 시나리오 모두 반복 실행</li><li>프로모션 적용, 예외 케이스, 경계 조건 포함</li></ul><p>이를 통해 “정상 케이스”뿐 아니라, 실제 운영에서 발생하는 <strong>복합적인 케이스들까지 충분히 검증</strong>할 수 있었습니다.</p><blockquote>불일치 발생 시 원인 추적 프로세스</blockquote><p>정산 결과와 수기 결과 간 불일치가 발견되면, 단순히 결과를 맞추는 것이 아니라 <strong>원인을 끝까지 추적하는 방식</strong>으로 접근했습니다.</p><p>불일치 발생 시 다음 순서로 원인을 분석했습니다.</p><ol><li>원천 데이터 자체의 차이 여부 확인</li><li>단가/프로모션 기준 적용 여부 점검</li><li>정책적으로 정의되지 않았던 엣지 케이스 식별</li></ol><p>기술적인 오류인 경우 로직을 수정했고, 정책적으로 판단이 필요한 경우에는 <strong>정산 기준을 명시적으로 정리한 뒤 시스템에 반영</strong>했습니다.</p><p>이 과정을 반복하면서 정산 로직의 안정성뿐 아니라, <strong>정산 기준 자체의 모호함도 함께 해소</strong>할 수 있었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*jvK_Iqus0EJPHI6PIlKu1w.png\" /></figure><blockquote>이 단계의 의미</blockquote><p>이 실데이터 기반 리허설 단계는 단순한 QA가 아니라,</p><ul><li>정산 로직의 정확성을 검증하고</li><li>기준을 명확히 정의하며</li><li>오픈 이후 재처리 가능성까지 점검하는</li></ul><p><strong>정산 시스템의 ‘예행 연습’에 해당하는 단계</strong>였습니다.</p><p>이 과정을 충분히 거쳤기 때문에, MASS는 시스템 오픈과 동시에 <strong>실제 정산을 안정적으로 마칠 수 있었습니다.</strong></p><h3>오픈 이후 시스템 지표와 운영 결과</h3><p>MASS 구축 시점에 팀이 설정한 목표는 명확했습니다.</p><ul><li><strong>정산은 반드시 회계 마감 기한 내에 끝나야 한다</strong></li><li><strong>재처리·재실행 상황에서도 정산 결과는 흔들리지 않아야 한다</strong></li><li><strong>정산 규모가 증가해도 운영 방식이 복잡해지지 않아야 한다</strong></li><li><strong>수기 보정 없이 시스템 결과만으로 정산을 마칠 수 있어야 한다</strong></li><li><strong>일 정산은 운영 관점에서 부담 없이 반복 실행할 수 있도록, 평균 처리 시간을 10분 이내로 유지해야 한다</strong></li></ul><p>이러한 목표를 기준으로 시스템을 설계했고, 시스템 오픈 이후 현재까지 수행된 정산은 다음과 같은 결과를 보였습니다.</p><h4>정산 처리 성공률과 결과 확정 안정성</h4><p>MASS에서 말하는 “정산 성공”은 단순히 배치가 오류 없이 종료되었다는 의미가 아닙니다.</p><p>본 문서에서의 정산 성공은 다음 조건을 모두 만족하는 경우를 의미합니다.</p><ul><li>정산 배치가 <strong>중단 없이 완료</strong></li><li>모든 정산 대상 데이터가 <strong>정합성 검증을 통과</strong></li><li>수기 보정 없이 <strong>시스템 계산 결과만으로 정산 결과 확정</strong></li><li>회계 마감 기한 내 모든 <strong>정산 상태가 COMPLETED로 전이</strong></li></ul><p>이 기준으로 시스템 오픈 이후 수행된 정산 결과는 다음과 같습니다.</p><ul><li><strong>일 정산 성공률: 100%</strong></li><li><strong>월 정산 성공률: 100%</strong></li><li><strong>월 정산 마감 확정 성공률: 100%</strong></li></ul><p>모든 정산은 마감 기한 내 정상적으로 완료되었으며, 정산 결과 확정 과정에서도 <strong>정합성 이슈나 수기 개입 없이 </strong>시스템 결과만으로 정산을 마무리할 수 있었습니다.</p><h4>정산 처리 시간</h4><ul><li><strong>일 정산 평균 소요 시간:</strong> 약 <strong>8분 26초</strong></li><li><strong>월 정산 평균 소요 시간:</strong> 약 <strong>2분 27초</strong></li></ul><p>일 정산의 경우, 초기 목표로 설정했던 <strong>‘10분 이내 처리’ 기준을 안정적으로 만족</strong>하고 있으며, 정산 대상 규모와 관계없이 일정한 처리 시간을 유지하고 있습니다.</p><p>이는 정산 배치가</p><ul><li>데이터 규모 증가</li><li>재실행</li><li>반복 실행</li></ul><p>과 같은 운영 시나리오에서도 부담 없이 실행될 수 있도록 설계되었음을 의미합니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/548/1*iSeBKNxGUiSUG_hswfYe3A.png\" /></figure><h4>재처리 상황에서도 유지되는 정합성</h4><p>12월 3일, upstream 시스템의 재고 스냅샷 이슈로 인해 해당 일자의 정산 데이터를 다시 계산해야 하는 상황이 발생했습니다.</p><p>정산 도메인에서 이와 같은 상황은 단순한 기술적 오류를 넘어, <strong>중복 청구, 과소·과대 정산, 파트너 업체 신뢰 훼손</strong>으로 직결될 수 있는 명확한 비즈니스 리스크를 동반합니다.<br>특히 월 마감 직전이었다면, 회계 마감 지연이나 수기 보정으로 이어질 가능성도 있었습니다.</p><p>이 상황에서 MASS는 기존 정산 결과를 임의로 수정하거나 덮어쓰는 대신,</p><ul><li>해당 일자의 정산 대상 원천 데이터만을 기준으로 재처리를 수행했고</li><li>멱등성 기반 처리로 <strong>중복 정산 없이 안전하게 재계산</strong>했으며</li><li>재처리 이후에도 <strong>정산 결과는 기존 기준과 동일하게 유지</strong>되었습니다.</li></ul><p>그 결과, 최초 정산 시점과 재처리 이후의 금액 차이에 대해서는 파트너 업체에 <strong>변경 사유와 함께 정산 결과를 다시 공유</strong>해야 했지만,</p><ul><li>변경된 금액이 어떤 기준에서 발생했는지 명확하게 설명할 수 있었고</li><li>수기 계산이나 임시 보정 없이 <strong>시스템 결과만으로 정산을 확정</strong>할 수 있었으며</li><li>회계 마감 일정 역시 영향을 받지 않았습니다.</li></ul><p>이 사례는 재처리와 복구를 전제로 한 설계가 단순히 “다시 계산할 수 있다”는 수준을 넘어, <strong>장애 상황에서도 정산 변경을 통제 가능한 방식으로 관리하며 비즈니스 리스크를 최소화했음을 보여주는 사례</strong>였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*MrJnJCWQWmq5WrvdMVZBaw.png\" /></figure><h4>수기 정산 프로세스 변화</h4><p>시스템 도입 전후의 정산 프로세스는 다음과 같이 변화했습니다.</p><p><strong>As-Is (수기 정산 — 6단계)</strong></p><ul><li>물류 데이터 추출</li><li>금액 산정(정산)</li><li>정산서 작성</li><li>품의 상신</li><li>품의 승인</li><li>세금계산서 반영</li></ul><p><strong>To-Be (시스템 정산 — 2단계)</strong></p><ul><li>정산 금액 확인</li><li>세금계산서 반영</li></ul><p>기존 <strong>6단계에 달하던 수기 정산 프로세스는 </strong>단 <strong>2단계의 확인 중심 프로세스로 축소</strong>되었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*PStZqs6VZ_2Jj1OQwB6Mzg.png\" /></figure><h4>정산 마감 소요 시간 변화</h4><p>정산 대상 업체 수가 증가함에 따라, 기존 수기 정산 방식은 <strong>업체 수에 정비례하여 작업 시간이 증가하는 구조</strong>였습니다.</p><ul><li><strong>정산 대상 40개 업체 기준</strong></li><li>수기 정산 마감 소요 시간: 약 <strong>23시간</strong></li><li><strong>정산 대상 100개 업체 기준</strong></li><li>수기 정산 마감 소요 시간: 약 <strong>30시간 이상</strong></li></ul><p>정산 마감은 영업일 기준 <strong>D+2(총 16 근무시간)</strong> 내 완료가 필요했기 때문에, 담당자 1명 기준으로는 <strong>40개 업체가 사실상 처리 가능한 한계</strong>였습니다.</p><p>반면, MASS 도입 이후에는 정산 방식이 근본적으로 달라졌습니다.</p><ul><li>정산 대상 업체 수와 무관하게</li><li><strong>월 정산 마감 확정까지 약 1시간 내 완료</strong></li></ul><p>즉,</p><ul><li>40개 업체 기준: <strong>23시간 → 1시간</strong></li><li>100개 업체 기준: <strong>30시간 → 1시간</strong></li></ul><p>정산 시스템 도입을 통해 <strong>정산 규모가 증가해도 마감 기한을 안정적으로 지킬 수 있는 구조</strong>를 확보했습니다.</p><blockquote>정산 방식에 따른 마감 소요 시간 비교</blockquote><p>아래 그래프는 정산 대상 업체 수 증가에 따른 <strong>수기 정산 방식과 시스템 정산 방식의 차이</strong>를 직관적으로 보여줍니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*YoHHgxcg181mGeTNOLjI1A.png\" /><figcaption>(베이지: 수기 / 주황: MASS)</figcaption></figure><p>이 그래프가 보여주듯,</p><ul><li>수기 정산은 <strong>업체 수 증가 = 마감 리스크 증가</strong></li><li>MASS 정산은 <strong>업체 수 증가와 무관한 일정한 처리 시간</strong></li></ul><p>이라는 차이를 가집니다.</p><p>이는 단순한 자동화 효과가 아니라, 정산 업무를 <strong>사람의 처리 한계에서 시스템 처리 한계로 전환</strong>한 결과였습니다.</p><h4>정산 데이터 제공 주기 변화</h4><p>정산 결과의 가시성 역시 크게 개선되었습니다.</p><ul><li><strong>정산 데이터 제공 주기:</strong> 월 1회 → <strong>매일</strong></li><li><strong>파트너 업체 조회 가능 시점:</strong> 매일 <strong>오전 11시</strong></li></ul><p>이를 통해 파트너 업체는 월 마감 이후가 아니라, 운영 중에도 매일 비용을 확인하고 관리할 수 있게 되었습니다.</p><h3>마치며</h3><p>정산 자동화의 진짜 가치는 단순한 시간 단축에 있지 않습니다. MASS는 정산을 사람의 경험과 기억이 아닌, 시스템의 책임으로 옮겼습니다.</p><p>이번 시리즈를 통해 정산이라는 어려운 도메인을 어떻게 설계하고, 구현하고, 운영으로 안착시켰는지를 공유했습니다. <br>MASS의 정산 자동화는 시작에 불과하며, 앞으로도 다양한 정산 도메인으로 확장해 나갈 예정입니다.</p><h3>Platform Business Operation 조직 및 팀 소개</h3><blockquote><em>무신사 플랫폼 비즈니스 오퍼레이션 조직은 국내외 물류 서비스, 재고 관리, 스토어 운영을 위한 물류 프로덕트를 구축하고 다양한 오프라인 비즈니스 모델에 맞춘 스토어 관리 시스템을 개발·고도화하고 있습니다.<br>또한, 무배당발 서비스를 포함한 무신사의 차별화된 고객 경험을 브랜딩하고 확장할 수 있는 멤버십 구조를 설계하며, 온·오프라인을 넘나드는 통합 커머스 경험을 기술로 실현하고 있습니다.</em></blockquote><blockquote><em>저희 팀은 OMS(주문관리시스템)를 기반으로 온라인 주문부터 재고·출고·배송·정산에 이르는 전 과정을 유기적으로 연결하고, 무신사의 다양한 오프라인 스토어를 효과적으로 운영할 수 있는 관리 시스템을 구축하여 고객이 온라인(무신사 스토어, 29CM 등)과 오프라인(무신사 스탠다드, 편집숍 등)에서 끊김 없는 쇼핑 경험을 누릴 수 있도록 지원합니다.</em></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/pbo\"><em>🚀 Platform Business Operation 한걸음 더 알아보기</em></a></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/home\"><em>🚀 팀 무신사 채용 페이지</em></a><em> (무신사/29CM 전체 포지션 확인이 가능해요)</em></blockquote><blockquote><em>🚀 </em><a href=\"https://kr.linkedin.com/company/musinsacom\"><em>팀 무신사 테크 소식을 받아보는 링크드인</em></a></blockquote><blockquote><em>🚀 </em><a href=\"https://newsroom.musinsa.com/\"><em>팀 무신사 뉴스룸</em></a></blockquote><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=4f09ae3bdf5d\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://techblog.musinsa.com/%EC%9D%B4%EB%B2%88-%EB%8B%AC%EB%8F%84-%EB%B0%A4%EC%83%98-%EC%A0%95%EC%82%B0%EC%9E%85%EB%8B%88%EB%8B%A4-%EB%8D%94-%EC%9D%B4%EC%83%81-%EB%B0%A4%EC%83%98%ED%95%98%EC%A7%80-%EC%95%8A%EC%95%84%EB%8F%84-%EB%90%A9%EB%8B%88%EB%8B%A4-%EC%9A%B4%EC%98%81%ED%8E%B8-4f09ae3bdf5d\">“이번 달도 밤샘 정산입니다.” — 더 이상 밤샘하지 않아도 됩니다 (운영편)</a> was originally published in <a href=\"https://techblog.musinsa.com\">MUSINSA techblog — 무신사 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2026-02-02T09:01:05.000Z",
    "url": "https://techblog.musinsa.com/%EC%9D%B4%EB%B2%88-%EB%8B%AC%EB%8F%84-%EB%B0%A4%EC%83%98-%EC%A0%95%EC%82%B0%EC%9E%85%EB%8B%88%EB%8B%A4-%EB%8D%94-%EC%9D%B4%EC%83%81-%EB%B0%A4%EC%83%98%ED%95%98%EC%A7%80-%EC%95%8A%EC%95%84%EB%8F%84-%EB%90%A9%EB%8B%88%EB%8B%A4-%EC%9A%B4%EC%98%81%ED%8E%B8-4f09ae3bdf5d?source=rss----f107b03c406e---4"
  },
  {
    "publisherId": "musinsa",
    "publisherName": "무신사 테크블로그",
    "specTitle": "e커머스 개발",
    "categories": [
      "backend"
    ],
    "specUrl": "https://medium.com/feed/musinsa-tech",
    "title": "“이번 달도 밤샘 정산입니다.” — 정산 시스템은 어떻게 만들었을까 (실전편)",
    "partialText": "<h3>“이번 달도 밤샘 정산입니다.” — 정산 시스템은 어떻게 만들었을까 (실전편)</h3><p>“이번 달도 밤샘 정산입니다.” 테크 블로그 시리즈</p><ol><li><a href=\"https://techblog.musinsa.com/%EC%9D%B4%EB%B2%88-%EB%8B%AC%EB%8F%84-%EB%B0%A4%EC%83%98-%EC%A0%95%EC%82%B0%EC%9E%85%EB%8B%88%EB%8B%A4-%EC%A0%95%EC%82%B0-%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%80-%EC%96%B4%EB%96%BB%EA%B2%8C-%EB%A7%8C%EB%93%A4%EC%97%88%EC%9D%84%EA%B9%8C-%EC%8B%A4%EC%A0%84%ED%8E%B8-74d8a5d22ba1\"><strong>정산 시스템은 어떻게 만들었을까 (실전편)</strong></a></li><li><a href=\"https://techblog.musinsa.com/22732a4a607f\">정산 시스템은 왜 필요했을까 (설계편)</a></li><li><a href=\"https://techblog.musinsa.com/이번-달도-밤샘-정산입니다-더-이상-밤샘하지-않아도-됩니다-운영편-4f09ae3bdf5d\">더 이상 밤샘하지 않아도 됩니다 (운영편)</a></li></ol><h3>들어가며</h3><p>앞선 글에서는 정산 시스템이 왜 본질적으로 어려운 문제인지, 그리고 MASS가 멱등성과 결정적 계산이라는 설계 원칙을 선택한 이유를 살펴보았습니다. <br>이번 글에서는 그 설계가 실제로 어떤 기술 선택과 구조를 통해 구현되었는지, MASS 정산 시스템의 실전 구축 과정을 이야기합니다.</p><h3>멱등성을 전제로 한 이벤트 처리</h3><p>정산에 사용되는 원천 데이터는 이벤트 형태로 유입됩니다.<br>이벤트 기반 시스템에서 중복 수신이나 재처리는 피할 수 없는 상황이기 때문에, MASS에서는 이를 <strong>전제 조건</strong>으로 두었습니다.</p><ul><li>이벤트 재시도(Retry)와 격리(DLT)를 분리해 처리</li><li>트랜잭션 식별자를 기준으로 서비스 레벨에서 멱등 갱신</li><li>동일 이벤트가 여러 번 처리되어도 결과는 항상 동일</li></ul><p>이를 통해 장애 상황에서도 안전하게 재처리할 수 있는 기반을 마련했습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*WVBTqEPRTnxzFRF5ux3o_Q.png\" /></figure><p>(⬆️ 1편 내용)</p><h4>DLT 메시지 모니터링과 처리 방식</h4><p>DLT로 전달된 이벤트는 <strong>정산 흐름에서 즉시 제외</strong>되며, 별도의 모니터링과 운영 프로세스를 통해 관리됩니다.</p><ul><li>DLT 발생 시 즉시 알림을 통해 운영자가 인지할 수 있도록 구성</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*jeNo9FnMmvUBNGb-NoSXtw.png\" /></figure><ul><li>DLT 메시지는 원본 이벤트와 동일한 컨텍스트를 유지한 채 저장</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*EMx-OyThRv5VNbvZEdccLQ.png\" /></figure><ul><li>이벤트 페이로드, 트랜잭션 식별자, 실패 사유를 기준으로 원인 분석 가능</li><li>정책 오류, 데이터 품질 문제 등 원인이 명확한 경우 기준 정리 후 재처리 수행</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/818/1*2u_Johv6F-ibbNFJZYBGDg.png\" /></figure><p>이를 통해 <strong>문제 있는 이벤트가 전체 정산 흐름을 멈추는 상황을 방지</strong>하면서도, 사후 분석과 재처리를 위한 정보는 모두 보존합니다.</p><h4>실제 운영 중 DLT 발생 현황</h4><p>시스템 오픈 이후 실제 운영 환경에서 발생한 DLT 이벤트는 전체 이벤트 대비 <strong>극히 낮은 비율</strong>로 유지되고 있습니다.</p><ul><li>DLT 발생 비율: <strong>전체 이벤트 중 0.001% 미만</strong></li><li>DLT로 격리된 이벤트 역시 정산 결과에는 영향을 주지 않음</li></ul><p>정산과 같이 결과의 정합성이 중요한 도메인에서 “실패를 격리하되, 전체 흐름은 멈추지 않는다”는 설계 의도가 운영 단계에서도 그대로 유지되고 있습니다.</p><h3>MASS의 모듈 구성</h3><p>MASS는 크게 세 개의 독립적인 애플리케이션 모듈로 나뉩니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*CiuUuW5tzyBNchxaGptz4A.png\" /></figure><h4>mass-consumer</h4><ul><li>물류 서비스 유형별 원천 데이터를 메시지로 수신하는 애플리케이션</li><li>Kafka를 통해 이벤트를 소비</li><li>멱등 처리 후 정산 원천 데이터로 저장</li><li>이벤트 기반 처리 영역의 진입점 역할</li></ul><h4>mass-batch</h4><ul><li>일/월 정산을 수행하는 배치 애플리케이션</li><li>정산 집계, 마감, 리포트 생성</li><li>Kafka 복구 잡 등 운영 유틸리티 배치 포함</li><li>재처리와 복구를 전제로 한 실행 구조</li></ul><h4>mass-api</h4><ul><li>내부 운영자와 파트너 업체를 위한 REST API 제공</li><li>정산, 프로모션 등의 데이터 조회 및 관리 기능</li><li>정산 결과를 외부에 안전하게 노출하는 인터페이스</li></ul><h4>재처리와 복구를 전제로 한 실행 구조</h4><p>정산 배치는 실패 가능성을 전제로 설계되었습니다.<br>중요한 것은 배치가 실패했을 때 <strong>어디서부터 다시 실행할 수 있는가</strong>가 아니라, <strong>어떤 상태를 기준으로 정산을 다시 정의할 수 있는가</strong>였습니다.</p><p>MASS에서는 이를 위해 정산 대상 원천 데이터에 명시적인 <strong>정산 상태 컬럼</strong>을 두고 배치 실행 흐름을 관리합니다.</p><p>정산 상태는 다음과 같이 관리됩니다.</p><ul><li><strong>PENDING</strong>: 정산 대상 후보 상태</li><li><strong>PROCESSING</strong>: 현재 정산 배치에서 처리 중인 상태</li><li><strong>COMPLETED</strong>: 정산이 정상 완료된 상태</li></ul><blockquote><strong>배치 실행 흐름과 상태 전이</strong></blockquote><p>정산 배치는 다음 순서로 수행됩니다.</p><ol><li>배치 시작 시점에 해당 실행의 정산 대상 원천 데이터만 <strong>PENDING → PROCESSING</strong> 상태로 마킹</li><li>마킹된 데이터만을 기준으로 step 별 <strong>chunk 단위 처리</strong> 수행</li><li>모든 step이 정상 완료되면 처리된 데이터의 상태를 <strong>COMPLETED</strong>로 전이</li><li>배치가 중간에 실패할 경우 해당 실행에서 <strong>PROCESSING 상태로 마킹되었던 데이터들을 다시 PENDING으로 롤백</strong></li></ol><p>이 구조를 통해 배치는 chunk 단위로 실행되지만, <strong>복구와 재처리의 기준은 항상 “정산 대상 전체”로 유지</strong>됩니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*v7YCvHYRi9pg9BFpq3F6Vw.png\" /></figure><blockquote><strong>재시도 시 처리 방식</strong></blockquote><p>배치 재시도 시에는 이전 실행 결과를 이어서 처리하지 않습니다.</p><ul><li>이전 실행에서 PROCESSING 상태였던 데이터는 모두 롤백</li><li>재시도 시점에 다시 정산 대상 데이터를 선정해 <strong>PROCESSING으로 재마킹</strong></li><li>이후 멱등성을 전제로 한 <strong>upsert 방식</strong>으로 정산 재수행</li></ul><p>이를 통해 재실행 시에도</p><ul><li>중복 정산 없이</li><li>동일한 기준으로</li><li>항상 동일한 결과를 얻을 수 있습니다.</li></ul><blockquote><strong>실제 재처리 사례: 12월 3일 재고 스냅샷 이슈</strong></blockquote><p>12월 3일, upstream 시스템의 재고 스냅샷 이슈로 인해 해당 일자의 정산 데이터에 대해 재처리가 필요했습니다.</p><p>이 경우 MASS에서는</p><ul><li>12월 3일 정산 대상 원천 데이터만 <strong>PENDING 상태로 롤백</strong></li><li>이슈 해결 후 동일 날짜의 정산 재실행</li></ul><p>재처리는 chunk 단위로 수행되었지만, 정산 대상 상태를 기준으로 재정의했기 때문에 중복 반영이나 부분 정산 없이 <strong>정산 결과를 처음부터 다시 계산</strong>할 수 있었습니다.</p><p>그 결과,</p><ul><li>다른 날짜의 정산 결과에는 영향을 주지 않았고</li><li>재처리 이후에도 <strong>정산 금액은 기존 기준과 동일하게 유지</strong>되었습니다.</li></ul><h3>이벤트 + 배치 하이브리드 구조</h3><p>MASS는 정산 도메인의 특성에 맞게, <strong>이벤트 기반 처리와 배치 기반 처리를 목적에 따라 분리한 하이브리드 구조</strong>로 설계되어 있습니다.</p><p>실시간에 가까운 데이터 반영이 필요한 영역과, 회계 마감처럼 안정성과 재현성이 중요한 영역의 요구사항이 다르기 때문입니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*cGARaSH-ca10vR3LYjUU1g.png\" /></figure><h4>이벤트 기반 처리 영역</h4><p>이벤트 기반 영역은 <strong>정산의 ‘원천 데이터’를 책임지는 영역</strong>입니다.</p><ul><li>물류 서비스 유형별로 발생하는 원천 이벤트를 수신</li><li>이벤트 중복이나 재처리를 고려한 멱등 저장</li></ul><p>이 영역은 <em>데이터를 빠르게 수집</em>하는 데 초점을 둡니다.</p><h4>배치 기반 처리 영역</h4><p>배치 기반 영역은 <strong>정산의 ‘확정’과 ‘마감’을 책임지는 영역</strong>입니다.</p><ul><li>일/월 단위 정산 대상 집계</li><li>정산 마감 처리</li><li>정산 리포트 생성</li><li>실패 시 재처리를 고려한 복구용 배치 운영</li></ul><p>이 영역은 속도보다는 <strong>안정성과 재현성</strong>을 우선하며, 동일 조건에서 언제 실행해도 같은 결과를 내는 것을 목표로 합니다.</p><h3>왜 이런 구조를 선택했는가</h3><p>이 구조를 통해 MASS는 다음 두 가지를 동시에 만족시킬 수 있었습니다.</p><ul><li>이벤트 기반 구조로 <strong>실시간에 가까운 데이터 가시성 확보</strong></li><li>배치 기반 구조로 <strong>회계 마감의 안정성과 재현성 보장</strong></li></ul><p>결과적으로 MASS는 <strong>“빠르게 변하는 데이터”와 “확정되어야 하는 숫자”를 하나의 시스템 안에서 충돌 없이 다룰 수 있는 구조</strong>를 갖추게 되었습니다.</p><h3>기술 선택과 그 배경</h3><p>앞선 섹션에서 MASS가 이벤트 기반과 배치 기반을 혼합한 구조를 선택한 이유를 설명했습니다.<br>이 섹션에서는 그 구조를 실제로 구현하기 위해 <strong>어떤 기술 스택을 선택했고, 그 선택이 정산 도메인에 왜 적합했는지</strong>를 정리합니다.</p><p>MASS에서의 기술 선택은 “어떤 기술이 더 최신인가”가 아니라 <strong>정산이라는 도메인의 핵심 요구사항인 ‘정합성, 재처리 가능성, 운영 안정성’을 얼마나 잘 만족시키는가</strong>를 기준으로 이루어졌습니다.</p><h4>전체 기술 스택 요약</h4><p>MASS는 JVM 기반의 안정적인 기술 스택 위에서 다음과 같이 구성되어 있습니다.</p><p><strong>언어 / 런타임</strong></p><ul><li>JVM 기반 (Kotlin)</li></ul><p><strong>애플리케이션 프레임워크</strong></p><ul><li>Spring Boot</li><li>Spring Batch (정산 배치 및 마감 처리)</li></ul><p><strong>메시징</strong></p><ul><li>Kafka (원천 데이터 이벤트 수신)</li></ul><p><strong>데이터베이스</strong></p><ul><li>MySQL (정산 결과의 Source of Truth)</li></ul><p><strong>운영 / 모니터링</strong></p><ul><li>배치 실행 상태 및 실패 로그 기반 모니터링</li><li>DLT 이벤트 및 배치 실패 시 알림 연계</li><li>에러, Latency, 인프라 모니터링</li></ul><p>이 스택은 고성능보다는 <strong>예측 가능성, 재현성, 장애 대응 용이성</strong>을 우선한 선택입니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*VN591bZIeeRGbdtCTpbxaw.png\" /></figure><h4>Kafka를 통한 원천 데이터 수신</h4><p>정산에 사용되는 원천 데이터는 다음과 같은 특성을 가집니다.</p><ul><li>입·출고, 재고 스냅샷 등 <strong>트래픽이 특정 시점에 집중</strong></li><li>동일 이벤트의 <strong>중복 수신, 재전송, 재처리 가능성</strong></li><li>일시적인 장애가 있더라도 <strong>데이터 유실은 절대 허용 불가</strong></li></ul><p>이러한 특성 때문에, 원천 데이터를 API 호출 방식으로 동기 수신하는 구조는 적합하지 않다고 판단했습니다.</p><p>Kafka 기반 이벤트 수신 방식은</p><ul><li>원천 데이터를 <strong>비동기로 안정적으로 적재</strong>할 수 있고</li><li>소비자 장애와 무관하게 이벤트를 보존할 수 있으며</li><li>동일 이벤트를 다시 소비하는 방식으로 <strong>재처리를 자연스럽게 지원</strong>합니다</li></ul><p>정산 데이터는 “빨리 처리되는 데이터”보다 <strong>“언제든 다시 처리할 수 있어야 하는 데이터”</strong>였기 때문에, MASS는 Kafka를 원천 데이터 수신 방식으로 선택했습니다.</p><h4>Spring Batch 기반의 정산 처리</h4><p>정산 처리에서 가장 중요한 요구사항은 실시간성이 아니라 다음과 같았습니다.</p><ul><li>회계 마감 기준에 맞는 <strong>명확한 실행 시점</strong></li><li>실패를 전제로 한 <strong>재처리·복구 구조</strong></li><li>실행 이력과 결과를 추적할 수 있는 <strong>감사 가능성</strong></li></ul><p>이를 위해 정산 집계와 마감 처리는 Spring Batch 기반으로 설계했습니다.</p><blockquote><strong>배치 실행 환경과 제어 방식</strong></blockquote><p>MASS는 Kubernetes 기반의 <strong>EKS 환경</strong>에서 운영되고 있으며, 정산 배치 역시 이 환경에 맞는 실행 구조를 갖도록 설계했습니다.</p><p>정산 배치는 애플리케이션 내부 스케줄러에 의해 자동 실행되는 방식이 아니라,</p><ul><li><strong>Spring Batch 기반의 batch 애플리케이션</strong>을 컨테이너로 구성하고</li><li>배치 실행 시점과 흐름은 <strong>Argo Workflow</strong>를 통해 외부에서 제어하는 방식으로 운영됩니다</li></ul><p>즉, Spring Batch는 <em>정산 로직과 실행 상태 관리</em>를 담당하고, 배치의 실행 시점과 재실행 제어는 <strong>Argo Workflow가 책임지는 구조</strong>입니다.</p><p>이를 통해 정산 배치는 “코드 안에 숨어 있는 백그라운드 작업”이 아니라, <strong>EKS 환경에서 명시적으로 관리되는 워크플로우 단계</strong>가 되었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/496/1*LAdmMX51xIOBKN3RHUGWRg.png\" /></figure><blockquote><strong>Job Parameter 기반 실행</strong></blockquote><p>Argo Workflow는 정산 배치를 실행할 때,</p><ul><li>정산 기준 날짜</li><li>정산 기준 타입</li></ul><p>등을 <strong>Job Parameter로 전달</strong>합니다.</p><p>이를 통해 MASS의 정산 배치는</p><ul><li>동일한 코드로</li><li>서로 다른 기간과 기준을</li><li>실행 이력으로 명확히 구분된 형태로 수행할 수 있습니다</li></ul><p>“어떤 기준으로, 언제 실행된 정산인지”가 로그가 아니라 <strong>Batch Execution 이력 자체로 추적 가능</strong>해졌습니다.</p><blockquote><strong>Spring Batch 선택 이유와 실행 모델</strong></blockquote><p>Spring Batch는</p><ul><li>Job / Step / Execution 단위로 <strong>실행 상태와 이력 관리</strong></li><li>대용량 데이터를 <strong>chunk 단위로 안정적으로 처리</strong></li><li>실패 시 <strong>재실행 시점 제어</strong></li></ul><p>를 기본적으로 제공합니다.</p><p>이 특성은 정산 배치를 “한 번 실행하고 끝나는 작업”이 아니라, <strong>실패와 재실행을 전제로 운영되는 작업</strong>으로 만드는 데 적합했습니다.</p><blockquote><strong>정산 대상 마킹 기반 실행 흐름</strong></blockquote><p>MASS에서는 배치 실행 시 다음과 같은 흐름을 따릅니다.</p><ol><li>배치 시작 시 해당 실행의 <strong>정산 대상 원천 데이터만 선별</strong></li><li>선별된 데이터의 정산 상태를 PENDING → PROCESSING으로 일괄 마킹</li><li>마킹된 데이터만을 기준으로 Step 별 <strong>chunk 단위 처리 수행</strong></li><li>모든 Step이 정상 완료되면 정산 상태를 COMPLETED로 전이</li><li>중간 실패 시 PROCESSING 상태 데이터를 다시 PENDING으로 롤백</li></ol><p>이 구조를 통해 배치는 chunk 단위로 실행되지만, <strong>재처리의 기준은 항상 ‘정산 대상 전체’로 유지</strong>됩니다.</p><p>즉, 배치가 어느 지점에서 실패하더라도 이전 실행 결과에 의존하지 않고 정산 대상 단위로 <strong>처음부터 다시 실행할 수 있는 구조</strong>를 만들었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*85NH0_qvf4s9kq_9hal8KQ.png\" /></figure><blockquote><strong>운영 관점에서의 의미</strong></blockquote><p>Spring Batch와 Argo Workflow를 결합한 이 실행 환경을 통해, 정산 배치는</p><ul><li>EKS 환경에서 <strong>운영자가 명시적으로 제어 가능한 작업</strong>이 되었고</li><li>실행 실패 역시 <strong>운영 이벤트로 인지하고 대응할 수 있는 대상</strong>이 되었으며</li><li>재실행이 두려운 배치가 아니라 <strong>언제든 다시 돌릴 수 있는 배치</strong>가 되었습니다</li></ul><p>그 결과 MASS의 정산 배치는 회계 마감이라는 높은 안정성이 요구되는 영역에서도 안전하게 운영될 수 있는 기반을 갖추게 되었습니다.</p><h4>데이터베이스 선택과 정합성 보장</h4><p>정산 결과는 반드시 <strong>하나의 기준(Source of Truth)</strong>으로 관리되어야 했기 때문에, MASS는 트랜잭션 처리가 명확한 <strong>RDB(MySQL)</strong>를 정산 결과 저장소로 선택했습니다.</p><p>RDB를 선택함으로써 다음을 명확히 할 수 있었습니다.</p><ul><li>정산 결과의 <strong>정합성 보장</strong></li><li>트랜잭션 단위의 상태 전이 관리</li><li>트랜잭션 식별자를 기준으로 한 <strong>멱등성 갱신(upsert)</strong></li></ul><p>이는 이벤트 중복, 재처리, 장애 복구 상황에서도 정산 결과가 흔들리지 않도록 하는 핵심 기반이 되었습니다.</p><h4>운영 / 모니터링 체계</h4><p>정산 시스템에서 운영과 모니터링은 “장애를 없애는 것”보다 <strong>장애를 빠르게 인지하고, 영향 범위를 통제하는 것</strong>이 더 중요했습니다.</p><p>MASS에서는 이를 위해 실시간 모니터링과 함께 <strong>주기적인 점검을 결합한 운영 체계</strong>를 구성했습니다.</p><p><strong>배치 실행 상태 및 실패 로그 기반 모니터링</strong></p><ul><li>일/월 정산 배치의 실행 성공 여부</li><li>Step 단위 실패 지점 및 재시도 여부</li><li>마감 미완료 상태에 대한 조기 감지</li></ul><p><strong>DLT 이벤트 및 배치 실패 시 알림 연계</strong></p><ul><li>재시도 한계를 초과한 이벤트는 DLT로 격리</li><li>DLT 발생 및 배치 실패 시 즉시 알림을 통해 인지</li><li>장애 상황에서도 원천 데이터 유실 없이 후속 조치 가능</li></ul><p><strong>에러, Latency, 인프라 지표 모니터링</strong></p><ul><li>이벤트 소비 지연(Lag) 및 처리 Latency 관측</li><li>애플리케이션 에러율과 비정상 트래픽 감지</li><li>인프라 리소스(CPU, Memory) 사용량을 통한 병목 사전 인지</li></ul><p><strong>주 단위 시스템 상태 점검</strong></p><ul><li>주 단위로 트래픽, 에러, Latency, 인프라 지표 추이 점검</li><li>잠재적인 성능 저하나 이상 징후를 사전에 식별하고 개선</li></ul><p>이러한 운영 체계를 통해 MASS는 장애가 발생한 이후에 대응하는 방식이 아니라, <strong>문제가 되기 전에 신호를 감지하고 선제적으로 조치하는 운영 방식</strong>을 갖추게 되었습니다.</p><h3>마치며</h3><p>정산 시스템의 구현에서 중요한 것은 최신 기술의 조합이 아니라, 실패와 재실행을 자연스럽게 받아들이는 구조였습니다. <br>MASS는 Kafka, Spring Batch, Argo Workflow를 통해 정산을 안정적으로 구현했고, 실패해도 다시 실행할 수 있는 시스템을 만들 수 있었습니다.</p><p>다음 글에서는 이 시스템을 어떻게 단계적으로 오픈했고, 실제 운영에서 어떤 변화와 성과를 만들었는지 살펴보겠습니다.</p><h3>Platform Business Operation 조직 및 팀 소개</h3><blockquote><em>무신사 플랫폼 비즈니스 오퍼레이션 조직은 국내외 물류 서비스, 재고 관리, 스토어 운영을 위한 물류 프로덕트를 구축하고 다양한 오프라인 비즈니스 모델에 맞춘 스토어 관리 시스템을 개발·고도화하고 있습니다.<br>또한, 무배당발 서비스를 포함한 무신사의 차별화된 고객 경험을 브랜딩하고 확장할 수 있는 멤버십 구조를 설계하며, 온·오프라인을 넘나드는 통합 커머스 경험을 기술로 실현하고 있습니다.</em></blockquote><blockquote><em>저희 팀은 OMS(주문관리시스템)를 기반으로 온라인 주문부터 재고·출고·배송·정산에 이르는 전 과정을 유기적으로 연결하고, 무신사의 다양한 오프라인 스토어를 효과적으로 운영할 수 있는 관리 시스템을 구축하여 고객이 온라인(무신사 스토어, 29CM 등)과 오프라인(무신사 스탠다드, 편집숍 등)에서 끊김 없는 쇼핑 경험을 누릴 수 있도록 지원합니다.</em></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/pbo\"><em>🚀 Platform Business Operation 한걸음 더 알아보기</em></a></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/home\"><em>🚀 팀 무신사 채용 페이지</em></a><em> (무신사/29CM 전체 포지션 확인이 가능해요)</em></blockquote><blockquote><em>🚀 </em><a href=\"https://kr.linkedin.com/company/musinsacom\"><em>팀 무신사 테크 소식을 받아보는 링크드인</em></a></blockquote><blockquote><em>🚀 </em><a href=\"https://newsroom.musinsa.com/\"><em>팀 무신사 뉴스룸</em></a></blockquote><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=74d8a5d22ba1\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://techblog.musinsa.com/%EC%9D%B4%EB%B2%88-%EB%8B%AC%EB%8F%84-%EB%B0%A4%EC%83%98-%EC%A0%95%EC%82%B0%EC%9E%85%EB%8B%88%EB%8B%A4-%EC%A0%95%EC%82%B0-%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%80-%EC%96%B4%EB%96%BB%EA%B2%8C-%EB%A7%8C%EB%93%A4%EC%97%88%EC%9D%84%EA%B9%8C-%EC%8B%A4%EC%A0%84%ED%8E%B8-74d8a5d22ba1\">“이번 달도 밤샘 정산입니다.” — 정산 시스템은 어떻게 만들었을까 (실전편)</a> was originally published in <a href=\"https://techblog.musinsa.com\">MUSINSA techblog — 무신사 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2026-01-27T05:01:27.000Z",
    "url": "https://techblog.musinsa.com/%EC%9D%B4%EB%B2%88-%EB%8B%AC%EB%8F%84-%EB%B0%A4%EC%83%98-%EC%A0%95%EC%82%B0%EC%9E%85%EB%8B%88%EB%8B%A4-%EC%A0%95%EC%82%B0-%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%80-%EC%96%B4%EB%96%BB%EA%B2%8C-%EB%A7%8C%EB%93%A4%EC%97%88%EC%9D%84%EA%B9%8C-%EC%8B%A4%EC%A0%84%ED%8E%B8-74d8a5d22ba1?source=rss----f107b03c406e---4"
  },
  {
    "publisherId": "musinsa",
    "publisherName": "무신사 테크블로그",
    "specTitle": "e커머스 개발",
    "categories": [
      "backend"
    ],
    "specUrl": "https://medium.com/feed/musinsa-tech",
    "title": "2025년 제 1회 29QA Con 진행 후기 (29QA Conference)",
    "partialText": "<p>29CM QE팀은 연말에 팀 자체적으로 Conference를 진행하였습니다.</p><p>2024년까지는 연 2회 워크샵을 진행해서 각자 레슨런을 공유하는 자리를 가졌는데 2025년에는 상반기 워크샵을 진행하지 못하여 하반기에만 진행하게 되었고 이렇게 된 김에 연 행사처럼 고유의 컨퍼런스를 개최해 보자는 생각에 29QA Con을 계획하였습니다.</p><p>나중에는 점점 규모가 커져서 다른 회사의 QA 분들도 모시고 싶다고 생각해서 처음부터 어느 정도 형식을 갖추자는 판단을 했습니다. 그래서 굿즈도 만들고 홍보 배너도 만들었는데 만들고 나니 정말 컨퍼런스 분위기가 물씬 풍겨 진행하기를 잘했다는 생각이 들었습니다.</p><p>한 달가량의 촉박한 일정이었지만 4명의 팀원이 3개 이상씩의 세션을 준비해서 총 13개의 세션이 진행되었습니다. 짧은 기간 동안 열심히 양질의 자료를 만들어서 공유해 준 팀원분들 덕분에 훌륭한 하나의 Conference가 진행될 수 있었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*a_kRGeIIOTyukVPti6WlgA.jpeg\" /><figcaption>컨퍼런스 느낌이 나도록 X배너도 제작해서 걸어두었습니다.</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*FBDeSTwJS4pZ3GP3eITbjA.jpeg\" /><figcaption>팀 마스코트인 ‘큐엉이&#39; 가 포함된 굿즈도 여러개 제작하였습니다. 스티커 빼고 완판(?) 되었답니다.</figcaption></figure><p>식순은 아래와 같이 진행되었습니다. <br>발표 15분, 쉬는 시간 5분 정도를 계획해 두었습니다.</p><pre>1.  29CM에서의 팀 셋팅, 지금의 신뢰받는 QE팀은 어떻게 만들어졌나 (박현준)<br>2.  차세대 테스트 자동화 - Vibium(조진현)<br>3.  25년 자동화 유지보수 여정 (정다정)<br>4.  iOS 자동화 1년 여정 + 코드리뷰의 중요성 (강보민)<br>5.  귀찮음을 해결했더니 팀이 빨라졌다: QA 업무 자동화 사례 (정다정)<br>6.  아무도 궁금하지 않은 QA Weekly 작성 vlog (박현준)<br>7.  혼자 할 때는 몰랐던 것들: 2인 이상의 QA로 얻은 교훈 (강보민)<br>8.  질문을 잘하는 것이 곧 살아남는 방법이다 (조진현)<br>9.  눈물과 분노없이 볼 수 없는 Cursor를 사용한 29TMS 제작기 (박현준)<br>10. 대 AI 시대 Testcase 생성 찍먹해보기 (강보민)<br>11. 글로벌 서비스 QA 시에는 무엇이 달라지나 (정다정)<br>12. 2025년 회고 (조진현)<br>13. 2025년 한해 돌아보기 (+팀 회고) (박현준)</pre><p>하지만 발표가 시작되면 어김없이 기존 발표시간이 초과되는 사태가 발생하여서 발표자분들의 열정을 느낄 수 있었지만 시간관리에는 어려움이 있었습니다. 😅</p><p>쉬는시간을 타이트하게 가져가면서 열심히 진행했던 기억이 남습니다.</p><p>1️⃣ 첫번째 세션으로는 <br>“29CM에서의 팀 셋팅, 지금의 신뢰받는 QE팀은 어떻게 만들어졌나” 가 진행되었습니다.</p><p>제가 처음으로 29CM에 입사하여 QA팀을 신설하고 지금의 조직으로 만들기까지의 과정을 팀원분들께 공유하는 시간이었습니다. 초반에 조직의 신뢰를 얻기 위해서 결과로 증명하기 위한 노력과 이후 팀 방향성을 견고히 하기 위해 어떤 액션들을 했는지에 대한 과정들을 공유하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*N4w85aXBj-lebCKf2w1wyw.jpeg\" /></figure><p>2️⃣ 두번째 세션으로는 <br>“차세대 테스트 자동화 — Vibium” 이 진행되었습니다.</p><p>Selenium을 세상에 나오게 하여 테스트 자동화의 발전을 가속화 시킨 Jason Huggins에 대한 이야기와 그가 현재 개발하고 있는 Vibium은 어떤 것이고 어떤 것이 가능하게 되는지에 대한 것을 공유하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*5eTtGCw4N-n0VjT4J316qQ.jpeg\" /></figure><p>3️⃣ 세번째 세션으로는 <br>“25년 자동화 유지보수 여정” 이 진행되었습니다.</p><p>29CM에서는 App 테스트 자동화를 2023년부터 운영하고 있는데 이 과정에서 점점 시나리오는 증가하고 기술 복잡도가 증가함으로 인해서 여러 가지 자동화 Fail 건들이 발생했습니다. 이 중에 주요 원인 3대장을 분석하였고 이를 해결하여 Fail율을 극적으로 낮출 수 있었던 과정을 공유하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*XHFZKjJC2YR9zZGYQj5tWA.jpeg\" /></figure><p>4️⃣ 네번째 세션으로는 <br>“iOS 자동화 1년 여정 + 코드 리뷰의 중요성” 이 진행되었습니다.</p><p>보민님은 최근에 iOS 자동화 Owner가 되시면서 어떻게 하면 더 효율적이고 개선된 환경으로 유지보수를 할 수 있는지에 대한 고민을 많이 하셨습니다. <br>그 과정에서 코드 리뷰의 중요성을 느끼시고 그곳에서 받은 도움과 효과를 공유하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*EhOzw8F7BhlRQlrEn1hlYQ.png\" /></figure><p>🍚 원래는 다섯번째 세션 완료 후 점심시간이였지만 시간이 좀 지나 점심시간 확보를 위해 약간 빠르게 점심식사를 하러 이동하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/816/1*2E5uOfWSn2jwqlOmg009tw.png\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/917/1*jHMYW29UTBmjlM0lY6Rcqg.png\" /><figcaption>냠냠냠!</figcaption></figure><p>5️⃣ 다섯번째 세션으로는 <br>“귀찮음을 해결했더니 팀이 빨라졌다: QA 업무 자동화 사례” 가 진행되었습니다.</p><p>QE팀은 현재 다양한 Slack bot을 사용 중에 있습니다. 테스트 결과 리포트를 도와주는 Daily Report Bot과 Google 문서들을 공유해 주는 Bot등 여러 가지의 Bot이 있는데, 이 Bot들을 개발하면서 진행하게 된 개선 활동에 대한 레슨런을 공유하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*EUy-GsVpgGAtwMQSpbAZPw.png\" /></figure><p>6️⃣ 여섯번째 세션으로는 <br>“아무도 궁금하지 않은 QA Weekly 작성 vlog” 가 진행되었습니다.</p><p>제가 매주 작성하고 있는 QA Weekly에 관한 내용입니다. 이것을 작성하기 위해 제가 어떤 과정을 진행하고 있는지에 대한 이야기였는데, 모두 궁금하지는 않았겠지만 의외로(?) 많은 시간과 노력이 들어가고 있다는 내용을 공유하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*A0Q8OS4seRa3dgPVJIy6OQ.png\" /></figure><p>7️⃣ 일곱번째 세션으로는 <br>“혼자 할 때는 몰랐던 것들: 2인 이상의 QA로 얻은 교훈” 이 진행되었습니다.</p><p>작년 상반기까지만 해도 1인 QA로 진행하는 업무들이 많았습니다. 하반기부터는 외주 QA분들과 함께하게 되면서 이제 2인 이상 QA업무를 같이 진행하는 경우가 많이 생겼는데, 이러한 과정에서 어떤 레슨런이 있었는지에 대한 내용을 공유하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*-XjOLHm2jIC0bnr3uE0DYQ.png\" /></figure><p>8️⃣ 여덟번째 세션으로는 <br>“질문을 잘하는 것이 곧 살아남는 방법이다” 가 진행되었습니다.</p><p>사내에서도 AI을 적극적으로 사용하는 것을 권장하기 때문에 작년에 QE팀도 다양한 AI 도구들을 사용할 수 있었습니다. 이 과정에서 프롬프트 엔지니어링에 대해 고민을 하였고, 내가 원하는 방향의 답변과 결과를 얻기 위해서 어떠한 질문들을 해야 하는지에 대한 고민과 연구를 진행한 내용을 공유하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*359U7U9nuXb0nrLMQK0TVA.png\" /></figure><p>9️⃣ 아홉번째 세션으로는 <br>“눈물과 분노 없이 볼 수 없는 Cursor를 사용한 29TMS 제작기” 가 진행되었습니다.</p><p>이건 아쉽게도 영상으로 찍히지 않아서 세션 진행 자료가 없습니다. 😢 그래서 발표 자료로 대체해야 할 것 같습니다.</p><p>AI 에이전트 관련 세션인 만큼 발표자료는 AI를 활용한 이미지 생성으로 진행하였는데, 각 사례에 맞는 이미지를 생성하면서 제가 생각한 이미지가 정확히 나왔을때 즐거워하며 작업던 기억이 있습니다.</p><p>테스트케이스 관리 도구의 불편함을 개선하기 위해 초반에는 Cursor로 개발을 시작하였고 후반부에는 Claude code로 전환하여 개발을 완료하게 된 29TMS (Testcase Management System)에 관련된 이야기입니다. 현재는 1.9 버전이 업데이트 되어서 초기에 비해 사용성이 대폭 증가하였고 3개월 넘는 기간 동안 실무에서 잘 사용중입니다.</p><blockquote>관련 블로그: <a href=\"https://techblog.musinsa.com/ai와의-성공적인-첫-co-work-바이브-코딩으로-탄생된-맞춤형-testcase-management-system-29tms-74062a620119\">AI와의 성공적인 첫 Co Work — 바이브 코딩으로 탄생된 맞춤형 Testcase Management System (29TMS)</a></blockquote><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/996/1*IPlQRzqXZX5tsIpuPNkd_w.png\" /><figcaption>나노바나나야 고마워</figcaption></figure><p>🔟 열번째 세션으로는 <br>“대 AI 시대 Testcase 생성 찍먹해보기” 가 진행되었습니다.</p><p>3가지의 생성형 AI 도구를 대상으로 테스트케이스 생성에 대한 품질 테스트를 진행한 내용입니다. 어떤 AI는 어느 부분에 강점이 있었고 최종적으로는 어떤 AI 도구가 가장 높은 점수의 테스트케이스 생성 능력을 보여주었는지에 대한 과정을 공유하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*WDYEbaAPJPl1EQN3RvYmvA.png\" /></figure><p>1️⃣1️⃣ 열한번째 세션으로는<br>“글로벌 서비스 QA 시에는 무엇이 달라지나” 가 진행되었습니다.</p><p>이전 회사에서 경험했었던 글로벌 서비스에 대한 경험을 가지고 실사례를 기반으로 하여 우리 서비스가 글로벌 진출을 하게 된다면 어떤 것을 고려해야 하고 유의해야 하는지에 대한 내용과 진행하면서 어려웠던 점들을 공유하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*lcfT8oVoAKvK63gvlbaG4A.png\" /></figure><p>1️⃣2️⃣ 열두번째 세션으로는<br>“2025년 회고 (조진현)” 가 진행되었습니다.</p><p>2024년 9월 입사 이후 2025년은 온전한 1년을 모두 보낸 해였습니다. 2025년에는 어떤 경험과 성장을 이루었는지 한해를 돌아보며 회고한 내용을 공유하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*MIhsntTkY0Ayl_dVSUu_IQ.png\" /></figure><p>1️⃣3️⃣ 열세번째 마지막 세션으로는<br>“2025년 한해 돌아보기 (+팀 회고)” 가 진행되었습니다.</p><p>2025년 저는 어떻게 팀을 운영하며 개인에 대한 성장을 이뤄냈고 어떠한 변화를 맞이하여 그것에 적응하고 또 팀을 운영해 나갔는지에 대한 내용을 공유하였습니다. 많은 일들이 있었던 한 해였던 것 같습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*2toHaPvkWj43c5eNl074vw.png\" /></figure><p>이렇게 준비한 모든 세션이 완료되고 준비한 모든 팀원분들이 서로에게 박수를 보내며 제1회 29QA Con은 마무리가 되었습니다.</p><p>인원수는 많지 않았지만 풍부한 세션과 레슨런이 있었고 중간에 참석해서 자리를 빛내주신 MUSINSA QE팀 분들 덕분에 더 풍부한 컨퍼런스가 될 수 있었던것 같습니다.</p><p>바쁘신 와중에 참석해주신 MUSINSA QE팀 분들 감사합니다 :)</p><p>저희 QE팀은 연말에 고유 행사가 있습니다. 제가 팀원분들께 연말 선물을 드리는 것인데요 2023년은 장식용 캘린더, 2024년은 드래곤볼 7성구 (소원이루시라는 뜻으로 ^^), 그리고 2025년은 각자의 얼굴을 팝아트로 다시 그려낸 캔버스 그림을 선물로 드렸습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*3HOVjowbc36PfzHj8I2LRA.png\" /><figcaption>짠</figcaption></figure><p>그리고는 맛있는 저녁회식을 떠났습니다.</p><p>모두 열심히 준비하고 진행해준 만큼 회식도 더 맛있고 즐거웠을것으로 예상해봅니다 :)</p><p>올해에도 잘 준비해서 다른 QA분들이 발표도 하실수 있고, 참여도 하실 수 있는 행사로 만들어 보도록 하겠습니다.</p><h3>TEAM MUSINSA CAREER</h3><blockquote><em>무신사는 2001년 온라인 커뮤니티로 시작해 2005년 무신사 매거진, 2009년 무신사 스토어를 오픈하며 빠르게 성장하고 있는 국내 대표 온라인 패션 스토어입니다. ‘입점 브랜드와 동반성장’이라는 경영 철학을 바탕으로 브랜드가 안정적으로 사업을 전개할 수 있도록 무신사가 보유한 노하우와 인프라를 지원합니다. 고객에게는 풍성한 패션 콘텐츠와 패션에 특화된 차별화된 서비스로 최상의 온라인 쇼핑 경험을 제공하고 있습니다. 글로벌 №1 패션 기업으로 성장할 무신사와 함께 새로운 도전과 혁신을 만들 인재를 기다립니다.</em></blockquote><blockquote><em>29CM는 ‘고객의 더 나은 선택을 돕는다’라는 미션으로 출발했습니다. 우리는 우리만의 방식으로 콘텐츠를 제공하며, 브랜드와 고객 모두에게 대체 불가능한 커머스 플랫폼을 만들어가고 있습니다. 이 미션을 이루기 위해 우리는 흥미로우면서도 복잡한 문제들을 해결하고 있습니다. 만약 우리와 함께 이 문제들을 해결해 보고 싶다면, 주저하지 말고 29CM에 합류하세요!</em></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/home\"><em>🚀 팀 무신사 채용 페이지</em></a><em> (무신사/29CM 전체 포지션 확인이 가능해요)</em></blockquote><blockquote><em>🚀 </em><a href=\"https://kr.linkedin.com/company/musinsacom\"><em>팀 무신사 테크 소식을 받아보는 링크드인</em></a></blockquote><blockquote><em>🚀 </em><a href=\"https://newsroom.musinsa.com/\"><em>팀 무신사 뉴스룸</em></a></blockquote><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=610644aaf27b\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://techblog.musinsa.com/2025%EB%85%84-%EC%A0%9C-1%ED%9A%8C-29qa-con-%EC%A7%84%ED%96%89-%ED%9B%84%EA%B8%B0-29qa-conference-610644aaf27b\">2025년 제 1회 29QA Con 진행 후기 (29QA Conference)</a> was originally published in <a href=\"https://techblog.musinsa.com\">MUSINSA techblog — 무신사 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2026-01-26T22:02:56.000Z",
    "url": "https://techblog.musinsa.com/2025%EB%85%84-%EC%A0%9C-1%ED%9A%8C-29qa-con-%EC%A7%84%ED%96%89-%ED%9B%84%EA%B8%B0-29qa-conference-610644aaf27b?source=rss----f107b03c406e---4"
  },
  {
    "publisherId": "musinsa",
    "publisherName": "무신사 테크블로그",
    "specTitle": "e커머스 개발",
    "categories": [
      "backend"
    ],
    "specUrl": "https://medium.com/feed/musinsa-tech",
    "title": "“이번 달도 밤샘 정산입니다.” — 정산 시스템은 왜 필요했을까 (설계편)",
    "partialText": "<h3>“이번 달도 밤샘 정산입니다.” — 정산 시스템은 왜 필요했을까 (설계편)</h3><p>“이번 달도 밤샘 정산입니다.” 테크 블로그 시리즈</p><ol><li><a href=\"https://techblog.musinsa.com/이번-달도-밤샘-정산입니다-정산-시스템은-어떻게-만들었을까-실전편-74d8a5d22ba1\">정산 시스템은 어떻게 만들었을까 (실전편)</a></li><li><a href=\"https://techblog.musinsa.com/%EC%9D%B4%EB%B2%88-%EB%8B%AC%EB%8F%84-%EB%B0%A4%EC%83%98-%EC%A0%95%EC%82%B0%EC%9E%85%EB%8B%88%EB%8B%A4-%EC%A0%95%EC%82%B0-%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%80-%EC%96%B4%EB%96%BB%EA%B2%8C-%EB%A7%8C%EB%93%A4%EC%97%88%EC%9D%84%EA%B9%8C-%EC%8B%A4%EC%A0%84%ED%8E%B8-74d8a5d22ba1?source=collection_home_page----f107b03c406e-----0-----------------------------------\"><strong>정산 시스템은 왜 필요했을까 (설계편)</strong></a></li><li><a href=\"https://techblog.musinsa.com/이번-달도-밤샘-정산입니다-더-이상-밤샘하지-않아도-됩니다-운영편-4f09ae3bdf5d\">더 이상 밤샘하지 않아도 됩니다 (운영편)</a></li></ol><h3>들어가며</h3><p>정산 업무를 경험해 본 조직이라면 익숙한 문장입니다.</p><p>정산은 매달 반드시 마감되어야 하지만, 그 과정은 늘 사람의 손과 기억에 크게 의존해 왔습니다. 데이터는 흩어져 있고, 기준은 상황마다 조금씩 달라지며, 한 번 계산한 결과도 다시 믿기 어려운 경우가 많습니다.</p><p>MASS는 이러한 문제의식에서 출발했습니다.</p><p>단순히 수기 작업을 자동화하는 것을 넘어, <strong>정산이라는 행위를 시스템이 책임질 수 있도록 만들고자 했습니다.</strong><br>이번 연재의 1편에서는 MASS를 설계하며 가장 먼저 고민했던 질문들, 그리고 그에 대한 설계 원칙을 공유합니다.</p><h3>MASS란 무엇인가</h3><p><strong>MASS는 Musinsa Accounting &amp; Settlement System의 약자</strong>로, <br>물류/운영 과정에서 발생하는 비용을 기준으로 파트너 업체와의 물류비 정산을 자동화하는 시스템입니다.</p><p>MASS는 다음 역할을 수행합니다.</p><ul><li>물류 운영 시 발생하는 입고/출고/반품/재고에 대한 <strong>원천 데이터를 수집</strong></li><li>조건과 단가를 기준으로 <strong>정산 금액을 계산</strong></li><li>일/월 단위로 <strong>정산을 집계하고 마감</strong></li><li>내부 담당자와 외부 파트너 업체가 <strong>동일한 기준의 정산 결과를 확인</strong>할 수 있도록 제공</li></ul><p>즉, MASS는 단순히 정산 금액을 계산하는 도구가 아니라, 정산 결과에 대한 논쟁이 생겼을 때 최종 기준이 되는 시스템을 목표로 설계되었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*e051S3n4IrpKebneSIYzDA.png\" /></figure><h3>정산 시스템이 어려운 이유</h3><p>정산은 단순히 숫자를 더하는 문제가 아닙니다.</p><ul><li>회계 마감이라는 <strong>절대적인 데드라인</strong></li><li>단 한 건의 오류도 허용되지 않는 <strong>정합성 요구</strong></li><li>과거 기준으로 언제든 다시 계산할 수 있어야 하는 <strong>재현성</strong></li></ul><p>기존에는 여러 단계의 수기 작업과 엑셀 검증을 통해 이를 처리하고 있었고, 이 방식은 높은 업무 부담과 오류 가능성을 동시에 안고 있었습니다.</p><p>MASS는 이 문제를 “정산을 더 빨리 하자”가 아니라 <strong>“정산을 시스템이 책임지게 하자”</strong>는 관점에서 접근했습니다.</p><h3>설계 원칙: 속도보다 신뢰성</h3><p>MASS를 설계하면서 가장 먼저 합의한 원칙은 다음과 같습니다.</p><blockquote><em>정산 시스템은 빠르게 계산하는 시스템이 아니라 </em><strong><em>실패해도 다시 계산할 수 있는 시스템이어야 합니다.</em></strong></blockquote><p>이를 위해 아래 원칙을 아키텍처 전반에 반영했습니다.</p><ul><li><strong>정합성과 멱등성</strong></li><li><strong>결정적 계산(재현성)</strong><br><em>(결정적 계산: 같은 원천 데이터와 계산 기준을 사용하면 언제 다시 계산해도 동일한 결과가 나오도록 설계된 계산)</em></li><li><strong>감사 가능성(추적성)</strong></li><li><strong>배치 실패 복구 및 재시작성</strong></li></ul><h3>멱등성을 전제로 한 이벤트 처리</h3><p>정산에 사용되는 원천 데이터는 이벤트 형태로 유입됩니다.</p><p>이벤트 기반 시스템에서 중복 수신이나 재처리는 피할 수 없는 상황이기 때문에, MASS에서는 이를 <strong>전제 조건</strong>으로 두었습니다.</p><ul><li>이벤트 재시도(Retry)와 격리(DLT)를 분리해 처리</li><li>트랜잭션 식별자를 기준으로 서비스 레벨에서 멱등 갱신</li><li>동일 이벤트가 여러 번 처리되어도 결과는 항상 동일</li></ul><p>이를 통해 장애 상황에서도 안전하게 재처리할 수 있는 기반을 마련했습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*xENmTFP7ucjwQzf10heeyg.png\" /></figure><h4>이벤트 재시도(Retry)와 격리(DLT)를 분리해 처리</h4><p>이벤트 기반 정산 시스템에서는 일시적인 실패와 구조적인 실패를 구분해 다루는 것이 중요합니다.</p><p>MASS에서는 이를 위해 <strong>이벤트 재시도(Retry)</strong>와 <strong>격리(DLT, Dead Letter Topic)</strong>를 명확히 분리해 처리합니다.</p><p>일시적인 네트워크 오류나 외부 의존성 문제로 인한 실패는 재시도를 통해 정상 흐름으로 복귀시키고, 반복 재시도 이후에도 처리할 수 없는 이벤트는 정상 파이프라인에서 분리해 DLT로 격리합니다.</p><h4>트랜잭션 식별자를 기준으로 한 서비스 레벨 멱등 갱신</h4><p>MASS에서는 모든 원천 이벤트에 대해 업스트림 시스템에서 이미 존재하는 고유 식별자를 활용합니다. <br>입·출고, 재고 스냅샷 이벤트에 포함된 식별자를 조합해 정산 도메인 관점의 트랜잭션 식별자로 사용합니다.</p><p>이 식별자는 단순한 DB Unique Key가 아니라, <strong>정산 관점에서 이미 처리된 이벤트인지 판단하는 기준</strong>입니다.</p><ul><li>동일 식별자가 처음 들어오면 신규 정산 데이터로 처리</li><li>이미 처리된 이벤트라면 결과를 유지하거나(no-op)</li><li>정책 변경 등 의도적인 경우에만 갱신</li></ul><p>이를 통해 MASS는 DB 예외에 의존하지 않고, 도메인 규칙에 기반한 멱등성을 확보했습니다.</p><h3>결정적 계산을 위한 정산 로직</h3><p>정산 금액 계산은 가능한 한 단순하고 결정적으로 설계했습니다.</p><ul><li>계산기 모듈은 입력값에만 의존</li><li>금액 스케일과 반올림 정책을 고정</li><li>계산 단계를 명확히 분리해 추론 가능성 확보</li></ul><p>이 구조의 핵심은 <strong>“같은 입력이면 언제 계산해도 같은 결과가 나온다”</strong>는 점입니다.<br>덕분에 이의 제기, 기준 변경, 재처리 상황에서도 동일한 기준으로 다시 계산할 수 있습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*ESdtMRhioW0uIXh6o5EH-g.png\" /></figure><h4>계산기 모듈은 입력값에만 의존</h4><p>정산 계산 로직은 외부 상태나 실행 시점에 따라 결과가 달라지지 않도록, <strong>입력값만으로 결과가 결정되는 순수 함수 형태</strong>로 설계했습니다.</p><p>정산 계산에 필요한 모든 정보는 CalculateCommand와 그 안의 SettlementContext에 명시적으로 포함됩니다.</p><pre>data class SettlementContext(<br>    val settlementDate: LocalDate,<br>    val settlementBaseType: SettlementBaseType,<br>)</pre><p>SettlementContext는 “언제, 어떤 기준으로 정산하는가”를 명확히 표현하는 최소 단위의 컨텍스트로, 정산 계산 과정에서 <strong>현재 시각, 실행 환경, 전역 상태</strong>와 같은 외부 요인을 참조하지 않도록 만든 장치입니다.</p><p>이를 단순화하면 일 정산 계산 로직은 다음과 같은 형태를 가집니다.</p><pre># pseudo code<br><br>function calculateDailySettlement(command):<br>    # command includes:<br>    # - settlementContext (settlementDate, settlementBaseType)<br>    # - serviceType, partnerId, brandId<br>    # - logisticsCategoryCode, quantity, policy flags<br><br>    # 1) 정산 기준일 기준으로 단가 조회<br>    base = findBasePrice(command)<br>    unitPrice = base.baseUnitPrice<br><br>    # 2) 정산 기준일 기준으로 할인 정책 적용<br>    discountedUnitPrice = applyDiscount(<br>        unitPrice,<br>        base.serviceChargeBase,<br>        command.settlementContext.settlementDate,<br>        command.partnerId,<br>        command.brandId<br>    )<br><br>    # 3) 수량 반영<br>    originAmount     = unitPrice * command.quantity<br>    discountedAmount = discountedUnitPrice * command.quantity<br><br>    # 4) 정산 결과 반환<br>    return {<br>        unitPrice,<br>        discountedUnitPrice,<br>        originAmount,<br>        discountedAmount,<br>        remoteAreaUnitPrice (optional)<br>    }</pre><p>이 구조에서 계산 결과는 오직 다음 입력에 의해서만 결정됩니다.</p><ul><li><strong>정산 기준일(settlementDate)</strong></li><li><strong>정산 기준 유형(settlementBaseType)</strong></li><li>정책 정보(단가, 할인 조건)</li><li>원천 데이터(수량 등)</li></ul><p>덕분에 동일한 정산 컨텍스트와 입력이 주어지면 <strong>언제, 몇 번을 실행하더라도 동일한 정산 결과가 보장</strong>됩니다.</p><p>이는 이의 제기 대응, 기준 변경 이후의 재계산, 장애 복구 후 재처리 상황에서도 <strong>과거 정산을 동일한 기준으로 다시 계산할 수 있는 재현성</strong>을 확보하는 핵심 전제였습니다.</p><h4>금액 스케일과 반올림 정책을 고정</h4><p>정산 도메인에서 반올림은 “표현 방식”이 아니라 <strong>결과 자체를 바꾸는 규칙</strong>입니다.<br>특히 할인/수수료처럼 소수점이 개입되는 계산은 <strong>반올림 시점과 방식이 조금만 달라도 최종 금액이 달라질 수 있습니다.</strong><br>일 단위로는 몇 원 수준의 차이처럼 보여도, 월 단위 집계로 누적되면 <strong>정산 금액 불일치</strong>로 이어질 수 있습니다.</p><p>그래서 MASS에서는 다음을 원칙으로 두었습니다.</p><ul><li>모든 금액 계산은 BigDecimal로 수행해 <strong>부동소수점 오차를 원천 차단</strong></li><li>할인 적용 시 <strong>스케일(MONEY_SCALE)을 강제로 고정</strong></li><li>반올림은 <strong>항상 동일한 정책(RoundingMode.DOWN)</strong>을 사용</li></ul><p>예를 들어 비율 할인(RATE)의 경우, 할인율을 퍼센트에서 실제 rate로 변환한 뒤 곱셈을 수행하고, 그 결과를 <strong>반드시 동일한 스케일로 내림(DOWN) 처리</strong>해 할인 적용 단가를 결정합니다.</p><pre>// RATE 할인: percent -&gt; rate 변환 후 곱셈, 그리고 스케일/반올림 정책 강제<br>val percent = discount.discountValue.max(BigDecimal.ZERO).min(MAX_RATE_VALUE)<br>val rate = BigDecimal.ONE.subtract(percent.movePointLeft(RATE_SCALE))<br><br>val discountedUnitPrice =<br>    unitPrice<br>        .multiply(rate)<br>        .setScale(MONEY_SCALE, RoundingMode.DOWN)<br>        .max(BigDecimal.ZERO)</pre><p>이처럼 “소수점이 생길 수 있는 지점”에서 <strong>정책을 코드로 강제</strong>해두면,</p><ul><li>계산 경로가 달라져도(일 정산/월 정산/재처리)</li><li>실행 환경이 달라져도(다른 서비스/다른 배치)</li></ul><p>항상 동일한 금액 산출이 가능해지고, 결과적으로 <strong>정산 결과의 재현성</strong>을 확보할 수 있습니다.</p><blockquote><em>정산 시스템에서 반올림 정책은 구현 디테일이 아니라, “같은 입력이면 같은 결과가 나와야 한다”는 신뢰를 지키는 핵심 규칙입니다.</em></blockquote><h3>마치며</h3><p>정산 시스템의 어려움은 계산식이 아니라, <strong>다시 계산해야 하는 현실</strong>에 있습니다. <br>MASS는 멱등성과 결정적 계산이라는 설계 원칙을 통해 정산을 사람의 기억이 아닌 시스템의 책임으로 옮기고자 했습니다.</p><p>다음 글에서는 이러한 설계가 실제로 어떤 기술 선택과 구조로 구현되었는지, Kafka와 Spring Batch, Argo Workflow를 활용한 정산 시스템의 실전 이야기를 다룰 예정입니다.</p><h3><strong>Platform Business Operation 조직 및 팀 소개</strong></h3><blockquote><em>무신사 플랫폼 비즈니스 오퍼레이션 조직은 국내외 물류 서비스, 재고 관리, 스토어 운영을 위한 물류 프로덕트를 구축하고 다양한 오프라인 비즈니스 모델에 맞춘 스토어 관리 시스템을 개발·고도화하고 있습니다.<br>또한, 무배당발 서비스를 포함한 무신사의 차별화된 고객 경험을 브랜딩하고 확장할 수 있는 멤버십 구조를 설계하며, 온·오프라인을 넘나드는 통합 커머스 경험을 기술로 실현하고 있습니다.</em></blockquote><blockquote><em>저희 팀은 OMS(주문관리시스템)를 기반으로 온라인 주문부터 재고·출고·배송·정산에 이르는 전 과정을 유기적으로 연결하고, 무신사의 다양한 오프라인 스토어를 효과적으로 운영할 수 있는 관리 시스템을 구축하여 고객이 온라인(무신사 스토어, 29CM 등)과 오프라인(무신사 스탠다드, 편집숍 등)에서 끊김 없는 쇼핑 경험을 누릴 수 있도록 지원합니다.</em></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/pbo\"><em>🚀 Platform Business Operation 한걸음 더 알아보기</em></a></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/home\"><em>🚀 팀 무신사 채용 페이지</em></a><em> (무신사/29CM 전체 포지션 확인이 가능해요)</em></blockquote><blockquote><em>🚀 </em><a href=\"https://kr.linkedin.com/company/musinsacom\"><em>팀 무신사 테크 소식을 받아보는 링크드인</em></a></blockquote><blockquote><em>🚀 </em><a href=\"https://newsroom.musinsa.com/\"><em>팀 무신사 뉴스룸</em></a></blockquote><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=22732a4a607f\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://techblog.musinsa.com/22732a4a607f\">“이번 달도 밤샘 정산입니다.” — 정산 시스템은 왜 필요했을까 (설계편)</a> was originally published in <a href=\"https://techblog.musinsa.com\">MUSINSA techblog — 무신사 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2026-01-21T22:22:08.000Z",
    "url": "https://techblog.musinsa.com/22732a4a607f?source=rss----f107b03c406e---4"
  },
  {
    "publisherId": "musinsa",
    "publisherName": "무신사 테크블로그",
    "specTitle": "e커머스 개발",
    "categories": [
      "backend"
    ],
    "specUrl": "https://medium.com/feed/musinsa-tech",
    "title": "이구위크 전시 장애 대응기: Redis에는 무슨 일이 있었나",
    "partialText": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*STYKSBA_rNy0r3jiD_Z-tw.png\" /></figure><p>안녕하세요. 29CM에서 고객이 상품을 탐색하고 발견하는 상품 전시 영역을 담당하고 있는 Customer Engagement Engineering 팀 김송이입니다.</p><p>2025년 겨울, 29CM 최대 규모의 블랙프라이데이 행사인 이구위크를 진행했습니다. 연중 가장 트래픽이 몰리는 행사인 만큼, 설렘과 긴장이 공존하는 시즌이기도 합니다. 매년 대규모 트래픽을 대비하지만, 플랫폼의 성장 속도만큼 새로운 변수도 함께 생겨납니다.</p><p>이구위크 시작 첫날이었던 11월 3일, 유저가 상품을 둘러보는 주요 상품 전시 화면에서 장애가 발생했습니다. 장애 원인을 추적하고 해결한 과정, 이후 개선한 내용을 정리해 공유합니다.</p><h3>1. 장애 발생과 원인을 찾기까지</h3><p>이구위크 본편이 시작된 지 얼마 되지 않아, 검색결과, 상품 리스팅 등의 전시 도메인을 담당하는 서버에 이상징후가 포착되기 시작했습니다. 파드(pod)가 일부 다운되며 트래픽을 못 받기 시작했습니다.</p><p>남아있는 파드도 처리 가능한 트래픽을 초과하면서 Netty 이벤트 루프 포화가 발생했습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*t-AYIgKOPCNUeUouWn9zGA.png\" /><figcaption>Netty Pending Tasks</figcaption></figure><p>전시 트래픽을 받는 서버의 경우 Netty, Spring WebFlux 기반으로 운영 중이었기 때문에, 트래픽 증가로 인한 다운스트림 지연이나 이벤트 루프 처리 지연 쪽을 먼저 점검했습니다. Redis도 확인했지만, CPU, Memory 등 주요 시스템 메트릭이 모두 정상 범위(10% 이하)였기 때문에 원인일 가능성을 낮게 판단했습니다.</p><h3>2. Redis 대역폭 병목이 드러나다</h3><p>원인 분석 중 Redis 헬스체크 실패 로그가 눈에 들어왔고, 메트릭 지표를 다시 살펴봤습니다.<br>리소스는 멀쩡한데, 왜 Redis와의 통신은 실패하고 있었을까?<br>이 의문은 네트워크 지표에서 풀렸습니다.</p><p>당시 운영 중이던 Redis 노드 타입은 cache.r7g.large로, 기본 네트워크 대역폭은 <strong>0.937Gbps</strong>였습니다. 이는 이론적으로 <strong>초당 약 117MB</strong> 수준의 데이터 전송량에 해당합니다.</p><p>평소에는 네트워크 Out 대역폭이 약 0.49Gbps(약 61MB/s) 수준으로 유지되고 있어, 기본 대역폭 범위 내에서 안정적으로 동작하고 있었습니다. 그러나 이구위크 트래픽이 몰리면서 피크 시점에는 네트워크 사용량이 평소 대비 약 4배 수준인 <strong>2.0Gbps(약 250MB/s)</strong>까지 치솟았습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*ET-G9Iw8KmC7IcisgzWnPA.png\" /><figcaption>Network In/Out 허용 초과량</figcaption></figure><p>여기서 문제가 되었던 것은 AWS의 <strong>네트워크 대역폭 스로틀링(Throttling) 메커니즘</strong>입니다. ElastiCache는 인스턴스 타입마다 기본 제공 대역폭 베이스라인(Baseline)이 정해져 있고, 순간적으로 베이스라인을 초과하는 트래픽이 발생했을 때, 이를 허용해 주는 버스트(Burst) 기능을 제공합니다. 이때 버스트는 ‘<strong>버스트 크레딧(Burst Credit)</strong>’이라는 일종의 네트워크 체력을 사용해 동작합니다.</p><p>휴대폰 데이터 요금제와 비슷하다고 생각하면 이해하기 쉽습니다. 기본 데이터를 다 쓰면 속도가 확 느려지는 것처럼, 크레딧이 소진되면 Baseline으로 강제 제한됩니다.</p><blockquote>Baseline 이하로 사용 → 크레딧 축적</blockquote><blockquote>Baseline 초과 → 크레딧 소모하며 버스트 유지</blockquote><blockquote>크레딧 소진 → AWS가 Baseline 이하로 강제 제한(Throttling)</blockquote><p>이번 장애는 바로 이 <strong>버스트 크레딧 소진 → 네트워크 강제 제한</strong> 과정에서 발생했습니다. 트래픽이 19시부터 Baseline을 초과해 계속 버스트 상태로 운영되었지만, 약 2시간 동안 누적된 버스트 크레딧이 모두 고갈된 시점(20:58)에 네트워크 Throttling이 시작되면서 Redis 응답 지연과 커넥션 실패가 갑자기 폭증했습니다. 결과적으로 Redis 커넥션과 커맨드가 실패하기 시작했고, 이로 인해 애플리케이션의 Readiness Probe가 실패하면서 다수의 파드가 다운되었습니다.</p><h3>3. 장애 대응과 즉시 조치</h3><p>19:00부터 트래픽이 Redis 대역폭 Baseline을 초과했지만, Burst 크레딧 덕분에 바로 문제가 드러나지 않았고, 약 2시간 뒤인 20:58 크레딧이 고갈되면서 Throttling이 시작되었습니다. Burst 구간이 있었기 때문에 원인 파악이 늦어진 측면이 있습니다.</p><p>원인 파악 후 즉시 Redis 노드 스케일업(<em>cache.r7g.large</em> → <em>cache.r7g.2xlarge</em>)을 진행했습니다. 2xlarge는 기본 대역폭이 1.875Gbps로, 기존 대비 약 2배의 네트워크 용량을 제공합니다. 서비스 장애는 당일 해소되었지만, 트래픽이 더 늘어나면 같은 문제가 반복될 수 있기 때문에 근본적인 재발 방지 전략이 필요했습니다.</p><h3>4. 재발 방지를 위한 개선 작업</h3><p>장애 직후, 같은 문제가 반복되지 않도록 몇 가지 조치를 진행했습니다.</p><p><strong>4–1. 모니터링 강화</strong></p><p>Burst 크레딧 구간 때문에 원인 파악이 늦어졌던 만큼, 네트워크 In/Out 대역폭 초과 여부를 실시간으로 확인할 수 있도록 모니터링 대시보드를 강화했습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*PNB-wltpqao1jiFFFma0Ag.png\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*grvFIRlbX0WoeR0dQ4s61g.png\" /></figure><p>주요 모니터링 지표는 아래와 같습니다.</p><ul><li>aws.elasticache.network_bytes_in : 네트워크 수신 바이트</li><li>aws.elasticache.network_bytes_out : 네트워크 송신 바이트</li><li>aws.elasticache.network_bandwidth_in_allowance_exceeded : 수신 대역폭 Baseline 초과 여부</li><li>aws.elasticache.network_bandwidth_out_allowance_exceeded : 송신 대역폭 Baseline 초과 여부</li><li>aws.elasticache.traffic_management_active : Throttling 발생 여부</li></ul><p>또한 Datadog Alert를 연동해 네트워크 대역폭이 임계치를 넘을 경우 즉시 알림을 받을 수 있도록 설정하여 이상 징후를 빠르게 인지하고 사전에 대응할 수 있는 기반을 마련했습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/612/1*Y4Km5VSRIFnqlYHaYNBTaA.png\" /></figure><p><strong>4–2. 캐시 전략 변경 (캐시 계층화)</strong></p><p>Redis 네트워크 부하를 줄이기 위해 로컬 캐시로 처리 가능한 데이터는 서버 내부 메모리에서 우선 처리하도록 구조를 변경했습니다.</p><p>응답 변경 빈도가 낮은 데이터를 중심으로, 기존의 단일 Redis 의존 구조에서 벗어나 <strong>Caffeine</strong>(<strong>Local Cache) → Redis (Remote Cache) → DB</strong>로 이어지는 캐시 계층화 구조로 전환했습니다. 이를 통해 Redis에 집중되던 트래픽을 완화하고, 전체적인 응답 안정성을 높일 수 있었습니다.</p><p>캐시 전략을 적용한 직후, 실제로 Redis 부하가 감소했는지 지표를 확인했습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*0W2L_YTOxTqUcjCb_O_--g.png\" /><figcaption>Redis Command Count</figcaption></figure><p>우선 로컬 캐시가 제대로 역할하고 있는지 확인하기 위해 Redis 명령어 호출 수를 살펴봤습니다. 그 결과, Redis 명령어 호출이 눈에 띄게 감소한 것을 확인할 수 있었습니다.</p><p>로컬 캐시가 상당 부분을 흡수하면서 Redis가 직접 처리해야 하는 요청이 그만큼 줄어든 것입니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*o_YtYlfrpkUW-Vx0qt64SQ.png\" /><figcaption>Redis Outgoing Bytes 일별 비교 (노란색: 전일, 빨간색: 당일)</figcaption></figure><p>Redis 명령어 호출이 줄어든 만큼, 네트워크 Outgoing Throughput 역시 함께 감소했습니다.</p><p>기존에는 대용량 데이터를 주고받느라 네트워크 사용량이 높게 유지되었으나, 로컬 캐시가 이를 대신 처리하면서 Redis까지 전달되는 데이터양이 크게 줄어들었습니다.</p><h3>5. 장기 개선 과제</h3><p>이번 장애를 계기로, 단기적인 문제 해결에 머무르지 않고 중·장기 관점에서 트래픽 성장에 대비할 수 있는 인프라 구조로 전환하고자 합니다.</p><p><strong>5–1. 캐시 데이터 최적화 (Snappy + protobuf)</strong></p><p>Redis 네트워크 대역폭 사용량을 근본적으로 줄이기 위해 캐시 데이터 압축을 검토하고 있습니다. CPU 사용량이 적고 압축/해제 속도가 빨라 실시간으로 데이터를 읽고 쓰는 캐시 환경에 적합한 Snappy 압축 알고리즘을 고려하고 있습니다.</p><p>또한 JSON 형태로 저장되고 있는 캐시 데이터를 Protocol Buffers(protobuf) 형식으로 전환하는 것을 검토 중입니다. protobuf는 JSON 대비 데이터 크기가 작고 직렬화/역직렬화 속도도 빠르므로, 네트워크 대역폭 절감과 성능 향상을 동시에 기대할 수 있습니다.</p><p>실제 캐싱 중인 Item Document 데이터를 기준으로 측정한 결과, Snappy 압축 + protobuf를 함께 적용했을 때 기존 대비 약 73%의 용량 절감이 가능할 것으로 예상합니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Noke_TgaixxkjZotLdPESA.png\" /></figure><h3>6. 마치며</h3><p>이번 장애를 통해 Redis 대역폭 초과라는 예상치 못한 장애 지점을 발견할 수 있었습니다. CPU와 Memory 지표만으로는 문제를 인지하기 어려웠으며, <strong>네트워크 관점의 모니터링 필요성</strong>을 다시 한번 체감하는 계기가 되었습니다.</p><p>문제 해결 과정에서 캐시 구조 개선, 모니터링 고도화, 읽기 분리 적용 등 여러 기술적 부채를 해소했고, 현재는 <strong>이를 바탕으로 트래픽 증가에 대비한 아키텍처 개선을 진행</strong>하고 있습니다.</p><p>저희 팀은 전시, 콘텐츠, 기획전, 선물하기 등 사용자가 마주하는 서비스의 첫인상과 주요 탐색 흐름을 책임지고 있습니다. 앞으로도 더 빠르고 안정적인 사용자 경험을 제공하기 위해 지속적으로 구조를 점검하고, 확장 가능한 시스템으로 발전해 나가고자 합니다. 언제나 문제 해결의 모든 과정에서 적극적으로 함께해 준 팀원 모두에게 감사의 말씀을 전하며 글을 마칩니다.</p><p>긴 글 읽어주셔서 감사합니다.</p><h3>TEAM MUSINSA CAREER</h3><blockquote><em>무신사는 2001년 온라인 커뮤니티로 시작해 2005년 무신사 매거진, 2009년 무신사 스토어를 오픈하며 빠르게 성장하고 있는 국내 대표 온라인 패션 스토어입니다. ‘입점 브랜드와 동반성장’이라는 경영 철학을 바탕으로 브랜드가 안정적으로 사업을 전개할 수 있도록 무신사가 보유한 노하우와 인프라를 지원합니다. 고객에게는 풍성한 패션 콘텐츠와 패션에 특화된 차별화된 서비스로 최상의 온라인 쇼핑 경험을 제공하고 있습니다. 글로벌 №1 패션 기업으로 성장할 무신사와 함께 새로운 도전과 혁신을 만들 인재를 기다립니다.</em></blockquote><blockquote><em>29CM는 ‘고객의 더 나은 선택을 돕는다’라는 미션으로 출발했습니다. 우리는 우리만의 방식으로 콘텐츠를 제공하며, 브랜드와 고객 모두에게 대체 불가능한 커머스 플랫폼을 만들어가고 있습니다. 이 미션을 이루기 위해 우리는 흥미로우면서도 복잡한 문제들을 해결하고 있습니다. 만약 우리와 함께 이 문제들을 해결해 보고 싶다면, 주저하지 말고 29CM에 합류하세요!</em></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/home\"><em>🚀 팀 무신사 채용 페이지</em></a><em> (무신사/29CM 전체 포지션 확인이 가능해요)</em></blockquote><blockquote><em>🚀 </em><a href=\"https://kr.linkedin.com/company/musinsacom\"><em>팀 무신사 테크 소식을 받아보는 링크드인</em></a></blockquote><blockquote><em>🚀 </em><a href=\"https://newsroom.musinsa.com/\"><em>팀 무신사 뉴스룸</em></a></blockquote><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=5599562d76b9\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://techblog.musinsa.com/%EC%9D%B4%EA%B5%AC%EC%9C%84%ED%81%AC-%EC%A0%84%EC%8B%9C-%EC%9E%A5%EC%95%A0-%EB%8C%80%EC%9D%91%EA%B8%B0-redis%EC%97%90%EB%8A%94-%EB%AC%B4%EC%8A%A8-%EC%9D%BC%EC%9D%B4-%EC%9E%88%EC%97%88%EB%82%98-5599562d76b9\">이구위크 전시 장애 대응기: Redis에는 무슨 일이 있었나</a> was originally published in <a href=\"https://techblog.musinsa.com\">MUSINSA techblog — 무신사 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2026-01-06T22:02:27.000Z",
    "url": "https://techblog.musinsa.com/%EC%9D%B4%EA%B5%AC%EC%9C%84%ED%81%AC-%EC%A0%84%EC%8B%9C-%EC%9E%A5%EC%95%A0-%EB%8C%80%EC%9D%91%EA%B8%B0-redis%EC%97%90%EB%8A%94-%EB%AC%B4%EC%8A%A8-%EC%9D%BC%EC%9D%B4-%EC%9E%88%EC%97%88%EB%82%98-5599562d76b9?source=rss----f107b03c406e---4"
  },
  {
    "publisherId": "musinsa",
    "publisherName": "무신사 테크블로그",
    "specTitle": "e커머스 개발",
    "categories": [
      "backend"
    ],
    "specUrl": "https://medium.com/feed/musinsa-tech",
    "title": "QA 자동화 결과를 데이터로 관리하다: Grafana Dashboard와 Weekly 분석의 힘",
    "partialText": "<p>안녕하세요 29CM QE팀 강보민입니다.</p><p>29CM QE 팀은 iOS와 Android 자동화를 Cell 단위로 분담해 운영하고 있으며, 그중 저는 iOS UI 자동화를 담당하고 있습니다.</p><p>특히, <strong>29CM QE팀은 테스트 자동화만 전담하는 인원 없이, 모든 QE가 매뉴얼 테스트와 자동화를 함께 수행합니다.</strong> 덕분에 상황에 따라 유동적으로 대응할 수 있고, 자동화 코드에 대한 팀 전체의 이해도와 오너십도 높습니다.</p><p>입사 6개월이 지난 시점, 신규 시나리오 추가와 유지보수에 익숙해지고 3Q(7~9월) 목표를 설정할 무렵 세 가지 의문이 들었습니다.</p><blockquote><strong><em>“단순히 지금처럼 fail이 나는 경우에만 수정하는 것이 의미가 있을까?”</em></strong></blockquote><blockquote><strong><em>“2%라는 Fail률이 과연 낮은 것일까?’</em></strong></blockquote><blockquote><strong><em>“간헐적으로 발생하는 fail에 대해 다시 매뉴얼 테스트를 하는 것이 효율적인 것인가?”</em></strong></blockquote><p>당시 iOS UI 자동화를 리드하시던 다정님께서 이미 약 2% 미만 수준의 낮은 Fail률로 안정적인 자동화 환경을 만들어주신 상태였지만,</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*QAQKOuvhawT8sBZKmpHE5w.png\" /><figcaption><strong>24년도 하반기 2% 미만의 fail률</strong></figcaption></figure><p>더 높은 신뢰성과 일관된 품질을 유지하기 위해, <strong>Fail률 0.7% 미만 달성</strong>을 공동 목표로 세웠습니다.</p><p>이후 자동화 테스트 케이스를 수행하면서 코드 구조상 개선이 필요한 영역, 간헐적으로 발생하는 오류 케이스 그리고 신규 시나리오 추가 과정에서 발생할 수 있는 불필요한 실패를 방지하기 위한 사전 안전장치들을 함께 점검하고 개선해 나가기 시작했습니다.</p><p>안드로이드 역시 진현님께서 시나리오 복구 작업 및 확장 과정에서 Fail률 2% 미만을 목표로 설정하고, 안정성 향상을 위한 개선 작업을 병행하는 목표를 세웠습니다. (안드로이드는 복구가 필요한 시나리오가 있어 iOS보단 높은 Fail률로 목표를 설정하고, 점차 낮춰 나가는 방향으로 진행하고 있습니다)</p><p>이 글에서는 그 과정에서 얻은 경험과 개선 방법을 공유하려 합니다.</p><h3><strong><em>Grafana Dashboard: 데이터 기반 분석의 시작</em></strong></h3><p>분석을 하기 위해 가장 먼저 필요했던 것은 <strong>테스트 자동화 결과의 DB화</strong>입니다. 29CM QE팀은 2024년도 1월부터 자동화 수행 결과를 DB에 적재해오고 있으며, 데이터를 바탕으로 <strong>Grafana Dashboard로 데이터를 시각화하고 있습니다.</strong></p><p><strong>* 참고 글: </strong><a href=\"https://medium.com/29cm/29cm-qa%ED%8C%80%EC%9D%80-%EC%96%B4%EB%96%BB%EA%B2%8C-%ED%85%8C%EC%8A%A4%ED%8A%B8-%EC%9E%90%EB%8F%99%ED%99%94-%EC%A7%80%ED%91%9C%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%98%EC%97%AC-%EC%8B%A0%EB%A2%B0%EC%84%B1%EC%9D%84-%ED%99%95%EB%B3%B4%ED%95%A0-%EC%88%98-%EC%9E%88%EC%97%88%EC%9D%84%EA%B9%8C-93ee5cca76ce\">현준님의 작년 포스팅 — 29CM QA팀은 어떻게 테스트 자동화 지표를 활용하여 신뢰성을 확보할 수 있었을까?</a></p><p>Grafana Dashboard에서 확인 가능한 데이터 및 그래프 구성 항목은 날짜별 Fail률, 평균 수행 시간, 이번 주 대비 지난주 수행 시간 비교, Fail 발생 시나리오 카운트 합산 등으로 구성되어 있습니다.</p><p>Dashboard에서 확인할 수 있는 정보들과 함께 fail률 개선에 활용한 경험을 이야기해 보겠습니다.</p><p><strong>첫 번째, 일 별 파이프라인 수행 개수입니다.</strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*PkkB3Buigx7jKkbiryqN5Q.png\" /><figcaption><strong>일 별 자동화 파이프라인 수행 개수</strong></figcaption></figure><p>자동화 수행은 Jenkins 스케줄링에 따라 24시간, 매일 1시간 간격으로 실행되고 있습니다.</p><p>앱 심사 이전의 BVT 최종 배포 테스트나, 신규 FE 배포 시 배포 트리거에 걸린 경우, 그리고 11월 이구위크 기간처럼 트래픽이 집중되는 시기에는 하루 최대 50회까지 수행되기도 합니다.</p><p>위 그래프에서 일자별 자동화 수행 횟수가 다르게 나타나는 이유가 바로 이 때문입니다.</p><h3><strong><em>Fail 시나리오 분석</em></strong></h3><p>두 번째, Grafana Dashboard에서 확인할 수 있는 여러 지표 중, Fail률을 줄이기 위해 가장 핵심적으로 활용한 데이터인 <strong>시나리오별 Fail 카운트 합계</strong>입니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*GSGRVxIdUf7SWvahkjMzUg.png\" /><figcaption><strong>7월fail 시나리오</strong></figcaption></figure><p>3Q OKR 시작과 동시에 어느 시나리오에서 높은 Fail률이 발생하는지 파악하기 위해, OKR 시작 첫 번째 달인 <strong>7월 데이터를 Grafana Dashboard를 통해 집중적으로 분석</strong>했습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*fWzSeC654FLt0rCQFRUx9Q.png\" /><figcaption><strong>7월 자동화 결과</strong></figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*JhD60kutwCthKBp4RtR63g.png\" /><figcaption><strong>7월 fail률</strong></figcaption></figure><p>7월 자동화 Fail률을 Grafana Dashboard에서 모니터링한 결과, 대부분 1% 미만의 Fail률을 유지했지만, 간헐적으로 2% 가까이 상승하는 구간이 확인되었습니다. 특히 간헐적 이슈로 잘못 판단하여 시나리오 주석 처리 등 즉각적인 대응을 하지 못한 경우에는 4%를 초과한 적도 있었습니다.</p><h4><strong>7월 문제점 분석</strong></h4><p>특히 구매 플로우, 로그인이 필요한 플로우, 그리고 저녁 시간대 29 라이브 수행으로 인해 Element 클릭 시 29 라이브 전체보기 모드가 클릭되는 현상이 발생했고, 29 라이브가 위치한 페이지의 Element에서 높은 Fail 카운트가 집중되어 있음을 확인했습니다.</p><p>이에 따라 해당 시나리오를 우선 개선 대상으로 선정하고, 다음과 같은 문제점을 도출했습니다.</p><ul><li>로그인이 필수인 시나리오에서 로그인 실패 시 후속 시나리오가 연쇄적으로 실패하는 구조</li><li>결제 수단 선택 시 결제 수단 Element 탐색은 가능하나, 클릭하지 못하는 현상</li><li>29 라이브 수행 시 PIP 모드가 페이지 이동 후 유지, 앱 재실행 시 유지되는 현상이 있음</li></ul><h4><strong>7월 개선 작업</strong></h4><p>문제점 도출을 바탕으로 다음과 같은 개선 작업을 진행했습니다.</p><ul><li>(1) <strong>사전 로그인 강화 </strong>: 로그인이 반드시 필요한 케이스에서 로그인 실패 시 뒤 시나리오가 모두 실패하므로, <strong>사전 로그인 케이스를 추가</strong>했습니다.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*rfN4X64zKfO0u8AC9DLtZw.png\" /><figcaption><strong>사전 로그인</strong></figcaption></figure><ul><li>(2) <strong>선택 동작 안정화</strong> : 결제 수단 선택 시, 스크롤 위치에 따라 다른 UI나 터치 방어 영역과 겹치는 현상이 있어, Element 탐색 후 화면을 살짝 스크롤 하여 안정적으로 선택되도록 처리했습니다.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/818/1*u5SvMqWR0kcZQEnZDZ2TqA.png\" /><figcaption><strong>스크롤 안정화</strong></figcaption></figure><ul><li><strong>(3) 시간대 분기</strong> : 29 라이브 수행 시 <strong>PIP 모드 닫기 동작을 추가하여 </strong>특정 시간대(17:30~21:30)에 PIP 모드가 노출되어 다른 시나리오에 영향을 주는 것을 방지했습니다.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Ps1H8BLSLFaoVAI3EuEB0Q.png\" /><figcaption><strong>PIP 닫기</strong></figcaption></figure><h4><strong>8월: 개선 효과 확인 및 추가 과제 발견</strong></h4><p>8월에는 7월에 진행한 개선 코드 기반으로 7월에 가장 많은 Fail을 기록했던 구매/로그인 관련 시나리오들이 8월에 대폭 개선된 것을 확인할 수 있습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*IxTGEkN4YWHHnz-HQ9zwPg.png\" /><figcaption><strong>8월 fail 시나리오</strong></figcaption></figure><p>하지만, 아직 개선해야 할 것들은 여전히 남아 있었습니다. 바로 간헐적 fail과 실험 중일 경우 유저 계정별 기대 결과가 달라지는 경우입니다.</p><h4><strong>8월 개선 작업</strong></h4><ul><li><strong>(1) A/B 실험 대응</strong> : PDP 내 추천구좌를 확인하는 케이스 중 A그룹에 해당하는 유저는 “당신을 위한 MD 추천”에 해당, B그룹에 해당하는 유저는 “주목할만한 상품”만 확인하도록 분기 처리했습니다.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/814/1*K1Fic2qmx-V6PwrVtV0pvA.png\" /><figcaption><strong>추천 구좌 분기</strong></figcaption></figure><ul><li><strong>(2) 카테고리 Depth 클릭 고도화</strong> : API에서 받아온 카테고리를 클릭하도록 작성된 기존 코드에서 UI Element 탐색 시 대/중/소 카테고리가 분리되어 작성되지 않아 카테고리 depth를 잘못 클릭하는 경우가 있었습니다.</li><li>그 결과 아래 이미지처럼 “원래 의도는 여성 의류(대) &gt; 단독(중) &gt; 상의(소) 순서로 클릭하는 것이었으나, 중 카테고리에도 동일한 이름의 “상의”가 존재하여 ‘소’ 카테고리 대신 ‘중’ 카테고리의 “상의”가 클릭 되는 현상이 발생했습니다.”</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*qTCYJgqf4G4VjrYSvznD3g.png\" /><figcaption><strong>카테고리 고도화 이전</strong></figcaption></figure><ul><li>API로 카테고리를 받아왔음에도 잘못 클릭 되는 현상을 방지하고자, 대/중/소 카테고리 탐색 로직을 개선하여 각 depth 별로 정확한 카테고리를 클릭할 수 있도록 했습니다.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*yiMHdk2N_jBAqOE57UThdw.png\" /><figcaption><strong>카테고리 고도화 이후</strong></figcaption></figure><ul><li><strong>(3) 텍스트 정합성 검증</strong> : 상품명에 불필요한 공백(앞뒤 공백, 중복 띄어쓰기 등)이 포함되어 있어도 FE에서 공백을 정리해 주는 로직이 적용되어 있음을 개발팀 확인 후 이에 맞춰 테스트 코드에서도 동일하게 공백을 제거한 후 비교하도록 개선하여, 불필요한 Fail이 발생하지 않도록 했습니다.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*fD0mMtdmNMKWLUAd4iSquQ.png\" /><figcaption><strong>불필요한 공백 제거 처리</strong></figcaption></figure><h4><strong>8월 결과</strong></h4><p>7월 대비 1%를 넘는 fail 률이 비교적 줄고, 목표 fail률인 0.7% 미만에 도달하였지만, 아직 목표 fail률인 0.7%를 초과하는 일자들이 다수 존재했습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*SSy9-8_SGOpKYhB2Q-aKgg.png\" /><figcaption><strong>8월 fail률</strong></figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/607/1*h-tKiMaDagK32R345Q2-eg.png\" /><figcaption><strong>8월 자동화 결과</strong></figcaption></figure><h4><strong>9월: 신규 시나리오 추가와 Fail률 감소의 동시 달성</strong></h4><p>OKR 마지막 달인 9월은 Fail률이 증가할 수 있는 달이었습니다. 왜냐하면 <strong>신규 시나리오를 추가함과 동시에 Fail률을 감소시켜야 하는 조건</strong>이 있었기 때문입니다.</p><p>3Q 추가한 시나리오는 브랜드 홈 고도화 작업, 쿠폰 적용 상품, 마수동 광수동 알람 등이 있었습니다.</p><h4><strong>9월 개선 작업</strong></h4><ul><li>브랜드 홈 NEW 구좌 조건부 검증 : 브랜드 홈에 노출되는 구좌는 NEW, BEST 등이 있습니다. BEST 구좌는 항상 노출되나, NEW 구좌는 상황에 따라 신규 상품이 없으면, 신규 상품이 있으나 그 개수가 적을 경우 등의 상황이 고려되어야 했습니다.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*q23Zssz2CgGhAsO-DoNoAw.png\" /><figcaption><strong>NEW 구좌 더보기 버튼 차이</strong></figcaption></figure><p><strong>(1) API 응답, ID 활용</strong> : 해당 구좌가 존재하는 경우를 판단하기 위해 API 호출 후 신규 상품이 있을 경우에만 검증하고, NEW 구좌 내 상품명 일치 검증을 하는 경우에도 NEW와 더보기 텍스트를 통해 구좌 위치를 판단하는 것보다 정확히 NEW 타이틀에 심어진 ID를 통해 해당 구좌를 판별하도록 수정했습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*iKk26dQylckZtvGM_hZj0w.png\" /><figcaption><strong>NEW 구좌 노출 여부 확인</strong></figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*FfqQmJ-NgafX4A9BvFcvTQ.png\" /><figcaption><strong>ID기준으로 판단</strong></figcaption></figure><ul><li><strong>(2) 패싯 선택 조건 강화</strong> : 쿠폰 적용 상품 페이지 내 가격 필터 패싯 선택 시 상품 종류에 따라 보유한 패싯 정보가 다르기 때문에, price의 최솟값과 최댓값을 받아온 후, 선택해야 하는 가격대 패싯이 있는 조건에 해당하는 경우에만 가격대 패싯을 선택하도록 개선했습니다.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Uf8bt1DoU4fAmQm0QJxmqg.png\" /><figcaption><strong>가격대 패싯 선택 로직 강화</strong></figcaption></figure><p>그 결과, 5만 원~10만 원 가격 패싯이 없는 경우에는 가격대 패싯을 선택하지 않도록 처리되었고, 상품명 데이터 비교를 위한 API 호출 시에도 가격 파라미터를 제외하여 정확한 데이터 검증이 가능해졌습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/667/1*iar_GI1Rr_gOH25EAemIrQ.png\" /><figcaption><strong>5~10만 원 패싯이 없을 경우 미 선택</strong></figcaption></figure><ul><li><strong>(3) 사전 조건 강화 </strong>: PLP, SRP 검증 시 다른 페이지에서 패싯 변경 후 진입하는 경우 패싯이 유지되는 경우를 방지하고자, 현재 패싯 정보를 저장하고 default 패싯 정보와 다를 경우 패싯 사전 조건을 세팅했습니다.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/782/1*NTSJ51ujUsaRY5fRf63qlg.png\" /><figcaption><strong>패싯 초기 상태가 달라질 수 있는 상황</strong></figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*dEffK8Q1-gHkSmcfDHccgg.png\" /><figcaption><strong>패싯 사전조건 세팅</strong></figcaption></figure><ul><li><strong>(4) 일관성 확보</strong> : 29CM 앱 내부에서 설정해야 하는 시나리오 중 설정 중간에 실패, 해제 중간에 실패하는 경우 이후 시나리오에 영향을 줄 수 있기에, 앞뒤 시나리오로 인해 해제 테스트 default 조건이 예상과 다르게 설정된 경우를 방지하기 위한 안전장치로 API를 수행하여 테스트 진행 전 환경을 동일하게 유지했습니다.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*A4ljf6VSXHn0-rNugql5Tg.png\" /><figcaption><strong>테스트 수행 전 API 호출로 테스트 환경 일관성 유지</strong></figcaption></figure><p>그 결과, 9월은 신규 시나리오 추가에도 불구하고 (극소수의 0.7% 초과 날짜는 있었지만) 목표치인 0.7%보다 훨씬 더 낮은 <strong>0.5% 미만의 Fail률</strong>에 도달할 수 있었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/609/1*SPlxxf_lan6x3nsWH22YJg.png\" /><figcaption><strong>9월 자동화 결과</strong></figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*mzzvVnSEcrg9DW9ueQn2ig.png\" /><figcaption><strong>9월 fail률 전체</strong></figcaption></figure><h3><strong><em>자동화 수행 시간 분석과 개선</em></strong></h3><p>Grafana Dashboard에서는 Fail률뿐만 아니라 <strong>시나리오별 수행 시간</strong>도 모니터링할 수 있습니다.</p><p>지난주 대비 이번 주 시나리오별 수행 시간에 차이가 있는 항목을 그래프로 한눈에 시각적으로 확인할 수 있도록 구성되어 있습니다. 이를 통해 어느 시나리오에 많은 수행 시간이 소요 되는지 체크하고, 다음과 같은 원인 분석을 진행했습니다.</p><ul><li>Element 탐색에 오래 걸리는 것인지</li><li>API 호출 후 데이터를 불러와 변환하는 과정이 오래 걸리는 것인지</li><li>불필요한 대기 시간이 포함된 것인지</li></ul><p>분석 결과를 바탕으로 <strong>테스트 케이스를 상황에 따라 분리</strong>하거나, 비효율적인 로직을 개선하여 <strong>수행 속도를 최적화</strong>하고자 했습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*lw3zhF_6249NENOFh4rKdQ.png\" /><figcaption><strong>지난주 대비 이번주 수행시간 비교</strong></figcaption></figure><h4><strong>자동화 수행 속도가 중요한 이유</strong></h4><p>이구위크는 29CM의 대규모 이벤트 기간으로, 유저 인입이 급증하고 장애 발생 시 신속한 제보가 필요합니다. 이에 따라 자동화 스케줄링 주기를 <strong>20~30분 단위</strong>로 단축하여 운영하게 됩니다.</p><p>만약 단일 시나리오의 수행 시간이 과도하게 길어지면, 전체 자동화 수행 시간이 스케줄링 주기를 초과하는 상황이 발생할 수 있습니다. 이는 곧 <strong>장애 탐지 지연</strong>으로 이어질 수 있기 때문에, 수행 속도 최적화는 안정적인 자동화 운영을 위한 필수 요소입니다.</p><h4><strong>🚨 실제 이슈 탐지 사례</strong></h4><p>자동화 수행으로 인해 3Q에 잡은 사유별 Fail을 하나씩 살펴보면 다음과 같습니다.</p><p><strong><em>실제 장애로 인한 fail 발생</em></strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/682/1*Cpa_9H1cqGPal-gfG-AcpQ.png\" /><figcaption>특정 페이지 진입 시 장애 발생으로, 문구를 확인하지 못함으로 인한 fail</figcaption></figure><p><strong><em>배포 직후 배포 트리거가 돌아 발견된 필터 패싯 미 노출 이슈</em></strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/502/1*BnnEhdo_ZgH5Xo44LkP9Pw.png\" /><figcaption>배포 트리거 이후 잡힌 패싯 미노출 fail</figcaption></figure><p><strong><em>피처플래그/앰플리튜드 설정 오류로 </em></strong>잘못된 앰플리튜드 설정으로 테스터가 아닌 유저에게 카테고리 핀메뉴가 미 노출</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/706/1*BVHq-6emfB7Ml9ZMdWVYYQ.png\" /><figcaption>피처플래그, 앰플리튜드 설정이 잘못된 경우 카테고리가 미노출 되었던 현상</figcaption></figure><h3><strong><em>모바일 개발팀과의 협업</em></strong></h3><p>29CM QE Team은 모바일 개발팀과 긴밀한 협업으로 <strong>Element ID를 심고</strong> 있습니다. Element ID가 달라질 경우 문의 시 적극적으로 확인과 재 작업을 잘 해주셔서 많은 도움이 됩니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*GD27h02GgrT25z5JvdCaJg.png\" /><figcaption><strong>긴밀한 협업</strong></figcaption></figure><h4>이 과정에서 가장 중요했던 것은 <strong>혼자 고민하지 않는 것</strong>이었습니다.</h4><p>위클리 진행을 통해 다음과 같은 규칙을 세웠습니다.</p><ul><li><strong>개선 대상 시나리오 선정</strong>: Fail률을 개선하기 위해 수정해야 하는 시나리오를 함께 논의하고 우선순위를 결정</li><li><strong>고민 시간 기준 설정</strong>: 코드 수정 중 혼자 작업 시 고민하는 시간의 기준을 정하고, 그 시간 초과 시 팀원 간 블로커 즉시 공유</li><li><strong>원 팀 모드</strong>: 자동화 코드 작성 중 질문이 있을 때 Q&amp;A 리스트업 후 팀원 모두 원팀 마음으로 해소하려고 서로 조언 주기</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*twhzw7EQo-F4xiZlwwFM2g.png\" /><figcaption><strong>위클리, Action Item</strong></figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*NhV8Mb0bdyPiaoFV0PyVoA.png\" /><figcaption><strong>Android 9월 fail률 목표 도달</strong></figcaption></figure><p>Android 또한 9월 Fail률 2% 미만을 달성하며 목표에 도달했습니다. 아직 시나리오 확장 단계라 iOS보다 목표치를 보수적으로 잡아둔 상황이었는데, 작년 시나리오 확장 초반 대비 매우 낮아진 Fail률은 플랫폼 담당자 간의 적극적인 원 팀 문화 덕분이라고 생각합니다. <br>iOS 담당자도 Android에 조언과 피드백을 아끼지 않았고, Android 담당자 역시 iOS에 적극적으로 피드백을 주며 서로 도왔기에 가능한 성과였습니다.</p><p>마지막으로, 목표만 말로 세우는 것이 아닌 <strong>실질적인 Agenda와 Action Item</strong>을 도출하고, <strong>Gantt 차트로 일정을 수립하여 </strong>누락 없이 진행할 수 있었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*A_BLNvp4YPRvBG7Y6wFn8A.png\" /><figcaption><strong>iOS</strong></figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/779/1*0DRrCH-8M0TJwFW46I_0Hg.png\" /><figcaption><strong>안드로이드</strong></figcaption></figure><p>이처럼 <strong>데이터 기반 분석 + 팀 협업 + 체계적인 일정 관리</strong>가 결합되어 3Q 목표였던 <strong>Fail률 0.7% 미만을 달성</strong>할 수 있었습니다.</p><p>단순히 자동화 테스트를 수행하는 것에서 그치지 않고, 데이터 기반으로 분석하고 개선하는 과정이 자동화의 신뢰성을 높이는 핵심이라는 것을 경험할 수 있었습니다.</p><p>앞으로도 지속적인 모니터링과 분석을 통해 더 안정적인 자동화 환경을 구축해 나가겠습니다.</p><p>29CM QE팀은 AI를 적극적으로 활용하고 있습니다. 현재 Grafana Dashboard를 활용한 분석에서 한발 더 나아가, AI를 통해 자동화 결과를 주 단위, 월 단위로 자동 분석하고 리포트를 받아볼 수 있도록 코드를 작성하고 있습니다.</p><p>다음 글에서는 AI를 활용해 29CM QE팀이 불필요한 시간을 줄이고, 얼마나 효율적으로 테스트 결과를 받아보며, 그 결과를 기반으로 개선해 나가고 있는지에 대한 이야기로 찾아뵙겠습니다.</p><p>긴 글 읽어주셔서 감사합니다.</p><h3>TEAM MUSINSA CAREER</h3><blockquote><em>무신사는 2001년 온라인 커뮤니티로 시작해 2005년 무신사 매거진, 2009년 무신사 스토어를 오픈하며 빠르게 성장하고 있는 국내 대표 온라인 패션 스토어입니다. ‘입점 브랜드와 동반성장’이라는 경영 철학을 바탕으로 브랜드가 안정적으로 사업을 전개할 수 있도록 무신사가 보유한 노하우와 인프라를 지원합니다. 고객에게는 풍성한 패션 콘텐츠와 패션에 특화된 차별화된 서비스로 최상의 온라인 쇼핑 경험을 제공하고 있습니다. 글로벌 №1 패션 기업으로 성장할 무신사와 함께 새로운 도전과 혁신을 만들 인재를 기다립니다.</em></blockquote><blockquote><em>29CM는 ‘고객의 더 나은 선택을 돕는다’라는 미션으로 출발했습니다. 우리는 우리만의 방식으로 콘텐츠를 제공하며, 브랜드와 고객 모두에게 대체 불가능한 커머스 플랫폼을 만들어가고 있습니다. 이 미션을 이루기 위해 우리는 흥미로우면서도 복잡한 문제들을 해결하고 있습니다. 만약 우리와 함께 이 문제들을 해결해 보고 싶다면, 주저하지 말고 29CM에 합류하세요!</em></blockquote><blockquote><em>🚀 </em><a href=\"https://corp.musinsa.com/ko/career/\"><em>팀 무신사 채용 페이지</em></a><em> (무신사/29CM 전체 포지션 확인이 가능해요)</em></blockquote><blockquote><em>🚀 </em><a href=\"https://kr.linkedin.com/company/musinsacom\"><em>팀 무신사 테크 소식을 받아보는 링크드인</em></a></blockquote><blockquote><em>🚀 </em><a href=\"https://newsroom.musinsa.com/\"><em>팀 무신사 뉴스룸</em></a></blockquote><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=e18deceed574\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://techblog.musinsa.com/qa-%EC%9E%90%EB%8F%99%ED%99%94-%EA%B2%B0%EA%B3%BC%EB%A5%BC-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A1%9C-%EA%B4%80%EB%A6%AC%ED%95%98%EB%8B%A4-grafana-dashboard%EC%99%80-weekly-%EB%B6%84%EC%84%9D%EC%9D%98-%ED%9E%98-e18deceed574\">QA 자동화 결과를 데이터로 관리하다: Grafana Dashboard와 Weekly 분석의 힘</a> was originally published in <a href=\"https://techblog.musinsa.com\">MUSINSA techblog — 무신사 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2025-12-28T22:02:23.000Z",
    "url": "https://techblog.musinsa.com/qa-%EC%9E%90%EB%8F%99%ED%99%94-%EA%B2%B0%EA%B3%BC%EB%A5%BC-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A1%9C-%EA%B4%80%EB%A6%AC%ED%95%98%EB%8B%A4-grafana-dashboard%EC%99%80-weekly-%EB%B6%84%EC%84%9D%EC%9D%98-%ED%9E%98-e18deceed574?source=rss----f107b03c406e---4"
  },
  {
    "publisherId": "musinsa",
    "publisherName": "무신사 테크블로그",
    "specTitle": "e커머스 개발",
    "categories": [
      "backend"
    ],
    "specUrl": "https://medium.com/feed/musinsa-tech",
    "title": "“우리가 직접 만들겠습니다” — 무신사의 POS 내재화 여정",
    "partialText": "<h3>“우리가 직접 만들겠습니다” — 무신사의 POS 내재화 여정</h3><h3>들어가며</h3><p>안녕하세요. 무신사 PBO(Platform Business Operation) 프론트엔드 개발자 구룡입니다.</p><p>무신사 오프라인 스토어는 자체 개발한 POS 클라이언트 시스템인 <strong>MPOS(Musinsa POS)를 도입</strong>하여, 온라인과의 상품 및 회원 연동 체계를 내부적으로 구축하였으며 <strong>2025년 7월 중 MPOS로의 전환을 완료</strong>하였습니다. 현재 내부 다양한 스토어 유형의 매장을 지원하고 있으며, 앞으로 더욱 다양한 형태의 스토어, 매장이 확장될 예정입니다.</p><p>무신사 오프라인 스토어는 과거에 POS 결제 솔루션으로 <strong>외부 3rd party 솔루션</strong>을 사용했습니다. 해당 솔루션은 초기 선정 당시 최적의 선택이었을수 있으나 온라인 플랫폼과의 연동성 및 개발 대응 속도 등의 한계로 인해 <strong>비즈니스의 빠른 성장을 제때에 지원하지 못하고 지속적으로 비즈니스의 병목으로 작용</strong>해 왔습니다.</p><p>당시에는 일부 기능이 web형태로 내재화되었으나, <strong>VAN사와의 결제 승인</strong>, 그리고 <strong>주문/정산 정보 인터페이스</strong>는 여전히 외부 솔루션에 의존하고 있었습니다. 이로 인해 다음과 같은 문제가 발생하고 있었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*7vmOAAmTXCL63lIp_xWuwQ.jpeg\" /></figure><ul><li><strong>외부 의존성으로 인한 개발 지연</strong>: 기능 추가나 수정 시 외부 업체와의 협의 및 개발 일정 조율 필요</li><li><strong>비용 부담</strong>: 외부 솔루션 사용료 및 추가 개발비 지속 발생</li><li><strong>유연성 부족</strong>: 비즈니스 요구사항에 대한 빠른 대응의 어려움</li><li><strong>시스템 통합의 복잡성</strong>: 외부 시스템과의 연동으로 인한 복잡도 증가</li></ul><p>이러한 문제들을 해결하기 위해 <strong>POS 시스템의 전면 내재화</strong>를 추진하게 되었고, 현재는 외부 솔루션에 대한 의존성을 완전히 제거하고 모든 POS 기능을 내재화하여 자체 개발 시스템으로 전환을 완료했습니다.</p><h3>1. POS 시스템 내재화의 필요성</h3><p>MPOS를 만들기로 했을 때 가장 먼저 고민한 건 “왜 지금까지 외부 솔루션에 붙어 있었나”였습니다. 매장에서 실시간으로 결제를 받고, VAN사와의 결제 승인을 받아야 하고, 정산을 연동해야 하는 상황에서 외부 시스템은 편리했지만, 그 편리함이 점점 발목을 잡기 시작했습니다.</p><p>그동안 웹 일부 기능만 자체 개발했고, 핵심 기능들은 여전히 외부 솔루션에 의존하고 있었습니다. 외부 솔루션을 통해 결제 승인이나 주문/정산 인터페이스를 처리하다 보니 기능 하나를 바꾸는 데도 외부 업체와의 미팅, 일정 조율, QA를 포함한 긴 시간이 필요했습니다. 비용도 계속 늘어나고, 새로운 요구사항이 생겨도 빠르게 반응하기 어려운 구조가 되었죠. 시스템 통합 역시 여러 외부 시스템이 서로 얽히면서 복잡도가 커졌고, 영수증 프린터처럼 고객과 아주 가까워야 하는 엔드포인트마저 외부 솔루션을 통해 처리하니 통제권이 없었습니다.</p><p>이런 경험들이 쌓일수록 “우리가 직접 만들고, 우리가 통제해야겠다”는 결심이 단단해졌습니다. MPOS 내재화는 단순히 개발팀의 자부심 차원이 아니었습니다. 개발 속도를 높이기 위해서, 외부 솔루션 사용료와 반복되는 커스터마이징 비용을 줄이기 위해서, 비즈니스 요구사항에 흔들리지 않기 위해서, 내부 시스템 간의 직접 연동으로 복잡도를 낮추기 위해서, 그리고 모든 데이터와 프로세스를 우리가 직접 관리하고 품질을 보장하기 위해서 필요한 결정이었습니다.</p><h3>2. 패키징 솔루션 검토</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*14lO4BFXvTYxSFQDc-h_3w.jpeg\" /></figure><p>MPOS를 데스크톱 애플리케이션으로 포장한다는 건 단순히 UI를 감싸는 문제가 아니었습니다. 기존 웹 기반 UI를 그대로 가지고 오면서도, 오프라인과 하드웨어 중심의 매장 환경에서 작동해야 했기 때문에, 선택의 기준이 많았습니다.</p><p>우리는 먼저 각 솔루션이 어떤 기술 스택 위에 올라서는지, 우리가 이미 가지고 있는 개발력을 얼마나 활용할 수 있는지를 중심으로 논의를 시작했습니다. Electron은 JavaScript/HTML/CSS의 재활용이 가능하다는 점에서 개발 속도를 크게 앞세울 수 있었고, Chromium과 Node.js를 함께 쓰면서 시스템 자원을 직접 다룰 수 있다는 점이 매력적으로 다가왔습니다. 반면, Tauri는 Rust 기반으로 경량이고 메모리 효율적인 장점이 있었지만, Rust에 익숙하지 않은 팀에서는 러닝 커브가 부담이었고, 매장에서 직접 제어해야 하는 하드웨어 드라이버를 연결하는 데 다소 제약이 있었습니다. 네이티브 개발은 퍼포먼스 면에서 뛰어났지만, Windows와 macOS를 각각 따로 개발해야 하는 실무 부담이 컸고, 유지보수할 개발자 리소스도 부족했습니다.</p><p>이렇게 여러 조건을 하나씩 놓고 비교하면서도, MPOS가 필요로 하는 것은 도구의 기능보다 매장 환경을 해석하고 빠르게 대응할 수 있는 능력이라는 점이 더 명확해졌습니다. 결국 우리는 <strong>현재 가진 웹 개발 역량을 최대한 활용하면서, 하드웨어·네트워크 제약을 묶어낼 수 있는 Electron</strong>을 선택하게 되었습니다. 이는 포장 솔루션을 단순히 기술 목록으로 고른 것이 아니라, MPOS라는 속도와 안정성을 동시에 요구하는 시스템의 경험으로 접근한 결정이었습니다.</p><h3>3. Electron 선택 이유</h3><p>솔루션을 고르는 회의 자리에서는 “그래도 Electron 아니면 안 될까요?”라는 질문이 자주 나왔습니다. MPOS는 기존 외부 솔루션의 영향을 받으며 개발 주기가 늘어나고 있었고, 영수증 출력·결제 승인·주문/정산 인터페이스처럼 하드웨어와 실시간으로 통신해야 하는 핵심 기능은 오래된 구조 위에서 유지·관리되고 있었습니다. 우리는 “특정 기술”이 아니라 MPOS의 다음 단계 운영 방식 자체를 정의할 수 있는 방안을 찾고 있었습니다.</p><p>그 과정에서 눈에 들어온 요소는 아래와 같습니다.<br><strong>첫째, 개발 속도</strong>입니다. 외부 솔루션을 끼고 개발하는 동안 요구사항 하나 제대로 반영하기까지 수주가 걸렸고, 새로운 스택을 도입하면 그만큼 시간과 리스크가 추가될 수밖에 없었습니다.<br><strong>둘째, 하드웨어와의 긴밀한 통신</strong>입니다. 영수증 프린터, 바코드 스캐너 등의 디바이스를 Node.js 수준에서 접근할 수 있어야 했고, 로컬 데이터 저장·네트워크 통신을 자유롭게 섞을 수 있어야 했습니다.<br><strong>셋째, 크로스 플랫폼과 시스템 독립성</strong>입니다. 매장마다 시스템 설정이 다르고, 브라우저 버전에 따라 동작이 달라지는 걸 막기 위해 동일한 런타임 위에서 작동하는 솔루션이 필요했습니다.<br><strong>마지막으로, 운영하고 있는 매장의 안정성</strong>을 고려해 검증된 생태계와 커뮤니티 지원도 중요했습니다.</p><p>이러한 조건을 놓고 비교한 결과, Electron이 가장 MPOS의 요구를 맞춰줄 수 있는 솔루션이라 판단했습니다. 기존의 JavaScript/HTML/CSS 기술 스택을 그대로 활용할 수 있어 팀 내 도입 장벽이 낮았고, npm 생태계의 serialport를 비롯한 하드웨어 연동 라이브러리를 통해 필요한 디바이스 통신을 구현할 수 있었습니다. Chromium을 내장해 시스템 브라우저와 무관하게 동일한 동작을 보장했고, 이미 VS Code, Slack, Discord처럼 신뢰받는 애플리케이션에서 쓰이며 안정성이 확인된 솔루션이었습니다.</p><p>결국 우리는 MPOS가 직면한 문제(느린 개발, 하드웨어 통신, 크로스 플랫폼, 안정성)를 Electron이 한 번에 묶어서 해결할 수 있다는 판단하에 Electron을 최종 솔루션으로 채택했습니다. 이 선택이 MPOS의 “포장을 넘어선” 전면 내재화 여정이자, MPOS 자체를 중심에 둔 기술 결정임을 팀 모두가 공감했습니다.</p><h3>4. MPOS에 Electron 적용후기</h3><p>Electron을 MPOS에 적용하며 직접 맞닥뜨린 현장의 문제들과, 그것들을 하나씩 풀어준 해결책들을 소개하려 합니다.</p><h3>4.1 빌드 환경 및 비용</h3><p>워크플로를 처음 정할 때 “그냥 다른프로젝트에서 하던대로 Linux에서 빌드하면 되지 않나”라는 질문이 정말 많았습니다. 하지만 MPOS는 Windows용, 실제 매장 환경에서 돌아가야 하는 애플리케이션이었고, Linux에서 나오는 바이너리와 실제 현장에서 쓰는 바이너리는 차이가 제법 컸습니다. 아무리 설정을 맞춰도 Windows에서 끊임없이 재검증해야 했고, 결국 Windows runner에서만 빌드하는 방향이 필요했습니다.</p><p>그렇다고 비용을 무작정 늘릴 수는 없었기에, 우리는 빌드를 최소화시키는 쪽으로 전략을 세웠습니다. Windows runner에서는 실제 설치 패키지를 만들고, Linux runner는 테스트와 lint 등 비용이 적은 작업만 맡겼습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*agIaKC25nb_lMASM3gppKg.jpeg\" /></figure><p>이 방식으로 Windows 빌드 횟수를 꼭 필요한 순간으로 압축하면서도, 현장에 정확한 바이너리를 전달하는 구조를 갖출 수 있었습니다.</p><h3>4.2 IPC 통신 끊김</h3><p>Windows 환경에서 일정 시간 대기 상태로 진입할 때 IPC(Inter-Process Communication)가 끊기면 하드웨어가 멈출 수 있다는 이야기를 듣고, 출시 전에 미리 시나리오를 만들어 테스트해봤습니다. 영수증 출력이나 결제가 들어온 순간을 시뮬레이션하자 IPC가 도중에 끊기며 메인 프로세스와 UI가 소통을 못 하는 상태가 재현되었고, “실제 고객 앞에서 이러면 큰일이겠구나”라는 경고가 내부에서 울렸습니다.</p><p>그래서 아예 그런 상황이 오기 전에 Electron의 powerSaveBlocker를 꺼두기로 했습니다. 메인 프로세스에 display sleep을 무시하도록 지시하니, Sleep모드 진입하지 않고 꾸준히 IPC 연결을 유지했고, 시리얼 통신이 예전처럼 끊길 조짐을 보이지 않았습니다. 설치 스크립트에는 아래처럼 sleep 방지를 켜고 종료 시 되돌리는 루틴을 넣어서 사고를 사전에 막을 수 있었습니다.</p><pre>// 메인 프로세스<br>const { powerSaveBlocker } = require(&quot;electron&quot;);<br>const id = powerSaveBlocker.start(&quot;prevent-display-sleep&quot;);<br><br>app.on(&quot;will-quit&quot;, () =&gt; {<br>  powerSaveBlocker.stop(id);<br>});</pre><p>이렇게 미리 막고 나니 어떤 상황에서도 IPC는 침착했고, 결제나 프린트 요청이 예측 가능한 흐름으로 이어지면서 현장 안정감이 훨씬 높아졌습니다.</p><h3>4.3 SerialPort로 외부 디바이스 연결</h3><p>MPOS는 영수증 프린터, 바코드 스캐너 등 시리얼 포트를 통해 연결되는 디바이스와 통신해야 합니다. 이를 위해 Node.js의 serialport 패키지를 사용했는데, Electron 환경에서 번들링 과정과 실행 파일에서 예상치 못한 문제가 발생했습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/561/1*roYANI8jsiuySnmFD1VJhA.png\" /></figure><p>serialport를 챙겨야 할 때, 빌드 과정에서 “특정 모듈을 못 찾는다”는 오류가 뜨며 멀쩡하던 연결이 한순간에 끊기는 일이 벌어졌습니다. 로컬에서는 문제없었지만 빌드된 실행 파일이 node_modules 구조를 그대로 갖고 있지 않다 보니, node-gyp-build.js가 상대 경로로 prebuilds를 찾다가 길을 잃은 것이었습니다. 하드웨어 통신이 이 부분에 달려 있었기 때문에, 이걸 풀지 않으면 MPOS가 기기를 아예 제어하지 못하는 위험한 상황이 되었죠.</p><p>그래서 우리는 두 방향으로 대응했습니다. 하나는 번들 결과물 안에 prebuilds 자체를 넣는 것, 다른 하나는 런타임에서 node-gyp-build.js가 절대 경로를 참고하도록 만드는 것이었습니다. rsbuild.main.config.ts에서 prebuilds 디렉토리를 출력 디렉토리로 복사하고, string-replace-loader로 경로 조합 코드를 건드려 __dirname 기반으로 바꾸면 빌드된 exe에서도 찾을 수 있게 됩니다.</p><pre>// rsbuild.main.config.ts<br>{<br>  output: [<br>    // prebuilds 파일을 빌드 출력 디렉토리로 복사<br>    {<br>      from: path.resolve(__dirname, &quot;./node_modules/@serialport/bindings-cpp/prebuilds/win32-x64&quot;),<br>      to: &quot;./prebuilds&quot;,<br>    },<br>    {<br>      from: path.resolve(__dirname, &quot;./node_modules/@serialport/bindings-cpp/prebuilds/win32-x64&quot;),<br>      to: &quot;./prebuilds/win32-x64&quot;,<br>    },<br>  ],<br>  tools: {<br>    rspack(config, { addRules }) {<br>      addRules([<br>        {<br>          test: /node-gyp-build\\.js$/,<br>          loader: &#39;string-replace-loader&#39;,<br>          options: {<br>            search: /path\\.join\\(dir, &#39;prebuilds&#39;/g,<br>            replace: &quot;path.join(__dirname, &#39;prebuilds&#39;&quot;,<br>          },<br>        },<br>      ])<br>    }<br>  }<br>}</pre><p>이렇게 두 손을 쓴 뒤부터는 설치 파일 안에서 serialport가 필요한 바인딩을 모두 찾아내고, 시리얼 통신도 끊김 없이 이어졌습니다. MPOS가 하드웨어와 대화를 하도록 묶어주는 연결고리를 잃지 않고 버티고 있다는 확신이 들면서, 현장에서 실제 디바이스를 붙였을 때도 문제가 없었습니다.</p><h3>4.4 ESC/POS 표준에 대한 지식 부족 및 대응</h3><p>영수증 프린터를 붙이는 순간부터 우리에게 필요한 건 ESC(Epson Standard Code)/POS 명령어를 다루는 능력이었습니다. 텍스트, 로고, 바코드, QR코드까지 모두 다루려면 표준을 거의 숙지해야 했고 제조사별 미묘한 차이까지 커버해야 했습니다. 처음에는 escpos 같은 오픈소스 라이브러리로 빠르게 시작해보려 했는데, 각 기능이 불안정하거나 우리가 필요한 스타일링이 빠져 있어서 “이대로 현장에 내보낼 수 없다”는 판단이 나왔습니다.</p><p>그때부터는 도면을 하나씩 뜯어보듯 ESC/POS 문서를 따라가며 기능을 직접 채워 넣었습니다. 프린터마다 명령어가 조금씩 달라 테스트를 반복했고, 필요한 기능은 직접 구현해서 내부 라이브러리로 묶었습니다.</p><p>이제 MPOS의 영수증 출력은 더 이상 외부 라이브러리에 기댈 필요가 없고, 우리가 만든 라이브러리 안에서 요구하는 출력 흐름을 그대로 그려낼 수 있게 되었습니다. 현장에서 프린터를 바꿔도 제어 로직은 그대로 재사용 가능했고, 앞으로 새로운 모델을 붙일 때도 일관된 경험을 유지할 자신감이 생겼습니다.</p><h3>4.5 인증서 적용</h3><p>SmartScreen에서 “알 수 없는 게시자” 경고가 뜨는 상황을 떠올리면 이미 마음이 따갑더라고요. 당장은 MPOS의 배포본이 ‘신뢰할 수 없는 앱’으로 찍히면 매장에 들어가기조차 어렵겠구나 하는 위기의식이 생겼습니다. 그래서 인증서를 준비해야겠다고 모두가 생각했고, OV(Organization Validation)와 EV(Extended Validation) 중 어느 쪽을 선택할지 진짜 여러 번 회의실에서 들여다보았습니다.</p><p>EV는 보안성이 높고 SmartScreen 신뢰도가 좋지만, USB eToken에 묶여서 자동화가 힘들고, CI/CD에서 사용할 수 있는 .pfx 추출도 불가능하다는 점이 발목을 잡았습니다. 반면 OV는 상대적으로 신뢰도가 낮지만 인증서 파일을 추출할 수 있어 GitHub Actions에서 자동으로 붙일 수 있었습니다. 우리가 원하는 건 ‘리모트에서도 코드 서명까지 끝나는 제대로 된 릴리즈’였고, 결국 OV 인증서가 실용적이라고 판단했습니다.</p><p>한국전자인증에서 OV CodeSign 인증서를 받아 cert.pfx를 확보한 뒤, GitHub Secrets에 base64로 저장하고 빌드 파이프라인에서 다시 복원하는 방식으로 연결했습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/996/1*TnrM9pGYFKCEsd9RysyQEA.png\" /></figure><p>결과적으로 매번 빌드마다 신뢰도를 확보한 EXE를 배포할 수 있게 되었고, SmartScreen만 통과하면 ‘정상적인 설치 과정’이라는 인상을 줄 수 있었습니다.</p><h3>4.6 네트워크 관련</h3><p>매장 네트워크는 괜찮다가도 가끔 연결이 끊기는 일도 있습니다. 우리가 미리 시뮬레이션해보니, 조금만 네트워크가 내려가도 기준정보 API를 못 받아서 메뉴판이 깨지고, 주문도 막히는 상황이 벌어질 수 있었습니다. 그래서 네트워크 문제를 “낮은 확률의 이슈”로 남겨두지 않고, 사전에 대처책을 짜기로 했습니다.</p><p>첫 번째는 진입시 매장기준정보 데이터를 캐싱하는 전략이었습니다. 매장 단말에 정보를 저장해두고, 서버와 통신이 끊겼을 때도 그 데이터를 참고하게 만들면, 결제나 주문처럼 필수적인 흐름은 계속 이어질 수 있겠다고 판단했죠. 네트워크가 다시 들어오면 캐시를 업데이트하고 최신 데이터를 가져오도록 했는데, 이렇게 하면 가끔 뜬금없이 접근 안되는 이슈도 해결되었습니다.</p><p>두 번째는 Network Information API를 붙여 사용자에게 네트워크 상태를 보여주는 것입니다. 연결이 나빠지거나 끊기면 MPOS 안에서 알림을 띄워서, 매장 직원이 “아, 지금 인터넷이 불안정하구나”라고 바로 알 수 있게 만들었습니다 그러니까 문제가 생겼을 때 무턱대고 온콜을 걸기보다, 스스로 확인하거나 관리자에게만 보고하도록 하여 감이 빨라졌습니다. 이런 미리보기 알림 덕분에 네트워크 이슈가 발생해도 대응 시간과 불안감이 크게 줄었고, 복구되면 알림도 조용히 사라지면서 원활한 유저 경험을 지켜냈습니다.</p><h3>4.7 모니터링 및 장애 대응</h3><p>MPOS를 현장에 올려놓은 뒤, “사용자의 행동이 곧 신호”라는 생각이 자꾸 들었습니다. 그래서 Datadog RUM을 연결해 실제 사용자의 행동을 살펴보며, 어떤 흐름이 정상이고 어디에서 낯선 패턴이 나오는지 이해하는 데 집중했습니다. RUM 덕분에 특정 기능이 반응하는 데 시간이 길어지거나, 사용자가 반복해서 클릭하는 화면이 감지되면 바로 알 수 있었고, 그것이 오류의 전조임을 알아차리는 데 큰 도움이 되었습니다.</p><p>추가로 JavaScript 예외, API 실패, 기타 SDK에서 잡은 오류들은 에러 트래킹 시스템을 통해 수집되었습니다. 어떤 오류가 발생하면 Slack 알림이 거의 실시간으로 들어왔고, 알람에는 오류 메시지·스택 트레이스·화면 context·영수증번호 등 필요한 정보를 담아두어 즉시 대응이 가능했습니다. Slack 메시지를 보고 개발팀이 바로 모여 핫픽스를 준비하거나, 후속 대응을 준비했습니다.</p><p>POS 시스템은 매장 매출과 직결되니 응답 시간이 느려지면 곧바로 민원이 들어왔지만, 이런 모니터링 + Slack 대응 구조 덕분에 평균 대응 시간이 짧아졌고, 문제의 영향을 최소화 할 수 있었습니다. 예전에는 고객 한 명이 장애를 먼저 얘기해야 알았던 일이, 이제는 시스템이 먼저 “이상 징후”를 울려주고, 우리끼리 먼저 해결할 수 있게 된 셈입니다.</p><h3>5. 내재화 이후 달라진 결과</h3><p>런칭 이후 가장 환한 변화는, 외부 업체에게 의존하지 않아도 된다는 점이었습니다. VAN사, SAP, 영수증 프린터까지 모든 노드가 외부 솔루션에 묶여 있었던 시절에는 하나의 요청에도 외부 일정과 정책을 맞춰야 했지만, MPOS를 직접 손보면서 문제를 마주할 때마다 로그를 들여다보고 고치게 되었습니다. 덕분에 커뮤니케이션이 줄고 결정 속도가 빨라졌으며, 팀에서도 “이 부분은 우리가 책임지고 돌린다”는 태도를 유지하게 되었습니다.</p><p>그 다음으로 반가웠던 건 외부 솔루션 사용료가 사라졌다는 사실입니다. 매장 수가 늘어날수록 예산 시뮬레이션이 부담으로 다가왔는데, MPOS 전환으로 그 걱정이 줄었습니다. 커스터마이징은 여전히 필요하지만 내부 프로젝트처럼 관리하니 비용 통제도 쉬웠고, 장기적으로 운영비가 내려간다는 감각이 눈에 보이기 시작했습니다.</p><p>개발 속도는 예전과 비교할 수 없을 만큼 달라졌습니다. 외부사를 기다리며 릴리즈가 밀리던 기억은 이제 옛이야기가 되었고, 요청이 들어오면 “이거 내가 맡을게요”라는 말과 함께 바로 코드에 손을 얹습니다. 빠른 피드백 루프 덕분에 이벤트성 프로모션도 단기간에 반영할 수 있었고, 시장 변화에 따른 대응 템포도 훨씬 빨라졌습니다. 기다림 대신 실행하는 분위기가 팀 내에 뿌리내렸고, 연속된 작은 승리들이 곧 개발자들에게 자신감으로 이어졌습니다.</p><p>통합 구조도 훨씬 쉬워졌습니다. 외부 솔루션을 여러 단계 거치던 시절에는 장애가 나면 “여기서 시작인가?” 하며 길을 헤맸지만, 지금은 내부 API만 보면서 데이터를 설계하고 장애를 추적할 수 있습니다. 간결해진 아키텍처 덕분에 장비 간 흐름을 눈으로 그려볼 수 있게 되었고, 장애 대응도 빨라졌으며 유지보수의 부담도 덜어졌습니다.</p><p>마지막으로 가장 안정감을 준 건 데이터였습니다. 외부 솔루션이 제공하는 로그는 제약이 많았지만, MPOS 전면 전환 이후에는 모든 로그를 자유롭게 수집하고 분석할 수 있게 되었습니다. “이 데이터는 우리 것”이라는 자부심과 함께 향후 활용까지 다양한 시나리오를 그릴 수 있게 되었습니다.</p><p>그동안 외부에 맡기고 기다려야 했던 시간에 비하면, 지금은 우리 손으로 뿌리를 내려뒀다는 느낌이 훨씬 강합니다. 작은 로그 한 줄, 빠른 결정 하나하나가 현장 직원들의 편의를 만들어내고, 그러한 변화가 곧 팀의 자신감으로 이어졌습니다. MPOS 런칭은 단순한 기술 서비스 개편이 아니라, 우리만의 운영 리듬을 찾은 순간이었습니다.</p><h3>6. 앞으로 개선해야 할 사항</h3><p>앞으로 개선하고 싶은 내용도 있는데요, 현재 영수증 출력 관련 로직이 메인 프로세스(main thread)에서 처리되고 있다는 점이 가장 먼저 떠올랐습니다. 이 구조는 메인 프로세스에 큰 부담을 주기 때문에, 렌더러 프로세스(renderer)에서 데이터를 다듬고 필요한 커맨드를 조립해 메인 프로세스에 넘기는 방식으로 처리하려고 합니다. 가능한 많은 작업을 렌더러에서 처리하고, 메인 프로세스는 하드웨어 통신(시리얼 포트 접근)처럼 절대 필요한 역할만 맡도록 구조를 재설계하면, 메인 프로세스 응답성이 자연스럽게 회복되고 여러 작업이 동시에 몰릴 때도 성능 저하를 막을 수 있습니다. 또한 이렇게 하면 Electron 전체 패키지를 다시 배포하지 않고도 Web 릴리스 루프만으로 UI나 기능을 빠르게 갱신할 수 있어, 유지보수와 테스트가 훨씬 수월해집니다.</p><p>다른 하나는 일부 저사양 장비에서는 Electron이 메모리 부족 상태에 빠져서 OOM(Out Of Memory) 상황이 있었는데, 이 경우 Tauri처럼 Rust 기반의 경량 런타임을 대안으로 함께 유지하는 방안도 검토 중입니다. Electron과 Tauri 빌드를 병행하여 각각의 디바이스 사양에 맞게 선택하도록 배포 채널을 구성하고, 공통 비즈니스 로직은 Web 코드로 공유하면서 OS별로 일부 구현만 분리하는 전략을 실험하고 있습니다.</p><p>이런 개선 과정을 하나씩 겪으며, 우리는 여전히 완벽하진 않지만 그만큼 팀으로서의 결속이 깊어지고 있다는 걸 느끼고 있습니다. 약한 부분을 대면할 때마다 함께 고민하고, 작은 실험을 지나며 “다음에는 더 단단해질 수 있겠다”는 믿음이 생깁니다. MPOS는 이제 우리 손끝에서 살아 숨 쉬는 시스템이며, 앞으로의 변화도 그렇게 정성을 쏟아 채워갈 예정입니다.</p><h3>마무리</h3><p>MPOS 프로젝트를 통해 POS 시스템을 완전히 내재화하는 데 성공했습니다. Electron을 선택한 것은 빠른 개발 속도, 성숙한 생태계, 시스템 독립성 등의 이유 때문이었고, 실제로 프로젝트를 진행하면서 이러한 선택이 적절했음을 확인할 수 있었습니다.</p><p>물론 Electron의 무거운 용량과 메모리 사용량 등의 단점도 있었지만, POS 시스템의 요구사항을 충족하고 빠르게 개발할 수 있다는 장점이 더 컸습니다.</p><p>PBO O4O팀은 앞으로는 성능 최적화와 의존성 최소화에 집중하여 더 나은 MPOS 시스템을 만들어 나가겠습니다.</p><p>감사합니다.</p><h3>TEAM MUSINSA CAREER</h3><blockquote><em>무신사는 2001년 온라인 커뮤니티로 시작해 2005년 무신사 매거진, 2009년 무신사 스토어를 오픈하며 빠르게 성장하고 있는 국내 대표 온라인 패션 스토어입니다. ‘입점 브랜드와 동반성장’이라는 경영 철학을 바탕으로 브랜드가 안정적으로 사업을 전개할 수 있도록 무신사가 보유한 노하우와 인프라를 지원합니다. 고객에게는 풍성한 패션 콘텐츠와 패션에 특화된 차별화된 서비스로 최상의 온라인 쇼핑 경험을 제공하고 있습니다. 글로벌 №1 패션 기업으로 성장할 무신사와 함께 새로운 도전과 혁신을 만들 인재를 기다립니다.</em></blockquote><blockquote><em>29CM는 ‘고객의 더 나은 선택을 돕는다’라는 미션으로 출발했습니다. 우리는 우리만의 방식으로 콘텐츠를 제공하며, 브랜드와 고객 모두에게 대체 불가능한 커머스 플랫폼을 만들어가고 있습니다. 이 미션을 이루기 위해 우리는 흥미로우면서도 복잡한 문제들을 해결하고 있습니다. 만약 우리와 함께 이 문제들을 해결해 보고 싶다면, 주저하지 말고 29CM에 합류하세요!</em></blockquote><blockquote><em>🚀 </em><a href=\"https://corp.musinsa.com/ko/career/\"><em>팀 무신사 채용 페이지</em></a><em> (무신사/29CM 전체 포지션 확인이 가능해요)</em></blockquote><blockquote><em>🚀 </em><a href=\"https://kr.linkedin.com/company/musinsacom\"><em>팀 무신사 테크 소식을 받아보는 링크드인</em></a></blockquote><blockquote><em>🚀 </em><a href=\"https://newsroom.musinsa.com/\"><em>팀 무신사 뉴스룸</em></a></blockquote><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=462a0d81b5a9\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://techblog.musinsa.com/%EC%9A%B0%EB%A6%AC%EA%B0%80-%EC%A7%81%EC%A0%91-%EB%A7%8C%EB%93%A4%EA%B2%A0%EC%8A%B5%EB%8B%88%EB%8B%A4-%EB%AC%B4%EC%8B%A0%EC%82%AC%EC%9D%98-pos-%EB%82%B4%EC%9E%AC%ED%99%94-%EC%97%AC%EC%A0%95-462a0d81b5a9\">“우리가 직접 만들겠습니다” — 무신사의 POS 내재화 여정</a> was originally published in <a href=\"https://techblog.musinsa.com\">MUSINSA techblog — 무신사 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2025-12-22T22:02:20.000Z",
    "url": "https://techblog.musinsa.com/%EC%9A%B0%EB%A6%AC%EA%B0%80-%EC%A7%81%EC%A0%91-%EB%A7%8C%EB%93%A4%EA%B2%A0%EC%8A%B5%EB%8B%88%EB%8B%A4-%EB%AC%B4%EC%8B%A0%EC%82%AC%EC%9D%98-pos-%EB%82%B4%EC%9E%AC%ED%99%94-%EC%97%AC%EC%A0%95-462a0d81b5a9?source=rss----f107b03c406e---4"
  },
  {
    "publisherId": "musinsa",
    "publisherName": "무신사 테크블로그",
    "specTitle": "e커머스 개발",
    "categories": [
      "backend"
    ],
    "specUrl": "https://medium.com/feed/musinsa-tech",
    "title": "우리는 달에 가기로 했습니다. - Hybrid인프라부터 네트워크 최적화까지, 무신사 AI Infra구축기",
    "partialText": "<h3>우리는 달에 가기로 했습니다. <br>- Hybrid인프라부터 네트워크 최적화까지, 무신사 AI Infra구축기</h3><h3>들어가며 — 시작은 정답이 아니라 질문에서</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*9-n-R-WNSDzNMAKlLIgbtw.jpeg\" /></figure><blockquote>이 글은 지난 AWS Summit 2025에서<a href=\"https://youtu.be/34J2LnTm2hU?si=bmRqQoMOs0y68nDk&amp;t=1006\"> 인터넷 안되는 하이브리드 환경에서 살아남기</a>(16:46부터) 발표한 자료와, AWS Community Day 2025에서<a href=\"https://www.youtube.com/watch?v=GceKWungnRQ\"> <strong>트래픽 폭주에도 흔들리지 않는 AI 서비스, Gateway API로 여는 안정적 확장성의 미래</strong></a> 발표한 내용을 포함하며, 거기서 못다한 이야기기들, <strong>실제 운영 경험·시행착오·로그·엔지니어링 의사결정의 뒷면까지 포함한 확장 기록입니다.</strong></blockquote><p>우리는 구축 과정 내내 같은 질문을 반복했습니다.</p><blockquote>“우리는 지금 올바른 결정을 하고 있는가?”</blockquote><p>AI 인프라를 구축하는 과정에서 중요한 것은<br> <strong>“어떤 기술을 선택했는가?”가 아니라,<br> “왜 그 기술을 선택해야 했는가?”</strong> 였습니다.</p><p>이 글은 <strong>정답이 아니라 탐색의 기록</strong>,<br><strong>완성물이 아니라 성장 중인 시스템의 항해 로그</strong>입니다.</p><p>이 기록이 앞으로 같은 고민을 하게 될 누군가에게 조금 더 빠르게, 조금 더 멀리 갈 수 있는 기록이 되길 바라며 펜을 듭니다.</p><p>—</p><p>—</p><h3>지속 가능성 없이는 미래도 없다</h3><p>2024–2025년의 AI 시장은 단순한 “기술 트렌드”가 아니라 <strong>생존의 조건</strong>이었습니다.<br>투자 확대, GPU 공급난, 운영비 증가. 그리고 그 결과로 이어진 비(非) AI 조직 축소.</p><p>문제는 명확했습니다.<br><strong>AI는 한 번 구축하면 끝나는 시스템이 아니라, 지속적으로 비용이 발생하는 기술이라는 점입니다.</strong></p><p>모델의 설계와 실험 과정에서 드는 트레이닝 비용,<br>트래픽 증가에 따라 폭증하는 inference 비용,<br>최신 데이터를 반영하기 위한 반복적 재학습.</p><p>초기에는 합리적으로 보였던 솔루션들 — SageMaker, Databricks 같은 관리형 서비스들은 트래픽 확장과 함께 비용 기울기가 기하급수적으로 올라갔습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*QArlo7zsbWpAWAT2n10YYA.jpeg\" /><figcaption>H100 8way 인스턴스 한 대만 해도 <em>월 비용이 1억 원에 달합니다. </em>그러나 이 한 대가 모든 문제를 해결해주진 않습니다.</figcaption></figure><p>기업이 AI를 본격적으로 사용하려면 보통 <strong>H100 40장 규모</strong>는 되어야 원활한 연구와 실험이 가능해지고, inference까지 고려하면 그 이상을 요구합니다.<br>아래는 40장 규모 기준 비교표 예시입니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*4Qanx1su1uLoINgmGPrkyA.jpeg\" /></figure><p>정리하면 결론은 명확했습니다.</p><blockquote><strong>지속 가능한 AI를 구축하려면, 온프레미스 GPU 운영을 반드시 고려해야 한다.</strong></blockquote><p>—</p><p>—</p><h3>우리는 달에 가기로 했습니다</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*dPsK7s2W9wlNnITPW5dWfg.jpeg\" /><figcaption><a href=\"https://newsroom.musinsa.com/newsroom-menu/2025-0331\">https://newsroom.musinsa.com/newsroom-menu/2025-0331</a></figcaption></figure><p>앞서 이야기한 것처럼, 트래픽은 폭발적으로 증가하고 있었습니다.<br>그리고 그 성장 속도에 따라 <strong>실험 비용과 inference 비용도 같은 기울기로, 아니 그보다 더 빠르게 상승하고 있었습니다.</strong></p><p>만약 이 문제를 제때 해결하지 못했다면, 이것은 단순한 비용 문제가 아니라 더 큰 파급으로 이어졌을 것입니다.</p><ul><li>실험량 감소</li><li>연구 속도 둔화</li><li>모델 경쟁력 저하</li><li>서비스 품질 정체</li><li>그리고 최종적으로 <strong>성장 속도 둔화</strong></li></ul><p>즉, <strong>혁신의 속도를 비용이 결정하는 구조</strong>가 되어버릴 가능성이 매우 컸습니다.</p><p>그리고 그 순간, 한 문장이 떠올랐습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*elGnYal49RFZJkUIwN1iIQ.jpeg\" /><figcaption><a href=\"https://www.chron.com/news/nation-world/space/article/We-choose-to-go-to-the-moon-The-text-of-13704557.php\">https://www.chron.com/news/nation-world/space/article/We-choose-to-go-to-the-moon-The-text-of-13704557.php</a></figcaption></figure><blockquote><em>“우리는 앞으로 10년 안에 달에 갈 것입니다.<br> 그것이 쉬운 일이기 때문이 아니라, 어려운 일이기 때문입니다.”<br></em> — 존 F. 케네디, 1962</blockquote><p>GPU도 없었고, 전력 인프라도 부족했고, 예산 역시 충분하지 않았습니다.<br> 그러나 하나는 분명했습니다.</p><blockquote><strong>“지금 하지 않으면, 미래에 우리는 더 큰 대가를 치르게 될 것이다.”</strong></blockquote><p>그래서 문서를 작성했습니다.<br>계산을 하고, 시나리오를 설계하고, 리스크와 기대 효익을 모두 적어냈습니다.</p><p>그리고 그 문서는 CTO님의 검토를 거쳐 정식으로 승인되었습니다.</p><p>그 순간이 전환점이었습니다.</p><p>그날 이후,<br>우리는 단순히 GPU를 사는 것이 아니라,<br><strong>회사의 기술 미래를 다시 설계하는 여정</strong>에 들어섰습니다.</p><p><strong>그렇게, 우리는 달에 가기로 했습니다.</strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*65-JYAHvNlkunL9aEObnHQ.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*KqatnXUA8m1n8mSgnyh9qQ.jpeg\" /></figure><p>—</p><p>—</p><h3>시작은 아주 작았다</h3><p>2025년 1월.<br>우리가 처음 마주한 건 기술적 난관이 아니라, 그보다 원초적인 문제였습니다.</p><p><strong>데이터 센터용 GPU인 H100 물량이 없었습니다.</strong></p><p>납기 최소 3개월, 수급 불안정.<br>그래서 우리는 그당시 가장 현실적인 RTX 4090을 검색하기 시작했습니다.<br>결과는 예상보다 더 무자비했습니다.</p><ul><li>H100 물량 없음</li><li>RTX 5090 출시 예정으로 <strong>4090 단종</strong></li><li>게이머/중국 수출업자/연구기관과 경쟁</li></ul><p>그래서 우리는 전화했고, 또 전화했고, 아예 용산에 찾아갔습니다.<br>그리고 결국 물량을 확보했습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*VTgNRB5ytzi_vtHmxBduzA.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*_irCMsTERa4jiKMwlRa6UQ.jpeg\" /></figure><p>그렇게 어렵게 들여온 RTX 4090,<br>GPU 초도물량이 쓰는 전력만 해도 <strong>가정집 3~4가구 수준</strong>이었습니다.</p><p>아직 전력 증설도 이루어 지지않은 상태로 급하게 들여온 GPU를 겨우 전력확보해서 돌렸는데요</p><p>하지만 놀라운 일은 그다음이었습니다.</p><p><strong>온프레미스 도입 1주일 만에 초도물량 BEP를 넘었습니다.</strong></p><p>이쯤에서 많은 사람들이 궁금해했습니다.</p><ul><li>온프레미스면 기존 클라우드 환경은 아예 배제하나?</li><li>데이터 전송은 어떻게 하나?</li><li>VM으로 운영하나? OpenStack인가?</li></ul><p>2024년 12월 AWS는 EKS HybridNode기능을 공개했고, 이는 우리가 원하는 바로 그 기능이었습니다.</p><p>라이센스 비용을 지불해야 했지만 기존 EC2 비용의 5%수준에 불과하고, 기존의 AWS인프라와 완전히 seamless하게 연결 될것같은 전망을 보여줬습니다.</p><p>물론, 이 seamless가 내가 전부 해야내야만 한다는걸 그땐 알지 못했습니다…</p><p>말그대로 ‘전부’요. 후술하겠지만 아주 기초적인 aws-cni라던지.. Metric-server plugin 조차 사용할수 없었습니다.</p><p>게다가 우리는 전기도, 냉방설비도, 공간도, 모든게 부족했고, 이걸 해결할 사람은 저밖에 없었습니다.</p><p>건물 전기 도면을 펼치고, 자문을 구하고, 전기공사를 발주넣고, 전력망 점검에 에어컨 증설까지.</p><p>그리고 GPU를 발주, 수령 및 장비를 점검하고, 동시에 EKS클러스터를 준비했습니다.</p><p>그리고 몇달 간격으로 H100과, H200, 그리고 블랙웰 기반의 장비까지.</p><p>우리의 아폴로 계획은 그렇게 시작되었습니다.</p><p>—</p><p>—</p><h3>해내야만 했습니다. 그것이 seamless Failover를 구현할 유일한 방법 이었으니까요.</h3><p>우리가 목표한 구조는 단순하지 않았습니다.</p><ul><li><strong>On-Prem + AWS가 하나의 클러스터처럼 동작</strong></li><li>GPU 부족 → 자동 AWS 확장</li><li>AWS 비정상 → On-Prem 자동 회귀</li><li>Zero interruption failover</li></ul><p>이건 PoC 수준이 아니라 <strong>운영 가능한 AI 서비스의 기준</strong>이었습니다.</p><p>그래서 물었습니다.</p><blockquote><strong>“이걸 이미 구현한 팀이 있나요?”</strong></blockquote><p>AWS, 벤더, 파트너, 커뮤니티 — 할 수 있는 모든 곳에 문의했습니다.<br> 하지만 돌아온 대답은 동일했습니다.</p><blockquote>“그 기능은 아직 레퍼런스가 거의 없습니다.”<br>“한국에는 없고, 해외 사례도 확인되지 않습니다.”<br>“문서 기준으로는 가능하지만, 실제 운영에 대한 보고는 없습니다.”</blockquote><p>그래서 결정했습니다.</p><p><strong>없다면, 우리가 첫 번째가 되자.</strong></p><p>문서만 보면 Hybrid Node는 단순한 기능처럼 보였지만,<br> 현실은 달랐습니다. 문서 그대로 적용하면 노드는 붙지 않았고,<br> AWS 기술 지원팀조차 일부 구성 요소의 동작 방식을 확신할 수 없었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*hWt7mZBdMWQDhu7IzbHwxQ.jpeg\" /><figcaption>EKS HybridNode는 Automode를 지원하지 않는다는 답변.</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*expDcytZ1_1GLCtKtHzwbw.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*yp8qUG1TuA5OZM0ikao3kQ.jpeg\" /></figure><p>누구도 정답을 가지고 있지 않은 환경이었고, 참고할 수 있는 아키텍처도 없었습니다.<br>하지만 멈출 수 없었습니다. 이유는 단순했습니다.</p><blockquote><strong>우리는 이 구조가 필요했습니다.</strong></blockquote><p>하이브리드 환경에서 트레이닝과 인퍼런스를 모두 안정적으로 동작시키려면, EC2와 온프레미스 GPU 장비가 하나의 클러스터 안에서 같은 기준으로 운영되어야 했습니다.</p><ul><li>On-Prem에서 모델이 학습되고</li><li>AWS에서 이 모델이 서빙되고</li><li>어느 한 쪽이 장애가 나면<br> → <strong>즉시 반대편에서 동작하는 구조</strong></li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*qeZMLko25Gjt0B8SxHqNAQ.jpeg\" /></figure><p>이것이 실현되어야 <strong>AI 제품화(Productization)</strong> 가 가능했습니다.</p><p>그렇게 뚝딱거리며 시간이 흐르다보니 어찌어찌 노드 연결이 되더라구요.</p><p>그런데 OnPrem노드를 AWS VPC로 연결해서 네트워크를 구성하려면 eBPF기반의 cilium을 도입하고 ISO L3레이어 부터 L7레이어까지 직접 컨트롤하며 aws vpc cni를 걷어낼수밖에 없었는데요, 그 과정에서 필연적으로 따라온것은, AWS CNI를 기반으로 만들어진 모든것들, 그러니까 아주작은 addon 하나하나 직접 구성 해야한다는 것이었습니다.</p><p>심지어 EKS에서 기존에 잘 동작하던 카펜터조차 동작을 안하더군요.</p><p>EKS쓸때 자주쓰는 AWS pod identity매니저도 동작 안했는데요, 이경우는 fork도 제공하지 않고, 다큐멘트도 딱히 없어서 pull땡기고 소스를 뜯어볼수밖에 없었습니다.</p><p>즉 EKS의 컨트롤 플레인만 사용하게되고, 나머지 모든것, addon들까지 모두 직접 구성해야 한다는것이었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*SWlq4jwgCoGLXZkFvkjulQ.jpeg\" /><figcaption>테크니션이 Automode와 Hybrid를 같이 쓸수 없다고 답변했지만, 결국 해냈다.</figcaption></figure><p><strong>우리는 이제 “가능성 너머”에 서 있었습니다.</strong></p><p>결국 끝내 해내고 나니 AWS Summit 2025에서<a href=\"https://youtu.be/34J2LnTm2hU?si=bmRqQoMOs0y68nDk&amp;t=1006\"> <strong>인터넷 안되는 하이브리드 환경에서 살아남기</strong></a><strong>(16:46부터)</strong> 라는 제목으로 공유하는 자리도 갖았습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*YVJYCDRM1s104f5hAmjOIQ.jpeg\" /></figure><p>—</p><p>—</p><h3>선택과 시행착오 — AutoMode, Karpenter, 그리고 충돌</h3><p>초기 설계는 아래와 같았습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*ZxgZbmCHWXBCI4YOqfkLYQ.jpeg\" /></figure><ul><li><strong>AutoMode + Managed Node + Hybrid Node</strong></li><li>이후 단계적으로 <strong>Karpenter 도입</strong></li></ul><p>논리적으로는 완벽했습니다.<br>AutoMode는 AWS가 관리하므로 안정적인 가용성을 기대할 수 있고, 모자란 On-Prem 자원을 EC2 자원이 자연스럽게 메워줄 것이라 생각했습니다.</p><p>추후 Karpenter를 도입하려고 하자 ‘완벽해 보였던’ 계획은 곧바로 문제를 일으켰습니다.</p><ul><li>Node scheduling mismatch</li><li>라벨 충돌</li><li>Scaling loop</li><li>CRD 충돌</li><li>Pod identity 불가</li></ul><p>AutoMode는 Karpenter 기반이었지만, Karpenter를 그대로 확장해 사용할 수 있는 구조는 아니었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*4kkbYO9FW2XnRN0193Qv_w.jpeg\" /></figure><p>문서를 다시 살펴보니 문구는 명확했습니다.</p><p><em>“EKS Auto Mode uses a Karpenter-based system.”<br></em> → 즉 <strong>커스터마이즈된 Karpenter</strong></p><p>그리고 이어진 문장은 더 명확했습니다.</p><p><em>“Self-managed Karpenter offers more flexibility… but requires customer management.”</em></p><p>즉 선택지는 두 개였습니다.</p><ol><li><strong>편하지만 제약이 있는 AutoMode</strong></li><li><strong>모든 걸 직접 관리해야 하지만, 무한히 확장 가능한 Self-managed Karpenter</strong></li></ol><p>우리는 다시 두 번째를 선택했습니다.</p><p>그리고 아키텍처는 아래처럼 바뀌었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*i0Mx52Ayv85w_hGV0xO30w.jpeg\" /></figure><p>그 순간이 전환점이었습니다.</p><p>—</p><p>—</p><h3>카오스 엔지니어링 — 클라우드가 비싼 이유는 다 있었다.</h3><p>우리는 처음으로 <strong>운영 비용이라는 세계</strong>를 직접 마주했습니다.</p><ul><li>GPU 커널 오류</li><li>NVLink handshake failure</li><li>NIC 장애</li><li>BIOS 업데이트 실패</li><li>파워 서플라이 스파크</li><li>물리적 냉각 부족</li><li>Deep learning workload에 따른 thermally induced throttling</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*3TtzOPvnS9TX9_YIH4aPSA.jpeg\" /><figcaption>GPU 장애</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*QIj8XdUXhNukszghAVUFsg.jpeg\" /><figcaption>GPU Kernel레벨 에러</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*eCUSfb6nDFynuyxBFUkalg.jpeg\" /><figcaption>네트워크 카드 장애</figcaption></figure><p>AWS는 단순히 <strong>컴퓨팅 자원을 파는 회사가 아니라,</strong> 우리가 겪지 않게 해주는 <strong>운영 리스크를 판매하는 회사</strong>였습니다.</p><p>우리는 그 리스크를 직접 감당하기로 선택한 것입니다.</p><p>제 마음을 아는지 모르는지 H100은 몇달 내내 24시간 뜨거운 열기를 내뿜으며 우리의 미래를 밝게 비추고 있었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*kFsV9kGXBL5iiSRBhLzkiA.jpeg\" /></figure><p>—</p><p>—</p><h3>지속 가능한, 초저지연 AI Infra를 꿈꾸다</h3><p>Hybrid Node를 통해 우리는 최대 <strong>95% 비용 절감 구조</strong>를 만들었고, 절감한 비용은 다시 <strong>성장과 확장에 재투자</strong>할 수 있는 구조가 되었습니다.</p><p>그러나 비용 절감만으로는 충분하지 않았습니다.</p><blockquote><strong>AI는 단독 서비스가 아니라, 기존 서비스 위에 자연스럽게 녹아야 합니다.</strong></blockquote><p>고객이 AI를 ‘사용한다’고 느끼지 않아야 하고, 그저 자연스럽게 <strong>도움을 받는다</strong>고 느끼게 해야 합니다.</p><p>그러려면 반드시 충족해야 하는 조건이 있습니다.</p><p><strong>끊김 없는 응답.<br>지연 없는 체감.<br>폭증 트래픽에서 무너지지 않는 안정성.</strong></p><p>실제 블랙프라이데이 기간, 초 단위로 솟구치는 트래픽에서<br> 단 <strong>1ms의 overhead latency</strong>가 tail latency를 수십 ms까지 밀어올렸습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*SLKiulTU1B4B8lwmuAwWuQ.jpeg\" /><figcaption>실제 블랙 무신사 프라이데이 AI 트래픽 추이</figcaption></figure><p>우린 결론지었습니다.</p><p><strong>이 구조는 빠르기만 하면 안 된다.<br> 폭발해도 무너지지 않아야 한다.</strong></p><p>그래서 아키텍처를 밑바닥 아주 사소한것부터 다시 설계 했습니다.</p><h4>🔧 kube-proxy → eBPF Cilium</h4><p>기존에도 HybridNode를위해 eBPF기반인 cilium을 도입하긴 했지만, 거기서 멈추지 않고 우선 가장 바닥이되는 커널 레벨부터 확인을 했습니다.</p><p>기존 kube-proxy기반의경우 아래처럼 iptable overhead가 발생하는데요, 서비스가 많아질경우 약 300usec, 즉 0.3ms정도의 overhead latency가 매 홉마다 증가되는 구조였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*uWyVJP4DGPcMUZRPlk8d3Q.jpeg\" /><figcaption><a href=\"https://cilium.io/blog/2021/05/11/cni-benchmark/\">https://cilium.io/blog/2021/05/11/cni-benchmark/</a></figcaption></figure><p>이에따라 kube-proxy를 eBPF로 완전히 대체했습니다.</p><p><strong>🔧 Sidecar 제거 → 단일 dataplane</strong><br>➡ 리소스 오버헤드 제거, 패킷 traversal path 감소</p><p><strong>🔧 ALB → NLB 전환<br></strong>➡ Layer7 편의 기능 제거 대신 <strong>순수 성능, deterministic latency 확보, HTTP3 지원</strong></p><p><strong>NLB는 </strong>공식 다큐멘트에서도 extream performance/low latency라고 표현하는 peformance 최적화된 LB입니다.<br>뿐만아니라 HTTP3까지 지원하려면 유일한 해결책이었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*ckzpBPF3wBOC5zLBSSZsxQ.jpeg\" /><figcaption><a href=\"https://aws.amazon.com/elasticloadbalancing/faqs/\"><strong>https://aws.amazon.com/elasticloadbalancing/faqs/</strong></a></figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*eMhuMHvHU5o5KciDcR0eHg.jpeg\" /><figcaption><a href=\"https://aws.amazon.com/compare/the-difference-between-the-difference-between-application-network-and-gateway-load-balancing/\"><strong>https://aws.amazon.com/compare/the-difference-between-the-difference-between-application-network-and-gateway-load-balancing/</strong></a></figcaption></figure><p><strong>🔧 OpenTelemetry 기반 로깅, APM data 수집</strong></p><p>정리하자면 기존 이런 아키텍처에서</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*2ZPOP6BuIUOwJv1B7XdY3w.jpeg\" /></figure><p>이렇게 변경되었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*oyb5mRhl_dtcvmMHhihx4w.jpeg\" /></figure><p>그리고 이 과정에서 작은 해프닝이 하나 있었습니다.<br> NLB로 전환하면서 OpenTelemetry 기반으로 모든 로그를 직접 수집해야 했는데,<br> “얼마나 쌓일지 감이 없으니 며칠만 전체 로그를 받아볼까?” 하는 마음으로 전량 수집을 켜두었습니다.</p><p>그런데 — <br> <strong>단 하루 만에 8TB가 쌓여버렸습니다.</strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*f1ZwmIpo20irurE0REDHvg.jpeg\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*s6QsBqBTzVvpgfVleJ0CAQ.jpeg\" /></figure><p>갑작스러운 스토리지 폭증에 시스템 알람이 울리고, 잠시 후 SRE와 FinOps 분들이 저를 찾아왔습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*V6btf9BF0OnAANV-A8w3eQ.png\" /></figure><p>원인은 간단했습니다.<br>제가 로그 적재 시 <strong>리소스명을 ‘opentelemetry-…’라고 명시해둔 바람에 현장에서 바로 검거(?)된 것이죠.</strong></p><p>하지만 이런 시행착오와 실험의 과정을 거치며, 우리는 시스템을 하나씩 최적화해 나갔습니다.<br>처음에는 모든 로그가 한꺼번에 쏟아져 8TB가 하루 만에 쌓이는 사고도 있었지만, 그 경험 덕분에 어떤 로그를 어떻게 수집해야 하고, 어떤 파이프라인이 플랫폼 중립적으로 유지될 수 있는지에 대한 기준이 명확해졌습니다.</p><p>지금은 OpenTelemetry 기반으로 로그·메트릭·트레이스를 일관되게 수집하며, 특정 벤더나 특정 AWS 서비스에 종속되지 않는 구조로 안정적으로 운용하고 있습니다. LB가 바뀌어도, CNI가 달라져도, 워크로드가 On-Prem이든 클라우드든 동일한 방식으로 관측이 가능하도록 설계된 것이죠.</p><p>결국 이 과정 전체가 <strong>무신사 AI Infra를 플랫폼 중립적이고, 확장 가능하고, 장애 내성이 있는 구조로 진화시키는 단계</strong>였습니다.</p><p>—</p><p>—</p><h3>Experiment — 우리는 요청의 ‘가치’에 따라 트래픽을 흘려보내기로 했습니다.</h3><p>Gateway API 기반 Inference Extension 글을 본 것은 정말 우연한 계기였습니다.</p><p>지인이 “이거 한 번 읽어봐”라며 건넨 링크 하나가,</p><p>우리 인프라의 방향을 다시 시험해보게 만든 출발점이 되었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*aUyTrKbSiQ2m6yZ0ujydMg.jpeg\" /><figcaption><a href=\"https://kubernetes.io/blog/2025/06/05/introducing-gateway-api-inference-extension/\">https://kubernetes.io/blog/2025/06/05/introducing-gateway-api-inference-extension/</a></figcaption></figure><p>글 하나였지만, 메시지는 분명했습니다.</p><ul><li>endpoint selection</li><li>priority routing</li><li>adapter 기반 확장</li><li>multi-model inference</li></ul><blockquote>“이거… 우리가 찾던 그 조각 아닐까?”<br> 그런 느낌이 드는 순간이 있죠. 이 글이 그랬습니다.</blockquote><p>그리고 결정적이었던 것은 성능 벤치마크였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*GIbalbaxOsZWhFBfPWB-CA.jpeg\" /><figcaption><a href=\"https://kubernetes.io/blog/2025/06/05/introducing-gateway-api-inference-extension/\">https://kubernetes.io/blog/2025/06/05/introducing-gateway-api-inference-extension/</a></figcaption></figure><p>파란색(Extension)과 오렌지색(기존 구조)은 QPS가 올라갈수록 <strong>마치 다른 세계의 곡선처럼</strong> 벌어지기 시작했습니다.<br> 특히 700 QPS 구간에서 레이턴시가 <strong>5배 이상</strong> 차이 나는 결과는 우리에게 하나의 실험적 질문을 던졌습니다.</p><blockquote>“모든 요청이 똑같이 빨라야 할까?”</blockquote><p>사용자에게 즉각적으로 반응해야 하는 요청이 있는 반면, 1~2초 정도는 충분히 기다릴 수 있는 내부 로직도 있습니다.<br>그 둘을 같은 우선순위로 취급하는 것은 오히려 전체 품질을 떨어뜨린다는 결론에 도달했습니다.</p><p>그래서 우리는 <strong>우선순위 레이어링이라는 작은 실험</strong>을 시작했습니다.</p><ul><li><strong>Priority 0</strong>: 사용자-facing, 즉시 응답 필요</li><li><strong>Priority 1</strong>: 모델 업데이트, 재시행 등 준-실시간 작업</li><li><strong>Priority 2</strong>: 관리형 요청, 비실시간 로직</li></ul><p>여기에 조건부 라우팅을 적용했습니다.</p><p>규칙은 단순합니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*c7ZdlgyuPZd-zaD-E3tSWg.jpeg\" /></figure><p>이 규칙은 단순해 보이지만, 실험해보니 효과가 분명했습니다.</p><p>“지금 반드시 처리해야 할 요청”과<br> “지연되어도 되는 요청”을 분리하는 것만으로도<br> 시스템 전체의 안정성이 놀라울 정도로 달라진 것입니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*V9cq2_sBRWXkd5_B_9YCGg.jpeg\" /></figure><p>그 구조는 거창한 이론이나 거대한 아키텍처에서 나온 것이 아니라,<br> <strong>실험이 흔들릴 듯 말 듯한 순간마다 다시 시스템을 붙잡아주는 작은 전략들</strong>에서 시작되었습니다.</p><p>그리고 지금도 우리는 이 전략들을 계속 다듬고, 측정하고, 다시 실험하고 있습니다.<br> “정답”을 찾았다기보다, <strong>더 나은 결과를 찾기 위해 실험을 이어가는 과정</strong>에 가깝습니다.</p><p>—</p><p>—</p><h3>끝이 아니라 시작 — 다음 단계</h3><p>RTX 4090에서 시작해, H100 → H200 → Blackwell까지.<br> 장비 설치부터 전력 증설, 냉방 공사, 네트워크 설계, 보안 정책,<br> 그리고 AWS 인프라 구축, 통합, 최적화까지 —</p><p>이 모든 과정은 단순한 구축이 아니라 <strong>AI 지속 가능성을 결정지을 여정</strong>이었습니다.</p><p>하지만 여기서 끝이 아닙니다.</p><p>우리가 향하는 다음 단계는 다음과 같습니다.</p><ul><li><strong>GPU Pooling<br></strong> : 지역·환경 상관없이 하나의 자원처럼 사용되는 GPU 구조</li><li><strong>SLA-aware Multi-cluster routing<br></strong> : 사용자 경험에 따라 라우팅되는 AI 서비스</li><li><strong>Observability 기반 자동 운영 시스템화<br></strong> : 운영자가 아니라 시스템이 문제를 감지하고 처리</li><li><strong>Blackwell 기반 대규모 inference optimization<br></strong> : 단순 성능이 아닌 효율 중심의 AI 인프라 설계</li></ul><p>지금까지 이야기한 모든 것은 단순한 구성 요소의 나열이 아닙니다.<br> 이건 <strong>0 → 1을 만드는 경험이자, 아직 존재하지 않던 길을 만드는 작업</strong>이었습니다.</p><p>우리는 실패했고, 다시 시도했고, 방향을 바꿨습니다.<br>문서에 없던 내용을 만들었고, 존재하지 않던 구조를 정의했습니다.</p><p>그리고 그 가능성은 이제 — 다음 사람에게 이어져야 합니다.</p><p>—</p><p>—</p><h3>채용합니다.</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*sPsfM7acbqftC6Nr7ywLYg.jpeg\" /></figure><blockquote><strong>우리는 달에 가기로 했습니다.</strong></blockquote><blockquote><strong>그리고 지금, 우리는 그 여정의 초입에 서서 우리가 가진 모든 역량을 실험하고 있습니다.</strong></blockquote><blockquote><strong>당신이 필요합니다.</strong></blockquote><p>우리가 찾는 사람은,<br> “원래 그랬으니까 너도 이렇게 해야 돼”라는 말에 쉽게 동의하지 않는 사람입니다.</p><p>다른 사람의 <strong>다른 생각을 존중할 수 있고</strong>,<br>그 다름이 만들어내는 가능성을 진지하게 바라볼 수 있는 사람을 찾습니다.</p><p>실패할 수도 있다는 걸 알면서도 <strong>한 번쯤은 직접 해보고 싶어지는 사람</strong>,<br>때로는 정신 나간 것처럼 보이는 아이디어라도 미친 척하고 끝까지 밀어붙일 수 있는, 그런 무모함을 가진 사람을 환영합니다.</p><p>비난을 두려워하기보다,<br>그 안에서 배울 수 있는 지점을 찾아낼 줄 아는 사람이라면 더 좋겠습니다.</p><p>우리의 여정은 결코 편하지 않을 것입니다.<br>어쩌면 우리가 도착한 곳은,<br>처음에 그렸던 모습과 전혀 다른 곳일지도 모릅니다.</p><p>그럼에도 불구하고,<br><strong>한계에 도전해보고 싶다는 마음 하나로 다시 출발할 수 있는 사람</strong>,<br>우리는 그런 동료를 찾고 있습니다.</p><p><strong>MLOps 지원하기 — </strong><a href=\"https://www.musinsacareers.com/ko/o/184612\"><strong>https://www.musinsacareers.com/ko/o/184612</strong></a></p><h3>글쓴이</h3><p><strong>이재영 MLOps — 무신사에서 AI Infra 0 to 1을 만들어나가고 있습니다.</strong></p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=3ffe4831c0a4\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://techblog.musinsa.com/%EC%9A%B0%EB%A6%AC%EB%8A%94-%EB%8B%AC%EC%97%90-%EA%B0%80%EA%B8%B0%EB%A1%9C-%ED%96%88%EC%8A%B5%EB%8B%88%EB%8B%A4-hybrid%EC%9D%B8%ED%94%84%EB%9D%BC%EB%B6%80%ED%84%B0-%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EC%B5%9C%EC%A0%81%ED%99%94%EA%B9%8C%EC%A7%80-%EB%AC%B4%EC%8B%A0%EC%82%AC-ai-infra%EA%B5%AC%EC%B6%95%EA%B8%B0-3ffe4831c0a4\">우리는 달에 가기로 했습니다. - Hybrid인프라부터 네트워크 최적화까지, 무신사 AI Infra구축기</a> was originally published in <a href=\"https://techblog.musinsa.com\">MUSINSA techblog — 무신사 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2025-12-15T22:02:16.000Z",
    "url": "https://techblog.musinsa.com/%EC%9A%B0%EB%A6%AC%EB%8A%94-%EB%8B%AC%EC%97%90-%EA%B0%80%EA%B8%B0%EB%A1%9C-%ED%96%88%EC%8A%B5%EB%8B%88%EB%8B%A4-hybrid%EC%9D%B8%ED%94%84%EB%9D%BC%EB%B6%80%ED%84%B0-%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EC%B5%9C%EC%A0%81%ED%99%94%EA%B9%8C%EC%A7%80-%EB%AC%B4%EC%8B%A0%EC%82%AC-ai-infra%EA%B5%AC%EC%B6%95%EA%B8%B0-3ffe4831c0a4?source=rss----f107b03c406e---4"
  },
  {
    "publisherId": "musinsa",
    "publisherName": "무신사 테크블로그",
    "specTitle": "e커머스 개발",
    "categories": [
      "backend"
    ],
    "specUrl": "https://medium.com/feed/musinsa-tech",
    "title": "하나의 ID로 모든 경험을 잇다: 팀 무신사 통합 회원 시스템 런치 여정",
    "partialText": "<figure><img alt=\"Team Musinsa Universe (with Gemini)\" src=\"https://cdn-images-1.medium.com/max/1024/1*TDb7BFP_DRjgogzR-pzh_Q.png\" /><figcaption>Team Musinsa Universe (with Gemini)</figcaption></figure><p>안녕하세요. Core Member팀 김범석, Core Engineering팀 김대일입니다.</p><p>여러분께 Core Member팀이 통합 회원 시스템을 안정적으로 런치하기까지 여정을 소개합니다!</p><blockquote>고객은 왜 무신사, 29CM, 솔드아웃에서 각각 가입하고 따로 로그인해야 할까요?</blockquote><p>이 질문은 팀 무신사가 ‘<em>OCMP(One Core Multi Platform) 통합 회원 시스템’</em> 프로젝트를 시작하게 된 가장 근본적인 질문이었습니다. 지금까지 팀 무신사 내의 비즈니스 플랫폼(무신사, 29CM, 솔드아웃, 엠프티 등)은 각자의 자리에서 독립적으로 빠르게 성장해 왔습니다. 하지만, 이 과정에서 고객 데이터와 멤버 시스템은 플랫폼별 ‘사일로(Silo)’에 갇히게 되었습니다.</p><p>이는 팀 무신사 관점에서는 중복된 개발 및 보안 관리 비용을 의미했고, 고객에게는 여러 플랫폼을 넘나드는 일관된 경험을 제공하는 데 큰 장벽이 되었습니다. 그리고 시작된 통합 회원을 정의하기까지의 여정은 기존의 틀을 깨는 과정의 연속이었습니다.</p><p>단순히 IdP(Identity Provider)의 역할이 아닌, 기존의 회원들과 통합되는 회원들을 연결해 주는 지점을 만들어내야 하는 과정이었습니다. 처음에는 로그인 화면으로 시작된 기획과 디자인은 단순히 로그인을 넘어 무신사를 사용하는 사용자들의 접점들을 하나하나 연결하는 과정으로 확장되었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*P24t1j9ibWY_ptA-o1wDVA.png\" /><figcaption>무신사, 29CM 로그인으로 시작되는 유저 경험</figcaption></figure><h3>1. ‘통합 회원’이란 무엇인가</h3><p>우리가 지향하는 OCMP(One Core Multi Platform) 통합 회원의 목표는 단순히 로그인 과정을 하나로 줄이는 ‘효율성’에 그치지 않습니다. 핵심은 각 플랫폼에 흩어진 데이터를 연결하여 고객이 누릴 수 있는 ‘경험의 가치’를 극대화하는 것입니다.</p><p>기존에는 무신사와 29CM의 고객 데이터가 분리되어 있어, 한 플랫폼에서의 깊은 취향과 행동 데이터가 다른 플랫폼의 경험으로 이어지지 못했습니다. 우리는 고객을 개별 플랫폼의 사용자가 아닌 ‘팀 무신사의 고객’으로 새롭게 정의함으로써 이 한계를 넘어서고자 했습니다.</p><p>이를 통해 고객이 어떤 플랫폼을 이용하든, 마치 하나의 서비스처럼 제약이나 막힘없이 자유롭게 넘나드는 고객 경험을 제공하는 것이 저희의 핵심 비전이었습니다.</p><p>이를 위해 고객에게 3가지 핵심 가치를 제공합니다.</p><ol><li><strong>Seamless Experience:</strong> 한 번의 가입/로그인으로 모든 플랫폼을 끊김 없이 이용합니다.</li><li><strong>Personalization:</strong> 통합된 고객 데이터를 기반으로 더 정교한 개인화 추천과 발견을 제공합니다.</li><li><strong>Trusted Security:</strong> 표준화된 정책과 강력한 권한 관리 체계로 고객의 개인정보를 중앙에서 안전하게 보호합니다.</li></ol><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*WgDof-enxMmvNxQqP8UaDQ.png\" /></figure><p>기술적인 관점에서, 이는 각 플랫폼에 흩어져 있던 멤버 시스템을 <strong>높은 확장성, 고가용성, 강력한 성능</strong>을 보장하는 하나의 ‘Core Member System’으로 수렴시키는 작업이었습니다. 모든 인증/인가 요청을 중앙의 IdP(Identity Provider)가 처리하고, 각 플랫폼(Service Provider)은 이 신뢰를 기반으로 고객에게 서비스를 제공하는 아키텍처입니다.</p><h3><strong>2. 통합 회원 런칭, 무엇이 어려웠을까</strong></h3><p>목표는 명확했지만, 수천만 명이 매일 사용하는 이커머스 시스템의 ‘심장’을 교체하는 일은 수많은 리스크를 안고 있었습니다.</p><h4>짧은 중단도 허용되지 않는 ‘무중단 전환‘</h4><p>멤버 시스템은 24시간 잠들지 않습니다. 고객이 새벽에 주문하든, 주말에 반품하든 로그인은 항상 가능해야 합니다. 멤버 시스템의 중단은 고객 경험에 치명적입니다.</p><p>수천만 사용자가 매일 사용하는 시스템을 교체하면서, 고객은 이 전환을 <strong>전혀 눈치채지 못해야 했습니다.</strong> 이는 ‘엔진이 켜진 비행기의 엔진을 교체’하는 것과 같은 고난도 미션이었습니다.</p><h4>이커머스의 심장: ‘핵심 기능’과의 강한 결합</h4><p>멤버 시스템은 단순히 로그인만 처리하지 않습니다. <strong>주문, 혜택, 반품, 추천, CS</strong> 등 이커머스의 거의 모든 핵심 기능이 고객 데이터를 주요 입력값으로 사용합니다.</p><p>멤버 시스템에서 발생하는 사소한 데이터 불일치나 지연은 즉시 대규모 장애로 이어질 수 있습니다. 그리고 그 여파는 고객 신뢰 하락, 매출 하락이라는 치명적인 결과로 직결됩니다.</p><h4>‘같지만 다른’ 시스템들의 통합 난이도</h4><p>각 플랫폼의 멤버 시스템은 지난 수년간 어떤 공통 지점도 없이, 각자의 비즈니스 환경에 최적화되며 독립적으로 성장해 왔습니다.</p><p>‘회원’이라는 기능적 공통점은 있었지만, 구현된 형태는 완전히 달랐습니다. 인증/인가 방식, API 프로토콜과 인터페이스, 연관 시스템과의 ‘계약’, 심지어 지원하는 기능의 미묘한 범위까지 모든 것이 달랐습니다.</p><p>이는 마치 ‘격리된 섬’들을 하나의 대륙으로 잇는 작업과 같았습니다. 어느 기능 하나 놓치지 않기 위해 모든 시스템을 속속들이 분석하는 데 엄청난 노력이 필요했습니다.</p><h3>3. ‘속도’보다 ‘안정성’: 가장 중요했던 의사결정</h3><p>뚜껑을 열어보니, 우리가 상상했던 것보다 시스템 간의 차이는 컸고, 통합의 난이도는 높았습니다. 구현이 어느 정도 진행된 시점, 우리는 중요한 의사결정을 내려야 했습니다.</p><blockquote>우리가 가진 마이그레이션 전략은 프로젝트의 안정적인 런치를 완벽하게 보장할 수 없다. 더 단단하고 집요한 마이그레이션 전략이 필요하며, 이를 위해 이전에 합의된 일정을 조정해야 한다.</blockquote><p>이 결정은 프로젝트 규모만큼이나 많은 팀에 영향을 미쳤습니다. 개발팀뿐만 아니라, 통합 회원을 기반으로 새로운 기능을 준비했던 프로덕트팀, 런칭을 준비하던 PR팀까지 모두의 일정이 변경되어야 했습니다.</p><p>하지만 팀 무신사가 의사결정을 내리는 데 가장 중요한 요소는 <strong>‘고객’</strong>입니다. 고객에게 더 안정적으로 서비스를 제공해야 한다는 최우선 목적을 달성하기 위해, 모든 이해당사자와 리더십 그룹은 기꺼이 이 의사결정에 동의하고 지지했습니다.</p><h3>4. 기술적 도전 과제</h3><h4>데이터 모델 설계: 플랫폼 간 격리와 확장성</h4><p>통합 회원 시스템 구축의 가장 큰 난제는 “여러 플랫폼의 거대한 데이터베이스와 로직을 어떻게 중단 없이, 변경을 최소화하며 하나로 묶을 것인가”였습니다.</p><p>우리는 모든 데이터와 로직을 물리적으로 합치는 방식 대신, <a href=\"https://learn.microsoft.com/en-us/azure/architecture/patterns/federated-identity\">Federated Identity Architecture</a>를 선택 했습니다.</p><ul><li>Identity 중앙화: 인증과 핵심 식별 정보는 중앙의 통합 회원 데이터베이스에서 관리되며, 통합 회원 시스템에 의해 모든 접근이 통제됩니다.</li><li>Mapping 계층을 통한 격리: 플랫폼 간 연결을 위해 one_uuid_mappings라는 매핑 계층을 두어, 서로 다른 시스템의 ID를 논리적으로 결합하는 구조를 설계했습니다.</li></ul><p>이러한 접근 방식 덕분에 우리는 기존 비즈니스 로직의 수정을 최소화하면서도, ‘팀 무신사’ 차원의 통합된 고객 식별 체계를 확보할 수 있었습니다.</p><h4>App-to-App SSO</h4><p>통합 회원의 핵심 경험 중 하나는 “무신사 앱에 로그인되어 있다면, 29CM 앱도 자동으로 로그인되는 것”입니다. 하지만 Android와 iOS는 보안 정책상 앱 간 데이터 공유를 엄격히 제한합니다. 특히 서로 다른 Team ID로 서명된 무신사와 29CM 앱 간의 iOS 키체인(Keychain) 공유 불가 문제는 큰 난관이었습니다.</p><p>이를 해결하기 위해 Universal Link와 PKCE(Proof Key for Code Exchange)를 결합한 인증 터널을 설계했습니다.</p><ol><li>Code Verifier 생성 및 저장: 사용자가 29CM 앱에서 통합 로그인을 시도하면, 앱은 암호학적으로 안전한 code_verifier를 생성하여 로컬 키체인에 저장합니다.</li><li>Universal Link 터널링: 29CM 앱은 code_challenge(verifier를 해싱한 값)를 서버에 등록한 뒤, Universal Link를 통해 무신사 앱을 호출합니다. 이 방식은 iOS 시스템 레벨에서 앱의 소유권을 검증하므로 피싱 앱의 개입을 원천 차단합니다.</li><li>인증 위임 및 콜백: 무신사 앱에서 인증이 완료되면, 다시 Universal Link를 통해 29CM 앱을 깨우며 토큰을 전달합니다.</li><li>최종 검증: 29CM 앱은 키체인에 저장해둔 code_verifier 원본을 꺼내 서버로 전송합니다. 서버는 이 값이 최초 요청 시의 code_challenge와 수학적으로 쌍을 이루는지 검증한 후 최종 액세스 토큰을 발급합니다.</li></ol><p>이 과정을 통해 우리는 OS의 샌드박스 제약을 뛰어넘어, 보안적으로 검증된 App-to-App SSO를 구현할 수 있었습니다.</p><h4>일관된 경험을 위한 A/B Test 설계</h4><p>점진적 런치 전략에서 가장 큰 기술적 장벽은, 단순히 트래픽을 N%로 나누는 것을 넘어, 사용자에게 어떤 상황(비로그인, 멀티 디바이스)에서도 일관된 경험을 보장하는 것이었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*HvoihURI7bf32jvUbQX8lg.png\" /></figure><p>우리는 이를 위해 두 가지 핵심 메커니즘을 적용했습니다.</p><p><strong>MurmurHash3 기반의 결정론적(Deterministic) 라우팅</strong></p><p>Experiment System은 디바이스 단위로 고유 식별자를 발급하고 관리하며, 이 식별자를 사용자 식별자와 연결합니다. 이 관계는 사용자가 여러 디바이스를 활용하거나 비로그인 상태이더라도 일관된 실험 세그먼트를 할당하는 주요 데이터입니다.</p><p>사용자 식별자는 MurmurHash3 알고리즘으로 연산하여 10,000개의 마이크로 버킷으로 나눠집니다. 이 방식을 통해 수학적 연산만으로 사용자의 그룹을 확정할 수 있으며, 0.01% 단위로 일관된 라우팅을 보장할 수 있습니다.</p><p><strong>멀티 디바이스 불일치를 해결하는 Self-Healing</strong></p><p>멀티 디바이스 식별자를 관리 함에도 여전히 디바이스 별 고객 경험 불일치 문제가 발생할 수 있습니다. 예를 들어, 사용자가 스마트폰(Device A) 에서는 런치 대상 그룹으로 선정되고 ‘통합 회원’으로 전환되었으나 식별자가 할당되지 않은 새로운 디바이스로 접속하는 경우를 상상해 볼 수 있습니다.</p><p>이 문제를 해결하기 위해 이상 감지 메트릭으로 이 상황을 탐지하고 자동으로 복구하는 파이프라인을 구축했습니다.</p><ol><li>감지: 로그인 실패가 발생할 경우, 시스템은 즉시 백그라운드에서 계정의 상태와 테스트 그룹 정보 등 여러 데이터를 기반으로 상황을 판단합니다.</li><li>치유: 만약 멀티 디바이스 불일치 문제에 의한 실패로 판단될 경우, 현재 접속 중인 디바이스의 그룹 정보를 런치 대상 그룹으로 선정합니다.</li><li>복구: 사용자를 ‘통합 회원’ 경험을 위한 페이지로 리다이렉트하여 여전히 사용자가 이전과 같은 경험을 할 수 있도록 보장합니다.</li></ol><p>이 프로세스의 전체 리드타임은 10ms 이하로 처리되며, 점진적 롤아웃 기간 동안 회원 관련 기능에서 VOC 0건을 달성할 수 있었습니다.</p><h3>5. <strong>안정적인 런치를 위한 4가지 핵심 전략</strong></h3><h4>준실시간 트랜잭션 감사: 모든 데이터의 ‘대사’</h4><p>고객 데이터는 팀 무신사가 보장해야 할 가장 중요한 자산입니다. Core Member System의 데이터는 기존 각 플랫폼의 데이터와 100% 정확하게 일치해야 했습니다.</p><p>우리는 단순히 오프라인 비교 배치를 돌리는 것을 넘어, ‘준실시간 트랜잭션 감사 시스템’을 구축했습니다. 이 시스템은 모든 데이터 변경 이벤트(가입, 수정, 탈퇴 등)를 트랜잭션 수준에서 비교하고 검증했습니다.</p><p>이는 단순히 ‘데이터의 정합성’을 넘어, 두 시스템의 ‘비즈니스 로직’이 완벽하게 동일하게 동작함을 보장하는 가장 강력한 무기였습니다.</p><h4>AI Agent가 검증하는 수많은 시나리오</h4><p>멤버 시스템 변경은 로그인, 회원정보 페이지 뿐만 아니라 수많은 연관 기능에 영향을 끼칩니다. 우리는 <strong>‘Cursor AI Agent’ 기반의 Automation Test 환경</strong>을 구축하여 고객 접점에서의 검증을 고도화했습니다.</p><p>엔지니어는 더 이상 테스트 스크립트를 작성하는 데 시간을 쏟지 않았습니다. 대신, 자연어로 테스트 시나리오(예: “무신사에서 가입하고 29CM에서 해당 ID로 로그인한 뒤, 비밀번호를 변경해 본다”)를 정의하고 AI Agent에게 자동화 테스트를 지시했습니다.</p><p>이 과정은 테스트 리드타임을 획기적으로 줄였고, 덕분에 우리는 수많은 복잡한 유저 시나리오를 검증하며 희박하게 발생했던 Timeout 예외 케이스(<a href=\"https://bugs.openjdk.org/browse/JDK-8358496\">JDK-8358496</a>)까지 사전에 식별하고 해결할 수 있었습니다.</p><h4>고객보다 먼저 경험하다: QA와 전사 임직원 테스트</h4><p>아무리 자동화 테스트가 완벽해도, ‘사람의 실제 경험’을 대체할 순 없습니다. 우리는 공식 QA 테스트는 물론, 대고객 런치 전 ‘전사 임직원 대상 내부 테스트’를 진행했습니다.</p><p>이는 ‘도그푸딩(Dogfooding)’의 일환으로, 실제 고객이 마주칠 수 있는 다양한 케이스와 예측 불가능한 사용 패턴을 발견하는 데 결정적인 역할을 했습니다.</p><p>엔지니어가 아닌 비개발 직군의 날카로운 피드백(예: “이 버튼의 위치가 어색해요”, “이 안내 문구가 직관적으로 이해되지 않아요”)은 기술적 결함을 넘어 고객 경험의 완성도를 높이는 데 크게 기여했습니다.</p><h4>불확실성 관리의 핵심: 점진적 런치와 A/B Test</h4><p>우리는 이미 수많은 테스트를 거쳤지만, ‘운영 환경에서도 절대 문제가 없을 것’이라고 가정할 수 없었습니다. 고객 영향을 최소화하고 운영 우수성을 보장하기 위해, 우리는 리스크가 높은 ‘빅뱅 런치’가 아닌 ‘점진적 런치’ 전략을 선택했습니다.</p><p>이 전략의 핵심은 ‘단계적 확산’과 ‘데이터 기반 의사결정’입니다. 우리는 신규 시스템으로 유입되는 트래픽을 1%, 5%, 10% 단위로 매우 보수적으로 제한했습니다. 각 단계마다 로그인 성공률, 에러율 등 핵심 지표를 실시간으로 모니터링하고, 지표가 안정적이라고 판단될 때만 다음 단계로 트래픽을 확대했습니다.</p><h3>6. 런칭, 그리고 우리가 얻은 결과</h3><p>이러한 전략적 결정과 촘촘한 검증 시스템 덕분에, 우리는 마침내 수천만 고객이 사용하는 핵심 시스템을 단 한 건의 장애 없이 성공적으로 전환할 수 있었습니다.</p><ul><li>신규 가입 고객의 통합 회원 가입 처리 100% 완료</li><li>무신사 기존 가입 계정의 통합 회원 전환 100% 완료</li><li>런칭 초기 1주일간 오류 VOC 0건</li><li>신규 플랫폼 런칭 시 회원 시스템 구축 리소스 약 80% 절감</li></ul><h3>7. 통합 ID는 끝이 아닌 시작</h3><p>OCMP 통합 회원 시스템의 안정적인 런칭은 그 자체로 거대한 이정표이지만, 이것은 끝이 아닙니다. 오히려 진정한 ‘One Team Musinsa’ 고객 경험을 제공하기 위한 단단한 기반을 마련한 ‘시작’입니다.</p><p>우리는 이 강력한 기반 위에 더 고도화된 개인화 추천, 모든 플랫폼을 아우르는 로열티 프로그램, 그리고 더 빠르고 유연한 신규 서비스 확장을 구축해 나갈 것입니다.</p><p>팀 무신사 그리고 OCMP의 다음 여정에도 많은 기대 부탁드립니다. 감사합니다.</p><h3>TEAM MUSINSA CAREER</h3><blockquote><em>Core Engineering 조직은 ​팀 무신사의 ​핵심 인프라를 ​구축하는 기술 조직으로, AI, ​개인화 ​플랫폼, 상품 ​카탈로그, 재고 관리, ​검색 서비스, ​파트너 ​솔루션, 광고 ​플랫폼, ​고객 ​지원까지 모든 영역의 ​기술 ​혁신을 이끌어가고 있습니다.</em></blockquote><blockquote><em>다양한 브랜드와 멀티 플랫폼, 글로벌 서비스로 확장하는 One Core Multi Platform 전략을 통해 확장성과 안정성을 갖춘 차세대 기술 생태계를 구축합니다. 머신러닝, 분산 시스템, 클라우드 네이티브 아키텍처를 바탕으로 고객 경험 혁신과 파트너 성장을 동시에 실현하는 조직입니다.</em></blockquote><blockquote><em>OCMP 기반의 전략적 혁신을 함께 이끌어 갈 분을 기다리고 있습니다.</em></blockquote><blockquote><em>🚀 </em><a href=\"https://corp.musinsa.com/ko/career/\"><em>팀 무신사 채용 페이지</em></a></blockquote><blockquote><em>🚀 </em><a href=\"https://kr.linkedin.com/company/musinsacom\"><em>팀 무신사 테크 소식을 받아보는 링크드인</em></a></blockquote><blockquote><em>🚀 </em><a href=\"https://newsroom.musinsa.com/\"><em>팀 무신사 뉴스룸</em></a></blockquote><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=72f5b0218c72\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://techblog.musinsa.com/%ED%95%98%EB%82%98%EC%9D%98-id%EB%A1%9C-%EB%AA%A8%EB%93%A0-%EA%B2%BD%ED%97%98%EC%9D%84-%EC%9E%87%EB%8B%A4-%ED%8C%80-%EB%AC%B4%EC%8B%A0%EC%82%AC-%ED%86%B5%ED%95%A9-%ED%9A%8C%EC%9B%90-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EB%9F%B0%EC%B9%98-%EC%97%AC%EC%A0%95-72f5b0218c72\">하나의 ID로 모든 경험을 잇다: 팀 무신사 통합 회원 시스템 런치 여정</a> was originally published in <a href=\"https://techblog.musinsa.com\">MUSINSA techblog — 무신사 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2025-12-09T22:02:14.000Z",
    "url": "https://techblog.musinsa.com/%ED%95%98%EB%82%98%EC%9D%98-id%EB%A1%9C-%EB%AA%A8%EB%93%A0-%EA%B2%BD%ED%97%98%EC%9D%84-%EC%9E%87%EB%8B%A4-%ED%8C%80-%EB%AC%B4%EC%8B%A0%EC%82%AC-%ED%86%B5%ED%95%A9-%ED%9A%8C%EC%9B%90-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EB%9F%B0%EC%B9%98-%EC%97%AC%EC%A0%95-72f5b0218c72?source=rss----f107b03c406e---4"
  }
]