[
  {
    "publisherId": "musinsa",
    "publisherName": "무신사 테크블로그",
    "specTitle": "e커머스 개발",
    "categories": [
      "backend"
    ],
    "specUrl": "https://medium.com/feed/musinsa-tech",
    "title": "무신사 오프라인 제품팀이 슬랙 대신 무전기를 들게된 사연",
    "partialText": "<p>무신사의 오프라인/리테일 제품을 담당하는 O4O(Online for Offline) 팀 17명의 무신사 스탠다드 매장 파트타임 체험기를 들려드려요.</p><h3>오프라인 확장기의 무신사</h3><p>O4O팀에 프로덕트 디자이너로 입사 후 <em>“오프라인 사업에서 지금 중요한건 뭘까?” </em>라는 질문에 답하기 위해 오프라인 사업부문 임직원분들과 인터뷰를 여러 차례 진행했어요. 이 과정을 통해 오프라인 사업은 크게 3가지 단계가 있다는 것을 알게 되었습니다.</p><ul><li><strong>도입기</strong> : 확장을 위한 재무/시스템적 구조를 갖추는 단계.</li><li><strong>확장기</strong> : 공격적으로 매장을 확장하는 단계.</li><li><strong>성숙기 </strong>: 안정적인 운영 위에 리뉴얼, 재배치 관리 등을 진행하는 단계.</li></ul><p>무신사는 이 중 확장기 단계로 진입하고 있었기에, 매장을 수십개 오픈하더라도 이슈가 없는 ‘확장성/안정성 있는 시스템’이 매우 중요한 시점이었습니다.</p><h3>오프라인은 저희도 처음인데요..</h3><p>하지만 저를 포함해 O4O 팀의 대부분은 온라인 제품 경력만 가지고 있는 상황.. 매장이 어떻게 돌아가는지, 그곳에서는 무엇이 가장 중요한지 소통할 수 있는 창구는 슬랙 채널 뿐이었어요.</p><p>슬랙으로는 현장 최전선에 계신 분들에게 온전히 이입하기 어렵다는 판단으로, 팀 채널에 파트타임 체험 모집을 열었는데..</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/800/1*00E81uWuicawwxWe-v41dQ.png\" /></figure><p>PM, PD, FE, BE, QA 직군을 가리지 않고 많은 팀원들이 앞다퉈(?) 신청을 해주셨고, 그룹의 부문장님이나 PM 조직의 실장님까지 참여하게되었어요. 감사하게도 무신사 리테일 서비스팀의 도움을 받아 전원이 무신사 스탠다드 매장 4곳에 배치가 되었습니다.</p><h3>본격적으로 무전기를 들다</h3><p>O4O팀이 배정된 매장은 잠실, 용산 메가스토어, 홍대, 명동점이었는데요. 각 매장마다 입점 조건, 층수, 고객 비율 등의 특징이 달랐어요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/800/1*Eo8KUYmNGCaHddq9C-UwQQ.png\" /></figure><p>매장에서는 1인 당 이름표와 워키(무전기)도 나눠 주시고 꼼꼼하게 여러 업무의 온보딩도 진행해주셨습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/400/1*Pti-8CmQiU1u7OHyS2THAw.png\" /><figcaption>이름표 배부와 온보딩 시간</figcaption></figure><p>온보딩 후에는 시간대별로 다양한 매장 업무에 집중했어요.</p><ul><li><strong>오픈 전</strong> : 입고된 재고의 스타일별 소팅 및 창고 적재 등 업무</li><li><strong>오픈 후</strong> : POS 결제, 피팅룸, DP 상품 리필, 재고 반출 등 업무</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*qnlgX9TkXCoAg6x6v3JZbQ.png\" /><figcaption>열심히 파트타임중인 팀원들</figcaption></figure><p>실제 현장 경험을 해보니.. 그냥 잘 돌아가는줄만 알았던 매장이 사실은 수많은 매니저와 크루 분들의 피땀과 노하우로 돌아가고 있다는 사실을 알게됐어요. 동시에 제품의 관점에서 최전선에 계신 분들의 업무 효율을 어떻게 향상시킬 수 있는지에 대한 아이디어도 많이 얻을 수 있었습니다.</p><h3>발견했던 주요 문제들</h3><p>온라인 커머스와 달리, 오프라인 매장은 장바구니에 넣어놨다가 몇일 후 다시 구매할 수 없어요. 즉시성이 중요한 매장에서 발생하는 허들 하나 하나가 모두 결제까지의 흐름을 방해하는 원인이 되기 때문에 주의깊게 문제를 관찰했습니다.</p><h4>수기/수동 작업으로 인한 운영 비효율</h4><ul><li>RFID를 도입하기 위해 변경된 신규 바코드 체계와 그 이전 구 바코드 체계가 매장 내에 혼용되면서, 같은 상품이지만 다른 바코드를 가진 케이스 존재. 숙련된 크루들만 구별 가능하고, 신규 크루들은 재고 조회/적재가 어려워지는 구간 발생.</li><li>매일 아침 수십 개의 박스를 일일이 열어 DP용과 창고용 등 분류 작업을 수기로 작업하는 상황.</li><li>판매된 DP 상품을 채우기 위해 시간별로 변경되는 Top 상품, 품목별 리필 개수, 재고 유무 등 여러 정보를 각기 다른 곳에서 확인해야 하는 번거로움 발생.</li></ul><h4>재고 정합성 오차</h4><ul><li>레거시 시스템의 재고 오차와 재고 실사의 휴먼에러 등으로 재고 조회 화면의 신뢰도를 높여야 하는 상황.</li></ul><h4>낮은 PDA 보급율</h4><ul><li>공용 PDA 보급율이 낮아 필요한 사람이 직접 정보를 조회하기보다 음질이 좋지 않은 워키(무전기)를 통해 다른 크루에게 요청하는 불편함 발생.</li></ul><p>발견한 주요 문제들은 제품 자동화나 정합성 보정, PDA용 제품 고도화 및 보급율 향상 등을 통해 해결해 나갈 예정이에요.</p><h3>파트타임 경험이 휘발되지 않도록</h3><p>팀원들의 경험이 날아가지 않도록 파트타임 종료 이후 회고 시간을 잡아두었는데요. 이게 웬걸.. 참여한 팀원들이 매장별로 문제점/인사이트/해결방안 등을 wiki 문서로 정리를 해와버렸습니다.. (감동)</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/800/1*p2tkPDxOBmXJiWuPq5mrfA.png\" /></figure><p>이후 리더분들을 포함한 회고를 진행해 빠르게 해결할 수 있는 일과 이후의 OKR로 진행해봐야할 일, 물류 등 O4O 팀을 너머 고민해봐야할 일로 나눠 관리하고있습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/333/1*Fxvk94E-3GOVO1W-y_MD_w.png\" /><figcaption>파트타임 체험 수료증도 제작했다</figcaption></figure><h4>프로덕트 디자이너의 시선으로 본 온라인 vs 오프라인 디자인</h4><p>온라인 제품의 디자인 영역이 ‘화면’까지라면, 오프라인 제품은 ‘동선’까지가 디자인 영역이라고 볼 수 있을 것 같아요. 사무실에서 PC를 보거나 집에서 앱을 쓰는 사용성과는 다릅니다. 매장을 누비며 일하거나 길게 줄서있는 고객들 앞에서 응대해야하는 사용성은 훨씬 더 입체적인 디자인 고려가 필요하다고 생각해요. 이와 관련된 내용은 다음 포스트에서 상세하게 다뤄볼 예정입니다.</p><h3>마무리</h3><p>유니클로, 자라 등 오프라인에서부터 시작한 타 브랜드와 온라인에서부터 시작한 무신사는 태생적인 차이가 있어요. 이미 오프라인 운영이 안정화 되어있는 브랜드들을 단시간에 뛰어넘어, 무신사만의 차별화를 만들기 위해 O4O팀의 책임은 막중합니다. 하지만 그만큼 회사에 기여할 수 있는 팀이라는 점이 매력적이기도 해요.</p><p>이번 파트타임 체험을 가능하게 해주신 무신사 리테일 서비스팀과 오프라인 사업부, 그리고 초보 파트타임 실수에도 인내로 지도해주신 매장에 다시한번 감사드리며.. 오프라인 비즈니스를 더 견인하는 O4O팀이 되도록 노력하겠습니다.</p><p>O4O팀에 대해 더 궁금하신 분들은 아래 글들도 참고해보세요 :)</p><ul><li><a href=\"https://medium.com/u/8811144aa51b\">Gunpyo Park</a>님의 <a href=\"https://medium.com/@gunpyo.park/무신사-오프라인-유니버스를-만드는-팀-o4o엔지니어링-5a57ed4c635e\">O4O 엔지니어링팀에 대한 소개글</a></li><li><a href=\"https://medium.com/u/bcccbc1c79df\">Brian Lim</a>님의 <a href=\"https://medium.com/@djadla/왜-무신사에-합류했나요-2e711ede4ded\">무신사에 합류한 이유와 O4O를 바라보는 관점에 대한 글</a></li></ul><h3>Platform Business Operation 조직 및 팀 소개</h3><blockquote><em>무신사 플랫폼 비즈니스 오퍼레이션 조직은 국내외 물류 서비스, 재고 관리, 스토어 운영을 위한 물류 프로덕트를 구축하고 다양한 오프라인 비즈니스 모델에 맞춘 스토어 관리 시스템을 개발·고도화하고 있습니다.<br>또한, 무배당발 서비스를 포함한 무신사의 차별화된 고객 경험을 브랜딩하고 확장할 수 있는 멤버십 구조를 설계하며, 온·오프라인을 넘나드는 통합 커머스 경험을 기술로 실현하고 있습니다.</em></blockquote><blockquote><em>저희 팀은 OMS(주문관리시스템)를 기반으로 온라인 주문부터 재고·출고·배송·정산에 이르는 전 과정을 유기적으로 연결하고, 무신사의 다양한 오프라인 스토어를 효과적으로 운영할 수 있는 관리 시스템을 구축하여 고객이 온라인(무신사 스토어, 29CM 등)과 오프라인(무신사 스탠다드, 편집숍 등)에서 끊김 없는 쇼핑 경험을 누릴 수 있도록 지원합니다.</em></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/pbo\"><em>🚀 Platform Business Operation 한걸음 더 알아보기</em></a></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/home\"><em>🚀 팀 무신사 채용 페이지</em></a><em> (무신사/29CM 전체 포지션 확인이 가능해요)</em></blockquote><blockquote><em>🚀 </em><a href=\"https://kr.linkedin.com/company/musinsacom\"><em>팀 무신사 테크 소식을 받아보는 링크드인</em></a></blockquote><blockquote><em>🚀 </em><a href=\"https://newsroom.musinsa.com/\"><em>팀 무신사 뉴스룸</em></a></blockquote><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=1e5aa0ad45f7\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://techblog.musinsa.com/%EB%AC%B4%EC%8B%A0%EC%82%AC-%EC%98%A4%ED%94%84%EB%9D%BC%EC%9D%B8-%EC%A0%9C%ED%92%88%ED%8C%80%EC%9D%B4-%EC%8A%AC%EB%9E%99-%EB%8C%80%EC%8B%A0-%EB%AC%B4%EC%A0%84%EA%B8%B0%EB%A5%BC-%EB%93%A4%EA%B2%8C%EB%90%9C-%EC%82%AC%EC%97%B0-1e5aa0ad45f7\">무신사 오프라인 제품팀이 슬랙 대신 무전기를 들게된 사연</a> was originally published in <a href=\"https://techblog.musinsa.com\">MUSINSA techblog — 무신사 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2026-02-20T09:01:02.000Z",
    "url": "https://techblog.musinsa.com/%EB%AC%B4%EC%8B%A0%EC%82%AC-%EC%98%A4%ED%94%84%EB%9D%BC%EC%9D%B8-%EC%A0%9C%ED%92%88%ED%8C%80%EC%9D%B4-%EC%8A%AC%EB%9E%99-%EB%8C%80%EC%8B%A0-%EB%AC%B4%EC%A0%84%EA%B8%B0%EB%A5%BC-%EB%93%A4%EA%B2%8C%EB%90%9C-%EC%82%AC%EC%97%B0-1e5aa0ad45f7?source=rss----f107b03c406e---4"
  },
  {
    "publisherId": "musinsa",
    "publisherName": "무신사 테크블로그",
    "specTitle": "e커머스 개발",
    "categories": [
      "backend"
    ],
    "specUrl": "https://medium.com/feed/musinsa-tech",
    "title": "무신사의 AI 코드 리뷰 프로세스 구축기",
    "partialText": "<p>안녕하세요. 무신사 Core Engineering/Personalization 팀에서 프론트엔드 개발을 맡고 있는 김의중입니다.<br>이 글은 LLM 기반 코드 리뷰를 무신사에 도입하고, 운영 가능한 수준의 인프라와 표준화된 프로세스로 구축해온 과정을 담고 있습니다. 단순히 “AI를 도입했습니다”가 아니라, <strong>도입 과정에서 마주한 시행착오와 이를 해결해 나간 방법</strong>을 공유합니다. 무신사의 여러 엔지니어들이 함께 아이디어를 모으고, 각자의 경험과 관찰을 공유하며 어떻게 AI 인프라로 발전시켰는지 그 과정의 기록입니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*YGFe1UTiYSTgwDOB71g-2w.png\" /><figcaption>출처: ChatGPT</figcaption></figure><h3>1. 왜 지금 AI 코드 리뷰인가?</h3><h4>과거의 한계 — “높은 진입장벽”</h4><p>AI를 활용한 코드 리뷰 는 새로운 아이디어가 아닙니다. 다만 과거에는 실무에 도입하기에는 ‘구축 비용’ 이라는 장벽이 다소 높았습니다. EKS(Kubernetes)에 Ollama 같은 LLM 서버를 직접 띄워서 운영 한다던지, PR이 생성될 때마다 diff를 추출해, 전송하고, 응답을 파싱해서 다시 코멘트로 작성하는 전체 파이프라인을 직접 설계 운영 해야 했습니다.</p><h4>전환점: anthropics/claude-code-action@v1 정식 출시</h4><p>Anthropic에서 GitHub Actions을 공식 지원하면서 이러한 문제들이 해소되었습니다. 이제 복잡한 인프라 구축 없이 몇 줄의 YAML만으로 고품질 코드 리뷰를 도입할 수 있게 되었습니다. 기술적 진입 장벽이 허물어지면서, <strong>‘구축’이 아닌 ‘활용’</strong>에 집중할 수 있는 시점을 맞이했습니다.</p><h4>AI 코드 리뷰의 가치 “워크플로우 증강하는 AI”</h4><p>AI를 단순히 코드를 생성하는 도구에 머무르기보다, <strong>협업 과정 전체를 매끄럽게 만드는 워크플로우 증강 도구</strong>로 활용하는 것이 중요합니다. 복잡한 변경 사항을 자동으로 요약해 리뷰어가 빠르게 맥락을 파악하도록 도울 뿐만 아니라, <strong>코드 라인 단위의 인라인 코멘트로 개선 방향을 구체적으로 제안하고, 누락된 예외 처리나 잠재적 버그까지 짚어주는 역할</strong>도 수행합니다.<br>이러한 기능들은 자연스럽게 리뷰 병목을 줄여주고, 팀 전체의 품질 기준을 일정 수준 이상으로 유지하는 데 큰 도움을 줍니다. 그 결과, 개인 개발자의 작업 속도만 빨라지는 것이 아니라 <strong>팀 전체의 개발 사이클이 더 유연하게 연결되는 구조적 효율성</strong>이 생깁니다.<br>결국 지금 LLM 코드 리뷰가 중요한 이유는 “코드를 대신 짓는 AI”가 등장해서가 아니라, <strong>AI가 팀의 워크플로우를 근본적으로 재설계하며 조직의 생산성을 실질적으로 끌어올리는 핵심 기술로 자리 잡았기 때문</strong>입니다.</p><h3>2. AI 코드 리뷰가 효과적인 이유</h3><h4>AI가 코드 리뷰를 잘하는 이유: 규칙과 패턴을 ‘꾸준히’ 잡아낸다</h4><p>코드는 자연어보다 훨씬 <strong>규칙적</strong>이고, 좋은 코드에는 반복되는 <strong>베스트 프랙티스 패턴</strong>이 있습니다. AI는 이런 패턴을 대량으로 학습해 두었기 때문에, 사람이 피곤하거나 바쁜 상황에서 놓치기 쉬운 것들을 <strong>일관된 기준으로</strong> 찾아냅니다.</p><ul><li>사소한 오타/휴먼 에러</li><li>흔한 성능 실수(불필요한 렌더/루프/쿼리 등)</li><li>스타일/컨벤션 불일치</li></ul><p>즉, AI에게 “고차원 의사결정”을 기대하기보다, <strong>반복적으로 발생하는 실수와 패턴 기반 이슈를 먼저 걸러서 리뷰어의 시간을 아끼는 것</strong>이 가장 큰 가치입니다.</p><h4>인라인 코멘트: 사람이 받기 좋은 형태로 피드백하기</h4><p>코드 리뷰에서 중요한 건 “요약”이 아니라 <strong>어디를 왜 고쳐야 하는지</strong>입니다.<br>anthropics/claude-code-action@v1은 인라인 코멘트를 공식 지원해서, 문제가 있는 라인에 바로 코멘트를 남기고:</p><ul><li>버그/성능/구조/스타일 같은 <strong>카테고리</strong>를 명확히 하고</li><li>“왜 문제인지 + 어떻게 바꾸면 좋은지”를 함께 제시합니다.</li></ul><p>그래서 작성자는 해당 라인에서 바로 맥락을 잡고, “AI가 뭘 근거로 말하는지”도 빠르게 확인할 수 있습니다.</p><h4>커밋 Suggestion: 리뷰를 넘어 실제 ‘패치’까지 자동 제안</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*OZVyUyHmtzG0az9912UQ0w.png\" /></figure><p>단순히 의견을 말하는 수준을 넘어서 <strong>GitHub의 Suggestion 블록을 활용해 실제 적용 가능한 수정안(diff)를 생성합니다</strong>. 즉, 리뷰 중 발견한 문제를 <strong>바로 적용 가능한 패치 형태로 만들어줍니다.</strong></p><p>이런 제안을 클릭 한 번으로 커밋에 반영할 수 있어, 사실상 <em>AI가 자동으로 작은 리팩토링과 안전한 수정 작업을 PR 과정에서 도와주는 흐름</em>이 만들어집니다. 결국 <strong>팀 전체의 리뷰 속도와 코드 품질이 자연스럽게 올라가는 구조</strong>가 됩니다</p><h3>3. “몇 줄의 YAML”로 끝나는 AI 코드 리뷰 도입</h3><h4>도입은 3단계면 끝납니다.</h4><p><strong>1단계: 토큰 발급</strong></p><pre>claude setup-token</pre><p>Claude Pro/Max 구독자라면 터미널에서 위 명령어 한줄로 인증 토큰을 발급받을 수 있습니다.</p><p><strong>2단계: GitHub Secrets 등록</strong></p><p>발급받은 토큰을 Organization의 Secrets에 CLAUDE_CODE_OAUTH_TOKEN으로 등록합니다.</p><p><strong>3단계: Workflow 파일 추가</strong></p><p>.github/workflows/claude-review.yml 파일을 생성하고 설정을 붙여 넣습니다.</p><h4>자주 묻는 질문: 토큰 비용</h4><blockquote><strong><em>Q. 토큰 발급과 사용은 유료인가요?</em></strong></blockquote><p>많은 분들이 오해하시는 부분으로 Pro/Max 플랜에 한하여 추가 API 비용은 없습니다. claude setup-token으로 생성하는 것은 <strong>API 키가 아닌 Claude 구독 인증 토큰</strong>입니다. 따라서 플랜의 사용량 <strong>한도 내에서 무료로 사용 가능</strong>합니다. 이 부분 때문에 도입을 망설이셨다면 안심하고 시작하셔도 됩니다.</p><h3>4. 함께 다듬다: 전사 프로세스 시스템 구축</h3><h4>공유 하나가 시작된 연쇄 반응</h4><p><strong>AI 코드 리뷰 가이드</strong>를 만들어 전사에 공유하자, 슬랙 스레드에는 <strong>43개의 댓글</strong>이 달렸습니다. 각 팀에서 자발적으로 “우리 팀은 이렇게 쓰고 있다”, “이런 문제가 있었는데 이렇게 해결했다”, “이건 이렇게 바꾸면 더 좋지 않을까”라는 논의가 이어졌습니다. 이 논의들은 <strong>LLM 코드 리뷰가 단순 스크립트에서 견고한 사내 인프라로 발전</strong>하는데 중요한 계기가 되었습니다.</p><h4>사례1: 개인 토큰에서 전사 공용 토큰으로(확장성)</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Mcp4Ee05YuX6-JW0MSgljA.png\" /></figure><p>처음에는 각자 개인 Claude 토큰을 발급받아 사용했습니다. 하지만 <strong>송정훈</strong>(<strong>29CM Engineering)님</strong> 은 <strong>모든 개발 조직이 더 안정적으로 사용할 수 있는 구조를 고민해</strong> “개인 토큰과 리뷰용 계정을 분리하여 관리하자”는 제안을 주셨습니다. 이 제안 덕분에 코드 리뷰 전용 전사 Claude 토큰을 발급받았고, 이를 GitHub Organization Secret(secrets.CLAUDE_CODE_TOKEN)으로 등록했습니다. 덕분에 무신사의 모든 레포지토리에서는 개별적인 키 발급 없이 안전하고 편리하게 AI 리뷰를 적용할 수 있는 기반이 만들어졌습니다.</p><h4>사례2: 기록은 남기고, 노이즈만 지운다(사용성)</h4><p>LLM 코드 리뷰를 PR에 붙이면 흔히 겪는 문제가 있습니다. <strong>커밋할 때마다 코멘트가 쌓여 PR이 지저분해지는 현상</strong>입니다.<br>처음에는 “그냥 전부 삭제하면 되지 않나?”라고 생각하기 쉽지만, 그렇게 하면 사람이 남긴 중요한 논의까지 같이 사라져 버립니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*TXM_XTunFttKi1uaiQtdRw.png\" /></figure><p><strong>임영태(MSS Engagement Frontend)</strong>님은 이 문제를 “무조건 삭제”가 아니라 ‘가치 있는 기록은 남기고, 봇이 만든 노이즈만 정리’하는 방식으로 풀었습니다. 핵심은 상태 기반 정책입니다.</p><ul><li><strong>보존:</strong> 사람이 답글을 달았거나, 이미 <strong>Resolved</strong> 처리된 스레드 → 팀이 의미 있게 소비한 기록</li><li><strong>삭제:</strong> 아무 상호작용 없이 방치된 미해결 봇 코멘트 → 반복 생성되는 노이즈</li></ul><p>이 방식 덕분에 PR 타임라인은 사람이 남긴 의미 있는 논의 중심으로 깔끔하게 유지되면서도, AI의 피드백은 적시에 필요한 만큼만 제공되는 쾌적한 리뷰 환경이 완성되었습니다.</p><h4>사례3: “Composite Action”으로 사내 플랫폼 구축</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*oMvz_DiEgMXvzJeqET_bXw.png\" /></figure><p>여러 레포지토리에 스크립트를 복사해서 쓰다 보니, 프롬프트 한 줄을 고치려 해도 모든 저장소를 수정해야 하는 ‘파편화 문제’가 발생했습니다. <strong>최용한(MSSnE Backend/Campaign) </strong>님은 이 비효율을 개선하기 위해, 무신사 공용 워크플로우 저장소(musinsa/workflows)에 액션을 추가했습니다. 그리고 <strong>홍일선(MSS Engineering/MSSnE Backend)</strong> 님의 제언이 더해져, 단순 공유를 넘어선 <strong>Composite Action</strong> 기반의 표준화된 구조로 고도화되었습니다. <strong>복잡한 로직은 중앙 저장소에 캡슐화하고, 각 서비스 레포에서는 몇 줄의 설정만 가져다 사용하는 구조</strong>입니다.</p><ul><li><strong>복잡함은 숨기고, 편의성은 높이다</strong> <br>리뷰 실행, 이전 코멘트 정리 같은 로직을 공용 레포지토리에 <strong>Composite Action</strong> 형태로 패키징했습니다. 덕분에 각 서비스 레포지토리에서는 내부 구현을 알 필요 없이, 마치 오픈소스 액션을 쓰듯, 단 몇 줄의 YAML로 모든 기능을 호출할 수 있습니다.</li><li><strong>“전사 표준”과 “팀별 커스텀”의 유연한 분리 </strong><br>“다 똑같이 해”가 아니라 <strong>공통 규칙은 지키되, 팀별 특성은 남길 수 있게</strong>. Composite Action의 inputs 기능을 활용해 인터페이스를 설계했습니다.</li><li><strong>고정 영역 (전사 표준):</strong> 이전 리뷰 자동 정리(Resolved 보존), 중복 코멘트 제거 로직, 기본 프롬프트 골격과 출력 포맷등은 중앙에서 관리하여 조직 전체 품질 표준을 유지합니다.</li><li><strong>가변 영역:</strong> review_language, project_context_path(CLAUDE.md 등), extra_prompt 등 팀별로 특화가 필요한 부분만 파라미터(with)로 열어두었습니다.</li></ul><p>이 구조 덕분에 “전사 공통 규칙”을 안전하게 지키면서도, 도메인 특성에 맞는 “팀별 유연성”을 확보했습니다.</p><p><strong>인프라 버전 관리 투트랙 전략 (@main vs @v1.0)</strong><br>‘지속적으로 진화하는 사내 제품’ 을 위한 두 가지 버전 관리 전략을 사용합니다. LLM의 응답 품질은 프롬프트 엔지니어링에 달려 있기 때문입니다.</p><ul><li>@main: 매 순간 업데이트되는 고도화된 프롬프트와 기능을 실시간으로 사용합니다.</li><li>@v1.x: 안정적인 운영이 중요한 서비스 팀이 사용하여, 프롬프트 변경에 따른 예기치 않은 부작용을 방지 합니다.</li></ul><p>결과적으로 사내 플랫폼 구축으로, 단순 스크립트 실행을 넘어 버전 관리와 배포가 가능한 하나의 <strong>‘사내 인프라 플랫폼’</strong>으로 자리 잡게 되었습니다. 이제 무신사 전체 레포지토리에서 단 몇 줄의 YAML 코드만으로 AI 리뷰 환경을 즉시 구축할 수 있습니다.</p><h3>5. 팀 단위 도입: Personalization 팀 전체로의 확장</h3><h4>다양한 직군, 하나의 협업 방식</h4><p>무신사 Personalization 팀은 Frontend, Backend, ML Engineer가 한곳에 모여 일하는 목적 조직(Cross-functional Team)입니다. 사용하는 기술 스택과 역할은 다르지만, 모두 GitHub PR 을 사용합니다. 그래서 AI 코드 리뷰는 특정 직군만의 도구가 아니라, 팀 전체가 같은 지점에서 효용을 체감할 수 있는 개선이었습니다. 아래는 팀 구성원이 남긴 실제 피드백 입니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*7DtPVT22-TJt_HMo43HaCA.png\" /><figcaption>ML 엔지니어 김윤태 님</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*E2Vz-kDAOLU9EDk8TIqxHg.png\" /><figcaption>Backend 엔지니어 정재호 님</figcaption></figure><h4>자연스러운 확장</h4><p>이처럼 각 직군 모두가 명확한 개선 효과를 경험하면서, 팀 전체 레포지토리로 범위를 확장하는 것이 자연스럽게 결정되었습니다. 무신사가 추구하는 “AI First”와 “자동화된 생산성 향상” 가치에 따라 Personalization 팀은 <strong>관리하는 모든 레포지토리에 AI 코드 리뷰를 기본 탑재</strong>하게 되었습니다.</p><h3>6. 최적화 전략 “PR은 깔끔하게, 프롬프트는 가볍게”</h3><p>다음은 팀에서 실제 사용 중인 설정입니다. 임영태 님이 제안주신 <strong>이전 코멘트 자동 정리</strong>와 최신 LLM의 추론 능력을 극대화 하기 위한 <strong>‘Minimalist Prompting’</strong> 전략 입니다.</p><h4>전략 1. 스마트 클린업: “봇의 노이즈는 지우되, 사람의 대화는 지킨다”</h4><p>PR에 커밋을 추가할 때마다 이전 코멘트와 새 코멘트가 뒤섞이는문제를 해결하기 위해 GraphQL을 활용한 <strong>맥락 보존 삭제 (Context-Aware Deletion) 규칙</strong>을 적용했습니다.</p><p><strong>보존 규칙 (Whitelist):</strong></p><ul><li><strong>Resolved(해결됨):</strong> 사용자가 ‘Resolve conversation’을 체크한 스레드는 이미 수정이 완료된 유의미한 기록이므로 보존합니다.</li><li><strong>Conversation(대화 중):</strong> 봇의 지적에 사람이 답글(Reply)을 달았다면, 이는 진행 중인 토론이므로 맥락 유지를 위해 보존합니다.</li></ul><p><strong>삭제 대상:</strong></p><ul><li>결국 “미해결(Unresolved) 상태”이면서 + <strong>“사람의 개입 없이 봇 혼자 떠들고 있는”</strong> 고립된 코멘트만 노이즈로 간주하여 제거합니다.</li></ul><p>이로써 개발자의 코멘트와 히스토리는 보호하면서, 더 이상 유효하지 않은 봇의 리뷰만 제거합니다.</p><h4>전략 2. Minimalist Prompting: “최고의 프롬프트는 가장 짧은 프롬프트”</h4><p>prompt 섹션은 놀라울 정도로 짧습니다. 이는 <strong>최신 파운데이션 모델의 제로샷(Zero-shot)능력을 극대화 하기 위한 선택입니다.</strong></p><p><strong>왜 짧은 프롬프트가 더 강력한가? “Less is More”</strong><br>흔히들 프롬프팅이 길고 정교할수록 잘 짜여진 프롬프트라고 생각하기 쉽습니다. 하지만 모델의 성능이 비약적으로 향상된 지금, 핵심 목표만 명확히 주고 나머지는 모델이 자연스럽게 판단하도록 두는 편이 오히려 안정적인 경우가 많습니다.</p><ul><li><strong>신호 대 잡음비(Signal-to-Noise) 악화:</strong> 프롬프트가 길어질수록 핵심 지시(Signal)가 부가적인 규칙(Noise)에 묻혀, 모델이 정작 중요한 요청을 놓칠 확률이 높아집니다.</li><li><strong>추론 능력 제한:</strong> 구체적인 예시를 강제하면, 모델은 자신이 가진 방대한 지식과 추론 능력을 사용하는 대신 좁은 예시를 단순히 흉내 내는 데 그칠 수 있습니다.</li></ul><p><strong>따라서 최소한의 프롬프트로 시작하고, 반복적으로 발생하는 이슈만 점진적으로 추가하는 방식으로 운영합니다.</strong></p><pre>name: &quot;Claude Code Review&quot;<br>on:<br>  pull_request:<br>    types: [ opened, reopened, synchronize ]<br>jobs:<br>  review:<br>    runs-on: ubuntu-latest<br>    permissions:<br>      contents: read<br>      pull-requests: write<br>    steps:<br>      - name: Checkout Code<br>        uses: actions/checkout@v4<br>      - name: Delete Previous Claude Reviews<br>        if: github.event.action == &#39;synchronize&#39;<br>        env:<br>          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}<br>        run: |<br>          set +e  # Continue on error<br>          PR_NUMBER=${{ github.event.pull_request.number }}<br>          REPO=${{ github.repository }}<br>          echo &quot;🔍 이전 Claude 리뷰 검색 중...&quot;<br>          # 1. PR 코멘트(요약) 삭제 - github-actions[bot]이 작성한 코멘트<br>          gh api &quot;repos/$REPO/issues/$PR_NUMBER/comments&quot; \\<br>            --jq &#39;.[] | select(.user.login == &quot;github-actions[bot]&quot;) | .id&#39; \\<br>            | while read comment_id; do<br>                if [ -n &quot;$comment_id&quot; ]; then<br>                  echo &quot;🗑️  PR 코멘트 삭제: $comment_id&quot;<br>                  gh api -X DELETE &quot;repos/$REPO/issues/comments/$comment_id&quot; 2&gt;/dev/null || echo &quot;⚠️  삭제 실패 (무시)&quot;<br>                  sleep 0.3<br>                fi<br>              done<br>          # 2. 인라인 리뷰 코멘트 삭제<br>          # - 미해결 스레드 중 bot 코멘트만 있는 스레드만 삭제<br>          # - 사용자 답글이 있는 스레드는 삭제하지 않음 (코드만 덩그러니 남는 문제 방지)<br>          OWNER=${REPO%/*}<br>          NAME=${REPO#*/}<br>          gh api graphql -F owner=&quot;$OWNER&quot; -F name=&quot;$NAME&quot; -F number=$PR_NUMBER -f query=&#39;<br>            query($owner: String!, $name: String!, $number: Int!) {<br>              repository(owner: $owner, name: $name) {<br>                pullRequest(number: $number) {<br>                  reviewThreads(last: 100) {<br>                    nodes {<br>                      isResolved<br>                      comments(first: 50) {<br>                        nodes {<br>                          databaseId<br>                          author {<br>                            login<br>                          }<br>                        }<br>                      }<br>                    }<br>                  }<br>                }<br>              }<br>            }&#39; \\<br>            --jq &#39;.data.repository.pullRequest.reviewThreads.nodes[] | select(.isResolved == false) | select([.comments.nodes[].author.login] | all(. == &quot;github-actions&quot;)) | .comments.nodes[].databaseId&#39; \\<br>            | while read comment_id; do<br>                if [ -n &quot;$comment_id&quot; ]; then<br>                  echo &quot;🗑️  인라인 코멘트 삭제: $comment_id&quot;<br>                  gh api -X DELETE &quot;repos/$REPO/pulls/comments/$comment_id&quot; 2&gt;/dev/null || echo &quot;⚠️  삭제 실패 (무시)&quot;<br>                  sleep 0.3<br>                fi<br>              done<br>          echo &quot;✅ 이전 리뷰 삭제 완료&quot;<br>      - name: Run Claude Code Review<br>        uses: anthropics/claude-code-action@v1<br>        with:<br>          show_full_output: true<br>          claude_code_oauth_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}<br>          github_token: ${{ secrets.GITHUB_TOKEN }}<br>          prompt: |<br>            REPO: ${{ github.repository }}<br>            PR NUMBER: ${{ github.event.pull_request.number }}<br>            이 PR을 리뷰하고 코멘트로 작성해주세요.<br>          claude_args: |<br>            --allowedTools &quot;mcp__github_inline_comment__create_inline_comment,Bash(gh pr comment:*),Bash(gh pr diff:*),Bash(gh pr view:*)&quot;</pre><h3>7. 마무리 — 함께 만들어가는 AI First</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*9pvOK3sHwjjvv4GEG03irQ.png\" /><figcaption>출처: ChatGPT</figcaption></figure><p>무신사 테크 조직은 ‘AI First’를 슬로건이 아닌 실천으로 만들어가고 있습니다. 실제 업무 속에서 <strong>반복되는 비효율을 줄이고 더 높은 가치</strong>를 만드는 데 집중하고 있습니다. 중요한건 ‘AI를 붙였다’가 아니라, <strong>운영 가능한 형태로 만들기 위해 무엇을 고민했고 어떻게 다듬었는가</strong> 였습니다.</p><h4>각자의 자리에서, 같은 방향으로</h4><p>엔지니어들은 각자의 자리에서 최적화를 고민했습니다. 그리고 해결책을 제안하고, 동료들과 논의하며 개선해 나갔습니다. 이렇게 서로 다른 관점의 개선이 쌓이면서 <strong>개인의 노하우는 곧 팀의 규칙이 되고, 팀의 규칙은 다시 전사적인 프로세스</strong>로 확장되었습니다.</p><h4>작은 실천이 프로세스가 되고, 프로세스가 문화가 된다</h4><p>이런 노력들이 모이자, 자연스럽게 <strong>시스템화가</strong> 이루어졌습니다. 흩어져 있던 스크립트는 Composite Action으로 표준화되었고, 개인의 토큰은 전사 인프라가 되었습니다. 이제 무신사의 어떤 팀이든 몇 줄의 YAML만으로 AI 코드 리뷰를 도입할 수 있으며, 누군가 더 좋은 방법을 찾아 기여하면 그 혜택이 전사로 전파되는 <strong>선순환 플랫폼</strong>이 구축되었습니다.</p><h4>앞으로의 격차: ‘과정의 밀도’</h4><p>향후 기술 조직 간의 격차는 단순히 “AI를 도입했는가”가 아니라, “AI를 내재화하는 과정을 어떻게 겪어냈는가”에서 벌어질 것입니다. 기술의 맹목적 수용이 아닌, 개발 프로세스에 깊숙이 녹여 자동화하고 시스템으로 정착시키는 ‘과정의 밀도’가 중요하기 때문입니다.<br>무신사는 오늘도 각자의 작은 실천을 집단 지성으로 모아, <strong>조직 전체의 AI 활용 능력</strong>을 체계적으로 성장시켜 나가고 있습니다. 이 글이 비슷한 고민을 하고 계신 분들께 의미 있는 참고가 되기를 바랍니다.</p><h3>TEAM MUSINSA CAREER</h3><blockquote><em>무신사는 2001년 온라인 커뮤니티로 시작해 2005년 무신사 매거진, 2009년 무신사 스토어를 오픈하며 빠르게 성장하고 있는 국내 대표 온라인 패션 스토어입니다. ‘입점 브랜드와 동반성장’이라는 경영 철학을 바탕으로 브랜드가 안정적으로 사업을 전개할 수 있도록 무신사가 보유한 노하우와 인프라를 지원합니다. 고객에게는 풍성한 패션 콘텐츠와 패션에 특화된 차별화된 서비스로 최상의 온라인 쇼핑 경험을 제공하고 있습니다. 글로벌 №1 패션 기업으로 성장할 무신사와 함께 새로운 도전과 혁신을 만들 인재를 기다립니다.</em></blockquote><blockquote><em>29CM는 ‘고객의 더 나은 선택을 돕는다’라는 미션으로 출발했습니다. 우리는 우리만의 방식으로 콘텐츠를 제공하며, 브랜드와 고객 모두에게 대체 불가능한 커머스 플랫폼을 만들어가고 있습니다. 이 미션을 이루기 위해 우리는 흥미로우면서도 복잡한 문제들을 해결하고 있습니다. 만약 우리와 함께 이 문제들을 해결해 보고 싶다면, 주저하지 말고 29CM에 합류하세요!</em></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/home\"><em>🚀 팀 무신사 채용 페이지</em></a><em> (무신사/29CM 전체 포지션 확인이 가능해요)</em></blockquote><blockquote><em>🚀 </em><a href=\"https://kr.linkedin.com/company/musinsacom\"><em>팀 무신사 테크 소식을 받아보는 링크드인</em></a></blockquote><blockquote><em>🚀 </em><a href=\"https://newsroom.musinsa.com/\"><em>팀 무신사 뉴스룸</em></a></blockquote><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=3ddb3c674e56\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://techblog.musinsa.com/%EB%AC%B4%EC%8B%A0%EC%82%AC%EC%9D%98-ai-%EC%BD%94%EB%93%9C-%EB%A6%AC%EB%B7%B0-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4-%EA%B5%AC%EC%B6%95%EA%B8%B0-3ddb3c674e56\">무신사의 AI 코드 리뷰 프로세스 구축기</a> was originally published in <a href=\"https://techblog.musinsa.com\">MUSINSA techblog — 무신사 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2026-02-09T22:01:01.000Z",
    "url": "https://techblog.musinsa.com/%EB%AC%B4%EC%8B%A0%EC%82%AC%EC%9D%98-ai-%EC%BD%94%EB%93%9C-%EB%A6%AC%EB%B7%B0-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4-%EA%B5%AC%EC%B6%95%EA%B8%B0-3ddb3c674e56?source=rss----f107b03c406e---4"
  },
  {
    "publisherId": "musinsa",
    "publisherName": "무신사 테크블로그",
    "specTitle": "e커머스 개발",
    "categories": [
      "backend"
    ],
    "specUrl": "https://medium.com/feed/musinsa-tech",
    "title": "질풍노도의 AI(Claude)에게 엄격한 선생님 장착하기",
    "partialText": "<h3>질풍노도의 AI(Claude)에게 엄격한 선생님 장착하기 — ArchUnit으로 아키텍처 규칙 자동 검증</h3><h3>들어가며</h3><p>무신사 물류플랫폼팀에서 백엔드 개발을 담당하고 있는 이상호입니다.</p><p>어느 날 코드 리뷰를 하다가 익숙한 장면을 마주했습니다. Claude가 생성한 코드에서 Repository 클래스가 Controller를 직접 참조하고 있었습니다. 레이어 의존성 위반. 리뷰 코멘트를 남겼습니다. 다음 PR에서도, 그다음 PR에서도 비슷한 위반이 보였습니다.</p><p><em>“AI한테 아키텍처 규칙을 매번 알려줬는데, 왜 자꾸 어기는 걸까?”</em></p><p>Claude Skill에 규칙을 정리해두기도 하고, 컨텍스트로 아키텍처 문서를 넘겨보기도 했습니다. 하지만 hit률은 기대에 한참 못 미쳤습니다. AI는 “알겠습니다”라고 대답하면서도 종종 규칙을 빠뜨렸습니다.</p><p>사실 이건 AI만의 문제가 아닙니다 사람도 마찬가지입니다. 아키텍처 규칙이라는 것은 한두 번 읽어서 되는 게 아니라, 매번 일관되게 지켜야 하는 규약입니다. 읽은 것과 지키는 것은 전혀 다른 이야기입니다.</p><p>그렇다면 접근을 바꿔야 했습니다. AI에게 규칙을 “알려주는” 것이 아니라, 규칙을 “어기면 안 되게 만드는” 방법은 없을까?</p><h3>기존 방식의 한계: 부탁은 강제가 아니다</h3><h3>첫 번째 시도 — 코드 리뷰에서 잡자</h3><p>모든 PR에서 리뷰어가 아키텍처 규칙 준수 여부를 눈으로 확인했습니다. 레이어 간 의존성 방향이 올바른지, 패키지 구조가 컨벤션에 맞는지를 한 줄 한 줄 살폈습니다.</p><p>문제는 AI의 코드 생성량이 늘수록 리뷰어의 부담도 비례해서 커진다는 점이었습니다. 비즈니스 로직을 검토해야 하는데, 아키텍처 위반을 찾느라 시간을 쓰고 있었습니다. 게다가 사람인 이상 누락은 불가피했습니다.</p><h3>두 번째 시도 — AI에게 교과서를 읽어주자</h3><p>Claude Skill과 컨텍스트에 아키텍처 규칙을 상세히 기술했습니다. “이 프로젝트는 Controller → Service → Repository 방향으로만 의존합니다. 역방향 의존은 금지입니다.”</p><p>AI는 이 내용을 잘 이해했습니다. 대부분의 경우 규칙을 따랐습니다. 하지만 대부분이 문제였습니다. 복잡한 기능을 구현할 때, 여러 파일을 동시에 생성할 때, 간혹 규칙이 빠졌습니다. 컨텍스트 기반의 접근은 “참고 자료”일 뿐, 강제력이 없었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*xLn6x_FtIuaZbsMppb3gmg.png\" /></figure><p>두 방식의 공통점이 보였습니다. 결국 누군가가 나중에 확인해야 한다는 것. 위반을 사전에 차단하는 것이 아니라, 사후에 발견하는 구조였습니다.</p><p>저희가 원한 것은 이것이었습니다:</p><ul><li>아키텍처 규칙 위반을 빌드 단계에서 자동 감지</li><li>AI가 스스로 위반을 인지하고 자동 수정</li><li>코드 리뷰에서 아키텍처 검증에 쏟는 시간을 0으로 만들기</li></ul><h3>교과서의 한계, 시험지의 가능성</h3><p>여기서 한 발 물러나 생각해보았습니다. 왜 교과서(컨텍스트)는 한계가 있을까?</p><p>교과서는 학습을 위한 도구입니다. AI는 교과서를 읽고 이해합니다. 하지만 이해한 것과 매번 정확하게 수행하는 것은 별개의 문제입니다. 사람도 교과서를 읽었다고 해서 시험에서 만점을 받지는 못합니다. AI도 마찬가지입니다. 교과서는 “이렇게 하면 좋겠다”는 방향을 제시할 뿐, 지금 이 코드가 규칙을 지키고 있는지 판단해주지 않습니다.</p><p>반면 시험지는 다릅니다. 시험지는 옳고 그름을 직접 판단합니다. “이 답은 맞다”, “이 답은 틀렸다” — 이 명확한 피드백이 핵심입니다. AI에게 “네가 방금 생성한 코드, 여기가 틀렸어”라고 구체적으로 알려줄 수 있습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*5srhGu55DIGL2OQncxNT9w.png\" /></figure><p>결국 필요한 것은 “더 좋은 교과서”가 아니라 “시험지”였습니다. AI가 생성한 코드를 즉시 검증하고, 위반이 있으면 명시적으로 “틀렸다”고 알려주는 자동화된 장치. 이 관점에서 도구를 찾기 시작했습니다.</p><h3>후보 비교와 선택: 선생님을 찾아서</h3><h3>먼저 떠오른 것: Java Lint</h3><p>“Java에도 Lint 도구가 있지 않나? Checkstyle이나 PMD로 규칙을 검증하면 되는 거 아닌가?”</p><p>결론부터 말하면, 기존의 Java Lint 도구로는 아키텍처 규칙을 검증하는 데 근본적인 한계가 있습니다.</p><p>Checkstyle이나 PMD 같은 Lint 도구는 단일 파일 수준에서 동작합니다. 변수 네이밍이 카멜케이스를 따르는지, 메서드 길이가 적정한지, 사용하지 않는 import가 있는지 — 이런 것들은 파일 하나만 보고 판단할 수 있습니다.</p><p>하지만 아키텍처 규칙은 다릅니다. “Repository가 Controller를 참조하면 안 된다”는 규칙을 생각해보겠습니다. 이 규칙을 검증하려면 OrderRepository.java 파일 하나만 봐서는 알 수 없습니다. 이 클래스가 어떤 패키지에 있는지, import하는 클래스가 어떤 레이어에 속하는지, 프로젝트 전체의 패키지 구조가 어떻게 되어 있는지를 함께 알아야 합니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*5yly8cVwowGWs4CusHgrlA.png\" /></figure><p>비유하자면, Lint는 글자 맞춤법 검사기입니다. 각 문장의 띄어쓰기와 문법은 잡아주지만, “3장의 내용이 1장의 결론과 모순된다”는 것은 발견하지 못합니다. 아키텍처 검증은 글 전체의 구조적 일관성을 보는 일이고, 이를 위해서는 프로젝트 전체를 하나의 단위로 분석할 수 있는 도구가 필요했습니다.</p><h3>아키텍처 검증 도구 3가지 비교</h3><p>Lint의 한계를 확인한 후, 아키텍처 규칙을 코드 레벨에서 자동 검증할 수 있는 도구 3가지를 검토했습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*byYGoHg7QeLqla9zaGbYwQ.png\" /></figure><h3>최종 선택: ArchUnit</h3><p>세 가지 후보 중 ArchUnit을 선택한 결정적 이유는 AI 연동 친화성이었습니다.</p><p>ArchUnit은 일반 JUnit 테스트처럼 동작합니다. 아키텍처 위반이 있으면 테스트가 실패하고, 무엇이 왜 잘못되었는지 명확한 에러 메시지를 출력합니다. 여기서 핵심적인 발견이 있었습니다. Claude는 테스트 실패 메시지를 매우 잘 이해합니다. 실패 원인을 읽고, 위반을 파악하고, 스스로 코드를 수정합니다.</p><p>즉, ArchUnit은 AI에게 “엄격한 선생님” 역할을 할 수 있었습니다.</p><p>교과서를 건네주며 “이렇게 해주세요”라고 부탁하는 것과, 시험을 보게 하며 “이것을 어기면 탈락입니다”라고 알려주는 것. 이 두 가지 사이에는 근본적인 차이가 있습니다.</p><h3>도입 과정: 선생님 세팅하기</h3><h3>1. ArchUnit 프로젝트 세팅</h3><p>첫 번째로 놀란 점은 도입이 너무 간단하다는 것이었습니다. Gradle 의존성 하나만 추가하면 끝입니다.</p><pre>dependencies {<br>    testImplementation(&quot;com.tngtech.archunit:archunit-junit5:1.3.0&quot;)<br>}</pre><p>별도의 서버를 구축하거나 인프라를 변경할 필요가 전혀 없었습니다. 기존 테스트 프레임워크 위에서 바로 동작했습니다.</p><h3>2. 시험지도 AI가 만든다</h3><p>여기서 재미있는 장면이 연출됩니다. ArchUnit 테스트 코드를 누가 작성할까요? 사람이 ArchUnit API를 공부해서 하나하나 작성할 수도 있습니다. 하지만 저희는 이 과정도 AI에게 맡겼습니다.</p><p>방법은 간단합니다. 사람은 자연어로 규칙을 설명하면 됩니다.</p><blockquote>“Repository 레이어는 Controller 레이어에 의존하면 안 됩니다” “Service 클래스는 반드시 service 패키지 안에 위치해야 합니다” “infrastructure 패키지는 domain 패키지에 접근할 수 있지만, 그 반대는 안 됩니다”</blockquote><p>Claude에게 이런 규칙을 자연어로 전달하면, AI가 해당 규칙에 대응하는 ArchUnit 테스트 코드를 생성합니다. 아키텍처에 대한 도메인 지식은 사람이, 그것을 코드로 옮기는 작업은 AI가 담당하는 셈입니다.</p><p>아이러니하게도, AI가 스스로 응시할 시험지를 AI가 만드는 구조입니다. 하지만 이것이 정확히 의도한 바입니다. 시험지를 만드는 것과 시험을 통과하는 것은 전혀 다른 일입니다. 시험지는 한 번만 만들면 되지만, 시험은 코드를 생성할 때마다 매번 치러야 합니다. 한 번 잘 만들어진 ArchUnit 테스트는 이후 생성되는 모든 코드에 대해 일관된 검증을 수행합니다.</p><h3>3. AI와의 연동: 질풍노도에서 절도 있는 행군으로</h3><p>선생님 세팅이 끝났습니다. 이제 실제로 AI와 어떻게 동작하는지가 중요합니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*lJuIaooI3-0ncUcMiqr-Aw.png\" /></figure><p>이전에는 이런 흐름이었습니다:</p><blockquote>개발자: “레이어 의존성을 지켜서 코드를 작성해줘” Claude: “네, 알겠습니다” (대부분 지키지만, 가끔 빠뜨림) 개발자: (코드 리뷰에서 발견) “여기 의존성 방향이 반대야” Claude: “죄송합니다, 수정하겠습니다”</blockquote><p>ArchUnit 도입 후에는 이렇게 바뀌었습니다:</p><blockquote>Claude가 코드를 생성합니다. 테스트를 실행합니다. ArchUnit: “Architecture Violation — Repository is not allowed to access Controller” Claude: (실패 메시지를 읽고) “레이어 의존성 위반이 있습니다. Service를 통해 접근하도록 수정하겠습니다.” 테스트를 재실행합니다. 통과.</blockquote><p>사람이 개입할 틈이 없습니다. AI가 코드를 생성하고, 테스트가 위반을 잡고, AI가 스스로 수정합니다. <strong>부탁에서 강제로, 사후 검증에서 사전 차단으로</strong> 전환된 것입니다.</p><p>흥미로운 점은 Claude가 ArchUnit 실패 메시지에 대응하는 방식이었습니다. 단순히 에러를 회피하는 것이 아니라, 위반 원인을 이해하고 올바른 아키텍처 패턴으로 코드를 재구성했습니다. 교과서를 읽었을 때는 가끔 빠뜨리던 AI가, 시험을 보게 하니 틀린 문제를 스스로 교정하기 시작한 셈입니다.</p><h3>적용한 규칙들: 선생님의 훈련 과목</h3><h3>1. 레이어 의존성 규칙 정의</h3><p>가장 먼저 잡고 싶었던 규칙은 레이어 간 의존성 방향이었습니다. Controller → Service → Repository 방향으로만 의존해야 하며, 역방향 의존은 허용하지 않습니다. 처음 코드 리뷰에서 발견했던 바로 그 문제입니다.</p><p>자연어로 설명한 규칙이 ArchUnit 코드로 변환되면 다음과 같은 모습이 됩니다:</p><pre>@ArchTest<br>val `레이어 의존성 규칙` = layeredArchitecture()<br>    .consideringAllDependencies()<br>    .layer(&quot;Controller&quot;).definedBy(&quot;..controller..&quot;)<br>    .layer(&quot;Service&quot;).definedBy(&quot;..service..&quot;)<br>    .layer(&quot;Repository&quot;).definedBy(&quot;..repository..&quot;)<br>    .layer(&quot;Domain&quot;).definedBy(&quot;..domain..&quot;)<br>    .whereLayer(&quot;Controller&quot;).mayOnlyBeAccessedByLayers(&quot;Controller&quot;)<br>    .whereLayer(&quot;Service&quot;).mayOnlyBeAccessedByLayers(&quot;Controller&quot;, &quot;Service&quot;)<br>    .whereLayer(&quot;Repository&quot;).mayOnlyBeAccessedByLayers(&quot;Service&quot;)<br>    .whereLayer(&quot;Domain&quot;).mayOnlyBeAccessedByLayers(&quot;Service&quot;, &quot;Repository&quot;, &quot;Controller&quot;)</pre><p>이 테스트가 실패하면 다음과 같은 메시지가 출력됩니다:</p><pre>Architecture Violation [Rule &#39;Layered architecture ...&#39;] -<br>Layer &#39;Repository&#39; is not allowed to access layer &#39;Controller&#39;,<br>but class com.musinsa.warehouse.repository.OrderRepository<br>accesses com.musinsa.warehouse.controller.OrderController</pre><p>메시지가 구체적입니다. 어떤 클래스가 어떤 레이어를 잘못 참조했는지 정확히 알려줍니다. 사람이 읽어도, AI가 읽어도 즉시 원인을 파악할 수 있습니다.</p><p>실제 프로젝트에서는 멀티 모듈 구조에 맞춰 모듈별로 레이어 규칙을 정의합니다. 예를 들어, API 모듈이 다른 모듈의 내부 구현에 직접 접근하는 것을 차단하는 규칙은 이렇게 작성됩니다</p><pre>@Test<br>@DisplayName(&quot;API 패키지만 접근해야 한다&quot;)<br>void adminShouldOnlyAccessAllowedApiPackages() {<br>    ArchRule rule = noClasses()<br>            .that()<br>            .resideInAPackage(&quot;com.musinsalogistics.sampleproject.admin..&quot;)<br>            .should()<br>            .accessClassesThat(resideInAPackage(&quot;com.musinsalogistics.sampleproject..&quot;)<br>                    .and(resideOutsideOfPackages(<br>                            &quot;com.musinsalogistics.sampleproject.admin..&quot;,<br>                            &quot;com.musinsalogistics.sampleproject..api..&quot;,<br>                            &quot;com.musinsalogistics.sampleproject..exception..&quot;)))<br>            .allowEmptyShould(true)<br>            .because(&quot;Admin은 다른 모듈의 api 패키지와 exception 패키지만 접근할 수 있습니다&quot;); <br>    rule.check(classes);<br>}<br></pre><blockquote>“다른 모듈의 api 패키지와 exception 패키지만 접근 가능&quot; — 이 한 줄의 비즈니스 규칙이 코드로 표현되면, AI가 모듈 경계를 넘어 내부 구현에 직접 의존하는 코드를 생성했을 때 즉시 테스트가 실패합니다.</blockquote><h3>2. 패키지 구조 규칙 정의</h3><p>레이어 의존성 외에도 팀의 패키지 네이밍 컨벤션을 강제했습니다. “Controller 클래스는 controller 패키지에”, “Service 클래스는 service 패키지에” — 단순하지만 AI가 종종 빠뜨리는 규칙이었습니다.</p><pre>@ArchTest<br>val `패키지 구조 규칙 - Controller는 controller 패키지에 위치` = classes()<br>    .that().haveSimpleNameEndingWith(&quot;Controller&quot;)<br>    .should().resideInAPackage(&quot;..controller..&quot;)<br>@ArchTest<br>val `패키지 구조 규칙 - Service는 service 패키지에 위치` = classes()<br>    .that().haveSimpleNameEndingWith(&quot;Service&quot;)<br>    .should().resideInAPackage(&quot;..service..&quot;)<br>@ArchTest<br>val `패키지 구조 규칙 - Repository는 repository 패키지에 위치` = classes()<br>    .that().haveSimpleNameEndingWith(&quot;Repository&quot;)<br>    .should().resideInAPackage(&quot;..repository..&quot;)</pre><h3>3. 순환 의존성 감지 규칙</h3><p>레이어 의존성과 패키지 구조 외에도, AI가 복잡한 기능을 구현하다 보면 의도치 않게 <strong>패키지 간 순환 참조</strong>를 만들어내는 경우가 있었습니다. A 패키지가 B를 참조하고, B가 다시 A를 참조하는 구조. 사람이 코드 리뷰에서 이런 순환을 발견하기란 쉽지 않습니다. 하지만 ArchUnit에게는 간단한 일입니다.</p><blockquote>“패키지 간 순환 의존이 발생하면 안 됩니다”</blockquote><p>이 한 줄의 자연어가 다음 테스트 코드가 됩니다:</p><pre>@ArchTest<br>val `패키지 간 순환 의존 금지` = slices()<br>    .matching(&quot;com.musinsa.warehouse.(*)..&quot;)<br>    .should().beFreeOfCycles()</pre><p>단 세 줄로, 프로젝트 전체의 패키지 순환을 감지합니다. 앞서 설명한 Lint가 절대 할 수 없는 영역입니다. 파일 하나만 봐서는 순환인지 알 수 없고, 전체 의존 그래프를 그려봐야 비로소 드러나는 문제이기 때문입니다.</p><p>ArchUnit의 검증 범위는 클래스 구조에 그치지 않습니다. 메서드 레벨의 규칙도 작성할 수 있습니다. 예를 들어, API URL이 팀에서 정한 형식을 따르는지 검증하는 규칙입니다:</p><pre>@Test<br>@DisplayName(&quot;Controller의 API는 /api/sampleproject/public/v{버전}/{비즈니스}... 형식을 준수해야 한다&quot;)<br>void controllerApiUrlShouldFollowPublicApiFormat() {<br>    ArchRule rule = ArchRuleDefinition.methods()<br>            .that().areDeclaredInClassesThat().resideInAPackage(&quot;..publicapi.controller..&quot;)<br>            .and().areDeclaredInClassesThat().haveSimpleNameEndingWith(&quot;Controller&quot;)<br>            .and().areAnnotatedWith(isHttpMappingAnnotation())<br>            .should(haveValidPublicApiUrlFormat())<br>            .allowEmptyShould(true)<br>            .because(&quot;Public API는 /api/sampleproject/public/v{버전번호}/{비즈니스}... 형식을 준수해야 합니다&quot;);</pre><p>AI가 새 API 엔드포인트를 생성할 때 URL 형식을 자유롭게 만들어버리는 경우가 있습니다. 이 규칙이 있으면 /api/sampleproject/public/v1/... 형식에 맞지 않는 URL은 즉시 감지됩니다. 사소해 보이지만, API URL의 일관성은 외부 시스템 연동에서 매우 중요합니다.</p><h3>4. 도메인 순수성 보호 규칙</h3><p>저희 팀이 특히 신경 쓰는 규칙이 하나 더 있습니다. 도메인 레이어는 외부 프레임워크에 의존하지 않아야 한다는 것입니다. Spring의 @Autowired, JPA의 @Entity 같은 프레임워크 어노테이션이 도메인 모델에 침투하면, 도메인이 특정 기술에 종속되어 버립니다.</p><blockquote>“domain 패키지의 클래스는 Spring이나 JPA 프레임워크에 의존하면 안 됩니다”</blockquote><pre>@ArchTest<br>val `도메인은 프레임워크에 의존하지 않는다` = classes()<br>    .that().resideInAPackage(&quot;..domain..&quot;)<br>    .should().onlyDependOnClassesThat()<br>    .resideInAnyPackage(<br>        &quot;..domain..&quot;,<br>        &quot;java..&quot;,<br>        &quot;kotlin..&quot;,<br>        &quot;org.slf4j..&quot;<br>    )</pre><p>이 규칙이 없을 때, AI는 가끔 도메인 클래스에 @Component를 붙이거나 JpaRepository를 직접 주입하는 코드를 생성했습니다. 테스트가 이를 잡아내면서, AI는 &quot;도메인은 순수해야 한다&quot;는 원칙을 코드 레벨에서 학습하게 되었습니다.</p><p>의존성 역전 원칙(DIP)도 ArchUnit으로 강제할 수 있습니다. 예를 들어, Security 모듈에서 provider 패키지가 component 패키지의 구체 클래스에 직접 의존하지 않도록 하는 규칙입니다.</p><p>먼저 DIP 위반과 준수가 어떤 구조인지 살펴보겠습니다:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*UOv8AaB-s-Q9XK51NFofoQ.png\" /></figure><p>Provider가 Component의 구체 클래스를 직접 참조하면 두 패키지가 강하게 결합됩니다. 대신 security.api 패키지의 인터페이스를 통해 소통하면, Component의 내부 구현이 바뀌어도 Provider는 영향을 받지 않습니다. 이 설계 원칙을 ArchUnit으로 강제하면:</p><pre>@Test<br>void securityProviderShouldNotDependOnComponentClasses() {<br>    ArchRule rule = noClasses()<br>            .that().resideInAnyPackage(&quot;..security.internal.provider..&quot;)<br>            .should().dependOnClassesThat()<br>            .resideInAnyPackage(&quot;..security.internal.component..&quot;)<br>            .because(&quot;의존성 역전 원칙(DIP)을 준수하여 추상화(인터페이스)에 의존해야 합니다&quot;);<br>    rule.check(securityModuleClasses);<br>}</pre><p>AI가 Provider 클래스에서 Component의 구체 클래스를 직접 import하면 즉시 테스트가 실패합니다.</p><blockquote><strong>“구체 클래스가 아닌 인터페이스에 의존하라”</strong>는 SOLID 원칙이 코드 레벨에서 자동 검증되는 셈입니다.</blockquote><h3>5. 어노테이션과 클래스 네이밍 일관성 규칙</h3><p>AI가 은근히 자주 저지르는 실수가 하나 더 있습니다. @Service 어노테이션을 Service가 아닌 클래스에 붙이는 것입니다. 예를 들어 OrderHelper나 PriceCalculator 같은 유틸리티 클래스에 습관적으로 @Service를 달아버립니다. 컴파일도 되고 동작도 합니다. 하지만 팀 컨벤션에서는 @Service는 ~Service로 끝나는 클래스에만 사용해야 합니다. 어노테이션과 클래스 이름이 일치하지 않으면, 코드를 읽는 사람이 역할을 오해하게 됩니다.</p><blockquote>“@Service 어노테이션은 이름이 Service로 끝나는 클래스에만 붙여야 합니다”</blockquote><pre>@ArchTest<br>val `@Service는 Service 클래스에만 사용` = classes()<br>    .that().areAnnotatedWith(Service::class.java)<br>    .should().haveSimpleNameEndingWith(&quot;Service&quot;)<br>@ArchTest<br>val `@Repository는 Repository 클래스에만 사용` = classes()<br>    .that().areAnnotatedWith(Repository::class.java)<br>    .should().haveSimpleNameEndingWith(&quot;Repository&quot;)<br>@ArchTest<br>val `@Controller는 Controller 클래스에만 사용` = classes()<br>    .that().areAnnotatedWith(RestController::class.java)<br>    .should().haveSimpleNameEndingWith(&quot;Controller&quot;)</pre><p>이 규칙의 효과는 생각보다 컸습니다. AI는 “빈으로 등록해야 하니까 @Service를 붙이자&quot;라는 판단을 자주 합니다. 기능적으로는 맞지만, 팀의 네이밍 컨벤션과는 어긋납니다. 테스트가 실패하면 AI는 @Service 대신 @Component를 사용하거나, 클래스 이름을 컨벤션에 맞게 변경합니다.</p><p>어노테이션 규칙은 여기서 한 단계 더 깊어질 수 있습니다. 저희 팀에서는 @Transactional의 readOnly 속성에 따라 Service 클래스의 네이밍까지 강제합니다</p><pre>@ArchTest<br>void Transactional_readOnly_false인_클래스는_FacadeService_또는_WriteService_이름을_가져야_한다(JavaClasses classes) {<br>    classes()<br>            .that().resideInAPackage(&quot;..domain..&quot;)<br>            .and().areAnnotatedWith(Transactional.class)<br>            .should(haveWriteServiceNaming())<br>            .allowEmptyShould(true)<br>            .because(&quot;쓰기 트랜잭션 서비스는 FacadeService 또는 WriteService 네이밍을 따라야 합니다&quot;)<br>            .check(classes);<br>}<br><br>@ArchTest<br>void Transactional_readOnly_true인_클래스는_ReadService_이름을_가져야_한다(JavaClasses classes) {<br>    classes()<br>            .that().resideInAPackage(&quot;..domain..&quot;)<br>            .and().areAnnotatedWith(Transactional.class)<br>            .should(haveReadServiceNaming())<br>            .allowEmptyShould(true)<br>            .because(&quot;읽기 전용 서비스는 ReadService 또는 SearchService 네이밍을 따라야 합니다&quot;)<br>            .check(classes);<br>}</pre><p>@Transactional(readOnly = true)인데 WriteService라는 이름을 가진 클래스가 있다면? 테스트가 실패합니다. 트랜잭션 속성과 클래스 이름이 일치해야 한다는 규칙은, 코드를 읽는 사람이 &quot;이 서비스가 읽기 전용인지, 쓰기도 하는지&quot;를 이름만으로 즉시 판단할 수 있게 해줍니다.</p><h3>왜 사람이 읽을 수 있는 코드여야 하는가</h3><p>“기능만 돌아가면 되는 거 아닌가?”라고 생각할 수도 있습니다. 하지만 여기서 한 가지 잊지 말아야 할 것이 있습니다. 코드를 생성하는 것은 AI지만, 그 코드를 감독하고, 유지보수하고, 장애에 책임지는 것은 사람입니다.</p><p>AI가 만든 코드는 결국 사람이 읽어야 합니다. 새로운 팀원이 합류했을 때, 장애가 터져서 새벽에 코드를 열었을 때, 반년 뒤 요구사항이 바뀌어 로직을 수정해야 할 때 — 그 코드를 마주하는 것은 사람입니다. OrderHelper에 @Service가 붙어 있으면, 사람은 &quot;이게 비즈니스 서비스인가?&quot;라고 오해합니다. 작은 혼란이 쌓이면 코드베이스 전체의 가독성이 무너집니다.</p><p>어노테이션과 클래스 이름의 일관성은 사소해 보이지만, <strong>사람이 코드를 빠르고 정확하게 이해하기 위한 최소한의 약속</strong>입니다.</p><blockquote>AI 시대에도 코드의 최종 독자는 여전히 사람이기 때문입니다.</blockquote><h3>도입 후 변화</h3><h3>정량적 변화</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*B_1Hgo-TwOUMC6cCc0JGpA.png\" /></figure><p>가장 체감이 컸던 변화는 코드 리뷰의 질이었습니다. 아키텍처 위반을 더 이상 눈으로 찾을 필요가 없으니, 리뷰어는 비즈니스 로직의 정확성과 엣지 케이스 처리에 온전히 집중할 수 있게 되었습니다.</p><h3>팀 피드백</h3><p>팀원들의 반응은 긍정적이었습니다. 특히 두 가지 목소리가 인상적이었습니다:</p><blockquote>“이제 아키텍처 위반은 ArchUnit이 잡아주니, 리뷰에서 비즈니스 로직에만 집중할 수 있어서 좋습니다”</blockquote><blockquote>“AI가 생성한 코드도 테스트를 통과해야 하니까, 예전보다 안심하고 AI를 활용할 수 있게 됐습니다”</blockquote><p>AI 활용에 대한 심리적 안전망이 생긴 것도 큰 변화였습니다. “AI가 혹시 규칙을 어기면 어쩌지?”라는 불안감이, “어겨도 테스트에서 잡히니까 괜찮아”로 바뀌었습니다.</p><h3>마무리</h3><h3>AI에게 부탁하지 말고, 시험을 보게 하라</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Kk0_qwVuPzw3VXqplJW56w.png\" /></figure><p>이번 도입 과정에서 가장 크게 깨달은 것은 AI에게 규칙을 전달하는 방식의 차이입니다.</p><blockquote>컨텍스트는 가이드라인입니다. 테스트는 제약 조건입니다. AI는 “이렇게 해주세요”라는 부탁보다 <strong>“이것을 어기면 빌드가 실패합니다”</strong>라는 명확한 피드백에 훨씬 잘 반응합니다.</blockquote><blockquote>이 관점은 아키텍처 규칙에만 국한되지 않습니다. 코딩 컨벤션, 네이밍 규칙, 모듈 경계 — <strong>팀이 일관되게 지키고 싶은 모든 규약</strong>을 “테스트로 검증 가능한 형태”로 만들 수 있다면, AI와의 협업 품질은 한 단계 올라갈 수 있습니다.</blockquote><h3>향후 과제</h3><p>현재는 레이어 의존성과 패키지 구조라는 가장 기본적인 규칙만 적용한 상태입니다. 앞으로 두 가지 방향으로 확장을 계획하고 있습니다.</p><ul><li>규칙 확대: 도메인 이벤트 발행 규칙, DTO 변환 위치 규칙, 외부 라이브러리 사용 범위 제한 등 더 세밀한 아키텍처 규칙을 추가할 예정입니다. 선생님의 훈련 과목을 늘리는 셈입니다.</li><li>다른 프로젝트 확산: 물류플랫폼팀 내 다른 프로젝트에도 동일한 ArchUnit 규칙 세트를 적용하여, 프로젝트가 달라져도 아키텍처의 일관성을 유지하려 합니다.</li></ul><p>AI 코드 생성 도구를 적극 활용하면서도 아키텍처 품질에 대한 고민이 있으신 분들에게, ArchUnit이 좋은 출발점이 될 수 있을 것입니다.</p><p>질풍노도의 AI에게 필요한 것은 더 많은 교과서가 아니라,</p><blockquote>시험지 한 장이었습니다.</blockquote><h3>Platform Business Operation 조직 및 팀 소개</h3><blockquote><em>무신사 플랫폼 비즈니스 오퍼레이션 조직은 국내외 물류 서비스, 재고 관리, 스토어 운영을 위한 물류 프로덕트를 구축하고 다양한 오프라인 비즈니스 모델에 맞춘 스토어 관리 시스템을 개발·고도화하고 있습니다.<br>또한, 무배당발 서비스를 포함한 무신사의 차별화된 고객 경험을 브랜딩하고 확장할 수 있는 멤버십 구조를 설계하며, 온·오프라인을 넘나드는 통합 커머스 경험을 기술로 실현하고 있습니다.</em></blockquote><blockquote><em>저희 팀은 OMS(주문관리시스템)를 기반으로 온라인 주문부터 재고·출고·배송·정산에 이르는 전 과정을 유기적으로 연결하고, 무신사의 다양한 오프라인 스토어를 효과적으로 운영할 수 있는 관리 시스템을 구축하여 고객이 온라인(무신사 스토어, 29CM 등)과 오프라인(무신사 스탠다드, 편집숍 등)에서 끊김 없는 쇼핑 경험을 누릴 수 있도록 지원합니다.</em></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/pbo\"><em>🚀 Platform Business Operation 한걸음 더 알아보기</em></a></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/home\"><em>🚀 팀 무신사 채용 페이지</em></a><em> (무신사/29CM 전체 포지션 확인이 가능해요)</em></blockquote><blockquote><em>🚀 </em><a href=\"https://kr.linkedin.com/company/musinsacom\"><em>팀 무신사 테크 소식을 받아보는 링크드인</em></a></blockquote><blockquote><em>🚀 </em><a href=\"https://newsroom.musinsa.com/\"><em>팀 무신사 뉴스룸</em></a></blockquote><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=61c3d533fc40\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://techblog.musinsa.com/%EC%A7%88%ED%92%8D%EB%85%B8%EB%8F%84%EC%9D%98-ai-claude-%EC%97%90%EA%B2%8C-%EC%97%84%EA%B2%A9%ED%95%9C-%EC%84%A0%EC%83%9D%EB%8B%98-%EC%9E%A5%EC%B0%A9%ED%95%98%EA%B8%B0-61c3d533fc40\">질풍노도의 AI(Claude)에게 엄격한 선생님 장착하기</a> was originally published in <a href=\"https://techblog.musinsa.com\">MUSINSA techblog — 무신사 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2026-02-09T08:01:02.000Z",
    "url": "https://techblog.musinsa.com/%EC%A7%88%ED%92%8D%EB%85%B8%EB%8F%84%EC%9D%98-ai-claude-%EC%97%90%EA%B2%8C-%EC%97%84%EA%B2%A9%ED%95%9C-%EC%84%A0%EC%83%9D%EB%8B%98-%EC%9E%A5%EC%B0%A9%ED%95%98%EA%B8%B0-61c3d533fc40?source=rss----f107b03c406e---4"
  },
  {
    "publisherId": "musinsa",
    "publisherName": "무신사 테크블로그",
    "specTitle": "e커머스 개발",
    "categories": [
      "backend"
    ],
    "specUrl": "https://medium.com/feed/musinsa-tech",
    "title": "“스케줄이 또 안 돌았어요” — 우리가 Temporal을 선택한 이유",
    "partialText": "<h3>“스케줄이 또 안 돌았어요” — 우리가 Temporal을 선택한 이유</h3><p>어느 날 아침, 슬랙 알림이 울렸습니다. <br>“출고지시 스케줄이 실행 안 된 것 같은데 확인 부탁드려요.”</p><p>Jenkins 콘솔을 열어보니 job이 멈춰있었고, 모니터링 job마저 함께 멈춰있었습니다. 급하게 수동으로 출고지시를 트리거하고 나서야 물류센터 작업이 시작될 수 있었습니다. 이런 일이 반복되면서 우리는 고민하게 되었습니다.</p><p><strong>“스케줄 하나 도는 게 왜 이렇게 불안할까?”</strong></p><h3>출고지시, 그리고 우리가 마주한 문제들</h3><p>무신사 풀필먼트의 OMS는 주문부터 출고까지 물류 전반을 책임지는 시스템입니다. 그 중에서도 <strong>출고지시는 물류센터의 하루를 시작하는 신호</strong>와도 같습니다. 정해진 시간에 출고지시가 생성되지 않으면 물류센터 작업이 지연되고, 그것은 곧 배송 지연으로 이어집니다.</p><p>초기에는 Jenkins crontab으로 충분했습니다. 정해진 시간에 실행하기만 하면 됐습니다. 하지만 화주사가 늘고 출고 물량이 커지면서, 이 구조의 한계가 하나둘 보이기 시작했습니다.</p><h3>1. 실패를 놓치는 순간들</h3><p>Jenkins 기반 스케줄은 job이 멈춰도 알려주지 않았습니다. 그래서 우리는 별도의 모니터링 job을 만들어 실행했습니다. <strong>“스케줄이 실행됐는지 확인하는 스케줄”</strong>을 또 만드는 거죠.</p><p>문제는 이 모니터링 job도 언제든 멈출 수 있다는 것이었습니다. 실제로 Jenkins 자체에 문제가 생기면 스케줄과 모니터링이 함께 멈췄고, 우리는 뒤늦게야 알게 되곤 했습니다. 모니터링을 위한 모니터링을 또 만들 수는 없었고, 이 구조 자체가 근본적인 한계를 가지고 있다는 걸 깨달았습니다.</p><h3>2. 로그 속에서 원인 찾기</h3><p>출고지시에 문제가 생기면, 저희는 Jenkins 콘솔 로그를 시작으로 애플리케이션 로그, DB 이력을 차례로 확인해야 했습니다.</p><p>“이번엔 어디서 실패한 거지?” <br>“입력값은 뭐였지?” <br>“결과는 어떻게 됐지?”</p><p>실행 이력을 한눈에 볼 수 있는 방법이 없었고, <strong>문제를 분석하는 것보다 로그를 따라가는 데 더 많은 시간</strong>이 들었습니다. 빠른 대응이 필요한 순간일수록, 이런 가시성 부족은 운영 리스크를 키우는 요인이 되었습니다.</p><h3>3. “다시 눌러주세요”</h3><p>스케줄이 실패하면 저희가 직접 재실행해야 했습니다. 단순히 일시적인 네트워크 오류로 실패한 경우에도, 원인을 확인하고 수동으로 재실행하는 과정에서 시간이 소요되었습니다.</p><p>대응이 조금만 늦어도 출고 SLA에 영향을 주는 경우가 생겼고, 담당자의 부담은 자연스럽게 커질 수밖에 없었습니다. 실제로는 단순 재시도만으로 해결될 수 있는 케이스도 많았지만, 원인을 확인하는 절차 자체가 출고 지연으로 이어지는 경우가 반복되었습니다.</p><p>결국 이러한 구조에서는 안정적인 운영을 기대하기 어려워졌습니다.</p><h3>4. 이벤트 기반으로의 확장</h3><p>출고 도메인에서는 정해진 스케줄 외에도, 특정 이벤트를 기점으로 Workflow를 실행해야 하는 요구가 늘어나고 있었습니다. 하지만 Jenkins는 cron 기반 실행에 최적화되어 있었고, 이벤트 기반 트리거를 자연스럽게 처리하기에는 구조적인 한계가 있었습니다.</p><p>결국 저희는 깨달았습니다. <br><strong>“출고 물량과 요구사항이 늘어날수록, 기존 구조로는 안정적인 운영을 기대하기 어렵다.”</strong></p><p>구조 자체를 다시 고민해야 할 시점이었습니다.</p><h3>대안을 찾아서</h3><p>저희는 여러가지 가능성을 열어두고 대안을 비교해보기 시작했습니다.</p><h4>Jenkins + 모니터링 Job 개선</h4><p>이미 운영 중인 구조라 리스크는 적었지만, 근본적인 한계를 해결하기는 어려웠습니다. 모니터링을 아무리 촘촘하게 만들어도, Jenkins 자체의 고가용성 문제는 해결되지 않았습니다.</p><h4>Spring Batch + Quartz</h4><p>Spring Batch + Quartz는 배치 처리에 최적화된 구조였고, 팀에서도 익숙한 스택이었습니다. 하지만 Batch Job 실행 이력은 확인할 수 있어도, “주문이 어디서 멈췄고, 왜 실패했는지”와 같은 비즈니스 흐름은 보이지 않았습니다. 재시도 로직 구현은 가능했지만, “이 조건이면 재시도, 저 조건이면 스킵” 같은 의사결정 로직이 코드 곳곳에 흩어지면서 전체 워크플로우를 파악하기 어려워졌습니다. 결국 “배치 Job”이 아닌 “비즈니스 워크플로우” 단위로 실행과 상태를 추적하고 싶었습니다.</p><h4>Temporal</h4><p>Temporal은 장기 실행되는 비즈니스 프로세스를 코드로 표현하고, 실패·재시도·상태 관리를 플랫폼 레벨에서 보장해주는 Workflow Engine입니다. Uber에서 만든 Cadence를 기반으로 개발되었으며, 서버 장애가 발생해도 중단된 지점부터 자동 복구됩니다.</p><p>생소한 이름이었습니다. 러닝 커브가 높다는 것도 부담이었습니다. 하지만 회의실에서 Temporal 문서를 보며 이야기를 나누다 보니, 저희가 원하던 것들이 하나하나 눈에 들어왔습니다.</p><ul><li>스케줄 기반 실행</li><li>Workflow 전체 흐름에 대한 가시성</li><li>자동 재시도와 복구</li><li>이벤트 기반 트리거</li></ul><p>어느 순간 팀 모두가 적합해 보인다고 생각했고, <strong>단순히 스케줄을 실행하는 기능을 넘어, 출고 도메인 전반의 흐름을 안정적으로 오케스트레이션할 수 있는 플랫폼</strong>이 될 수 있겠다고 판단했습니다.</p><h3>설계하면서 고민한 것들</h3><h4>무엇을 목표로 설계하는가</h4><p>기존 Jenkins crontab 기반 스케줄링 방식은 운영 안정성, 실행 가시성, 복구 가능성 측면에서 여러 한계를 갖고 있었습니다.</p><p>이에 따라 스케줄 실행 방식을 보다 안정적이고 자동화된 구조로 전환하고, 운영자가 수행하던 수동 확인과 재실행 작업을 최소화하는 것을 목표로 했습니다.</p><h4>Workflow와 Activity, 어떻게 나눌 것인가</h4><p>Temporal 공식 문서는 이렇게 말합니다.</p><blockquote><em>Workflow는 전체 비즈니스 프로세스의 오케스트레이션을 담당하고, Activity는 외부 시스템과의 상호작용이나 단위 작업을 수행한다.</em></blockquote><p>Workflow와 Activity의 경계를 정하는 데 가장 어려웠던 점은, 단순히 “외부 시스템을 호출하는가”가 아니라 “이 분기가 비즈니스 정책인가, 실행 세부사항인가”를 판단하는 일이었습니다. 예를 들어 “중복 주문이면 스킵한다”는 비즈니스 정책이므로 Workflow에서 분기하고, “DB에서 중복 여부를 조회한다”는 실행 세부사항이므로 Activity로 분리했습니다.</p><p>논의 끝에 저희가 세운 기준은 이렇습니다:</p><ul><li>Workflow: 비즈니스 정책에 따른 분기와 흐름 제어</li><li>Activity: 멱등성이 보장되는 단위 작업, 외부 시스템 호출</li></ul><p>출고지시의 경우, Workflow는 “정책 조회 → 중복 체크 → 차수 생성 → 파이프라인 트리거” 흐름을 조율하고, 각 단계의 실제 작업은 Activity가 수행합니다. 이 구분이 명확할수록 향후 출고 파이프라인 전체를 Workflow로 확장할 때도 일관성 있게 설계할 수 있을 거라 생각했습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*iO5YSi38Zj2O5Ue3f43rbQ.png\" /></figure><ul><li>앞서 정의한 기준에 따라, Workflow는 출고지시 트리거의 전체 흐름과 분기·의사결정을 조율하고 Activity는 정책 조회, 중복 체크, 차수 생성 등 실제 작업을 수행합니다.</li><li>Temporal 내 정의된 스케줄을 기반으로 Workflow가 실행되며, 각 단계는 Activity로 위임되어 상태를 명확히 관리하고 출고지시 흐름을 조율합니다.</li></ul><h3>출고지시 Workflow 구현</h3><p>최종적으로 <strong>1개의 Workflow</strong>와 <strong>5개의 Activity</strong>로 구성했습니다. (아래는 간략화된 코드입니다.)</p><pre>@WorkflowImplement<br>class CutOffTriggerWorkflowImpl : CutOffTriggerWorkflow {<br>    override fun run() {<br>      <br>        // 출고지시 정책 조회<br>        val policies = getCutOffPolicies.get(now)<br><br>        policies.forEach { policy -&gt;<br>            // 출고지시 차수 생성<br>            val cutSequence = createCutSequence.create(policy)<br><br>            // 파이프라인 트리거<br>            triggerPipeline.trigger(cutSequence, now)<br>        }<br>    }<br>}</pre><h3>29CM 주문수집도 자동화하다</h3><p>출고지시 트리거를 Temporal로 전환하고 나니, 또 다른 수동 작업이 눈에 들어왔습니다. <strong>29CM 주문수집</strong>이었습니다.</p><p>담당자가 MOMS 화면에서 버튼을 눌러 수동으로 주문을 수집하고 있었는데, 물량이 늘면서 이 방식도 한계가 드러나기 시작했습니다. 버튼 클릭을 누락하는 경우도 있었고, 담당자 부재 시 주문 수집이 지연되기도 했습니다.</p><p>“출고지시와 비슷한 문제잖아?”</p><p>팀 내에서 자연스럽게 이러한 논의가 이어졌고, 29CM 주문수집도 Temporal Workflow로 자동화하기로 했습니다.</p><h3>개인정보 보호를 고려한 설계</h3><p>하지만 여기서 중요한 고민이 하나 있었습니다. 우리는 Temporal Cloud를 사용할 계획이므로 무신사 고객의 개인정보를 Temporal에 전달하는 것은 부적절했습니다.</p><p>회의실에서 여러 방안을 논의했고, 결국 다음과 같이 설계했습니다:</p><ol><li>29CM에서 받은 API Payload를 MOMS DB에 저장</li><li>Payload ID만 Temporal Workflow에 전달</li><li>Activity에서 Payload ID로 DB 조회 후 처리</li></ol><p><strong>즉, 개인정보는 우리 인프라 안에 머물고, Temporal에는 ID만 전달되는 구조</strong>입니다.</p><h3>주문수집 Workflow 시나리오</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*3ZllJ7Z8IUJJ-n4sSJFbYQ.png\" /></figure><ul><li>29CM API에서 주문을 조회해서 DB에 저장(ORDER_COLLECTED)합니다.</li><li>성공한 건에 대해 29CM에 상품준비중 상태 변경을 요청한 뒤, 상태를 ORDER_ACCEPTED로 변경하는 플로우입니다.</li></ul><h3>주문수집 Workflow 구현</h3><p><strong>1개의 Workflow</strong>와 <strong>4개의 Activity</strong>로 구성했습니다.</p><pre>@WorkflowImplement<br>class AddStandardOrderWorkflowImpl : AddStandardOrderWorkflow {<br>    override fun addOrders(payloadId: Long) {<br>        // 1. 주문 수집<br>        val upsertResults = addStandardOrderActivity.addOrders(payloadId)<br>        val successOrders = upsertResults.filter { it.success }<br>        if (successOrders.isEmpty()) return<br><br>        // 2. 상품 준비중 API 요청<br>        val shippingResults = requestPrepareShippingActivity.request(successOrders)<br><br>        // 3. 주문 상태를 ORDER_ACCEPTED로 변경<br>        if (shippingResults.items.isNotEmpty()) {<br>            val request = convertActivity.convert(shippingResults)<br>            changeStatusActivity.updateToAccepted(request)<br>        }<br>    }<br>}</pre><p>주문 수집 → 29CM API 호출 → 상태 변경까지의 흐름이 하나의 Workflow로 표현됩니다. 출고지시 Workflow와 비슷한 구조지만, 도메인의 특성에 맞게 Activity를 구성했습니다.</p><h3>운영하면서 느낀 것들</h3><h4>좋았던 점들</h4><h4>1. 장애 대응이 ‘케이스 바이 케이스’에서 ‘시스템’으로</h4><p>가장 먼저 체감한 변화는 <strong>자동 재시도</strong>였습니다. Activity에 정의한 Retry/Backoff/Timeout 규칙에 따라 자동으로 재시도되는 걸 보면서, “아, 이제 Spring Batch에 복잡하게 구현하지 않아도 되겠구나”라는 생각이 들었습니다.</p><p>실제로 운영 중 일시적인 네트워크 오류로 출고지시가 실패한 적이 있었는데, Temporal UI를 보니 자동으로 3번 재시도하고 성공한 걸 확인할 수 있었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*xRR-OkSmY4zf8tIl_XvT1A.png\" /><figcaption>EventID 12 : 재시도 후 성공한 케이스</figcaption></figure><h4>2. Workflow 단위로 보이는 실행 이력</h4><p>이전에는 Jenkins 로그, 애플리케이션 로그를 모두 열어봐야 했지만, <strong>Temporal UI에서 타임라인을 한눈에 확인</strong>할 수 있게 되었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*GbkPp4FK89-3N4aff2Xllg.png\" /><figcaption>하단부터 시간순 타임라인</figcaption></figure><p>특히 Activity 단위로 input, output을 빠르게 확인할 수 있어 원인 파악이 훨씬 쉬워졌습니다. “이 시점에 어떤 정책이 들어왔고, 어떤 결과가 나왔는지”를 클릭 몇 번으로 확인할 수 있게 되니, 장애 대응 시간이 크게 줄었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*nynJLox02b6lW5mbMBDJvg.png\" /><figcaption>특정 Activity의 Input, Output</figcaption></figure><h4>3. 부분 도입만으로도 체감된 변화</h4><p>출고지시 전체 파이프라인이 아닌 <strong>“트리거 + 특정 화주 주문수집”만 Temporal로 옮겼는데도</strong>, 해당 구간의 장애 대응과 모니터링 편의성은 즉시 체감할 수 있었습니다.</p><p>또한, 동일 도메인을 Spring Batch + Jenkins와 Temporal 두 체계에서 비교해보면서, 어떤 유형의 작업이 Temporal에 더 적합한지 기준을 잡는 데 도움이 되었습니다.</p><h4>고려해봐야 할 것들</h4><h4>1. Workflow·Activity 경계 설정의 어려움</h4><p>“무엇을 하나의 Workflow로 보고, 어느 단위를 Activity로 분리할 것인가”에 대한 기준을 잡는 게 쉽지 않았습니다. 팀 내에서도 의견이 엇갈릴 때가 많았고, 결국 “실제로 만들어보고 조정하자”는 방식으로 진행했습니다.</p><p>이번에는 일부에만 적용했지만, 향후 출고 전체 파이프라인으로 확장하려면 <strong>더 명확한 설계 원칙</strong>이 필요할 것 같습니다.</p><h4>2. 디버깅 포인트의 증가</h4><p>Temporal을 도입하면서 애플리케이션 로그 외에 Temporal History, Worker 메트릭까지 함께 봐야 해서 디버깅 지점이 늘어난 것은 사실입니다. 하지만 이는 단순히 복잡도가 증가했다기보다, 실행 상태를 구조적으로 관측할 수 있게 된 결과라고 느끼고 있습니다.</p><p>다만 이 장점을 살리기 위해서는, 로그·메트릭·Workflow History를 어떤 순서로 확인할지에 대한 팀 차원의 디버깅 가이드가 반드시 필요하다는 점도 함께 깨달았습니다. 현재는 이슈 대응 시 “애플리케이션 로그 → Temporal History → Worker 메트릭” 순으로 확인하는 기준을 정리 중이며, Datadog/Slack 알림 임계값도 함께 다듬어가고 있습니다.</p><h4>3. Batch와 Temporal의 공존</h4><p>Batch와 Temporal이 공존하는 현재 상태는 운영 부담이 분명 존재합니다. “이 배치는 Jenkins에서 보고, 저 워크플로우는 Temporal에서 본다”는 식으로 운영하다 보니 온콜 대응 가이드도 두 체계로 작성해야 했습니다.</p><p>하지만 이 공존은 모든 파이프라인을 한 번에 전환하지 않기 위한 의도적인 과도기이기도 합니다. 이 기간 동안 동일 도메인을 두 체계에서 비교해보면서, “장기 실행·재시도·이력 추적이 중요한 작업”은 Temporal에, “단순 반복 처리”는 Batch에 적합하다는 기준을 점점 명확히 하고 있습니다. 이러한 기준이 쌓이면 전환 시점에 대한 판단도 훨씬 명확해질 것으로 기대하고 있습니다.</p><h3>다음 여정: 출고지시 파이프라인 전체를 Temporal로</h3><p>이제 저희는 더 큰 그림을 그리고 있습니다. 출고지시 트리거와 주문수집을 Temporal로 전환하면서, 다음 단계가 분명해졌습니다.</p><p><strong>출고지시 파이프라인 전체를 Workflow로 전환하는 것.</strong></p><p>현재 출고지시는 대용량 처리 시 약 30분이 소요됩니다 (2만 건 기준). 이를 Workflow 기반 병렬 처리 구조로 전환하면 <strong>평균 90% 이상 단축</strong>할 수 있을 것으로 예상하고 있습니다.</p><p>또한 출고 전 구간의 상태, 처리 속도, 실패 지점을 실시간으로 가시화하여 문제의 원인과 영향 범위를 신속하게 파악할 수 있는 Observability 체계를 구축하려 합니다.</p><p>지금은 Child Workflow, Signal 기반 접근 방식 등 다양한 방법을 테스트하고 있습니다. 만만치 않은 도전이겠지만, 트리거와 주문수집을 통해 얻은 경험이 큰 자산이 되고 있습니다.</p><h4>AS-IS</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*UWukKCCNJBhQrh_sCo_aMw.png\" /></figure><h4>TO-BE</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*5BuNX8-EiwvfJ1Pn_BVhsw.png\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*1q4EV4qdgzZjN1HD2ClhOg.png\" /></figure><h3>마치며</h3><p>“스케줄이 또 안 돌았어요”라는 알림에서 시작된 이 여정은, 단순히 기술 스택을 바꾸는 것 이상의 의미를 가졌습니다.</p><p>저희는 <strong>“실패하지 않는 시스템”을 만드는 게 아니라, “실패해도 스스로 복구되는 시스템”</strong>을 만들고 있습니다. Temporal을 도입하면서 가장 크게 느낀 건, 기술 선택이 단순히 “어떤 라이브러리를 쓸 것인가”가 아니라 <strong>“우리가 어떻게 운영할 것인가”</strong>를 결정한다는 점이었습니다.</p><p>물론 아직 갈 길이 멉니다. Workflow 설계 기준도 계속 다듬어야 하고, 모니터링 체계도 개선해야 합니다. 출고 파이프라인 전체를 Workflow로 전환하는 것도 쉽지 않은 도전이 될 것입니다.</p><p>하지만 새벽에 출고지시 알림을 받고 급하게 수동 실행하던 날들이 조금씩 줄어들고 있습니다. 그리고 그 시간에 저희는 더 중요한 문제를 고민할 수 있게 되었습니다.</p><p>긴 글 읽어주셔서 감사합니다. <br>저희의 경험이 비슷한 고민을 하고 계신 분들께 조금이나마 도움이 되었으면 좋겠습니다.</p><h3>Platform Business Operation 조직 및 팀 소개</h3><blockquote>무신사 플랫폼 비즈니스 오퍼레이션 조직은 국내외 물류 서비스, 재고 관리, 스토어 운영을 위한 물류 프로덕트를 구축하고 다양한 오프라인 비즈니스 모델에 맞춘 스토어 관리 시스템을 개발·고도화하고 있습니다.<br>또한, 무배당발 서비스를 포함한 무신사의 차별화된 고객 경험을 브랜딩하고 확장할 수 있는 멤버십 구조를 설계하며, 온·오프라인을 넘나드는 통합 커머스 경험을 기술로 실현하고 있습니다.</blockquote><blockquote>저희 팀은 OMS(주문관리시스템)를 기반으로 온라인 주문부터 재고·출고·배송·정산에 이르는 전 과정을 유기적으로 연결하고, 무신사의 다양한 오프라인 스토어를 효과적으로 운영할 수 있는 관리 시스템을 구축하여 고객이 온라인(무신사 스토어, 29CM 등)과 오프라인(무신사 스탠다드, 편집숍 등)에서 끊김 없는 쇼핑 경험을 누릴 수 있도록 지원합니다.</blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/pbo\">🚀 Platform Business Operation 한걸음 더 알아보기</a></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/home\">🚀 팀 무신사 채용 페이지</a> (무신사/29CM 전체 포지션 확인이 가능해요)</blockquote><blockquote>🚀 <a href=\"https://kr.linkedin.com/company/musinsacom\">팀 무신사 테크 소식을 받아보는 링크드인</a></blockquote><blockquote>🚀 <a href=\"https://newsroom.musinsa.com/\">팀 무신사 뉴스룸</a></blockquote><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=f491e79a0f8f\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://techblog.musinsa.com/%EC%8A%A4%EC%BC%80%EC%A4%84%EC%9D%B4-%EB%98%90-%EC%95%88-%EB%8F%8C%EC%95%98%EC%96%B4%EC%9A%94-%EC%9A%B0%EB%A6%AC%EA%B0%80-temporal%EC%9D%84-%EC%84%A0%ED%83%9D%ED%95%9C-%EC%9D%B4%EC%9C%A0-f491e79a0f8f\">“스케줄이 또 안 돌았어요” — 우리가 Temporal을 선택한 이유</a> was originally published in <a href=\"https://techblog.musinsa.com\">MUSINSA techblog — 무신사 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2026-02-05T02:17:35.000Z",
    "url": "https://techblog.musinsa.com/%EC%8A%A4%EC%BC%80%EC%A4%84%EC%9D%B4-%EB%98%90-%EC%95%88-%EB%8F%8C%EC%95%98%EC%96%B4%EC%9A%94-%EC%9A%B0%EB%A6%AC%EA%B0%80-temporal%EC%9D%84-%EC%84%A0%ED%83%9D%ED%95%9C-%EC%9D%B4%EC%9C%A0-f491e79a0f8f?source=rss----f107b03c406e---4"
  },
  {
    "publisherId": "musinsa",
    "publisherName": "무신사 테크블로그",
    "specTitle": "e커머스 개발",
    "categories": [
      "backend"
    ],
    "specUrl": "https://medium.com/feed/musinsa-tech",
    "title": "“이번 달도 밤샘 정산입니다.” — 더 이상 밤샘하지 않아도 됩니다 (운영편)",
    "partialText": "<h3>“이번 달도 밤샘 정산입니다.” — 더 이상 밤샘하지 않아도 됩니다 (운영편)</h3><p>“이번 달도 밤샘 정산입니다.” 시리즈</p><ol><li><a href=\"https://techblog.musinsa.com/%EC%9D%B4%EB%B2%88-%EB%8B%AC%EB%8F%84-%EB%B0%A4%EC%83%98-%EC%A0%95%EC%82%B0%EC%9E%85%EB%8B%88%EB%8B%A4-%EC%A0%95%EC%82%B0-%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%80-%EC%96%B4%EB%96%BB%EA%B2%8C-%EB%A7%8C%EB%93%A4%EC%97%88%EC%9D%84%EA%B9%8C-%EC%8B%A4%EC%A0%84%ED%8E%B8-74d8a5d22ba1\">정산 시스템은 어떻게 만들었을까 (실전편)</a></li><li><a href=\"https://techblog.musinsa.com/%EC%9D%B4%EB%B2%88-%EB%8B%AC%EB%8F%84-%EB%B0%A4%EC%83%98-%EC%A0%95%EC%82%B0%EC%9E%85%EB%8B%88%EB%8B%A4-%EC%A0%95%EC%82%B0-%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%80-%EC%96%B4%EB%96%BB%EA%B2%8C-%EB%A7%8C%EB%93%A4%EC%97%88%EC%9D%84%EA%B9%8C-%EC%8B%A4%EC%A0%84%ED%8E%B8-74d8a5d22ba1\">정산 시스템은 왜 필요했을까 (설계편)</a></li><li><a href=\"https://techblog.musinsa.com/이번-달도-밤샘-정산입니다-더-이상-밤샘하지-않아도-됩니다-운영편-4f09ae3bdf5d\"><strong>더 이상 밤샘하지 않아도 됩니다 (운영편)</strong></a></li></ol><h3>들어가며</h3><p>앞선 두 편에서는 정산 시스템이 왜 어려운 문제인지, 그리고 그 문제를 어떤 구조와 기술로 풀어냈는지를 다뤘습니다. <br>마지막 글에서는 MASS 정산 시스템을 실제 운영 환경에 단계적으로 오픈하며 어떤 변화와 성과를 만들어냈는지를 정리합니다.</p><h3>단계적 오픈 전략</h3><p>정산 시스템은 한 번에 완성해서 오픈하기에는 리스크가 너무 큰 시스템입니다.<br>그래서 MASS는 기능이 아닌 <strong>데이터를 기준으로 단계적 오픈 전략</strong>을 선택했습니다.</p><ol><li><strong>원천 데이터 적재 모듈 선배포<br></strong>a. 실제 운영 환경에서 발생하는 모든 케이스를 먼저 수집<br>b. 수집 과정에서 드러난 데이터 품질 이슈와 처리 오류를 사전에 식별/수정<br>c. 정산 정책 결정이 필요한 엣지 케이스들을 정리하고 기준을 확정<br>ㅤi. 예외 데이터 처리 기준<br>ㅤii. 경계 조건에서의 금액 산정 방식 등</li><li><strong>실데이터 기반 QA/시뮬레이션<br></strong>a. 실제 데이터를 기준으로 정산 배치를 반복 실행하며 리허설</li><li><strong>검증 완료 후 전체 정산 오픈<br></strong>a. 한 달 단위 정산을 처음부터 끝까지 무결하게 수행</li></ol><p>이 전략 덕분에 시스템 오픈과 동시에 실제 정산을 안정적으로 마칠 수 있었습니다.</p><h4>단계적 오픈 전략 (데이터 적재 → QA/시뮬레이션 → 전체 오픈)</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Pcq6TxN82czZdu5eoZYe-w.png\" /></figure><h4>실데이터 기반 QA / 시뮬레이션</h4><p>정산 시스템은 실제 데이터로 검증하지 않으면, 오픈 이후에 반드시 예상하지 못한 불일치가 발생합니다.<br>그래서 MASS는 <strong>실제 운영 데이터를 기준으로 한 리허설</strong>에 집중했습니다.</p><blockquote>리허설 환경 구성</blockquote><p>QA 및 시뮬레이션은 <strong>운영 환경과 동일한 스키마를 가진 개발 환경</strong>에서 수행되었습니다.<br>운영 DB를 직접 사용하는 방식이 아니라,</p><ul><li>8월부터 10월까지 발생한 <strong>실제 원천 데이터를 개발 환경으로 마이그레이션</strong></li><li>정산 로직, 배치 설정, 기준 데이터는 운영과 동일하게 유지</li><li>운영과 분리된 환경에서 반복 실행이 가능하도록 구성</li></ul><p>이를 통해 운영 데이터의 현실적인 복잡성을 그대로 가져오면서도, 정산 배치를 <strong>수차례 재실행할 수 있는 안전한 실험 환경</strong>을 확보했습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*X28LQEXpzlOIiBpF0JzJhA.png\" /></figure><blockquote>검증 방식: 수기 정산 결과와의 비교</blockquote><p>정산 결과 검증은 <strong>수기 정산 결과와의 직접 비교</strong>를 기준으로 진행했습니다.</p><ul><li>기존 수기 정산으로 확정된 결과를 기준 데이터로 사용</li><li>동일 기간, 동일 조건으로 MASS 정산 배치를 반복 실행</li><li>업체별·항목별 금액을 단위까지 대조하며 결과 비교</li></ul><p>초기 단계에서는 일부 수동 대조가 필요했지만, 반복되는 검증 구간에 대해서는 <strong>리포트 형태로 검증을 자동화</strong>해 불일치 여부를 빠르게 식별할 수 있도록 했습니다.</p><blockquote>리허설 범위와 데이터 규모</blockquote><p>리허설은 <strong>단일 케이스가 아닌, 수개월치 실데이터</strong>를 대상으로 수행되었습니다.</p><ul><li><strong>8월 ~ 10월, 총 3개월치 실제 원천 데이터</strong></li><li>일 정산, 월 정산 시나리오 모두 반복 실행</li><li>프로모션 적용, 예외 케이스, 경계 조건 포함</li></ul><p>이를 통해 “정상 케이스”뿐 아니라, 실제 운영에서 발생하는 <strong>복합적인 케이스들까지 충분히 검증</strong>할 수 있었습니다.</p><blockquote>불일치 발생 시 원인 추적 프로세스</blockquote><p>정산 결과와 수기 결과 간 불일치가 발견되면, 단순히 결과를 맞추는 것이 아니라 <strong>원인을 끝까지 추적하는 방식</strong>으로 접근했습니다.</p><p>불일치 발생 시 다음 순서로 원인을 분석했습니다.</p><ol><li>원천 데이터 자체의 차이 여부 확인</li><li>단가/프로모션 기준 적용 여부 점검</li><li>정책적으로 정의되지 않았던 엣지 케이스 식별</li></ol><p>기술적인 오류인 경우 로직을 수정했고, 정책적으로 판단이 필요한 경우에는 <strong>정산 기준을 명시적으로 정리한 뒤 시스템에 반영</strong>했습니다.</p><p>이 과정을 반복하면서 정산 로직의 안정성뿐 아니라, <strong>정산 기준 자체의 모호함도 함께 해소</strong>할 수 있었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*jvK_Iqus0EJPHI6PIlKu1w.png\" /></figure><blockquote>이 단계의 의미</blockquote><p>이 실데이터 기반 리허설 단계는 단순한 QA가 아니라,</p><ul><li>정산 로직의 정확성을 검증하고</li><li>기준을 명확히 정의하며</li><li>오픈 이후 재처리 가능성까지 점검하는</li></ul><p><strong>정산 시스템의 ‘예행 연습’에 해당하는 단계</strong>였습니다.</p><p>이 과정을 충분히 거쳤기 때문에, MASS는 시스템 오픈과 동시에 <strong>실제 정산을 안정적으로 마칠 수 있었습니다.</strong></p><h3>오픈 이후 시스템 지표와 운영 결과</h3><p>MASS 구축 시점에 팀이 설정한 목표는 명확했습니다.</p><ul><li><strong>정산은 반드시 회계 마감 기한 내에 끝나야 한다</strong></li><li><strong>재처리·재실행 상황에서도 정산 결과는 흔들리지 않아야 한다</strong></li><li><strong>정산 규모가 증가해도 운영 방식이 복잡해지지 않아야 한다</strong></li><li><strong>수기 보정 없이 시스템 결과만으로 정산을 마칠 수 있어야 한다</strong></li><li><strong>일 정산은 운영 관점에서 부담 없이 반복 실행할 수 있도록, 평균 처리 시간을 10분 이내로 유지해야 한다</strong></li></ul><p>이러한 목표를 기준으로 시스템을 설계했고, 시스템 오픈 이후 현재까지 수행된 정산은 다음과 같은 결과를 보였습니다.</p><h4>정산 처리 성공률과 결과 확정 안정성</h4><p>MASS에서 말하는 “정산 성공”은 단순히 배치가 오류 없이 종료되었다는 의미가 아닙니다.</p><p>본 문서에서의 정산 성공은 다음 조건을 모두 만족하는 경우를 의미합니다.</p><ul><li>정산 배치가 <strong>중단 없이 완료</strong></li><li>모든 정산 대상 데이터가 <strong>정합성 검증을 통과</strong></li><li>수기 보정 없이 <strong>시스템 계산 결과만으로 정산 결과 확정</strong></li><li>회계 마감 기한 내 모든 <strong>정산 상태가 COMPLETED로 전이</strong></li></ul><p>이 기준으로 시스템 오픈 이후 수행된 정산 결과는 다음과 같습니다.</p><ul><li><strong>일 정산 성공률: 100%</strong></li><li><strong>월 정산 성공률: 100%</strong></li><li><strong>월 정산 마감 확정 성공률: 100%</strong></li></ul><p>모든 정산은 마감 기한 내 정상적으로 완료되었으며, 정산 결과 확정 과정에서도 <strong>정합성 이슈나 수기 개입 없이 </strong>시스템 결과만으로 정산을 마무리할 수 있었습니다.</p><h4>정산 처리 시간</h4><ul><li><strong>일 정산 평균 소요 시간:</strong> 약 <strong>8분 26초</strong></li><li><strong>월 정산 평균 소요 시간:</strong> 약 <strong>2분 27초</strong></li></ul><p>일 정산의 경우, 초기 목표로 설정했던 <strong>‘10분 이내 처리’ 기준을 안정적으로 만족</strong>하고 있으며, 정산 대상 규모와 관계없이 일정한 처리 시간을 유지하고 있습니다.</p><p>이는 정산 배치가</p><ul><li>데이터 규모 증가</li><li>재실행</li><li>반복 실행</li></ul><p>과 같은 운영 시나리오에서도 부담 없이 실행될 수 있도록 설계되었음을 의미합니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/548/1*iSeBKNxGUiSUG_hswfYe3A.png\" /></figure><h4>재처리 상황에서도 유지되는 정합성</h4><p>12월 3일, upstream 시스템의 재고 스냅샷 이슈로 인해 해당 일자의 정산 데이터를 다시 계산해야 하는 상황이 발생했습니다.</p><p>정산 도메인에서 이와 같은 상황은 단순한 기술적 오류를 넘어, <strong>중복 청구, 과소·과대 정산, 파트너 업체 신뢰 훼손</strong>으로 직결될 수 있는 명확한 비즈니스 리스크를 동반합니다.<br>특히 월 마감 직전이었다면, 회계 마감 지연이나 수기 보정으로 이어질 가능성도 있었습니다.</p><p>이 상황에서 MASS는 기존 정산 결과를 임의로 수정하거나 덮어쓰는 대신,</p><ul><li>해당 일자의 정산 대상 원천 데이터만을 기준으로 재처리를 수행했고</li><li>멱등성 기반 처리로 <strong>중복 정산 없이 안전하게 재계산</strong>했으며</li><li>재처리 이후에도 <strong>정산 결과는 기존 기준과 동일하게 유지</strong>되었습니다.</li></ul><p>그 결과, 최초 정산 시점과 재처리 이후의 금액 차이에 대해서는 파트너 업체에 <strong>변경 사유와 함께 정산 결과를 다시 공유</strong>해야 했지만,</p><ul><li>변경된 금액이 어떤 기준에서 발생했는지 명확하게 설명할 수 있었고</li><li>수기 계산이나 임시 보정 없이 <strong>시스템 결과만으로 정산을 확정</strong>할 수 있었으며</li><li>회계 마감 일정 역시 영향을 받지 않았습니다.</li></ul><p>이 사례는 재처리와 복구를 전제로 한 설계가 단순히 “다시 계산할 수 있다”는 수준을 넘어, <strong>장애 상황에서도 정산 변경을 통제 가능한 방식으로 관리하며 비즈니스 리스크를 최소화했음을 보여주는 사례</strong>였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*MrJnJCWQWmq5WrvdMVZBaw.png\" /></figure><h4>수기 정산 프로세스 변화</h4><p>시스템 도입 전후의 정산 프로세스는 다음과 같이 변화했습니다.</p><p><strong>As-Is (수기 정산 — 6단계)</strong></p><ul><li>물류 데이터 추출</li><li>금액 산정(정산)</li><li>정산서 작성</li><li>품의 상신</li><li>품의 승인</li><li>세금계산서 반영</li></ul><p><strong>To-Be (시스템 정산 — 2단계)</strong></p><ul><li>정산 금액 확인</li><li>세금계산서 반영</li></ul><p>기존 <strong>6단계에 달하던 수기 정산 프로세스는 </strong>단 <strong>2단계의 확인 중심 프로세스로 축소</strong>되었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*PStZqs6VZ_2Jj1OQwB6Mzg.png\" /></figure><h4>정산 마감 소요 시간 변화</h4><p>정산 대상 업체 수가 증가함에 따라, 기존 수기 정산 방식은 <strong>업체 수에 정비례하여 작업 시간이 증가하는 구조</strong>였습니다.</p><ul><li><strong>정산 대상 40개 업체 기준</strong></li><li>수기 정산 마감 소요 시간: 약 <strong>23시간</strong></li><li><strong>정산 대상 100개 업체 기준</strong></li><li>수기 정산 마감 소요 시간: 약 <strong>30시간 이상</strong></li></ul><p>정산 마감은 영업일 기준 <strong>D+2(총 16 근무시간)</strong> 내 완료가 필요했기 때문에, 담당자 1명 기준으로는 <strong>40개 업체가 사실상 처리 가능한 한계</strong>였습니다.</p><p>반면, MASS 도입 이후에는 정산 방식이 근본적으로 달라졌습니다.</p><ul><li>정산 대상 업체 수와 무관하게</li><li><strong>월 정산 마감 확정까지 약 1시간 내 완료</strong></li></ul><p>즉,</p><ul><li>40개 업체 기준: <strong>23시간 → 1시간</strong></li><li>100개 업체 기준: <strong>30시간 → 1시간</strong></li></ul><p>정산 시스템 도입을 통해 <strong>정산 규모가 증가해도 마감 기한을 안정적으로 지킬 수 있는 구조</strong>를 확보했습니다.</p><blockquote>정산 방식에 따른 마감 소요 시간 비교</blockquote><p>아래 그래프는 정산 대상 업체 수 증가에 따른 <strong>수기 정산 방식과 시스템 정산 방식의 차이</strong>를 직관적으로 보여줍니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*YoHHgxcg181mGeTNOLjI1A.png\" /><figcaption>(베이지: 수기 / 주황: MASS)</figcaption></figure><p>이 그래프가 보여주듯,</p><ul><li>수기 정산은 <strong>업체 수 증가 = 마감 리스크 증가</strong></li><li>MASS 정산은 <strong>업체 수 증가와 무관한 일정한 처리 시간</strong></li></ul><p>이라는 차이를 가집니다.</p><p>이는 단순한 자동화 효과가 아니라, 정산 업무를 <strong>사람의 처리 한계에서 시스템 처리 한계로 전환</strong>한 결과였습니다.</p><h4>정산 데이터 제공 주기 변화</h4><p>정산 결과의 가시성 역시 크게 개선되었습니다.</p><ul><li><strong>정산 데이터 제공 주기:</strong> 월 1회 → <strong>매일</strong></li><li><strong>파트너 업체 조회 가능 시점:</strong> 매일 <strong>오전 11시</strong></li></ul><p>이를 통해 파트너 업체는 월 마감 이후가 아니라, 운영 중에도 매일 비용을 확인하고 관리할 수 있게 되었습니다.</p><h3>마치며</h3><p>정산 자동화의 진짜 가치는 단순한 시간 단축에 있지 않습니다. MASS는 정산을 사람의 경험과 기억이 아닌, 시스템의 책임으로 옮겼습니다.</p><p>이번 시리즈를 통해 정산이라는 어려운 도메인을 어떻게 설계하고, 구현하고, 운영으로 안착시켰는지를 공유했습니다. <br>MASS의 정산 자동화는 시작에 불과하며, 앞으로도 다양한 정산 도메인으로 확장해 나갈 예정입니다.</p><h3>Platform Business Operation 조직 및 팀 소개</h3><blockquote><em>무신사 플랫폼 비즈니스 오퍼레이션 조직은 국내외 물류 서비스, 재고 관리, 스토어 운영을 위한 물류 프로덕트를 구축하고 다양한 오프라인 비즈니스 모델에 맞춘 스토어 관리 시스템을 개발·고도화하고 있습니다.<br>또한, 무배당발 서비스를 포함한 무신사의 차별화된 고객 경험을 브랜딩하고 확장할 수 있는 멤버십 구조를 설계하며, 온·오프라인을 넘나드는 통합 커머스 경험을 기술로 실현하고 있습니다.</em></blockquote><blockquote><em>저희 팀은 OMS(주문관리시스템)를 기반으로 온라인 주문부터 재고·출고·배송·정산에 이르는 전 과정을 유기적으로 연결하고, 무신사의 다양한 오프라인 스토어를 효과적으로 운영할 수 있는 관리 시스템을 구축하여 고객이 온라인(무신사 스토어, 29CM 등)과 오프라인(무신사 스탠다드, 편집숍 등)에서 끊김 없는 쇼핑 경험을 누릴 수 있도록 지원합니다.</em></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/pbo\"><em>🚀 Platform Business Operation 한걸음 더 알아보기</em></a></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/home\"><em>🚀 팀 무신사 채용 페이지</em></a><em> (무신사/29CM 전체 포지션 확인이 가능해요)</em></blockquote><blockquote><em>🚀 </em><a href=\"https://kr.linkedin.com/company/musinsacom\"><em>팀 무신사 테크 소식을 받아보는 링크드인</em></a></blockquote><blockquote><em>🚀 </em><a href=\"https://newsroom.musinsa.com/\"><em>팀 무신사 뉴스룸</em></a></blockquote><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=4f09ae3bdf5d\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://techblog.musinsa.com/%EC%9D%B4%EB%B2%88-%EB%8B%AC%EB%8F%84-%EB%B0%A4%EC%83%98-%EC%A0%95%EC%82%B0%EC%9E%85%EB%8B%88%EB%8B%A4-%EB%8D%94-%EC%9D%B4%EC%83%81-%EB%B0%A4%EC%83%98%ED%95%98%EC%A7%80-%EC%95%8A%EC%95%84%EB%8F%84-%EB%90%A9%EB%8B%88%EB%8B%A4-%EC%9A%B4%EC%98%81%ED%8E%B8-4f09ae3bdf5d\">“이번 달도 밤샘 정산입니다.” — 더 이상 밤샘하지 않아도 됩니다 (운영편)</a> was originally published in <a href=\"https://techblog.musinsa.com\">MUSINSA techblog — 무신사 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2026-02-02T09:01:05.000Z",
    "url": "https://techblog.musinsa.com/%EC%9D%B4%EB%B2%88-%EB%8B%AC%EB%8F%84-%EB%B0%A4%EC%83%98-%EC%A0%95%EC%82%B0%EC%9E%85%EB%8B%88%EB%8B%A4-%EB%8D%94-%EC%9D%B4%EC%83%81-%EB%B0%A4%EC%83%98%ED%95%98%EC%A7%80-%EC%95%8A%EC%95%84%EB%8F%84-%EB%90%A9%EB%8B%88%EB%8B%A4-%EC%9A%B4%EC%98%81%ED%8E%B8-4f09ae3bdf5d?source=rss----f107b03c406e---4"
  },
  {
    "publisherId": "musinsa",
    "publisherName": "무신사 테크블로그",
    "specTitle": "e커머스 개발",
    "categories": [
      "backend"
    ],
    "specUrl": "https://medium.com/feed/musinsa-tech",
    "title": "“이번 달도 밤샘 정산입니다.” — 정산 시스템은 어떻게 만들었을까 (실전편)",
    "partialText": "<h3>“이번 달도 밤샘 정산입니다.” — 정산 시스템은 어떻게 만들었을까 (실전편)</h3><p>“이번 달도 밤샘 정산입니다.” 테크 블로그 시리즈</p><ol><li><a href=\"https://techblog.musinsa.com/%EC%9D%B4%EB%B2%88-%EB%8B%AC%EB%8F%84-%EB%B0%A4%EC%83%98-%EC%A0%95%EC%82%B0%EC%9E%85%EB%8B%88%EB%8B%A4-%EC%A0%95%EC%82%B0-%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%80-%EC%96%B4%EB%96%BB%EA%B2%8C-%EB%A7%8C%EB%93%A4%EC%97%88%EC%9D%84%EA%B9%8C-%EC%8B%A4%EC%A0%84%ED%8E%B8-74d8a5d22ba1\"><strong>정산 시스템은 어떻게 만들었을까 (실전편)</strong></a></li><li><a href=\"https://techblog.musinsa.com/22732a4a607f\">정산 시스템은 왜 필요했을까 (설계편)</a></li><li><a href=\"https://techblog.musinsa.com/이번-달도-밤샘-정산입니다-더-이상-밤샘하지-않아도-됩니다-운영편-4f09ae3bdf5d\">더 이상 밤샘하지 않아도 됩니다 (운영편)</a></li></ol><h3>들어가며</h3><p>앞선 글에서는 정산 시스템이 왜 본질적으로 어려운 문제인지, 그리고 MASS가 멱등성과 결정적 계산이라는 설계 원칙을 선택한 이유를 살펴보았습니다. <br>이번 글에서는 그 설계가 실제로 어떤 기술 선택과 구조를 통해 구현되었는지, MASS 정산 시스템의 실전 구축 과정을 이야기합니다.</p><h3>멱등성을 전제로 한 이벤트 처리</h3><p>정산에 사용되는 원천 데이터는 이벤트 형태로 유입됩니다.<br>이벤트 기반 시스템에서 중복 수신이나 재처리는 피할 수 없는 상황이기 때문에, MASS에서는 이를 <strong>전제 조건</strong>으로 두었습니다.</p><ul><li>이벤트 재시도(Retry)와 격리(DLT)를 분리해 처리</li><li>트랜잭션 식별자를 기준으로 서비스 레벨에서 멱등 갱신</li><li>동일 이벤트가 여러 번 처리되어도 결과는 항상 동일</li></ul><p>이를 통해 장애 상황에서도 안전하게 재처리할 수 있는 기반을 마련했습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*WVBTqEPRTnxzFRF5ux3o_Q.png\" /></figure><p>(⬆️ 1편 내용)</p><h4>DLT 메시지 모니터링과 처리 방식</h4><p>DLT로 전달된 이벤트는 <strong>정산 흐름에서 즉시 제외</strong>되며, 별도의 모니터링과 운영 프로세스를 통해 관리됩니다.</p><ul><li>DLT 발생 시 즉시 알림을 통해 운영자가 인지할 수 있도록 구성</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*jeNo9FnMmvUBNGb-NoSXtw.png\" /></figure><ul><li>DLT 메시지는 원본 이벤트와 동일한 컨텍스트를 유지한 채 저장</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*EMx-OyThRv5VNbvZEdccLQ.png\" /></figure><ul><li>이벤트 페이로드, 트랜잭션 식별자, 실패 사유를 기준으로 원인 분석 가능</li><li>정책 오류, 데이터 품질 문제 등 원인이 명확한 경우 기준 정리 후 재처리 수행</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/818/1*2u_Johv6F-ibbNFJZYBGDg.png\" /></figure><p>이를 통해 <strong>문제 있는 이벤트가 전체 정산 흐름을 멈추는 상황을 방지</strong>하면서도, 사후 분석과 재처리를 위한 정보는 모두 보존합니다.</p><h4>실제 운영 중 DLT 발생 현황</h4><p>시스템 오픈 이후 실제 운영 환경에서 발생한 DLT 이벤트는 전체 이벤트 대비 <strong>극히 낮은 비율</strong>로 유지되고 있습니다.</p><ul><li>DLT 발생 비율: <strong>전체 이벤트 중 0.001% 미만</strong></li><li>DLT로 격리된 이벤트 역시 정산 결과에는 영향을 주지 않음</li></ul><p>정산과 같이 결과의 정합성이 중요한 도메인에서 “실패를 격리하되, 전체 흐름은 멈추지 않는다”는 설계 의도가 운영 단계에서도 그대로 유지되고 있습니다.</p><h3>MASS의 모듈 구성</h3><p>MASS는 크게 세 개의 독립적인 애플리케이션 모듈로 나뉩니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*CiuUuW5tzyBNchxaGptz4A.png\" /></figure><h4>mass-consumer</h4><ul><li>물류 서비스 유형별 원천 데이터를 메시지로 수신하는 애플리케이션</li><li>Kafka를 통해 이벤트를 소비</li><li>멱등 처리 후 정산 원천 데이터로 저장</li><li>이벤트 기반 처리 영역의 진입점 역할</li></ul><h4>mass-batch</h4><ul><li>일/월 정산을 수행하는 배치 애플리케이션</li><li>정산 집계, 마감, 리포트 생성</li><li>Kafka 복구 잡 등 운영 유틸리티 배치 포함</li><li>재처리와 복구를 전제로 한 실행 구조</li></ul><h4>mass-api</h4><ul><li>내부 운영자와 파트너 업체를 위한 REST API 제공</li><li>정산, 프로모션 등의 데이터 조회 및 관리 기능</li><li>정산 결과를 외부에 안전하게 노출하는 인터페이스</li></ul><h4>재처리와 복구를 전제로 한 실행 구조</h4><p>정산 배치는 실패 가능성을 전제로 설계되었습니다.<br>중요한 것은 배치가 실패했을 때 <strong>어디서부터 다시 실행할 수 있는가</strong>가 아니라, <strong>어떤 상태를 기준으로 정산을 다시 정의할 수 있는가</strong>였습니다.</p><p>MASS에서는 이를 위해 정산 대상 원천 데이터에 명시적인 <strong>정산 상태 컬럼</strong>을 두고 배치 실행 흐름을 관리합니다.</p><p>정산 상태는 다음과 같이 관리됩니다.</p><ul><li><strong>PENDING</strong>: 정산 대상 후보 상태</li><li><strong>PROCESSING</strong>: 현재 정산 배치에서 처리 중인 상태</li><li><strong>COMPLETED</strong>: 정산이 정상 완료된 상태</li></ul><blockquote><strong>배치 실행 흐름과 상태 전이</strong></blockquote><p>정산 배치는 다음 순서로 수행됩니다.</p><ol><li>배치 시작 시점에 해당 실행의 정산 대상 원천 데이터만 <strong>PENDING → PROCESSING</strong> 상태로 마킹</li><li>마킹된 데이터만을 기준으로 step 별 <strong>chunk 단위 처리</strong> 수행</li><li>모든 step이 정상 완료되면 처리된 데이터의 상태를 <strong>COMPLETED</strong>로 전이</li><li>배치가 중간에 실패할 경우 해당 실행에서 <strong>PROCESSING 상태로 마킹되었던 데이터들을 다시 PENDING으로 롤백</strong></li></ol><p>이 구조를 통해 배치는 chunk 단위로 실행되지만, <strong>복구와 재처리의 기준은 항상 “정산 대상 전체”로 유지</strong>됩니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*v7YCvHYRi9pg9BFpq3F6Vw.png\" /></figure><blockquote><strong>재시도 시 처리 방식</strong></blockquote><p>배치 재시도 시에는 이전 실행 결과를 이어서 처리하지 않습니다.</p><ul><li>이전 실행에서 PROCESSING 상태였던 데이터는 모두 롤백</li><li>재시도 시점에 다시 정산 대상 데이터를 선정해 <strong>PROCESSING으로 재마킹</strong></li><li>이후 멱등성을 전제로 한 <strong>upsert 방식</strong>으로 정산 재수행</li></ul><p>이를 통해 재실행 시에도</p><ul><li>중복 정산 없이</li><li>동일한 기준으로</li><li>항상 동일한 결과를 얻을 수 있습니다.</li></ul><blockquote><strong>실제 재처리 사례: 12월 3일 재고 스냅샷 이슈</strong></blockquote><p>12월 3일, upstream 시스템의 재고 스냅샷 이슈로 인해 해당 일자의 정산 데이터에 대해 재처리가 필요했습니다.</p><p>이 경우 MASS에서는</p><ul><li>12월 3일 정산 대상 원천 데이터만 <strong>PENDING 상태로 롤백</strong></li><li>이슈 해결 후 동일 날짜의 정산 재실행</li></ul><p>재처리는 chunk 단위로 수행되었지만, 정산 대상 상태를 기준으로 재정의했기 때문에 중복 반영이나 부분 정산 없이 <strong>정산 결과를 처음부터 다시 계산</strong>할 수 있었습니다.</p><p>그 결과,</p><ul><li>다른 날짜의 정산 결과에는 영향을 주지 않았고</li><li>재처리 이후에도 <strong>정산 금액은 기존 기준과 동일하게 유지</strong>되었습니다.</li></ul><h3>이벤트 + 배치 하이브리드 구조</h3><p>MASS는 정산 도메인의 특성에 맞게, <strong>이벤트 기반 처리와 배치 기반 처리를 목적에 따라 분리한 하이브리드 구조</strong>로 설계되어 있습니다.</p><p>실시간에 가까운 데이터 반영이 필요한 영역과, 회계 마감처럼 안정성과 재현성이 중요한 영역의 요구사항이 다르기 때문입니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*cGARaSH-ca10vR3LYjUU1g.png\" /></figure><h4>이벤트 기반 처리 영역</h4><p>이벤트 기반 영역은 <strong>정산의 ‘원천 데이터’를 책임지는 영역</strong>입니다.</p><ul><li>물류 서비스 유형별로 발생하는 원천 이벤트를 수신</li><li>이벤트 중복이나 재처리를 고려한 멱등 저장</li></ul><p>이 영역은 <em>데이터를 빠르게 수집</em>하는 데 초점을 둡니다.</p><h4>배치 기반 처리 영역</h4><p>배치 기반 영역은 <strong>정산의 ‘확정’과 ‘마감’을 책임지는 영역</strong>입니다.</p><ul><li>일/월 단위 정산 대상 집계</li><li>정산 마감 처리</li><li>정산 리포트 생성</li><li>실패 시 재처리를 고려한 복구용 배치 운영</li></ul><p>이 영역은 속도보다는 <strong>안정성과 재현성</strong>을 우선하며, 동일 조건에서 언제 실행해도 같은 결과를 내는 것을 목표로 합니다.</p><h3>왜 이런 구조를 선택했는가</h3><p>이 구조를 통해 MASS는 다음 두 가지를 동시에 만족시킬 수 있었습니다.</p><ul><li>이벤트 기반 구조로 <strong>실시간에 가까운 데이터 가시성 확보</strong></li><li>배치 기반 구조로 <strong>회계 마감의 안정성과 재현성 보장</strong></li></ul><p>결과적으로 MASS는 <strong>“빠르게 변하는 데이터”와 “확정되어야 하는 숫자”를 하나의 시스템 안에서 충돌 없이 다룰 수 있는 구조</strong>를 갖추게 되었습니다.</p><h3>기술 선택과 그 배경</h3><p>앞선 섹션에서 MASS가 이벤트 기반과 배치 기반을 혼합한 구조를 선택한 이유를 설명했습니다.<br>이 섹션에서는 그 구조를 실제로 구현하기 위해 <strong>어떤 기술 스택을 선택했고, 그 선택이 정산 도메인에 왜 적합했는지</strong>를 정리합니다.</p><p>MASS에서의 기술 선택은 “어떤 기술이 더 최신인가”가 아니라 <strong>정산이라는 도메인의 핵심 요구사항인 ‘정합성, 재처리 가능성, 운영 안정성’을 얼마나 잘 만족시키는가</strong>를 기준으로 이루어졌습니다.</p><h4>전체 기술 스택 요약</h4><p>MASS는 JVM 기반의 안정적인 기술 스택 위에서 다음과 같이 구성되어 있습니다.</p><p><strong>언어 / 런타임</strong></p><ul><li>JVM 기반 (Kotlin)</li></ul><p><strong>애플리케이션 프레임워크</strong></p><ul><li>Spring Boot</li><li>Spring Batch (정산 배치 및 마감 처리)</li></ul><p><strong>메시징</strong></p><ul><li>Kafka (원천 데이터 이벤트 수신)</li></ul><p><strong>데이터베이스</strong></p><ul><li>MySQL (정산 결과의 Source of Truth)</li></ul><p><strong>운영 / 모니터링</strong></p><ul><li>배치 실행 상태 및 실패 로그 기반 모니터링</li><li>DLT 이벤트 및 배치 실패 시 알림 연계</li><li>에러, Latency, 인프라 모니터링</li></ul><p>이 스택은 고성능보다는 <strong>예측 가능성, 재현성, 장애 대응 용이성</strong>을 우선한 선택입니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*VN591bZIeeRGbdtCTpbxaw.png\" /></figure><h4>Kafka를 통한 원천 데이터 수신</h4><p>정산에 사용되는 원천 데이터는 다음과 같은 특성을 가집니다.</p><ul><li>입·출고, 재고 스냅샷 등 <strong>트래픽이 특정 시점에 집중</strong></li><li>동일 이벤트의 <strong>중복 수신, 재전송, 재처리 가능성</strong></li><li>일시적인 장애가 있더라도 <strong>데이터 유실은 절대 허용 불가</strong></li></ul><p>이러한 특성 때문에, 원천 데이터를 API 호출 방식으로 동기 수신하는 구조는 적합하지 않다고 판단했습니다.</p><p>Kafka 기반 이벤트 수신 방식은</p><ul><li>원천 데이터를 <strong>비동기로 안정적으로 적재</strong>할 수 있고</li><li>소비자 장애와 무관하게 이벤트를 보존할 수 있으며</li><li>동일 이벤트를 다시 소비하는 방식으로 <strong>재처리를 자연스럽게 지원</strong>합니다</li></ul><p>정산 데이터는 “빨리 처리되는 데이터”보다 <strong>“언제든 다시 처리할 수 있어야 하는 데이터”</strong>였기 때문에, MASS는 Kafka를 원천 데이터 수신 방식으로 선택했습니다.</p><h4>Spring Batch 기반의 정산 처리</h4><p>정산 처리에서 가장 중요한 요구사항은 실시간성이 아니라 다음과 같았습니다.</p><ul><li>회계 마감 기준에 맞는 <strong>명확한 실행 시점</strong></li><li>실패를 전제로 한 <strong>재처리·복구 구조</strong></li><li>실행 이력과 결과를 추적할 수 있는 <strong>감사 가능성</strong></li></ul><p>이를 위해 정산 집계와 마감 처리는 Spring Batch 기반으로 설계했습니다.</p><blockquote><strong>배치 실행 환경과 제어 방식</strong></blockquote><p>MASS는 Kubernetes 기반의 <strong>EKS 환경</strong>에서 운영되고 있으며, 정산 배치 역시 이 환경에 맞는 실행 구조를 갖도록 설계했습니다.</p><p>정산 배치는 애플리케이션 내부 스케줄러에 의해 자동 실행되는 방식이 아니라,</p><ul><li><strong>Spring Batch 기반의 batch 애플리케이션</strong>을 컨테이너로 구성하고</li><li>배치 실행 시점과 흐름은 <strong>Argo Workflow</strong>를 통해 외부에서 제어하는 방식으로 운영됩니다</li></ul><p>즉, Spring Batch는 <em>정산 로직과 실행 상태 관리</em>를 담당하고, 배치의 실행 시점과 재실행 제어는 <strong>Argo Workflow가 책임지는 구조</strong>입니다.</p><p>이를 통해 정산 배치는 “코드 안에 숨어 있는 백그라운드 작업”이 아니라, <strong>EKS 환경에서 명시적으로 관리되는 워크플로우 단계</strong>가 되었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/496/1*LAdmMX51xIOBKN3RHUGWRg.png\" /></figure><blockquote><strong>Job Parameter 기반 실행</strong></blockquote><p>Argo Workflow는 정산 배치를 실행할 때,</p><ul><li>정산 기준 날짜</li><li>정산 기준 타입</li></ul><p>등을 <strong>Job Parameter로 전달</strong>합니다.</p><p>이를 통해 MASS의 정산 배치는</p><ul><li>동일한 코드로</li><li>서로 다른 기간과 기준을</li><li>실행 이력으로 명확히 구분된 형태로 수행할 수 있습니다</li></ul><p>“어떤 기준으로, 언제 실행된 정산인지”가 로그가 아니라 <strong>Batch Execution 이력 자체로 추적 가능</strong>해졌습니다.</p><blockquote><strong>Spring Batch 선택 이유와 실행 모델</strong></blockquote><p>Spring Batch는</p><ul><li>Job / Step / Execution 단위로 <strong>실행 상태와 이력 관리</strong></li><li>대용량 데이터를 <strong>chunk 단위로 안정적으로 처리</strong></li><li>실패 시 <strong>재실행 시점 제어</strong></li></ul><p>를 기본적으로 제공합니다.</p><p>이 특성은 정산 배치를 “한 번 실행하고 끝나는 작업”이 아니라, <strong>실패와 재실행을 전제로 운영되는 작업</strong>으로 만드는 데 적합했습니다.</p><blockquote><strong>정산 대상 마킹 기반 실행 흐름</strong></blockquote><p>MASS에서는 배치 실행 시 다음과 같은 흐름을 따릅니다.</p><ol><li>배치 시작 시 해당 실행의 <strong>정산 대상 원천 데이터만 선별</strong></li><li>선별된 데이터의 정산 상태를 PENDING → PROCESSING으로 일괄 마킹</li><li>마킹된 데이터만을 기준으로 Step 별 <strong>chunk 단위 처리 수행</strong></li><li>모든 Step이 정상 완료되면 정산 상태를 COMPLETED로 전이</li><li>중간 실패 시 PROCESSING 상태 데이터를 다시 PENDING으로 롤백</li></ol><p>이 구조를 통해 배치는 chunk 단위로 실행되지만, <strong>재처리의 기준은 항상 ‘정산 대상 전체’로 유지</strong>됩니다.</p><p>즉, 배치가 어느 지점에서 실패하더라도 이전 실행 결과에 의존하지 않고 정산 대상 단위로 <strong>처음부터 다시 실행할 수 있는 구조</strong>를 만들었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*85NH0_qvf4s9kq_9hal8KQ.png\" /></figure><blockquote><strong>운영 관점에서의 의미</strong></blockquote><p>Spring Batch와 Argo Workflow를 결합한 이 실행 환경을 통해, 정산 배치는</p><ul><li>EKS 환경에서 <strong>운영자가 명시적으로 제어 가능한 작업</strong>이 되었고</li><li>실행 실패 역시 <strong>운영 이벤트로 인지하고 대응할 수 있는 대상</strong>이 되었으며</li><li>재실행이 두려운 배치가 아니라 <strong>언제든 다시 돌릴 수 있는 배치</strong>가 되었습니다</li></ul><p>그 결과 MASS의 정산 배치는 회계 마감이라는 높은 안정성이 요구되는 영역에서도 안전하게 운영될 수 있는 기반을 갖추게 되었습니다.</p><h4>데이터베이스 선택과 정합성 보장</h4><p>정산 결과는 반드시 <strong>하나의 기준(Source of Truth)</strong>으로 관리되어야 했기 때문에, MASS는 트랜잭션 처리가 명확한 <strong>RDB(MySQL)</strong>를 정산 결과 저장소로 선택했습니다.</p><p>RDB를 선택함으로써 다음을 명확히 할 수 있었습니다.</p><ul><li>정산 결과의 <strong>정합성 보장</strong></li><li>트랜잭션 단위의 상태 전이 관리</li><li>트랜잭션 식별자를 기준으로 한 <strong>멱등성 갱신(upsert)</strong></li></ul><p>이는 이벤트 중복, 재처리, 장애 복구 상황에서도 정산 결과가 흔들리지 않도록 하는 핵심 기반이 되었습니다.</p><h4>운영 / 모니터링 체계</h4><p>정산 시스템에서 운영과 모니터링은 “장애를 없애는 것”보다 <strong>장애를 빠르게 인지하고, 영향 범위를 통제하는 것</strong>이 더 중요했습니다.</p><p>MASS에서는 이를 위해 실시간 모니터링과 함께 <strong>주기적인 점검을 결합한 운영 체계</strong>를 구성했습니다.</p><p><strong>배치 실행 상태 및 실패 로그 기반 모니터링</strong></p><ul><li>일/월 정산 배치의 실행 성공 여부</li><li>Step 단위 실패 지점 및 재시도 여부</li><li>마감 미완료 상태에 대한 조기 감지</li></ul><p><strong>DLT 이벤트 및 배치 실패 시 알림 연계</strong></p><ul><li>재시도 한계를 초과한 이벤트는 DLT로 격리</li><li>DLT 발생 및 배치 실패 시 즉시 알림을 통해 인지</li><li>장애 상황에서도 원천 데이터 유실 없이 후속 조치 가능</li></ul><p><strong>에러, Latency, 인프라 지표 모니터링</strong></p><ul><li>이벤트 소비 지연(Lag) 및 처리 Latency 관측</li><li>애플리케이션 에러율과 비정상 트래픽 감지</li><li>인프라 리소스(CPU, Memory) 사용량을 통한 병목 사전 인지</li></ul><p><strong>주 단위 시스템 상태 점검</strong></p><ul><li>주 단위로 트래픽, 에러, Latency, 인프라 지표 추이 점검</li><li>잠재적인 성능 저하나 이상 징후를 사전에 식별하고 개선</li></ul><p>이러한 운영 체계를 통해 MASS는 장애가 발생한 이후에 대응하는 방식이 아니라, <strong>문제가 되기 전에 신호를 감지하고 선제적으로 조치하는 운영 방식</strong>을 갖추게 되었습니다.</p><h3>마치며</h3><p>정산 시스템의 구현에서 중요한 것은 최신 기술의 조합이 아니라, 실패와 재실행을 자연스럽게 받아들이는 구조였습니다. <br>MASS는 Kafka, Spring Batch, Argo Workflow를 통해 정산을 안정적으로 구현했고, 실패해도 다시 실행할 수 있는 시스템을 만들 수 있었습니다.</p><p>다음 글에서는 이 시스템을 어떻게 단계적으로 오픈했고, 실제 운영에서 어떤 변화와 성과를 만들었는지 살펴보겠습니다.</p><h3>Platform Business Operation 조직 및 팀 소개</h3><blockquote><em>무신사 플랫폼 비즈니스 오퍼레이션 조직은 국내외 물류 서비스, 재고 관리, 스토어 운영을 위한 물류 프로덕트를 구축하고 다양한 오프라인 비즈니스 모델에 맞춘 스토어 관리 시스템을 개발·고도화하고 있습니다.<br>또한, 무배당발 서비스를 포함한 무신사의 차별화된 고객 경험을 브랜딩하고 확장할 수 있는 멤버십 구조를 설계하며, 온·오프라인을 넘나드는 통합 커머스 경험을 기술로 실현하고 있습니다.</em></blockquote><blockquote><em>저희 팀은 OMS(주문관리시스템)를 기반으로 온라인 주문부터 재고·출고·배송·정산에 이르는 전 과정을 유기적으로 연결하고, 무신사의 다양한 오프라인 스토어를 효과적으로 운영할 수 있는 관리 시스템을 구축하여 고객이 온라인(무신사 스토어, 29CM 등)과 오프라인(무신사 스탠다드, 편집숍 등)에서 끊김 없는 쇼핑 경험을 누릴 수 있도록 지원합니다.</em></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/pbo\"><em>🚀 Platform Business Operation 한걸음 더 알아보기</em></a></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/home\"><em>🚀 팀 무신사 채용 페이지</em></a><em> (무신사/29CM 전체 포지션 확인이 가능해요)</em></blockquote><blockquote><em>🚀 </em><a href=\"https://kr.linkedin.com/company/musinsacom\"><em>팀 무신사 테크 소식을 받아보는 링크드인</em></a></blockquote><blockquote><em>🚀 </em><a href=\"https://newsroom.musinsa.com/\"><em>팀 무신사 뉴스룸</em></a></blockquote><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=74d8a5d22ba1\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://techblog.musinsa.com/%EC%9D%B4%EB%B2%88-%EB%8B%AC%EB%8F%84-%EB%B0%A4%EC%83%98-%EC%A0%95%EC%82%B0%EC%9E%85%EB%8B%88%EB%8B%A4-%EC%A0%95%EC%82%B0-%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%80-%EC%96%B4%EB%96%BB%EA%B2%8C-%EB%A7%8C%EB%93%A4%EC%97%88%EC%9D%84%EA%B9%8C-%EC%8B%A4%EC%A0%84%ED%8E%B8-74d8a5d22ba1\">“이번 달도 밤샘 정산입니다.” — 정산 시스템은 어떻게 만들었을까 (실전편)</a> was originally published in <a href=\"https://techblog.musinsa.com\">MUSINSA techblog — 무신사 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2026-01-27T05:01:27.000Z",
    "url": "https://techblog.musinsa.com/%EC%9D%B4%EB%B2%88-%EB%8B%AC%EB%8F%84-%EB%B0%A4%EC%83%98-%EC%A0%95%EC%82%B0%EC%9E%85%EB%8B%88%EB%8B%A4-%EC%A0%95%EC%82%B0-%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%80-%EC%96%B4%EB%96%BB%EA%B2%8C-%EB%A7%8C%EB%93%A4%EC%97%88%EC%9D%84%EA%B9%8C-%EC%8B%A4%EC%A0%84%ED%8E%B8-74d8a5d22ba1?source=rss----f107b03c406e---4"
  },
  {
    "publisherId": "musinsa",
    "publisherName": "무신사 테크블로그",
    "specTitle": "e커머스 개발",
    "categories": [
      "backend"
    ],
    "specUrl": "https://medium.com/feed/musinsa-tech",
    "title": "2025년 제 1회 29QA Con 진행 후기 (29QA Conference)",
    "partialText": "<p>29CM QE팀은 연말에 팀 자체적으로 Conference를 진행하였습니다.</p><p>2024년까지는 연 2회 워크샵을 진행해서 각자 레슨런을 공유하는 자리를 가졌는데 2025년에는 상반기 워크샵을 진행하지 못하여 하반기에만 진행하게 되었고 이렇게 된 김에 연 행사처럼 고유의 컨퍼런스를 개최해 보자는 생각에 29QA Con을 계획하였습니다.</p><p>나중에는 점점 규모가 커져서 다른 회사의 QA 분들도 모시고 싶다고 생각해서 처음부터 어느 정도 형식을 갖추자는 판단을 했습니다. 그래서 굿즈도 만들고 홍보 배너도 만들었는데 만들고 나니 정말 컨퍼런스 분위기가 물씬 풍겨 진행하기를 잘했다는 생각이 들었습니다.</p><p>한 달가량의 촉박한 일정이었지만 4명의 팀원이 3개 이상씩의 세션을 준비해서 총 13개의 세션이 진행되었습니다. 짧은 기간 동안 열심히 양질의 자료를 만들어서 공유해 준 팀원분들 덕분에 훌륭한 하나의 Conference가 진행될 수 있었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*a_kRGeIIOTyukVPti6WlgA.jpeg\" /><figcaption>컨퍼런스 느낌이 나도록 X배너도 제작해서 걸어두었습니다.</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*FBDeSTwJS4pZ3GP3eITbjA.jpeg\" /><figcaption>팀 마스코트인 ‘큐엉이&#39; 가 포함된 굿즈도 여러개 제작하였습니다. 스티커 빼고 완판(?) 되었답니다.</figcaption></figure><p>식순은 아래와 같이 진행되었습니다. <br>발표 15분, 쉬는 시간 5분 정도를 계획해 두었습니다.</p><pre>1.  29CM에서의 팀 셋팅, 지금의 신뢰받는 QE팀은 어떻게 만들어졌나 (박현준)<br>2.  차세대 테스트 자동화 - Vibium(조진현)<br>3.  25년 자동화 유지보수 여정 (정다정)<br>4.  iOS 자동화 1년 여정 + 코드리뷰의 중요성 (강보민)<br>5.  귀찮음을 해결했더니 팀이 빨라졌다: QA 업무 자동화 사례 (정다정)<br>6.  아무도 궁금하지 않은 QA Weekly 작성 vlog (박현준)<br>7.  혼자 할 때는 몰랐던 것들: 2인 이상의 QA로 얻은 교훈 (강보민)<br>8.  질문을 잘하는 것이 곧 살아남는 방법이다 (조진현)<br>9.  눈물과 분노없이 볼 수 없는 Cursor를 사용한 29TMS 제작기 (박현준)<br>10. 대 AI 시대 Testcase 생성 찍먹해보기 (강보민)<br>11. 글로벌 서비스 QA 시에는 무엇이 달라지나 (정다정)<br>12. 2025년 회고 (조진현)<br>13. 2025년 한해 돌아보기 (+팀 회고) (박현준)</pre><p>하지만 발표가 시작되면 어김없이 기존 발표시간이 초과되는 사태가 발생하여서 발표자분들의 열정을 느낄 수 있었지만 시간관리에는 어려움이 있었습니다. 😅</p><p>쉬는시간을 타이트하게 가져가면서 열심히 진행했던 기억이 남습니다.</p><p>1️⃣ 첫번째 세션으로는 <br>“29CM에서의 팀 셋팅, 지금의 신뢰받는 QE팀은 어떻게 만들어졌나” 가 진행되었습니다.</p><p>제가 처음으로 29CM에 입사하여 QA팀을 신설하고 지금의 조직으로 만들기까지의 과정을 팀원분들께 공유하는 시간이었습니다. 초반에 조직의 신뢰를 얻기 위해서 결과로 증명하기 위한 노력과 이후 팀 방향성을 견고히 하기 위해 어떤 액션들을 했는지에 대한 과정들을 공유하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*N4w85aXBj-lebCKf2w1wyw.jpeg\" /></figure><p>2️⃣ 두번째 세션으로는 <br>“차세대 테스트 자동화 — Vibium” 이 진행되었습니다.</p><p>Selenium을 세상에 나오게 하여 테스트 자동화의 발전을 가속화 시킨 Jason Huggins에 대한 이야기와 그가 현재 개발하고 있는 Vibium은 어떤 것이고 어떤 것이 가능하게 되는지에 대한 것을 공유하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*5eTtGCw4N-n0VjT4J316qQ.jpeg\" /></figure><p>3️⃣ 세번째 세션으로는 <br>“25년 자동화 유지보수 여정” 이 진행되었습니다.</p><p>29CM에서는 App 테스트 자동화를 2023년부터 운영하고 있는데 이 과정에서 점점 시나리오는 증가하고 기술 복잡도가 증가함으로 인해서 여러 가지 자동화 Fail 건들이 발생했습니다. 이 중에 주요 원인 3대장을 분석하였고 이를 해결하여 Fail율을 극적으로 낮출 수 있었던 과정을 공유하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*XHFZKjJC2YR9zZGYQj5tWA.jpeg\" /></figure><p>4️⃣ 네번째 세션으로는 <br>“iOS 자동화 1년 여정 + 코드 리뷰의 중요성” 이 진행되었습니다.</p><p>보민님은 최근에 iOS 자동화 Owner가 되시면서 어떻게 하면 더 효율적이고 개선된 환경으로 유지보수를 할 수 있는지에 대한 고민을 많이 하셨습니다. <br>그 과정에서 코드 리뷰의 중요성을 느끼시고 그곳에서 받은 도움과 효과를 공유하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*EhOzw8F7BhlRQlrEn1hlYQ.png\" /></figure><p>🍚 원래는 다섯번째 세션 완료 후 점심시간이였지만 시간이 좀 지나 점심시간 확보를 위해 약간 빠르게 점심식사를 하러 이동하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/816/1*2E5uOfWSn2jwqlOmg009tw.png\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/917/1*jHMYW29UTBmjlM0lY6Rcqg.png\" /><figcaption>냠냠냠!</figcaption></figure><p>5️⃣ 다섯번째 세션으로는 <br>“귀찮음을 해결했더니 팀이 빨라졌다: QA 업무 자동화 사례” 가 진행되었습니다.</p><p>QE팀은 현재 다양한 Slack bot을 사용 중에 있습니다. 테스트 결과 리포트를 도와주는 Daily Report Bot과 Google 문서들을 공유해 주는 Bot등 여러 가지의 Bot이 있는데, 이 Bot들을 개발하면서 진행하게 된 개선 활동에 대한 레슨런을 공유하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*EUy-GsVpgGAtwMQSpbAZPw.png\" /></figure><p>6️⃣ 여섯번째 세션으로는 <br>“아무도 궁금하지 않은 QA Weekly 작성 vlog” 가 진행되었습니다.</p><p>제가 매주 작성하고 있는 QA Weekly에 관한 내용입니다. 이것을 작성하기 위해 제가 어떤 과정을 진행하고 있는지에 대한 이야기였는데, 모두 궁금하지는 않았겠지만 의외로(?) 많은 시간과 노력이 들어가고 있다는 내용을 공유하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*A0Q8OS4seRa3dgPVJIy6OQ.png\" /></figure><p>7️⃣ 일곱번째 세션으로는 <br>“혼자 할 때는 몰랐던 것들: 2인 이상의 QA로 얻은 교훈” 이 진행되었습니다.</p><p>작년 상반기까지만 해도 1인 QA로 진행하는 업무들이 많았습니다. 하반기부터는 외주 QA분들과 함께하게 되면서 이제 2인 이상 QA업무를 같이 진행하는 경우가 많이 생겼는데, 이러한 과정에서 어떤 레슨런이 있었는지에 대한 내용을 공유하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*-XjOLHm2jIC0bnr3uE0DYQ.png\" /></figure><p>8️⃣ 여덟번째 세션으로는 <br>“질문을 잘하는 것이 곧 살아남는 방법이다” 가 진행되었습니다.</p><p>사내에서도 AI을 적극적으로 사용하는 것을 권장하기 때문에 작년에 QE팀도 다양한 AI 도구들을 사용할 수 있었습니다. 이 과정에서 프롬프트 엔지니어링에 대해 고민을 하였고, 내가 원하는 방향의 답변과 결과를 얻기 위해서 어떠한 질문들을 해야 하는지에 대한 고민과 연구를 진행한 내용을 공유하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*359U7U9nuXb0nrLMQK0TVA.png\" /></figure><p>9️⃣ 아홉번째 세션으로는 <br>“눈물과 분노 없이 볼 수 없는 Cursor를 사용한 29TMS 제작기” 가 진행되었습니다.</p><p>이건 아쉽게도 영상으로 찍히지 않아서 세션 진행 자료가 없습니다. 😢 그래서 발표 자료로 대체해야 할 것 같습니다.</p><p>AI 에이전트 관련 세션인 만큼 발표자료는 AI를 활용한 이미지 생성으로 진행하였는데, 각 사례에 맞는 이미지를 생성하면서 제가 생각한 이미지가 정확히 나왔을때 즐거워하며 작업던 기억이 있습니다.</p><p>테스트케이스 관리 도구의 불편함을 개선하기 위해 초반에는 Cursor로 개발을 시작하였고 후반부에는 Claude code로 전환하여 개발을 완료하게 된 29TMS (Testcase Management System)에 관련된 이야기입니다. 현재는 1.9 버전이 업데이트 되어서 초기에 비해 사용성이 대폭 증가하였고 3개월 넘는 기간 동안 실무에서 잘 사용중입니다.</p><blockquote>관련 블로그: <a href=\"https://techblog.musinsa.com/ai와의-성공적인-첫-co-work-바이브-코딩으로-탄생된-맞춤형-testcase-management-system-29tms-74062a620119\">AI와의 성공적인 첫 Co Work — 바이브 코딩으로 탄생된 맞춤형 Testcase Management System (29TMS)</a></blockquote><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/996/1*IPlQRzqXZX5tsIpuPNkd_w.png\" /><figcaption>나노바나나야 고마워</figcaption></figure><p>🔟 열번째 세션으로는 <br>“대 AI 시대 Testcase 생성 찍먹해보기” 가 진행되었습니다.</p><p>3가지의 생성형 AI 도구를 대상으로 테스트케이스 생성에 대한 품질 테스트를 진행한 내용입니다. 어떤 AI는 어느 부분에 강점이 있었고 최종적으로는 어떤 AI 도구가 가장 높은 점수의 테스트케이스 생성 능력을 보여주었는지에 대한 과정을 공유하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*WDYEbaAPJPl1EQN3RvYmvA.png\" /></figure><p>1️⃣1️⃣ 열한번째 세션으로는<br>“글로벌 서비스 QA 시에는 무엇이 달라지나” 가 진행되었습니다.</p><p>이전 회사에서 경험했었던 글로벌 서비스에 대한 경험을 가지고 실사례를 기반으로 하여 우리 서비스가 글로벌 진출을 하게 된다면 어떤 것을 고려해야 하고 유의해야 하는지에 대한 내용과 진행하면서 어려웠던 점들을 공유하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*lcfT8oVoAKvK63gvlbaG4A.png\" /></figure><p>1️⃣2️⃣ 열두번째 세션으로는<br>“2025년 회고 (조진현)” 가 진행되었습니다.</p><p>2024년 9월 입사 이후 2025년은 온전한 1년을 모두 보낸 해였습니다. 2025년에는 어떤 경험과 성장을 이루었는지 한해를 돌아보며 회고한 내용을 공유하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*MIhsntTkY0Ayl_dVSUu_IQ.png\" /></figure><p>1️⃣3️⃣ 열세번째 마지막 세션으로는<br>“2025년 한해 돌아보기 (+팀 회고)” 가 진행되었습니다.</p><p>2025년 저는 어떻게 팀을 운영하며 개인에 대한 성장을 이뤄냈고 어떠한 변화를 맞이하여 그것에 적응하고 또 팀을 운영해 나갔는지에 대한 내용을 공유하였습니다. 많은 일들이 있었던 한 해였던 것 같습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*2toHaPvkWj43c5eNl074vw.png\" /></figure><p>이렇게 준비한 모든 세션이 완료되고 준비한 모든 팀원분들이 서로에게 박수를 보내며 제1회 29QA Con은 마무리가 되었습니다.</p><p>인원수는 많지 않았지만 풍부한 세션과 레슨런이 있었고 중간에 참석해서 자리를 빛내주신 MUSINSA QE팀 분들 덕분에 더 풍부한 컨퍼런스가 될 수 있었던것 같습니다.</p><p>바쁘신 와중에 참석해주신 MUSINSA QE팀 분들 감사합니다 :)</p><p>저희 QE팀은 연말에 고유 행사가 있습니다. 제가 팀원분들께 연말 선물을 드리는 것인데요 2023년은 장식용 캘린더, 2024년은 드래곤볼 7성구 (소원이루시라는 뜻으로 ^^), 그리고 2025년은 각자의 얼굴을 팝아트로 다시 그려낸 캔버스 그림을 선물로 드렸습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*3HOVjowbc36PfzHj8I2LRA.png\" /><figcaption>짠</figcaption></figure><p>그리고는 맛있는 저녁회식을 떠났습니다.</p><p>모두 열심히 준비하고 진행해준 만큼 회식도 더 맛있고 즐거웠을것으로 예상해봅니다 :)</p><p>올해에도 잘 준비해서 다른 QA분들이 발표도 하실수 있고, 참여도 하실 수 있는 행사로 만들어 보도록 하겠습니다.</p><h3>TEAM MUSINSA CAREER</h3><blockquote><em>무신사는 2001년 온라인 커뮤니티로 시작해 2005년 무신사 매거진, 2009년 무신사 스토어를 오픈하며 빠르게 성장하고 있는 국내 대표 온라인 패션 스토어입니다. ‘입점 브랜드와 동반성장’이라는 경영 철학을 바탕으로 브랜드가 안정적으로 사업을 전개할 수 있도록 무신사가 보유한 노하우와 인프라를 지원합니다. 고객에게는 풍성한 패션 콘텐츠와 패션에 특화된 차별화된 서비스로 최상의 온라인 쇼핑 경험을 제공하고 있습니다. 글로벌 №1 패션 기업으로 성장할 무신사와 함께 새로운 도전과 혁신을 만들 인재를 기다립니다.</em></blockquote><blockquote><em>29CM는 ‘고객의 더 나은 선택을 돕는다’라는 미션으로 출발했습니다. 우리는 우리만의 방식으로 콘텐츠를 제공하며, 브랜드와 고객 모두에게 대체 불가능한 커머스 플랫폼을 만들어가고 있습니다. 이 미션을 이루기 위해 우리는 흥미로우면서도 복잡한 문제들을 해결하고 있습니다. 만약 우리와 함께 이 문제들을 해결해 보고 싶다면, 주저하지 말고 29CM에 합류하세요!</em></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/home\"><em>🚀 팀 무신사 채용 페이지</em></a><em> (무신사/29CM 전체 포지션 확인이 가능해요)</em></blockquote><blockquote><em>🚀 </em><a href=\"https://kr.linkedin.com/company/musinsacom\"><em>팀 무신사 테크 소식을 받아보는 링크드인</em></a></blockquote><blockquote><em>🚀 </em><a href=\"https://newsroom.musinsa.com/\"><em>팀 무신사 뉴스룸</em></a></blockquote><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=610644aaf27b\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://techblog.musinsa.com/2025%EB%85%84-%EC%A0%9C-1%ED%9A%8C-29qa-con-%EC%A7%84%ED%96%89-%ED%9B%84%EA%B8%B0-29qa-conference-610644aaf27b\">2025년 제 1회 29QA Con 진행 후기 (29QA Conference)</a> was originally published in <a href=\"https://techblog.musinsa.com\">MUSINSA techblog — 무신사 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2026-01-26T22:02:56.000Z",
    "url": "https://techblog.musinsa.com/2025%EB%85%84-%EC%A0%9C-1%ED%9A%8C-29qa-con-%EC%A7%84%ED%96%89-%ED%9B%84%EA%B8%B0-29qa-conference-610644aaf27b?source=rss----f107b03c406e---4"
  },
  {
    "publisherId": "musinsa",
    "publisherName": "무신사 테크블로그",
    "specTitle": "e커머스 개발",
    "categories": [
      "backend"
    ],
    "specUrl": "https://medium.com/feed/musinsa-tech",
    "title": "“이번 달도 밤샘 정산입니다.” — 정산 시스템은 왜 필요했을까 (설계편)",
    "partialText": "<h3>“이번 달도 밤샘 정산입니다.” — 정산 시스템은 왜 필요했을까 (설계편)</h3><p>“이번 달도 밤샘 정산입니다.” 테크 블로그 시리즈</p><ol><li><a href=\"https://techblog.musinsa.com/이번-달도-밤샘-정산입니다-정산-시스템은-어떻게-만들었을까-실전편-74d8a5d22ba1\">정산 시스템은 어떻게 만들었을까 (실전편)</a></li><li><a href=\"https://techblog.musinsa.com/%EC%9D%B4%EB%B2%88-%EB%8B%AC%EB%8F%84-%EB%B0%A4%EC%83%98-%EC%A0%95%EC%82%B0%EC%9E%85%EB%8B%88%EB%8B%A4-%EC%A0%95%EC%82%B0-%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%80-%EC%96%B4%EB%96%BB%EA%B2%8C-%EB%A7%8C%EB%93%A4%EC%97%88%EC%9D%84%EA%B9%8C-%EC%8B%A4%EC%A0%84%ED%8E%B8-74d8a5d22ba1?source=collection_home_page----f107b03c406e-----0-----------------------------------\"><strong>정산 시스템은 왜 필요했을까 (설계편)</strong></a></li><li><a href=\"https://techblog.musinsa.com/이번-달도-밤샘-정산입니다-더-이상-밤샘하지-않아도-됩니다-운영편-4f09ae3bdf5d\">더 이상 밤샘하지 않아도 됩니다 (운영편)</a></li></ol><h3>들어가며</h3><p>정산 업무를 경험해 본 조직이라면 익숙한 문장입니다.</p><p>정산은 매달 반드시 마감되어야 하지만, 그 과정은 늘 사람의 손과 기억에 크게 의존해 왔습니다. 데이터는 흩어져 있고, 기준은 상황마다 조금씩 달라지며, 한 번 계산한 결과도 다시 믿기 어려운 경우가 많습니다.</p><p>MASS는 이러한 문제의식에서 출발했습니다.</p><p>단순히 수기 작업을 자동화하는 것을 넘어, <strong>정산이라는 행위를 시스템이 책임질 수 있도록 만들고자 했습니다.</strong><br>이번 연재의 1편에서는 MASS를 설계하며 가장 먼저 고민했던 질문들, 그리고 그에 대한 설계 원칙을 공유합니다.</p><h3>MASS란 무엇인가</h3><p><strong>MASS는 Musinsa Accounting &amp; Settlement System의 약자</strong>로, <br>물류/운영 과정에서 발생하는 비용을 기준으로 파트너 업체와의 물류비 정산을 자동화하는 시스템입니다.</p><p>MASS는 다음 역할을 수행합니다.</p><ul><li>물류 운영 시 발생하는 입고/출고/반품/재고에 대한 <strong>원천 데이터를 수집</strong></li><li>조건과 단가를 기준으로 <strong>정산 금액을 계산</strong></li><li>일/월 단위로 <strong>정산을 집계하고 마감</strong></li><li>내부 담당자와 외부 파트너 업체가 <strong>동일한 기준의 정산 결과를 확인</strong>할 수 있도록 제공</li></ul><p>즉, MASS는 단순히 정산 금액을 계산하는 도구가 아니라, 정산 결과에 대한 논쟁이 생겼을 때 최종 기준이 되는 시스템을 목표로 설계되었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*e051S3n4IrpKebneSIYzDA.png\" /></figure><h3>정산 시스템이 어려운 이유</h3><p>정산은 단순히 숫자를 더하는 문제가 아닙니다.</p><ul><li>회계 마감이라는 <strong>절대적인 데드라인</strong></li><li>단 한 건의 오류도 허용되지 않는 <strong>정합성 요구</strong></li><li>과거 기준으로 언제든 다시 계산할 수 있어야 하는 <strong>재현성</strong></li></ul><p>기존에는 여러 단계의 수기 작업과 엑셀 검증을 통해 이를 처리하고 있었고, 이 방식은 높은 업무 부담과 오류 가능성을 동시에 안고 있었습니다.</p><p>MASS는 이 문제를 “정산을 더 빨리 하자”가 아니라 <strong>“정산을 시스템이 책임지게 하자”</strong>는 관점에서 접근했습니다.</p><h3>설계 원칙: 속도보다 신뢰성</h3><p>MASS를 설계하면서 가장 먼저 합의한 원칙은 다음과 같습니다.</p><blockquote><em>정산 시스템은 빠르게 계산하는 시스템이 아니라 </em><strong><em>실패해도 다시 계산할 수 있는 시스템이어야 합니다.</em></strong></blockquote><p>이를 위해 아래 원칙을 아키텍처 전반에 반영했습니다.</p><ul><li><strong>정합성과 멱등성</strong></li><li><strong>결정적 계산(재현성)</strong><br><em>(결정적 계산: 같은 원천 데이터와 계산 기준을 사용하면 언제 다시 계산해도 동일한 결과가 나오도록 설계된 계산)</em></li><li><strong>감사 가능성(추적성)</strong></li><li><strong>배치 실패 복구 및 재시작성</strong></li></ul><h3>멱등성을 전제로 한 이벤트 처리</h3><p>정산에 사용되는 원천 데이터는 이벤트 형태로 유입됩니다.</p><p>이벤트 기반 시스템에서 중복 수신이나 재처리는 피할 수 없는 상황이기 때문에, MASS에서는 이를 <strong>전제 조건</strong>으로 두었습니다.</p><ul><li>이벤트 재시도(Retry)와 격리(DLT)를 분리해 처리</li><li>트랜잭션 식별자를 기준으로 서비스 레벨에서 멱등 갱신</li><li>동일 이벤트가 여러 번 처리되어도 결과는 항상 동일</li></ul><p>이를 통해 장애 상황에서도 안전하게 재처리할 수 있는 기반을 마련했습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*xENmTFP7ucjwQzf10heeyg.png\" /></figure><h4>이벤트 재시도(Retry)와 격리(DLT)를 분리해 처리</h4><p>이벤트 기반 정산 시스템에서는 일시적인 실패와 구조적인 실패를 구분해 다루는 것이 중요합니다.</p><p>MASS에서는 이를 위해 <strong>이벤트 재시도(Retry)</strong>와 <strong>격리(DLT, Dead Letter Topic)</strong>를 명확히 분리해 처리합니다.</p><p>일시적인 네트워크 오류나 외부 의존성 문제로 인한 실패는 재시도를 통해 정상 흐름으로 복귀시키고, 반복 재시도 이후에도 처리할 수 없는 이벤트는 정상 파이프라인에서 분리해 DLT로 격리합니다.</p><h4>트랜잭션 식별자를 기준으로 한 서비스 레벨 멱등 갱신</h4><p>MASS에서는 모든 원천 이벤트에 대해 업스트림 시스템에서 이미 존재하는 고유 식별자를 활용합니다. <br>입·출고, 재고 스냅샷 이벤트에 포함된 식별자를 조합해 정산 도메인 관점의 트랜잭션 식별자로 사용합니다.</p><p>이 식별자는 단순한 DB Unique Key가 아니라, <strong>정산 관점에서 이미 처리된 이벤트인지 판단하는 기준</strong>입니다.</p><ul><li>동일 식별자가 처음 들어오면 신규 정산 데이터로 처리</li><li>이미 처리된 이벤트라면 결과를 유지하거나(no-op)</li><li>정책 변경 등 의도적인 경우에만 갱신</li></ul><p>이를 통해 MASS는 DB 예외에 의존하지 않고, 도메인 규칙에 기반한 멱등성을 확보했습니다.</p><h3>결정적 계산을 위한 정산 로직</h3><p>정산 금액 계산은 가능한 한 단순하고 결정적으로 설계했습니다.</p><ul><li>계산기 모듈은 입력값에만 의존</li><li>금액 스케일과 반올림 정책을 고정</li><li>계산 단계를 명확히 분리해 추론 가능성 확보</li></ul><p>이 구조의 핵심은 <strong>“같은 입력이면 언제 계산해도 같은 결과가 나온다”</strong>는 점입니다.<br>덕분에 이의 제기, 기준 변경, 재처리 상황에서도 동일한 기준으로 다시 계산할 수 있습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*ESdtMRhioW0uIXh6o5EH-g.png\" /></figure><h4>계산기 모듈은 입력값에만 의존</h4><p>정산 계산 로직은 외부 상태나 실행 시점에 따라 결과가 달라지지 않도록, <strong>입력값만으로 결과가 결정되는 순수 함수 형태</strong>로 설계했습니다.</p><p>정산 계산에 필요한 모든 정보는 CalculateCommand와 그 안의 SettlementContext에 명시적으로 포함됩니다.</p><pre>data class SettlementContext(<br>    val settlementDate: LocalDate,<br>    val settlementBaseType: SettlementBaseType,<br>)</pre><p>SettlementContext는 “언제, 어떤 기준으로 정산하는가”를 명확히 표현하는 최소 단위의 컨텍스트로, 정산 계산 과정에서 <strong>현재 시각, 실행 환경, 전역 상태</strong>와 같은 외부 요인을 참조하지 않도록 만든 장치입니다.</p><p>이를 단순화하면 일 정산 계산 로직은 다음과 같은 형태를 가집니다.</p><pre># pseudo code<br><br>function calculateDailySettlement(command):<br>    # command includes:<br>    # - settlementContext (settlementDate, settlementBaseType)<br>    # - serviceType, partnerId, brandId<br>    # - logisticsCategoryCode, quantity, policy flags<br><br>    # 1) 정산 기준일 기준으로 단가 조회<br>    base = findBasePrice(command)<br>    unitPrice = base.baseUnitPrice<br><br>    # 2) 정산 기준일 기준으로 할인 정책 적용<br>    discountedUnitPrice = applyDiscount(<br>        unitPrice,<br>        base.serviceChargeBase,<br>        command.settlementContext.settlementDate,<br>        command.partnerId,<br>        command.brandId<br>    )<br><br>    # 3) 수량 반영<br>    originAmount     = unitPrice * command.quantity<br>    discountedAmount = discountedUnitPrice * command.quantity<br><br>    # 4) 정산 결과 반환<br>    return {<br>        unitPrice,<br>        discountedUnitPrice,<br>        originAmount,<br>        discountedAmount,<br>        remoteAreaUnitPrice (optional)<br>    }</pre><p>이 구조에서 계산 결과는 오직 다음 입력에 의해서만 결정됩니다.</p><ul><li><strong>정산 기준일(settlementDate)</strong></li><li><strong>정산 기준 유형(settlementBaseType)</strong></li><li>정책 정보(단가, 할인 조건)</li><li>원천 데이터(수량 등)</li></ul><p>덕분에 동일한 정산 컨텍스트와 입력이 주어지면 <strong>언제, 몇 번을 실행하더라도 동일한 정산 결과가 보장</strong>됩니다.</p><p>이는 이의 제기 대응, 기준 변경 이후의 재계산, 장애 복구 후 재처리 상황에서도 <strong>과거 정산을 동일한 기준으로 다시 계산할 수 있는 재현성</strong>을 확보하는 핵심 전제였습니다.</p><h4>금액 스케일과 반올림 정책을 고정</h4><p>정산 도메인에서 반올림은 “표현 방식”이 아니라 <strong>결과 자체를 바꾸는 규칙</strong>입니다.<br>특히 할인/수수료처럼 소수점이 개입되는 계산은 <strong>반올림 시점과 방식이 조금만 달라도 최종 금액이 달라질 수 있습니다.</strong><br>일 단위로는 몇 원 수준의 차이처럼 보여도, 월 단위 집계로 누적되면 <strong>정산 금액 불일치</strong>로 이어질 수 있습니다.</p><p>그래서 MASS에서는 다음을 원칙으로 두었습니다.</p><ul><li>모든 금액 계산은 BigDecimal로 수행해 <strong>부동소수점 오차를 원천 차단</strong></li><li>할인 적용 시 <strong>스케일(MONEY_SCALE)을 강제로 고정</strong></li><li>반올림은 <strong>항상 동일한 정책(RoundingMode.DOWN)</strong>을 사용</li></ul><p>예를 들어 비율 할인(RATE)의 경우, 할인율을 퍼센트에서 실제 rate로 변환한 뒤 곱셈을 수행하고, 그 결과를 <strong>반드시 동일한 스케일로 내림(DOWN) 처리</strong>해 할인 적용 단가를 결정합니다.</p><pre>// RATE 할인: percent -&gt; rate 변환 후 곱셈, 그리고 스케일/반올림 정책 강제<br>val percent = discount.discountValue.max(BigDecimal.ZERO).min(MAX_RATE_VALUE)<br>val rate = BigDecimal.ONE.subtract(percent.movePointLeft(RATE_SCALE))<br><br>val discountedUnitPrice =<br>    unitPrice<br>        .multiply(rate)<br>        .setScale(MONEY_SCALE, RoundingMode.DOWN)<br>        .max(BigDecimal.ZERO)</pre><p>이처럼 “소수점이 생길 수 있는 지점”에서 <strong>정책을 코드로 강제</strong>해두면,</p><ul><li>계산 경로가 달라져도(일 정산/월 정산/재처리)</li><li>실행 환경이 달라져도(다른 서비스/다른 배치)</li></ul><p>항상 동일한 금액 산출이 가능해지고, 결과적으로 <strong>정산 결과의 재현성</strong>을 확보할 수 있습니다.</p><blockquote><em>정산 시스템에서 반올림 정책은 구현 디테일이 아니라, “같은 입력이면 같은 결과가 나와야 한다”는 신뢰를 지키는 핵심 규칙입니다.</em></blockquote><h3>마치며</h3><p>정산 시스템의 어려움은 계산식이 아니라, <strong>다시 계산해야 하는 현실</strong>에 있습니다. <br>MASS는 멱등성과 결정적 계산이라는 설계 원칙을 통해 정산을 사람의 기억이 아닌 시스템의 책임으로 옮기고자 했습니다.</p><p>다음 글에서는 이러한 설계가 실제로 어떤 기술 선택과 구조로 구현되었는지, Kafka와 Spring Batch, Argo Workflow를 활용한 정산 시스템의 실전 이야기를 다룰 예정입니다.</p><h3><strong>Platform Business Operation 조직 및 팀 소개</strong></h3><blockquote><em>무신사 플랫폼 비즈니스 오퍼레이션 조직은 국내외 물류 서비스, 재고 관리, 스토어 운영을 위한 물류 프로덕트를 구축하고 다양한 오프라인 비즈니스 모델에 맞춘 스토어 관리 시스템을 개발·고도화하고 있습니다.<br>또한, 무배당발 서비스를 포함한 무신사의 차별화된 고객 경험을 브랜딩하고 확장할 수 있는 멤버십 구조를 설계하며, 온·오프라인을 넘나드는 통합 커머스 경험을 기술로 실현하고 있습니다.</em></blockquote><blockquote><em>저희 팀은 OMS(주문관리시스템)를 기반으로 온라인 주문부터 재고·출고·배송·정산에 이르는 전 과정을 유기적으로 연결하고, 무신사의 다양한 오프라인 스토어를 효과적으로 운영할 수 있는 관리 시스템을 구축하여 고객이 온라인(무신사 스토어, 29CM 등)과 오프라인(무신사 스탠다드, 편집숍 등)에서 끊김 없는 쇼핑 경험을 누릴 수 있도록 지원합니다.</em></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/pbo\"><em>🚀 Platform Business Operation 한걸음 더 알아보기</em></a></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/home\"><em>🚀 팀 무신사 채용 페이지</em></a><em> (무신사/29CM 전체 포지션 확인이 가능해요)</em></blockquote><blockquote><em>🚀 </em><a href=\"https://kr.linkedin.com/company/musinsacom\"><em>팀 무신사 테크 소식을 받아보는 링크드인</em></a></blockquote><blockquote><em>🚀 </em><a href=\"https://newsroom.musinsa.com/\"><em>팀 무신사 뉴스룸</em></a></blockquote><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=22732a4a607f\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://techblog.musinsa.com/22732a4a607f\">“이번 달도 밤샘 정산입니다.” — 정산 시스템은 왜 필요했을까 (설계편)</a> was originally published in <a href=\"https://techblog.musinsa.com\">MUSINSA techblog — 무신사 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2026-01-21T22:22:08.000Z",
    "url": "https://techblog.musinsa.com/22732a4a607f?source=rss----f107b03c406e---4"
  },
  {
    "publisherId": "musinsa",
    "publisherName": "무신사 테크블로그",
    "specTitle": "e커머스 개발",
    "categories": [
      "backend"
    ],
    "specUrl": "https://medium.com/feed/musinsa-tech",
    "title": "이구위크 전시 장애 대응기: Redis에는 무슨 일이 있었나",
    "partialText": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*STYKSBA_rNy0r3jiD_Z-tw.png\" /></figure><p>안녕하세요. 29CM에서 고객이 상품을 탐색하고 발견하는 상품 전시 영역을 담당하고 있는 Customer Engagement Engineering 팀 김송이입니다.</p><p>2025년 겨울, 29CM 최대 규모의 블랙프라이데이 행사인 이구위크를 진행했습니다. 연중 가장 트래픽이 몰리는 행사인 만큼, 설렘과 긴장이 공존하는 시즌이기도 합니다. 매년 대규모 트래픽을 대비하지만, 플랫폼의 성장 속도만큼 새로운 변수도 함께 생겨납니다.</p><p>이구위크 시작 첫날이었던 11월 3일, 유저가 상품을 둘러보는 주요 상품 전시 화면에서 장애가 발생했습니다. 장애 원인을 추적하고 해결한 과정, 이후 개선한 내용을 정리해 공유합니다.</p><h3>1. 장애 발생과 원인을 찾기까지</h3><p>이구위크 본편이 시작된 지 얼마 되지 않아, 검색결과, 상품 리스팅 등의 전시 도메인을 담당하는 서버에 이상징후가 포착되기 시작했습니다. 파드(pod)가 일부 다운되며 트래픽을 못 받기 시작했습니다.</p><p>남아있는 파드도 처리 가능한 트래픽을 초과하면서 Netty 이벤트 루프 포화가 발생했습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*t-AYIgKOPCNUeUouWn9zGA.png\" /><figcaption>Netty Pending Tasks</figcaption></figure><p>전시 트래픽을 받는 서버의 경우 Netty, Spring WebFlux 기반으로 운영 중이었기 때문에, 트래픽 증가로 인한 다운스트림 지연이나 이벤트 루프 처리 지연 쪽을 먼저 점검했습니다. Redis도 확인했지만, CPU, Memory 등 주요 시스템 메트릭이 모두 정상 범위(10% 이하)였기 때문에 원인일 가능성을 낮게 판단했습니다.</p><h3>2. Redis 대역폭 병목이 드러나다</h3><p>원인 분석 중 Redis 헬스체크 실패 로그가 눈에 들어왔고, 메트릭 지표를 다시 살펴봤습니다.<br>리소스는 멀쩡한데, 왜 Redis와의 통신은 실패하고 있었을까?<br>이 의문은 네트워크 지표에서 풀렸습니다.</p><p>당시 운영 중이던 Redis 노드 타입은 cache.r7g.large로, 기본 네트워크 대역폭은 <strong>0.937Gbps</strong>였습니다. 이는 이론적으로 <strong>초당 약 117MB</strong> 수준의 데이터 전송량에 해당합니다.</p><p>평소에는 네트워크 Out 대역폭이 약 0.49Gbps(약 61MB/s) 수준으로 유지되고 있어, 기본 대역폭 범위 내에서 안정적으로 동작하고 있었습니다. 그러나 이구위크 트래픽이 몰리면서 피크 시점에는 네트워크 사용량이 평소 대비 약 4배 수준인 <strong>2.0Gbps(약 250MB/s)</strong>까지 치솟았습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*ET-G9Iw8KmC7IcisgzWnPA.png\" /><figcaption>Network In/Out 허용 초과량</figcaption></figure><p>여기서 문제가 되었던 것은 AWS의 <strong>네트워크 대역폭 스로틀링(Throttling) 메커니즘</strong>입니다. ElastiCache는 인스턴스 타입마다 기본 제공 대역폭 베이스라인(Baseline)이 정해져 있고, 순간적으로 베이스라인을 초과하는 트래픽이 발생했을 때, 이를 허용해 주는 버스트(Burst) 기능을 제공합니다. 이때 버스트는 ‘<strong>버스트 크레딧(Burst Credit)</strong>’이라는 일종의 네트워크 체력을 사용해 동작합니다.</p><p>휴대폰 데이터 요금제와 비슷하다고 생각하면 이해하기 쉽습니다. 기본 데이터를 다 쓰면 속도가 확 느려지는 것처럼, 크레딧이 소진되면 Baseline으로 강제 제한됩니다.</p><blockquote>Baseline 이하로 사용 → 크레딧 축적</blockquote><blockquote>Baseline 초과 → 크레딧 소모하며 버스트 유지</blockquote><blockquote>크레딧 소진 → AWS가 Baseline 이하로 강제 제한(Throttling)</blockquote><p>이번 장애는 바로 이 <strong>버스트 크레딧 소진 → 네트워크 강제 제한</strong> 과정에서 발생했습니다. 트래픽이 19시부터 Baseline을 초과해 계속 버스트 상태로 운영되었지만, 약 2시간 동안 누적된 버스트 크레딧이 모두 고갈된 시점(20:58)에 네트워크 Throttling이 시작되면서 Redis 응답 지연과 커넥션 실패가 갑자기 폭증했습니다. 결과적으로 Redis 커넥션과 커맨드가 실패하기 시작했고, 이로 인해 애플리케이션의 Readiness Probe가 실패하면서 다수의 파드가 다운되었습니다.</p><h3>3. 장애 대응과 즉시 조치</h3><p>19:00부터 트래픽이 Redis 대역폭 Baseline을 초과했지만, Burst 크레딧 덕분에 바로 문제가 드러나지 않았고, 약 2시간 뒤인 20:58 크레딧이 고갈되면서 Throttling이 시작되었습니다. Burst 구간이 있었기 때문에 원인 파악이 늦어진 측면이 있습니다.</p><p>원인 파악 후 즉시 Redis 노드 스케일업(<em>cache.r7g.large</em> → <em>cache.r7g.2xlarge</em>)을 진행했습니다. 2xlarge는 기본 대역폭이 1.875Gbps로, 기존 대비 약 2배의 네트워크 용량을 제공합니다. 서비스 장애는 당일 해소되었지만, 트래픽이 더 늘어나면 같은 문제가 반복될 수 있기 때문에 근본적인 재발 방지 전략이 필요했습니다.</p><h3>4. 재발 방지를 위한 개선 작업</h3><p>장애 직후, 같은 문제가 반복되지 않도록 몇 가지 조치를 진행했습니다.</p><p><strong>4–1. 모니터링 강화</strong></p><p>Burst 크레딧 구간 때문에 원인 파악이 늦어졌던 만큼, 네트워크 In/Out 대역폭 초과 여부를 실시간으로 확인할 수 있도록 모니터링 대시보드를 강화했습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*PNB-wltpqao1jiFFFma0Ag.png\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*grvFIRlbX0WoeR0dQ4s61g.png\" /></figure><p>주요 모니터링 지표는 아래와 같습니다.</p><ul><li>aws.elasticache.network_bytes_in : 네트워크 수신 바이트</li><li>aws.elasticache.network_bytes_out : 네트워크 송신 바이트</li><li>aws.elasticache.network_bandwidth_in_allowance_exceeded : 수신 대역폭 Baseline 초과 여부</li><li>aws.elasticache.network_bandwidth_out_allowance_exceeded : 송신 대역폭 Baseline 초과 여부</li><li>aws.elasticache.traffic_management_active : Throttling 발생 여부</li></ul><p>또한 Datadog Alert를 연동해 네트워크 대역폭이 임계치를 넘을 경우 즉시 알림을 받을 수 있도록 설정하여 이상 징후를 빠르게 인지하고 사전에 대응할 수 있는 기반을 마련했습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/612/1*Y4Km5VSRIFnqlYHaYNBTaA.png\" /></figure><p><strong>4–2. 캐시 전략 변경 (캐시 계층화)</strong></p><p>Redis 네트워크 부하를 줄이기 위해 로컬 캐시로 처리 가능한 데이터는 서버 내부 메모리에서 우선 처리하도록 구조를 변경했습니다.</p><p>응답 변경 빈도가 낮은 데이터를 중심으로, 기존의 단일 Redis 의존 구조에서 벗어나 <strong>Caffeine</strong>(<strong>Local Cache) → Redis (Remote Cache) → DB</strong>로 이어지는 캐시 계층화 구조로 전환했습니다. 이를 통해 Redis에 집중되던 트래픽을 완화하고, 전체적인 응답 안정성을 높일 수 있었습니다.</p><p>캐시 전략을 적용한 직후, 실제로 Redis 부하가 감소했는지 지표를 확인했습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*0W2L_YTOxTqUcjCb_O_--g.png\" /><figcaption>Redis Command Count</figcaption></figure><p>우선 로컬 캐시가 제대로 역할하고 있는지 확인하기 위해 Redis 명령어 호출 수를 살펴봤습니다. 그 결과, Redis 명령어 호출이 눈에 띄게 감소한 것을 확인할 수 있었습니다.</p><p>로컬 캐시가 상당 부분을 흡수하면서 Redis가 직접 처리해야 하는 요청이 그만큼 줄어든 것입니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*o_YtYlfrpkUW-Vx0qt64SQ.png\" /><figcaption>Redis Outgoing Bytes 일별 비교 (노란색: 전일, 빨간색: 당일)</figcaption></figure><p>Redis 명령어 호출이 줄어든 만큼, 네트워크 Outgoing Throughput 역시 함께 감소했습니다.</p><p>기존에는 대용량 데이터를 주고받느라 네트워크 사용량이 높게 유지되었으나, 로컬 캐시가 이를 대신 처리하면서 Redis까지 전달되는 데이터양이 크게 줄어들었습니다.</p><h3>5. 장기 개선 과제</h3><p>이번 장애를 계기로, 단기적인 문제 해결에 머무르지 않고 중·장기 관점에서 트래픽 성장에 대비할 수 있는 인프라 구조로 전환하고자 합니다.</p><p><strong>5–1. 캐시 데이터 최적화 (Snappy + protobuf)</strong></p><p>Redis 네트워크 대역폭 사용량을 근본적으로 줄이기 위해 캐시 데이터 압축을 검토하고 있습니다. CPU 사용량이 적고 압축/해제 속도가 빨라 실시간으로 데이터를 읽고 쓰는 캐시 환경에 적합한 Snappy 압축 알고리즘을 고려하고 있습니다.</p><p>또한 JSON 형태로 저장되고 있는 캐시 데이터를 Protocol Buffers(protobuf) 형식으로 전환하는 것을 검토 중입니다. protobuf는 JSON 대비 데이터 크기가 작고 직렬화/역직렬화 속도도 빠르므로, 네트워크 대역폭 절감과 성능 향상을 동시에 기대할 수 있습니다.</p><p>실제 캐싱 중인 Item Document 데이터를 기준으로 측정한 결과, Snappy 압축 + protobuf를 함께 적용했을 때 기존 대비 약 73%의 용량 절감이 가능할 것으로 예상합니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Noke_TgaixxkjZotLdPESA.png\" /></figure><h3>6. 마치며</h3><p>이번 장애를 통해 Redis 대역폭 초과라는 예상치 못한 장애 지점을 발견할 수 있었습니다. CPU와 Memory 지표만으로는 문제를 인지하기 어려웠으며, <strong>네트워크 관점의 모니터링 필요성</strong>을 다시 한번 체감하는 계기가 되었습니다.</p><p>문제 해결 과정에서 캐시 구조 개선, 모니터링 고도화, 읽기 분리 적용 등 여러 기술적 부채를 해소했고, 현재는 <strong>이를 바탕으로 트래픽 증가에 대비한 아키텍처 개선을 진행</strong>하고 있습니다.</p><p>저희 팀은 전시, 콘텐츠, 기획전, 선물하기 등 사용자가 마주하는 서비스의 첫인상과 주요 탐색 흐름을 책임지고 있습니다. 앞으로도 더 빠르고 안정적인 사용자 경험을 제공하기 위해 지속적으로 구조를 점검하고, 확장 가능한 시스템으로 발전해 나가고자 합니다. 언제나 문제 해결의 모든 과정에서 적극적으로 함께해 준 팀원 모두에게 감사의 말씀을 전하며 글을 마칩니다.</p><p>긴 글 읽어주셔서 감사합니다.</p><h3>TEAM MUSINSA CAREER</h3><blockquote><em>무신사는 2001년 온라인 커뮤니티로 시작해 2005년 무신사 매거진, 2009년 무신사 스토어를 오픈하며 빠르게 성장하고 있는 국내 대표 온라인 패션 스토어입니다. ‘입점 브랜드와 동반성장’이라는 경영 철학을 바탕으로 브랜드가 안정적으로 사업을 전개할 수 있도록 무신사가 보유한 노하우와 인프라를 지원합니다. 고객에게는 풍성한 패션 콘텐츠와 패션에 특화된 차별화된 서비스로 최상의 온라인 쇼핑 경험을 제공하고 있습니다. 글로벌 №1 패션 기업으로 성장할 무신사와 함께 새로운 도전과 혁신을 만들 인재를 기다립니다.</em></blockquote><blockquote><em>29CM는 ‘고객의 더 나은 선택을 돕는다’라는 미션으로 출발했습니다. 우리는 우리만의 방식으로 콘텐츠를 제공하며, 브랜드와 고객 모두에게 대체 불가능한 커머스 플랫폼을 만들어가고 있습니다. 이 미션을 이루기 위해 우리는 흥미로우면서도 복잡한 문제들을 해결하고 있습니다. 만약 우리와 함께 이 문제들을 해결해 보고 싶다면, 주저하지 말고 29CM에 합류하세요!</em></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/home\"><em>🚀 팀 무신사 채용 페이지</em></a><em> (무신사/29CM 전체 포지션 확인이 가능해요)</em></blockquote><blockquote><em>🚀 </em><a href=\"https://kr.linkedin.com/company/musinsacom\"><em>팀 무신사 테크 소식을 받아보는 링크드인</em></a></blockquote><blockquote><em>🚀 </em><a href=\"https://newsroom.musinsa.com/\"><em>팀 무신사 뉴스룸</em></a></blockquote><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=5599562d76b9\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://techblog.musinsa.com/%EC%9D%B4%EA%B5%AC%EC%9C%84%ED%81%AC-%EC%A0%84%EC%8B%9C-%EC%9E%A5%EC%95%A0-%EB%8C%80%EC%9D%91%EA%B8%B0-redis%EC%97%90%EB%8A%94-%EB%AC%B4%EC%8A%A8-%EC%9D%BC%EC%9D%B4-%EC%9E%88%EC%97%88%EB%82%98-5599562d76b9\">이구위크 전시 장애 대응기: Redis에는 무슨 일이 있었나</a> was originally published in <a href=\"https://techblog.musinsa.com\">MUSINSA techblog — 무신사 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2026-01-06T22:02:27.000Z",
    "url": "https://techblog.musinsa.com/%EC%9D%B4%EA%B5%AC%EC%9C%84%ED%81%AC-%EC%A0%84%EC%8B%9C-%EC%9E%A5%EC%95%A0-%EB%8C%80%EC%9D%91%EA%B8%B0-redis%EC%97%90%EB%8A%94-%EB%AC%B4%EC%8A%A8-%EC%9D%BC%EC%9D%B4-%EC%9E%88%EC%97%88%EB%82%98-5599562d76b9?source=rss----f107b03c406e---4"
  },
  {
    "publisherId": "musinsa",
    "publisherName": "무신사 테크블로그",
    "specTitle": "e커머스 개발",
    "categories": [
      "backend"
    ],
    "specUrl": "https://medium.com/feed/musinsa-tech",
    "title": "QA 자동화 결과를 데이터로 관리하다: Grafana Dashboard와 Weekly 분석의 힘",
    "partialText": "<p>안녕하세요 29CM QE팀 강보민입니다.</p><p>29CM QE 팀은 iOS와 Android 자동화를 Cell 단위로 분담해 운영하고 있으며, 그중 저는 iOS UI 자동화를 담당하고 있습니다.</p><p>특히, <strong>29CM QE팀은 테스트 자동화만 전담하는 인원 없이, 모든 QE가 매뉴얼 테스트와 자동화를 함께 수행합니다.</strong> 덕분에 상황에 따라 유동적으로 대응할 수 있고, 자동화 코드에 대한 팀 전체의 이해도와 오너십도 높습니다.</p><p>입사 6개월이 지난 시점, 신규 시나리오 추가와 유지보수에 익숙해지고 3Q(7~9월) 목표를 설정할 무렵 세 가지 의문이 들었습니다.</p><blockquote><strong><em>“단순히 지금처럼 fail이 나는 경우에만 수정하는 것이 의미가 있을까?”</em></strong></blockquote><blockquote><strong><em>“2%라는 Fail률이 과연 낮은 것일까?’</em></strong></blockquote><blockquote><strong><em>“간헐적으로 발생하는 fail에 대해 다시 매뉴얼 테스트를 하는 것이 효율적인 것인가?”</em></strong></blockquote><p>당시 iOS UI 자동화를 리드하시던 다정님께서 이미 약 2% 미만 수준의 낮은 Fail률로 안정적인 자동화 환경을 만들어주신 상태였지만,</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*QAQKOuvhawT8sBZKmpHE5w.png\" /><figcaption><strong>24년도 하반기 2% 미만의 fail률</strong></figcaption></figure><p>더 높은 신뢰성과 일관된 품질을 유지하기 위해, <strong>Fail률 0.7% 미만 달성</strong>을 공동 목표로 세웠습니다.</p><p>이후 자동화 테스트 케이스를 수행하면서 코드 구조상 개선이 필요한 영역, 간헐적으로 발생하는 오류 케이스 그리고 신규 시나리오 추가 과정에서 발생할 수 있는 불필요한 실패를 방지하기 위한 사전 안전장치들을 함께 점검하고 개선해 나가기 시작했습니다.</p><p>안드로이드 역시 진현님께서 시나리오 복구 작업 및 확장 과정에서 Fail률 2% 미만을 목표로 설정하고, 안정성 향상을 위한 개선 작업을 병행하는 목표를 세웠습니다. (안드로이드는 복구가 필요한 시나리오가 있어 iOS보단 높은 Fail률로 목표를 설정하고, 점차 낮춰 나가는 방향으로 진행하고 있습니다)</p><p>이 글에서는 그 과정에서 얻은 경험과 개선 방법을 공유하려 합니다.</p><h3><strong><em>Grafana Dashboard: 데이터 기반 분석의 시작</em></strong></h3><p>분석을 하기 위해 가장 먼저 필요했던 것은 <strong>테스트 자동화 결과의 DB화</strong>입니다. 29CM QE팀은 2024년도 1월부터 자동화 수행 결과를 DB에 적재해오고 있으며, 데이터를 바탕으로 <strong>Grafana Dashboard로 데이터를 시각화하고 있습니다.</strong></p><p><strong>* 참고 글: </strong><a href=\"https://medium.com/29cm/29cm-qa%ED%8C%80%EC%9D%80-%EC%96%B4%EB%96%BB%EA%B2%8C-%ED%85%8C%EC%8A%A4%ED%8A%B8-%EC%9E%90%EB%8F%99%ED%99%94-%EC%A7%80%ED%91%9C%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%98%EC%97%AC-%EC%8B%A0%EB%A2%B0%EC%84%B1%EC%9D%84-%ED%99%95%EB%B3%B4%ED%95%A0-%EC%88%98-%EC%9E%88%EC%97%88%EC%9D%84%EA%B9%8C-93ee5cca76ce\">현준님의 작년 포스팅 — 29CM QA팀은 어떻게 테스트 자동화 지표를 활용하여 신뢰성을 확보할 수 있었을까?</a></p><p>Grafana Dashboard에서 확인 가능한 데이터 및 그래프 구성 항목은 날짜별 Fail률, 평균 수행 시간, 이번 주 대비 지난주 수행 시간 비교, Fail 발생 시나리오 카운트 합산 등으로 구성되어 있습니다.</p><p>Dashboard에서 확인할 수 있는 정보들과 함께 fail률 개선에 활용한 경험을 이야기해 보겠습니다.</p><p><strong>첫 번째, 일 별 파이프라인 수행 개수입니다.</strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*PkkB3Buigx7jKkbiryqN5Q.png\" /><figcaption><strong>일 별 자동화 파이프라인 수행 개수</strong></figcaption></figure><p>자동화 수행은 Jenkins 스케줄링에 따라 24시간, 매일 1시간 간격으로 실행되고 있습니다.</p><p>앱 심사 이전의 BVT 최종 배포 테스트나, 신규 FE 배포 시 배포 트리거에 걸린 경우, 그리고 11월 이구위크 기간처럼 트래픽이 집중되는 시기에는 하루 최대 50회까지 수행되기도 합니다.</p><p>위 그래프에서 일자별 자동화 수행 횟수가 다르게 나타나는 이유가 바로 이 때문입니다.</p><h3><strong><em>Fail 시나리오 분석</em></strong></h3><p>두 번째, Grafana Dashboard에서 확인할 수 있는 여러 지표 중, Fail률을 줄이기 위해 가장 핵심적으로 활용한 데이터인 <strong>시나리오별 Fail 카운트 합계</strong>입니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*GSGRVxIdUf7SWvahkjMzUg.png\" /><figcaption><strong>7월fail 시나리오</strong></figcaption></figure><p>3Q OKR 시작과 동시에 어느 시나리오에서 높은 Fail률이 발생하는지 파악하기 위해, OKR 시작 첫 번째 달인 <strong>7월 데이터를 Grafana Dashboard를 통해 집중적으로 분석</strong>했습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*fWzSeC654FLt0rCQFRUx9Q.png\" /><figcaption><strong>7월 자동화 결과</strong></figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*JhD60kutwCthKBp4RtR63g.png\" /><figcaption><strong>7월 fail률</strong></figcaption></figure><p>7월 자동화 Fail률을 Grafana Dashboard에서 모니터링한 결과, 대부분 1% 미만의 Fail률을 유지했지만, 간헐적으로 2% 가까이 상승하는 구간이 확인되었습니다. 특히 간헐적 이슈로 잘못 판단하여 시나리오 주석 처리 등 즉각적인 대응을 하지 못한 경우에는 4%를 초과한 적도 있었습니다.</p><h4><strong>7월 문제점 분석</strong></h4><p>특히 구매 플로우, 로그인이 필요한 플로우, 그리고 저녁 시간대 29 라이브 수행으로 인해 Element 클릭 시 29 라이브 전체보기 모드가 클릭되는 현상이 발생했고, 29 라이브가 위치한 페이지의 Element에서 높은 Fail 카운트가 집중되어 있음을 확인했습니다.</p><p>이에 따라 해당 시나리오를 우선 개선 대상으로 선정하고, 다음과 같은 문제점을 도출했습니다.</p><ul><li>로그인이 필수인 시나리오에서 로그인 실패 시 후속 시나리오가 연쇄적으로 실패하는 구조</li><li>결제 수단 선택 시 결제 수단 Element 탐색은 가능하나, 클릭하지 못하는 현상</li><li>29 라이브 수행 시 PIP 모드가 페이지 이동 후 유지, 앱 재실행 시 유지되는 현상이 있음</li></ul><h4><strong>7월 개선 작업</strong></h4><p>문제점 도출을 바탕으로 다음과 같은 개선 작업을 진행했습니다.</p><ul><li>(1) <strong>사전 로그인 강화 </strong>: 로그인이 반드시 필요한 케이스에서 로그인 실패 시 뒤 시나리오가 모두 실패하므로, <strong>사전 로그인 케이스를 추가</strong>했습니다.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*rfN4X64zKfO0u8AC9DLtZw.png\" /><figcaption><strong>사전 로그인</strong></figcaption></figure><ul><li>(2) <strong>선택 동작 안정화</strong> : 결제 수단 선택 시, 스크롤 위치에 따라 다른 UI나 터치 방어 영역과 겹치는 현상이 있어, Element 탐색 후 화면을 살짝 스크롤 하여 안정적으로 선택되도록 처리했습니다.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/818/1*u5SvMqWR0kcZQEnZDZ2TqA.png\" /><figcaption><strong>스크롤 안정화</strong></figcaption></figure><ul><li><strong>(3) 시간대 분기</strong> : 29 라이브 수행 시 <strong>PIP 모드 닫기 동작을 추가하여 </strong>특정 시간대(17:30~21:30)에 PIP 모드가 노출되어 다른 시나리오에 영향을 주는 것을 방지했습니다.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Ps1H8BLSLFaoVAI3EuEB0Q.png\" /><figcaption><strong>PIP 닫기</strong></figcaption></figure><h4><strong>8월: 개선 효과 확인 및 추가 과제 발견</strong></h4><p>8월에는 7월에 진행한 개선 코드 기반으로 7월에 가장 많은 Fail을 기록했던 구매/로그인 관련 시나리오들이 8월에 대폭 개선된 것을 확인할 수 있습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*IxTGEkN4YWHHnz-HQ9zwPg.png\" /><figcaption><strong>8월 fail 시나리오</strong></figcaption></figure><p>하지만, 아직 개선해야 할 것들은 여전히 남아 있었습니다. 바로 간헐적 fail과 실험 중일 경우 유저 계정별 기대 결과가 달라지는 경우입니다.</p><h4><strong>8월 개선 작업</strong></h4><ul><li><strong>(1) A/B 실험 대응</strong> : PDP 내 추천구좌를 확인하는 케이스 중 A그룹에 해당하는 유저는 “당신을 위한 MD 추천”에 해당, B그룹에 해당하는 유저는 “주목할만한 상품”만 확인하도록 분기 처리했습니다.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/814/1*K1Fic2qmx-V6PwrVtV0pvA.png\" /><figcaption><strong>추천 구좌 분기</strong></figcaption></figure><ul><li><strong>(2) 카테고리 Depth 클릭 고도화</strong> : API에서 받아온 카테고리를 클릭하도록 작성된 기존 코드에서 UI Element 탐색 시 대/중/소 카테고리가 분리되어 작성되지 않아 카테고리 depth를 잘못 클릭하는 경우가 있었습니다.</li><li>그 결과 아래 이미지처럼 “원래 의도는 여성 의류(대) &gt; 단독(중) &gt; 상의(소) 순서로 클릭하는 것이었으나, 중 카테고리에도 동일한 이름의 “상의”가 존재하여 ‘소’ 카테고리 대신 ‘중’ 카테고리의 “상의”가 클릭 되는 현상이 발생했습니다.”</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*qTCYJgqf4G4VjrYSvznD3g.png\" /><figcaption><strong>카테고리 고도화 이전</strong></figcaption></figure><ul><li>API로 카테고리를 받아왔음에도 잘못 클릭 되는 현상을 방지하고자, 대/중/소 카테고리 탐색 로직을 개선하여 각 depth 별로 정확한 카테고리를 클릭할 수 있도록 했습니다.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*yiMHdk2N_jBAqOE57UThdw.png\" /><figcaption><strong>카테고리 고도화 이후</strong></figcaption></figure><ul><li><strong>(3) 텍스트 정합성 검증</strong> : 상품명에 불필요한 공백(앞뒤 공백, 중복 띄어쓰기 등)이 포함되어 있어도 FE에서 공백을 정리해 주는 로직이 적용되어 있음을 개발팀 확인 후 이에 맞춰 테스트 코드에서도 동일하게 공백을 제거한 후 비교하도록 개선하여, 불필요한 Fail이 발생하지 않도록 했습니다.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*fD0mMtdmNMKWLUAd4iSquQ.png\" /><figcaption><strong>불필요한 공백 제거 처리</strong></figcaption></figure><h4><strong>8월 결과</strong></h4><p>7월 대비 1%를 넘는 fail 률이 비교적 줄고, 목표 fail률인 0.7% 미만에 도달하였지만, 아직 목표 fail률인 0.7%를 초과하는 일자들이 다수 존재했습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*SSy9-8_SGOpKYhB2Q-aKgg.png\" /><figcaption><strong>8월 fail률</strong></figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/607/1*h-tKiMaDagK32R345Q2-eg.png\" /><figcaption><strong>8월 자동화 결과</strong></figcaption></figure><h4><strong>9월: 신규 시나리오 추가와 Fail률 감소의 동시 달성</strong></h4><p>OKR 마지막 달인 9월은 Fail률이 증가할 수 있는 달이었습니다. 왜냐하면 <strong>신규 시나리오를 추가함과 동시에 Fail률을 감소시켜야 하는 조건</strong>이 있었기 때문입니다.</p><p>3Q 추가한 시나리오는 브랜드 홈 고도화 작업, 쿠폰 적용 상품, 마수동 광수동 알람 등이 있었습니다.</p><h4><strong>9월 개선 작업</strong></h4><ul><li>브랜드 홈 NEW 구좌 조건부 검증 : 브랜드 홈에 노출되는 구좌는 NEW, BEST 등이 있습니다. BEST 구좌는 항상 노출되나, NEW 구좌는 상황에 따라 신규 상품이 없으면, 신규 상품이 있으나 그 개수가 적을 경우 등의 상황이 고려되어야 했습니다.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*q23Zssz2CgGhAsO-DoNoAw.png\" /><figcaption><strong>NEW 구좌 더보기 버튼 차이</strong></figcaption></figure><p><strong>(1) API 응답, ID 활용</strong> : 해당 구좌가 존재하는 경우를 판단하기 위해 API 호출 후 신규 상품이 있을 경우에만 검증하고, NEW 구좌 내 상품명 일치 검증을 하는 경우에도 NEW와 더보기 텍스트를 통해 구좌 위치를 판단하는 것보다 정확히 NEW 타이틀에 심어진 ID를 통해 해당 구좌를 판별하도록 수정했습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*iKk26dQylckZtvGM_hZj0w.png\" /><figcaption><strong>NEW 구좌 노출 여부 확인</strong></figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*FfqQmJ-NgafX4A9BvFcvTQ.png\" /><figcaption><strong>ID기준으로 판단</strong></figcaption></figure><ul><li><strong>(2) 패싯 선택 조건 강화</strong> : 쿠폰 적용 상품 페이지 내 가격 필터 패싯 선택 시 상품 종류에 따라 보유한 패싯 정보가 다르기 때문에, price의 최솟값과 최댓값을 받아온 후, 선택해야 하는 가격대 패싯이 있는 조건에 해당하는 경우에만 가격대 패싯을 선택하도록 개선했습니다.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Uf8bt1DoU4fAmQm0QJxmqg.png\" /><figcaption><strong>가격대 패싯 선택 로직 강화</strong></figcaption></figure><p>그 결과, 5만 원~10만 원 가격 패싯이 없는 경우에는 가격대 패싯을 선택하지 않도록 처리되었고, 상품명 데이터 비교를 위한 API 호출 시에도 가격 파라미터를 제외하여 정확한 데이터 검증이 가능해졌습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/667/1*iar_GI1Rr_gOH25EAemIrQ.png\" /><figcaption><strong>5~10만 원 패싯이 없을 경우 미 선택</strong></figcaption></figure><ul><li><strong>(3) 사전 조건 강화 </strong>: PLP, SRP 검증 시 다른 페이지에서 패싯 변경 후 진입하는 경우 패싯이 유지되는 경우를 방지하고자, 현재 패싯 정보를 저장하고 default 패싯 정보와 다를 경우 패싯 사전 조건을 세팅했습니다.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/782/1*NTSJ51ujUsaRY5fRf63qlg.png\" /><figcaption><strong>패싯 초기 상태가 달라질 수 있는 상황</strong></figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*dEffK8Q1-gHkSmcfDHccgg.png\" /><figcaption><strong>패싯 사전조건 세팅</strong></figcaption></figure><ul><li><strong>(4) 일관성 확보</strong> : 29CM 앱 내부에서 설정해야 하는 시나리오 중 설정 중간에 실패, 해제 중간에 실패하는 경우 이후 시나리오에 영향을 줄 수 있기에, 앞뒤 시나리오로 인해 해제 테스트 default 조건이 예상과 다르게 설정된 경우를 방지하기 위한 안전장치로 API를 수행하여 테스트 진행 전 환경을 동일하게 유지했습니다.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*A4ljf6VSXHn0-rNugql5Tg.png\" /><figcaption><strong>테스트 수행 전 API 호출로 테스트 환경 일관성 유지</strong></figcaption></figure><p>그 결과, 9월은 신규 시나리오 추가에도 불구하고 (극소수의 0.7% 초과 날짜는 있었지만) 목표치인 0.7%보다 훨씬 더 낮은 <strong>0.5% 미만의 Fail률</strong>에 도달할 수 있었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/609/1*SPlxxf_lan6x3nsWH22YJg.png\" /><figcaption><strong>9월 자동화 결과</strong></figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*mzzvVnSEcrg9DW9ueQn2ig.png\" /><figcaption><strong>9월 fail률 전체</strong></figcaption></figure><h3><strong><em>자동화 수행 시간 분석과 개선</em></strong></h3><p>Grafana Dashboard에서는 Fail률뿐만 아니라 <strong>시나리오별 수행 시간</strong>도 모니터링할 수 있습니다.</p><p>지난주 대비 이번 주 시나리오별 수행 시간에 차이가 있는 항목을 그래프로 한눈에 시각적으로 확인할 수 있도록 구성되어 있습니다. 이를 통해 어느 시나리오에 많은 수행 시간이 소요 되는지 체크하고, 다음과 같은 원인 분석을 진행했습니다.</p><ul><li>Element 탐색에 오래 걸리는 것인지</li><li>API 호출 후 데이터를 불러와 변환하는 과정이 오래 걸리는 것인지</li><li>불필요한 대기 시간이 포함된 것인지</li></ul><p>분석 결과를 바탕으로 <strong>테스트 케이스를 상황에 따라 분리</strong>하거나, 비효율적인 로직을 개선하여 <strong>수행 속도를 최적화</strong>하고자 했습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*lw3zhF_6249NENOFh4rKdQ.png\" /><figcaption><strong>지난주 대비 이번주 수행시간 비교</strong></figcaption></figure><h4><strong>자동화 수행 속도가 중요한 이유</strong></h4><p>이구위크는 29CM의 대규모 이벤트 기간으로, 유저 인입이 급증하고 장애 발생 시 신속한 제보가 필요합니다. 이에 따라 자동화 스케줄링 주기를 <strong>20~30분 단위</strong>로 단축하여 운영하게 됩니다.</p><p>만약 단일 시나리오의 수행 시간이 과도하게 길어지면, 전체 자동화 수행 시간이 스케줄링 주기를 초과하는 상황이 발생할 수 있습니다. 이는 곧 <strong>장애 탐지 지연</strong>으로 이어질 수 있기 때문에, 수행 속도 최적화는 안정적인 자동화 운영을 위한 필수 요소입니다.</p><h4><strong>🚨 실제 이슈 탐지 사례</strong></h4><p>자동화 수행으로 인해 3Q에 잡은 사유별 Fail을 하나씩 살펴보면 다음과 같습니다.</p><p><strong><em>실제 장애로 인한 fail 발생</em></strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/682/1*Cpa_9H1cqGPal-gfG-AcpQ.png\" /><figcaption>특정 페이지 진입 시 장애 발생으로, 문구를 확인하지 못함으로 인한 fail</figcaption></figure><p><strong><em>배포 직후 배포 트리거가 돌아 발견된 필터 패싯 미 노출 이슈</em></strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/502/1*BnnEhdo_ZgH5Xo44LkP9Pw.png\" /><figcaption>배포 트리거 이후 잡힌 패싯 미노출 fail</figcaption></figure><p><strong><em>피처플래그/앰플리튜드 설정 오류로 </em></strong>잘못된 앰플리튜드 설정으로 테스터가 아닌 유저에게 카테고리 핀메뉴가 미 노출</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/706/1*BVHq-6emfB7Ml9ZMdWVYYQ.png\" /><figcaption>피처플래그, 앰플리튜드 설정이 잘못된 경우 카테고리가 미노출 되었던 현상</figcaption></figure><h3><strong><em>모바일 개발팀과의 협업</em></strong></h3><p>29CM QE Team은 모바일 개발팀과 긴밀한 협업으로 <strong>Element ID를 심고</strong> 있습니다. Element ID가 달라질 경우 문의 시 적극적으로 확인과 재 작업을 잘 해주셔서 많은 도움이 됩니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*GD27h02GgrT25z5JvdCaJg.png\" /><figcaption><strong>긴밀한 협업</strong></figcaption></figure><h4>이 과정에서 가장 중요했던 것은 <strong>혼자 고민하지 않는 것</strong>이었습니다.</h4><p>위클리 진행을 통해 다음과 같은 규칙을 세웠습니다.</p><ul><li><strong>개선 대상 시나리오 선정</strong>: Fail률을 개선하기 위해 수정해야 하는 시나리오를 함께 논의하고 우선순위를 결정</li><li><strong>고민 시간 기준 설정</strong>: 코드 수정 중 혼자 작업 시 고민하는 시간의 기준을 정하고, 그 시간 초과 시 팀원 간 블로커 즉시 공유</li><li><strong>원 팀 모드</strong>: 자동화 코드 작성 중 질문이 있을 때 Q&amp;A 리스트업 후 팀원 모두 원팀 마음으로 해소하려고 서로 조언 주기</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*twhzw7EQo-F4xiZlwwFM2g.png\" /><figcaption><strong>위클리, Action Item</strong></figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*NhV8Mb0bdyPiaoFV0PyVoA.png\" /><figcaption><strong>Android 9월 fail률 목표 도달</strong></figcaption></figure><p>Android 또한 9월 Fail률 2% 미만을 달성하며 목표에 도달했습니다. 아직 시나리오 확장 단계라 iOS보다 목표치를 보수적으로 잡아둔 상황이었는데, 작년 시나리오 확장 초반 대비 매우 낮아진 Fail률은 플랫폼 담당자 간의 적극적인 원 팀 문화 덕분이라고 생각합니다. <br>iOS 담당자도 Android에 조언과 피드백을 아끼지 않았고, Android 담당자 역시 iOS에 적극적으로 피드백을 주며 서로 도왔기에 가능한 성과였습니다.</p><p>마지막으로, 목표만 말로 세우는 것이 아닌 <strong>실질적인 Agenda와 Action Item</strong>을 도출하고, <strong>Gantt 차트로 일정을 수립하여 </strong>누락 없이 진행할 수 있었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*A_BLNvp4YPRvBG7Y6wFn8A.png\" /><figcaption><strong>iOS</strong></figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/779/1*0DRrCH-8M0TJwFW46I_0Hg.png\" /><figcaption><strong>안드로이드</strong></figcaption></figure><p>이처럼 <strong>데이터 기반 분석 + 팀 협업 + 체계적인 일정 관리</strong>가 결합되어 3Q 목표였던 <strong>Fail률 0.7% 미만을 달성</strong>할 수 있었습니다.</p><p>단순히 자동화 테스트를 수행하는 것에서 그치지 않고, 데이터 기반으로 분석하고 개선하는 과정이 자동화의 신뢰성을 높이는 핵심이라는 것을 경험할 수 있었습니다.</p><p>앞으로도 지속적인 모니터링과 분석을 통해 더 안정적인 자동화 환경을 구축해 나가겠습니다.</p><p>29CM QE팀은 AI를 적극적으로 활용하고 있습니다. 현재 Grafana Dashboard를 활용한 분석에서 한발 더 나아가, AI를 통해 자동화 결과를 주 단위, 월 단위로 자동 분석하고 리포트를 받아볼 수 있도록 코드를 작성하고 있습니다.</p><p>다음 글에서는 AI를 활용해 29CM QE팀이 불필요한 시간을 줄이고, 얼마나 효율적으로 테스트 결과를 받아보며, 그 결과를 기반으로 개선해 나가고 있는지에 대한 이야기로 찾아뵙겠습니다.</p><p>긴 글 읽어주셔서 감사합니다.</p><h3>TEAM MUSINSA CAREER</h3><blockquote><em>무신사는 2001년 온라인 커뮤니티로 시작해 2005년 무신사 매거진, 2009년 무신사 스토어를 오픈하며 빠르게 성장하고 있는 국내 대표 온라인 패션 스토어입니다. ‘입점 브랜드와 동반성장’이라는 경영 철학을 바탕으로 브랜드가 안정적으로 사업을 전개할 수 있도록 무신사가 보유한 노하우와 인프라를 지원합니다. 고객에게는 풍성한 패션 콘텐츠와 패션에 특화된 차별화된 서비스로 최상의 온라인 쇼핑 경험을 제공하고 있습니다. 글로벌 №1 패션 기업으로 성장할 무신사와 함께 새로운 도전과 혁신을 만들 인재를 기다립니다.</em></blockquote><blockquote><em>29CM는 ‘고객의 더 나은 선택을 돕는다’라는 미션으로 출발했습니다. 우리는 우리만의 방식으로 콘텐츠를 제공하며, 브랜드와 고객 모두에게 대체 불가능한 커머스 플랫폼을 만들어가고 있습니다. 이 미션을 이루기 위해 우리는 흥미로우면서도 복잡한 문제들을 해결하고 있습니다. 만약 우리와 함께 이 문제들을 해결해 보고 싶다면, 주저하지 말고 29CM에 합류하세요!</em></blockquote><blockquote><em>🚀 </em><a href=\"https://corp.musinsa.com/ko/career/\"><em>팀 무신사 채용 페이지</em></a><em> (무신사/29CM 전체 포지션 확인이 가능해요)</em></blockquote><blockquote><em>🚀 </em><a href=\"https://kr.linkedin.com/company/musinsacom\"><em>팀 무신사 테크 소식을 받아보는 링크드인</em></a></blockquote><blockquote><em>🚀 </em><a href=\"https://newsroom.musinsa.com/\"><em>팀 무신사 뉴스룸</em></a></blockquote><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=e18deceed574\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://techblog.musinsa.com/qa-%EC%9E%90%EB%8F%99%ED%99%94-%EA%B2%B0%EA%B3%BC%EB%A5%BC-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A1%9C-%EA%B4%80%EB%A6%AC%ED%95%98%EB%8B%A4-grafana-dashboard%EC%99%80-weekly-%EB%B6%84%EC%84%9D%EC%9D%98-%ED%9E%98-e18deceed574\">QA 자동화 결과를 데이터로 관리하다: Grafana Dashboard와 Weekly 분석의 힘</a> was originally published in <a href=\"https://techblog.musinsa.com\">MUSINSA techblog — 무신사 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2025-12-28T22:02:23.000Z",
    "url": "https://techblog.musinsa.com/qa-%EC%9E%90%EB%8F%99%ED%99%94-%EA%B2%B0%EA%B3%BC%EB%A5%BC-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A1%9C-%EA%B4%80%EB%A6%AC%ED%95%98%EB%8B%A4-grafana-dashboard%EC%99%80-weekly-%EB%B6%84%EC%84%9D%EC%9D%98-%ED%9E%98-e18deceed574?source=rss----f107b03c406e---4"
  }
]