[
  {
    "publisherId": "musinsa",
    "publisherName": "무신사 테크블로그",
    "specTitle": "e커머스 개발",
    "categories": [
      "backend"
    ],
    "specUrl": "https://medium.com/feed/musinsa-tech",
    "title": "“이 장애, 얼마나 심각한가요?” 사용자 경험을 기준으로 비즈니스 심각도를 정의하다",
    "partialText": "<p>안녕하세요, 큐레이터 서비스를 담당하고 있는 Partner Growth PM 최혜원, Backend Engineer 권혁주입니다.</p><p>큐레이터 서비스는 인플루언서가 SNS를 통해 상품을 소개하고, 해당 경로를 통해 발생한 구매 성과에 대해 수수료를 지급받는 팀 무신사의 공식 어필리에이트 서비스입니다. 인플루언서 커머스가 성장함에 따라, 큐레이터를 통한 매출 기여 역시 팀 무신사 비즈니스에서 점차 중요한 영역으로 확대되고 있습니다.</p><p>서비스의 비즈니스적 중요도가 높아지면서, 장애 발생 시 <strong>어떤 이슈를 우선적으로 대응해야 하는지에 대한 명확한 판단 기준</strong>과 이를 뒷받침할 <strong>체계적인 관리 프로세스의 필요성</strong>도 함께 커졌습니다. 이러한 배경에서 큐레이터 서비스의 <strong>비즈니스 심각도 정의</strong>를 시도하게 되었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/640/1*LLTYAiN7Owh7oqLh2-Tn5Q.png\" /></figure><p>이번 프로젝트는 프로덕트에서 <strong>비즈니스 관점의 핵심 사용자 여정(Critical User Journey)</strong> 을 정의하고, 이를 기준으로 엔지니어링과 함께 <strong>서비스 SLI(Service Level Indicator), SLA(Service Level Agreement) 기준을 수립하고 SEV(Severity) 심각도를 판단하여, 대시보드 및 얼럿 시스템 구축으로 확장한 협업 프로젝트</strong>입니다.</p><p>이 글에서는 CUJ, CSP, SLI, SLA, SEV 등 다소 생소할 수 있는 용어들이 함께 등장합니다. <br>각 개념은 서로 다른 역할을 가지지만, 비즈니스 심각도를 정의하고 장애를 판단하는 과정에서는 긴밀하게 연결되어 있습니다.</p><p>본격적인 내용에 앞서, 이후 설명을 보다 쉽게 이해하실 수 있도록 이번 프로젝트에서 언급되는 주요 용어들을 먼저 간단히 정리해보고자 합니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Vu62EtWsbcd2v1OpxG0Uew.png\" /></figure><p>이제 공통의 용어를 정리했으니, 실제 서비스 운영 과정에서 우리가 마주했던 질문으로 들어가보겠습니다.</p><blockquote>“이 장애, 그래서 얼마나 심각한가요?”</blockquote><blockquote><em>서비스를 운영하면서 장애 상황을 마주할 때마다 반복적으로 등장하던 질문이 있었습니다.<br></em><strong>“이 장애는 어느 정도로 심각한가요?”</strong><br><strong>“지금 바로 대응해야 하나요, 아니면 조금 지켜봐도 되나요?”</strong></blockquote><p>기존에도 에러율, 지연시간 등 SEV 지표를 기준으로 한 장애 레벨은 존재했습니다.<br>SEV(Severity)는 장애가 서비스와 비즈니스에 미치는 영향도를 기준으로 한 심각도 등급입니다. 장애 발생 시 대응 우선순위, 커뮤니케이션 범위, 투입 리소스를 결정하기 위해 사용됩니다.<br>하지만 큐레이터 서비스에서는 기술적으로 동일한 장애라도 비즈니스 영향은 크게 달라지는 경우가 자주 발생했습니다.</p><p>예를 들어,</p><ul><li>특정 페이지의 에러율이 일시적으로 상승했지만 큐레이터 서비스의 핵심 기능인 수익 발생 및 기여 측정에 영향 없는 경우</li><li>고객이 경험하는 페이지는 아니지만, 구매 기여 누락이나 수익 오집계로 이어지는 경우</li></ul><p>이처럼 장애의 ‘기술적 크기’와 ‘비즈니스적 치명도’가 항상 일치하지 않는 상황에서, 우리는 점점 더 자주 장애의 우선순위를 두고 논의하게 되었습니다.</p><h3>기존 심각도 기준이 충분하지 않았던 이유</h3><p>전사 공통의 SEV 기준은 이미 존재했고, 에러율, 지연시간 등 객관적인 지표를 기반으로 판단할 수 있었습니다.<br>하지만 큐레이터 서비스에 그대로 적용해보니 한계가 분명해졌습니다.</p><ul><li>동일한 에러율이라도 어떤 기능에서는 단순 불편에 그치고, 어떤 기능에서는 <strong>즉각적인 수익 손실</strong>로 이어졌습니다.</li><li>어떤 장애는 빠르게 복구하면 영향이 제한적이었지만,어떤 장애는 <strong>고객 경험 및 신뢰를 훼손해 회복 비용이 훨씬 컸습니다.</strong></li></ul><p>결국 문제는 ‘기술 지표가 부족해서’가 아니라,<br><strong>비즈니스 관점에서 무엇이 치명적인지에 대한 기준이 명시적으로 정의되지 않았다는 점</strong>이었습니다.</p><p>그래서 본 프로젝트의 출발점은 기술이 아니라, <strong>비즈니스가 성립되는 구조를 다시 바라보는 것</strong>이었습니다.</p><h3>비즈니스 심각도 정의 접근 방식</h3><blockquote><strong>“그렇다면, 비즈니스 관점에서의 심각도는 어디서부터 어떻게 정의해야 할까?”</strong></blockquote><p>이번 비즈니스 심각도 정의 프로젝트에서는 개별 장애나 지표를 바로 정의하기보다, <strong>비즈니스가 성립되는 구조를 단계적으로 분해하는 방식</strong>을 선택했습니다. 이를 위해 아래와 같은 <strong>4단계 프로세스</strong>로 비즈니스 심각도 정의를 진행했습니다.</p><p><strong>비즈니스 심각도 정의 4단계</strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*B4sh8Mo5y6hJFsYtudHeTQ.png\" /></figure><ol><li><strong>핵심 사용자 여정(CUJ) 정의</strong><br>고객이 서비스를 통해 핵심 목표를 달성하는 경로를 정의하고, 서비스의 핵심 가치와 반드시 지켜져야 할 단계들을 식별합니다.</li><li><strong>CSP / NON-CSP 구분</strong><br>핵심 사용자 여정 중에서도, 장애 발생 시 매출·전환에 직접적인 영향을 주는 핵심 경로(CSP)와 그렇지 않은 경로(NON-CSP)를 서비스 Function 단위로 구분합니다.</li><li><strong>CSP Priority 정의</strong><br>CSP로 분류된 기능들 사이에서도 고객 경험과 비즈니스 영향도의 크기에 따라 대응 우선순위를 나누고, 비즈니스 가치에 critical한 기준을 등급화합니다.</li><li><strong>SEV 설계 및 시스템 연결</strong><br>앞서 정의한 기준을 기반으로 SLI(Service Level Indicator) 지표를 수립합니다. SLI는 서비스의 현재 상태를 수치로 측정하기 위한 지표이며, 서비스가 얼마나 잘 동작하고 있는지를 객관적으로 나타냅니다. 도출된 SLI를 근거로 엔지니어링의 SEV(Severity, 장애 심각도 등급) 판단 체계를 수립하고, 이를 모니터링 및 알림(alert) 시스템으로 연동합니다.</li></ol><p>이러한 단계적 접근을 통해, ‘장애를 어떻게 감지할 것인가’가 아니라 ‘무엇을 기준으로 중요하다고 판단할 것인가’에 초점을 맞추었습니다.</p><h3>1. 출발점: 큐레이터 서비스의 핵심 사용자 여정(CUJ)</h3><p>프로덕트 관점에서 서비스의 장애를 판단하기에 앞서, 우리는 먼저 서비스가 언제 ‘정상적으로 작동하고 있다’고 말할 수 있는지에 대한 기준이 필요하다고 느꼈습니다. 이 기준이 없다면, 에러율이나 지연시간 같은 수치는 존재하더라도 그것이 비즈니스적으로 얼마나 중요한 문제인지 설명하기 어렵기 때문입니다.</p><p>그동안 프로덕트에서는 서비스 장애가 실제로 발생한 이후 대응 과정에서 판단을 내리는 경우가 대부분이었고, 사전에 장애를 구조적으로 분석하는 깊은 고민으로는 이어지지 못했습니다. 그 결과 어떤 장애가 정말 중요한지, 무엇을 먼저 개선해야 하는지에 대한 판단 기준이 명확하지 않았고, 이를 정리하기 위해 고객 경험 관점에서 서비스가 전달해야 하는 가장 중요한 가치가 무엇인지부터 다시 고민하게 되었습니다.</p><p>이 고민의 출발점으로 선택한 것이 바로 <strong>핵심 사용자 여정(Critical User Journey, CUJ)</strong> 입니다.</p><p>CUJ는 사용자가 서비스에서 핵심 가치를 경험하기 위해 반드시 거쳐야 하는 필수 경로이며, 프로덕트 관점에서 ‘이 서비스가 제대로 가치를 전달하고 있는가’를 판단하는 기준선에 해당합니다.</p><p>큐레이터 서비스에서 이 기준은, 큐레이터가 자신의 활동을 통해 수익을 창출하고 그 결과를 신뢰할 수 있는 경험을 제공하는지로 이어집니다. 즉, 서비스의 성공 여부는 개별 기능의 정상 동작이 아니라, 수익이 발생하고 그 기여가 정확히 측정 되는 경험이 끊김 없이 이어지는지에 달려 있다고 보았습니다.</p><p>이 관점에서 정의한 큐레이터 서비스의 핵심 사용자 여정(Critical User Journey)은 다음과 같습니다.</p><blockquote><strong>“큐레이터가 링크를 공유하고, 해당 링크를 통해 유입된 고객이 주문을 완료하며, 그 주문의 구매 기여가 정확히 측정된다.”</strong></blockquote><ul><li>서비스 핵심 가치: 큐레이터가 추천한 상품 판매로 수익을 얻는 경험을 한다.</li><li>핵심 단계: 제휴 링크 생성 → 고객 유입 → 구매 발생→ 기여 측정</li><li>성공 조건: 구매 기여 측정이 정확하게 이루어지고, 수익이 정상 반영되는 것</li><li>비즈니스 영향: 해당 여정이 정상 작동하지 않으면 서비스 핵심 가치(수익 창출)가 중단됨</li></ul><p>이 여정은 큐레이터 서비스가 제공하는 핵심 가치가 완성되는 최소 경로입니다.<br>따라서 이 흐름 중 어느 하나라도 정상적으로 동작하지 않는다면, 이는 단순한 기능 장애가 아니라 <strong>서비스가 본래 제공해야 할 가치를 전달하지 못하는 상태</strong>에 가깝다고 판단했습니다.</p><p>이렇게 정의된 CUJ는 이후 단계에서 어떤 기능이 비즈니스적으로 치명적인지(CSP), 그리고 장애 발생 시 무엇을 먼저 대응해야 하는지(SEV)를 판단하는 기준으로 활용되었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/640/1*2GIyVSKmjl5hwGsQ0n6OzA.png\" /></figure><h3>2. CSP/NON-CSP 정의: 무엇이 정말 치명적인가를 구분하기</h3><blockquote><em>핵심 사용자 여정(CUJ)을 정의하고 나니, 다음 질문이 자연스럽게 이어졌습니다.<br></em><strong>“이 여정을 구성하는 모든 기능이 동일한 수준으로 중요한가?”</strong></blockquote><p>CUJ는 큐레이터 서비스의 비즈니스가 성립되기 위한 <strong>최소 조건</strong>을 설명해 주지만, 실제 서비스는 이 여정을 구성하는 여러 기능과 시스템 위에서 동작합니다. 그리고 이들 중 일부는 장애 발생 시 곧바로 <strong>수익 손실이나 기여 누락</strong>으로 이어지는 반면, 일부는 불편을 유발하더라도 비즈니스 영향은 제한적인 경우도 있었습니다.</p><p>이 차이를 명확히 구분하기 위해 도입한 개념이 CSP(Critical Serving Path) 입니다. CSP란, 고객의 핵심 행동에서 장애 발생 시 직접적으로 매출·전환에 영향을 주는 핵심 경로를 의미하며, 큐레이터 서비스에서 CSP는 다음과 같이 정의했습니다.</p><p>큐레이터 서비스의 CSP는 수익 발생과 구매 기여 측정에 직접적인 영향을 주는 핵심 서비스 경로에 해당하며, 즉, 장애가 발생했을 때 큐레이터의 수익이 발생하지 않거나, 구매 기여가 누락되거나, 수익 집계의 정합성이 깨질 수 있는 경로를 CSP로 보았습니다.</p><p>이에 따라 다음 기능들이 <strong>CSP</strong>로 분류되었습니다.</p><ul><li>제휴 링크 생성</li><li>고객 유입 트래킹</li><li>구매 기여 측정</li></ul><p>반대로, 큐레이터 수익 활동 이전에 발생하는 사용자 경험 관련 기능이나 장애 발생 시 내부 운영으로 대체·보완 가능한 기능은 <strong>NON-CSP</strong>로 분류했습니다.<br>이 구분을 통해, 모든 장애를 동일한 기준으로 바라보는 대신 <strong>비즈니스적으로 반드시 지켜야 할 경로를 명확히 식별</strong>할 수 있었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/640/1*02pijDjLh9A2sYd0sx6FgQ.png\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*-Ei_AilYGPrZDHim9o4HHQ.png\" /></figure><h3>3. CSP Priority: 고객 경험과 비즈니스 영향을 함께 고려하다</h3><p>핵심 경로(CSP)로 분류된 기능들이라 하더라도, 장애가 발생했을 때 고객 경험 저하로 인해 발생하는 비즈니스 영향의 크기는 달랐습니다. 이에 따라 CSP 내부에서도, 사용자 경험과 비즈니스 영향을 함께 고려한 Priority 구분이 필요했습니다.</p><p>CSP Priority 정의 단계에서는 <strong>장애로 인해 어떤 사용자의 어떤 경험이 중단되는지를 기준으로 삼고</strong>, 그 경험 단절이 <strong>매출·신뢰·운영 비용 등 비즈니스 전반에 미치는 영향을 함께 고려해</strong> 정의했습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*PLSSgHW5gNKAHk0AtyWICg.png\" /></figure><ul><li><strong>P0: Customer 구매 경험 단절</strong><br>고객이 제휴 링크를 통해 유입된 이후 구매를 완료하지 못하거나, 구매 기여가 정상적으로 측정되지 않는 경우입니다.<br>고객의 핵심 구매 경험이 직접적으로 중단되며, 서비스 신뢰와 성과에 즉각적인 영향을 미칩니다.<br>(예: 제휴 링크 접근 불가, 구매 기여 누락, 기여 측정 불일치 등)</li><li><strong>P1: Curator 수익 활동 경험 단절</strong><br>고객의 구매는 가능하지만, 큐레이터가 상품을 탐색하거나 링크를 생성·관리하는 과정에서 장애가 발생해 수익 활동이 제한되는 경우입니다.<br>(예: 추천 상품 탐색 불가, 큐레이터샵 관리 오류, 제휴 링크 생성 불가 등)</li><li><strong>P2: Curator 일반 서비스 이용 경험 단절</strong><br>큐레이터의 일부 기능 이용에 불편이 발생하지만, 구매 발생이나 기여 측정에는 직접적인 영향이 없는 경우입니다.<br>(예: 큐레이터 회원 가입/정보 수정 불가 등)</li><li><strong>P3: 운영·관리 경험 단절</strong><br>서비스의 핵심 기능에는 영향이 없으나, 내부 운영이나 관리 과정에서 불편이 발생하는 경우입니다.<br>(예: 내부 어드민, 대시보드 오류 등)</li></ul><p>이렇게 CSP Priority를 정의함으로써, 장애 발생 시 고객 경험과 비즈니스 영향 관점에서 <strong>무엇을 먼저 보호해야 하는지</strong>를 명확히 판단할 수 있게 되었습니다.</p><h3>4. 비즈니스 심각도를 SEV로 연결하기</h3><p>CUJ와 CSP, Priority 정의까지는 장애를 <strong>비즈니스 관점에서 해석하기 위한 기준</strong>을 세우는 과정이었다면, 다음 단계는 이를 <strong>엔지니어링의 SEV 기준으로 연결하는 것</strong>이었습니다.</p><p>SEV는 장애 대응 시 얼마나 빠르게, 어디까지 대응해야 하는지를 결정하는 기준이기 때문에 비즈니스 심각도가 <strong>엔지니어링에서 바로 활용 가능한 형태</strong>로 번역될 필요가 있었습니다.<br>기존 SLI인 Availability, Latency(P95)를 그대로 사용하되, <strong>CSP 여부와 Priority를 함께 고려해 SEV를 판단</strong>하도록 기준을 정렬했습니다.</p><p>SEV 레벨 정의 (요약)</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/820/1*KIvBj8O86J_7UPCqp7FOVg.png\" /></figure><h4>SEV 판단의 핵심 기준: 무엇을 기준으로 장애라 부를 것인가?</h4><p>서비스를 운영하다 보면 크고 작은 문제들이 발생합니다. 하지만 모든 문제를 ‘장애(Severity, 이하 SEV)’로 규정하고 모든 엔지니어가 달려들 수는 없습니다. 리소스는 한정되어 있기 때문이죠. 그렇다면 어떤 기준으로 SEV 등급을 결정해야 할까요? <a href=\"https://cloud.google.com/blog/products/devops-sre/sre-fundamentals-slis-slas-and-slos?hl=en\"><strong>Google의 SRE(Site Reliability Engineering) 방법론</strong></a><strong> </strong>에서는 서비스의 건강 상태를 정량적으로 측정하고, 이를 바탕으로 객관적인 판단을 내릴 것을 권장합니다. 그 중심에는 다음 두 가지 핵심 요소가 있습니다.</p><p><strong>1) SLI (Service Level Indicator): 서비스의 ‘건강 지표’<br></strong>SEV를 판단하기 위한 첫 번째 단계는 ‘무엇을 측정할 것인가’입니다. SLI는 서비스 수준을 나타내는 정량적인 측정치를 의미하며, 쉽게 말해 우리 서비스의 현재 건강 상태를 보여주는 ‘체온계’와 같습니다.<br><strong>활용 목적은 </strong>SLI는 단순히 숫자를 나열하는 것이 아니라, <strong>서비스의 상태를 객관적으로 측정</strong>하고 뒤에서 설명할 <strong>SLO 달성 여부 및 SEV 등급을 결정하는 가장 기초적인 근거 데이터</strong>가 됩니다.</p><p><strong>주요 예시</strong></p><ul><li><strong>가용성(Availability):</strong> 전체 요청 중 성공한 요청의 비율</li><li><strong>응답 지연(Latency):</strong> 요청이 처리되는 데 걸리는 시간 (예: P95 latency — 하위 95%의 유저가 겪는 속도)</li><li><strong>에러율(Error Rate):</strong> HTTP 5XX 에러 등 실패한 요청의 비율</li><li><strong>처리량(Throughput):</strong> 초당 처리되는 요청 수 (QPS)</li><li><strong>이벤트 적재 성공률:</strong> 데이터 파이프라인에서 손실 없이 데이터가 쌓이는 비율</li></ul><p><strong>2) SLO (Service Level Objective)와의 결합: ‘장애의 경계선’<br></strong>SLI가 체온계라면, SLO는 ‘어느 정도 온도부터 해열제를 먹을 것인가(장애인가)’를 결정하는 기준치입니다. SEV는 단순히 “속도가 느리다”가 아니라, “설정한 SLO를 얼마나 벗어났는가”를 보고 결정합니다.</p><p><strong>판단 프로세스</strong></p><ul><li><strong>SLI 관측:</strong> 현재 에러율이 5% 발생 중임 (SLI)</li><li><strong>SLO 비교</strong>: 우리 서비스의 에러율 기준은 0.1% 미만임 (SLO)</li><li>S<strong>EV 결정</strong>: SLO를 심각하게 초과했으며, 영향 범위가 넓으므로 SEV 1 발령</li></ul><p><strong>3) 데이터 기반의 의사결정<br></strong>결국 SEV 판단의 핵심은 “주관적인 느낌이 아닌, 정량적인 데이터(SLI)와 약속된 기준(SLO)에 의거하는 것”입니다.</p><ul><li><strong>SLI</strong>를 통해 실시간 데이터를 수집하고,</li><li><strong>SLO</strong>를 통해 허용 가능한 범위를 설정하며,</li><li>이 범위를 벗어난 정도와 사용자 영향도에 따라 <strong>SEV 등급</strong>을 부여합니다.</li></ul><p>이렇게 체계화된 기준이 있다면, 긴박한 장애 상황에서도 팀 전체가 혼선 없이 빠르게 대응 우선순위를 정할 수 있습니다.</p><p><strong>4) 비즈니스 영향 (CSP / NON-CSP Priority)</strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Dbc1qgksLOVwxBGLZCg_ww.png\" /></figure><p>핵심 사용자 여정(CSP)에 직접 영향을 주는 기능은 더 높은 심각도를 가집니다.<br>이렇게 정의함으로써, 장애의 크기보다 ‘이 장애가 비즈니스에 어떤 영향을 주는지’를 기준으로 대응 우선순위를 정할 수 있게 되었습니다.</p><h4>대시보드와 얼럿으로 운영하기</h4><p><strong>1)핵심 사용자 여정 기준 대시보드<br></strong>대시보드는 <strong>핵심 사용자 여정(CUJ)을 구성하는 주요 기능별 SEV</strong>를 한눈에 볼 수 있도록 구성했습니다.<br>각 기능의 Error Rate, Latency(P95)을 함께 표시하여, 어떤 기능에서 문제가 발생했는지 빠르게 파악할 수 있습니다<em>.</em></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*qyZcw_rkCaRG8ZPyoVaRqg.png\" /></figure><p>각 단계를 분리해 모니터링함으로써, 장애 발생 시 <strong>어느 지점에서 비즈니스 흐름이 끊어졌는지</strong>를 빠르게 파악할 수 있도록 했습니다.</p><p><strong>2) 얼럿: 무엇이 끊겼는지를 바로 알 수 있게<br></strong>얼럿은 단순한 에러 알림이 아니라, <strong>문제의 위치와 심각도</strong>를 즉시 파악할 수 있도록 설계했습니다.</p><ul><li>어떤 기능에서 문제가 발생했는지</li><li>문제의 유형이 무엇인지 (에러율 / 지연시간)</li><li>즉시 대응이 필요한 수준(SEV)인지</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/531/1*zVtIk-wPjE-Otfm_48gSeA.png\" /><figcaption>alert message</figcaption></figure><p>알림을 받는 순간부터 “지금 무엇이 가장 중요한 문제인지”를 바로 판단할 수 있도록 하기 위함입니다.</p><p><strong>3) 운영 관점에서 달라진 점</strong></p><blockquote>이 기준을 대시보드와 얼럿에 반영한 이후, 장애 대응 방식에도 명확한 변화가 있었습니다.</blockquote><ul><li>장애 우선순위에 대한 논의 시간 감소</li><li>프로덕트–엔지니어링 간 판단 기준 정렬</li><li>기술 상태가 아닌 <strong>비즈니스 영향 중심의 대응 정착</strong></li></ul><p>결과적으로, 장애 대응이 더 빠르고 일관된 방향으로 이루어지기 시작했습니다.</p><h3>비즈니스 심각도 정의 이후, 무엇이 달라졌는가: “장애 지표는 숫자가 아니라, 합의된 관점이다”</h3><p>이번 비즈니스 심각도 정의 프로젝트를 통해 얻은 가장 큰 인사이트는 명확했습니다. 장애를 바라보는 기준은 기술 지표 자체가 아니라, <strong>무엇을 먼저 지켜야 하는지에 대한 관점</strong>이라는 점이었습니다.</p><ul><li><strong>장애 대응 기준의 전환: </strong>장애 발생 시, “에러율이 몇 퍼센트인가?”보다 <strong>“고객 경험이 영향을 받는가?”를 먼저 묻게 되었습니다.</strong></li><li><strong>대응 우선순위 체계화: </strong>기술 상태가 아닌 <strong>고객 경험 저하가 비즈니스에 미치는 영향 기준으로 대응 순서를 판단</strong>할 수 있게 되었습니다.</li><li><strong>커뮤니케이션 리소스 감소: </strong>합의된 비즈니스 심각도를 기준으로 대시보드 모니터링을 진행하므로 장애 우선순위에 대한 논의 비용이 눈에 띄게 줄었습니다.</li></ul><p>장애의 심각도가 지표로 자동 결정되기에 앞서, <strong>서비스의 핵심 가치와 사용자 여정을 기준으로 중요도를 판단하는 구조를 마련한 전환점</strong>이었습니다.<br>앞으로도 큐레이터 서비스에서는 핵심 사용자 여정을 중심으로, 비즈니스와 기술이 같은 질문을 던지고 같은 판단을 내릴 수 있는 운영 구조를 지속적으로 고도화해 나가고자 합니다.</p><h4>Partner Growth 팀 소개</h4><blockquote><em>Partner Growth 인플루언서 플랫폼에서는 무신사의 핵심 비즈니스 모델인 인플루언서 마케팅 서비스를 담당하고 있습니다.<br>브랜드와 인플루언서 간 협업을 가장 합리적인 구조로 연결하여, 무신사/브랜드/인플루언서 모두의 성장을 돕는 것이 우리 팀의 미션입니다.<br>단순히 무신사의 핵심 수익원이 되는 것을 넘어서, 높은 기술력을 가지고 브랜드와 인플루언서의 성공을 돕는 플랫폼이 되는 것을 지향점으로 서비스를 만들어가고 있습니다.<br>2026년도에는 인플루언서 플랫폼의 스케일업을 본격적으로 추진합니다.<br>이 여정을 함께 이끌어갈 Backend, Frontend Engineer를 찾습니다. 많은 지원 부탁드립니다!</em></blockquote><blockquote><em>🔗 무신사 채용 페이지: </em><a href=\"https://corp.musinsa.com/ko/\"><em>https://corp.musinsa.com/ko/</em></a></blockquote><blockquote><em>🔗 (Backend)광고&amp;인플루언서 개발팀 채용 공고: </em><a href=\"https://www.musinsacareers.com/ko/o/175930\"><em>https://www.musinsacareers.com/ko/o/175930</em></a></blockquote><blockquote><em>🔗 (Frontend)코어 파트너 프론트엔드 채용 공고: </em><a href=\"https://www.musinsacareers.com/ko/o/169076\"><em>https://www.musinsacareers.com/ko/o/169076</em></a></blockquote><blockquote><em>🚀 </em><a href=\"https://kr.linkedin.com/company/musinsacom\"><em>팀 무신사 테크 소식을 받아보는 링크드인</em></a></blockquote><blockquote><em>🚀 </em><a href=\"https://newsroom.musinsa.com/\"><em>팀 무신사 뉴스룸</em></a></blockquote><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=b13bf1d52b19\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://techblog.musinsa.com/%EC%9D%B4-%EC%9E%A5%EC%95%A0-%EC%96%BC%EB%A7%88%EB%82%98-%EC%8B%AC%EA%B0%81%ED%95%9C%EA%B0%80%EC%9A%94-%EC%82%AC%EC%9A%A9%EC%9E%90-%EA%B2%BD%ED%97%98%EC%9D%84-%EA%B8%B0%EC%A4%80%EC%9C%BC%EB%A1%9C-%EB%B9%84%EC%A6%88%EB%8B%88%EC%8A%A4-%EC%8B%AC%EA%B0%81%EB%8F%84%EB%A5%BC-%EC%A0%95%EC%9D%98%ED%95%98%EB%8B%A4-b13bf1d52b19\">“이 장애, 얼마나 심각한가요?” 사용자 경험을 기준으로 비즈니스 심각도를 정의하다</a> was originally published in <a href=\"https://techblog.musinsa.com\">MUSINSA techblog — 무신사 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2026-02-24T22:01:01.000Z",
    "url": "https://techblog.musinsa.com/%EC%9D%B4-%EC%9E%A5%EC%95%A0-%EC%96%BC%EB%A7%88%EB%82%98-%EC%8B%AC%EA%B0%81%ED%95%9C%EA%B0%80%EC%9A%94-%EC%82%AC%EC%9A%A9%EC%9E%90-%EA%B2%BD%ED%97%98%EC%9D%84-%EA%B8%B0%EC%A4%80%EC%9C%BC%EB%A1%9C-%EB%B9%84%EC%A6%88%EB%8B%88%EC%8A%A4-%EC%8B%AC%EA%B0%81%EB%8F%84%EB%A5%BC-%EC%A0%95%EC%9D%98%ED%95%98%EB%8B%A4-b13bf1d52b19?source=rss----f107b03c406e---4"
  },
  {
    "publisherId": "musinsa",
    "publisherName": "무신사 테크블로그",
    "specTitle": "e커머스 개발",
    "categories": [
      "backend"
    ],
    "specUrl": "https://medium.com/feed/musinsa-tech",
    "title": "추측이 아닌 데이터로: 3개 서비스 27개 SLO와 54개 모니터를 설정하고 배포 자동화까지 구축한 2주의 집중 작업",
    "partialText": "<p>| AI 활용으로 7일 만에 완성한 O4O 팀의 SRE 실전 가이드</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/640/0*HGIKFgEARpo7iKec\" /></figure><h3>서론: 배포할 때마다 터지는 알림들</h3><p>안녕하세요, O4O 엔지니어링팀에서 백엔드 개발을 담당하고 있는 성주현입니다.</p><p>저희 팀은 무신사의 오프라인 커머스 플랫폼인 O4O 서비스를 운영하고 있습니다. 각각 특성이 다른 3개의 주요 서비스를 운영하면서, 안정성을 관리하는 것이 점점 번거로워지고 있었습니다.</p><ul><li><strong>sales-api</strong>: B2C 실시간 주문 처리 (24시간 운영)</li><li><strong>moss-api</strong>: B2B 배치 처리 및 주문 관리 (24시간 운영)</li><li><strong>mpos-api</strong>: 오프라인 매장 POS 시스템 (10–21시 운영)</li></ul><p><strong>매주 수요일 오전 8시, 정기 배포를 시작하면 익숙한 광경이 펼쳐졌습니다.</strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*zfTNKY43N37G7tzp1EhVVg.png\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*jHlvpm4Bj6xEE5-VHJ0eVg.png\" /></figure><p><strong>더 심각한 문제는 따로 있었습니다.</strong></p><p>moss-api Success Rate 모니터는 <strong>매일 여러 차례 오탐 알림</strong>을 발생시키고 있었습니다. 조사 결과, 동일 목적의 SLO가 2개 존재했고, 하나는 HTTP 2xx 상태 코드만 성공으로 간주하는 부정확한 방식을 사용하고 있었습니다.</p><p>400 Bad Request, 404 Not Found 같은 <strong>클라이언트 오류</strong>를 서버 장애로 판단하여 매일 허위 알림을 발생시켰습니다. 반대로, HTTP 200을 반환하지만 비즈니스 로직이 실패한 경우는 “성공”으로 오판했습니다.</p><p><strong>계획된 배포는 불필요한 알림, 실제 비즈니스 실패는 탐지 못하는 상황이 발생했습니다.</strong> 측정 방식 자체를 바꿔야 했습니다.</p><p>이 상황을 바꾸기로 했습니다. AI를 활용한 집중 작업으로 완성한 <strong>SLO(Service Level Objective, 이하 SLO)</strong> 자동화 시스템 덕분에, 배포 중 오탐 알림은 0건이 되었고, 비즈니스 실패는 즉시 탐지할 수 있게 되었습니다.</p><p>이 글에서는 저희 팀이 3개 서비스(sales/moss/mpos)에 27개 SLO와 54개 모니터를 설정하고, 배포 중 <strong>Error Budget(오류 예산)</strong>을 자동으로 보호하는 시스템을 구축한 과정을 공유합니다.</p><blockquote><strong>용어 설명</strong></blockquote><blockquote><strong>- SLO(Service Level Objective)</strong>: 서비스가 달성해야 할 신뢰성 목표 (예: 가용성 99.9%, 응답시간 p99 &lt; 1초)<br><strong>- SLI(Service Level Indicator)</strong>: SLO 달성 여부를 측정하는 지표<br><strong>- Error Budget</strong>: 목표를 달성하면서 허용 가능한 실패율 (예: 99.9% 목표 = 0.1% 실패 허용)<br><strong>- APM(Application Performance Monitoring)</strong>: 애플리케이션 성능 모니터링 도구</blockquote><h3>PART 1: 조직 임팩트</h3><h4>정량적 성과: 실제로 얼마나 절감했을까?</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*wWV5FFu7mJgcXEXPc3rzxA.png\" /></figure><h4>ROI: 투자 대비 효과</h4><p><strong>우리 팀만의 시간 절감 (월간):</strong></p><ul><li>장애 분석 시간 단축: 50분 × 4회 = 200분</li><li>오탐 대응 시간 제거: 5분 × 20건 = 100분</li><li>신규 멤버 온보딩: 20시간 (분기당 1명 기준)</li><li><strong>합계: 월 25시간 = 연간 300시간</strong></li></ul><p><strong>전사 확산 시 (6개 팀 가정):</strong></p><ul><li>25시간 × 6팀 = 150시간/월</li><li><strong>연간 1,800시간 = 엔지니어 1명/년</strong></li></ul><p><strong>비용 환산 (시간당 5만원 기준):</strong></p><ul><li>우리 팀: 월 125만원 → <strong>연간 1,500만원</strong></li><li>전사 확산: <strong>연간 9,000만원</strong></li></ul><h4>정성적 성과: 팀원들의 목소리</h4><p><strong>개발자 피드백:</strong></p><ul><li>“알림이 왔을 때 진짜 장애인지 즉시 판단할 수 있습니다”</li><li>“Error Budget 걱정 없습니다”</li><li>“새로 합류한 동료가 당일부터 대시보드를 이해합니다”</li></ul><p><strong>조직 내 공유:</strong></p><ul><li>PBO 조직 Tech Talk 진행 (참석 약 20명)</li><li>팀 내 SLO 운영 노하우 축적</li></ul><h3>PART 2: 데이터 기반 프로세스 — 어떻게 이런 결과를 만들었나</h3><h3>WHY: 왜 SLO가 필요했는가</h3><h4>팀 상황</h4><p>저희 팀은 sales-api, moss-api, mpos-api 등 여러 서비스를 동시에 운영하고 있습니다. 그런데 각 서비스의 성격이 완전히 달라서 모니터링 기준을 하나로 맞추기가 쉽지 않았습니다. 특성이 다르다 보니 “어디까지가 정상이고 어디서부터 장애인지” 기준이 애매했습니다. 그래서 각 서비스에 맞는 안정성 기준, 즉 SLO가 꼭 필요하다고 판단했습니다.</p><h4>기존 모니터링의 한계</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*6JJXHJIW2BDwHWwg_pVw4A.png\" /></figure><p><strong>실제 사례: moss-api 오탐 알림 문제<br></strong>moss-api Success Rate 모니터는 <strong>매일 여러 차례 오탐 알림</strong>을 발생시켰습니다.</p><p><strong>원인 조사:<br></strong>동일 목적의 SLO가 <strong>2개</strong> 존재했습니다. 하나는 HTTP 2xx만 성공으로 측정하는 <strong>부정확한 방식</strong>이었습니다.</p><p><strong>기존 모니터의 판단:</strong></p><pre>-- AS-IS: HTTP 2xx만 성공으로 간주<br>SELECT count(http.status_code = 2xx) / count(*) as success_rate<br>FROM traces<br>WHERE service = &#39;moss-api&#39;<br>-- 결과: 400 Bad Request, 404 Not Found도 실패로 처리<br>-- → 매일 10회 이상 False Positive 알림</pre><p><strong>문제의 본질:<br>400 Bad Request, 404 Not Found는 클라이언트 오류</strong>입니다. 서버는 정상 작동했지만, HTTP 상태 코드 기반 측정은 이를 “실패”로 판단했습니다. 반대로, HTTP 200을 반환하지만 비즈니스 로직이 실패한 경우는 “성공”으로 오판하는 경우도 있었습니다.</p><p><strong>개선 후 (APM error 기반 측정):</strong></p><pre>-- TO-BE: APM error 태그 기반<br>SELECT count(@error != true) / count(*) as success_rate<br>FROM traces<br>WHERE service = &#39;moss-api&#39;<br>-- 결과: 실제 비즈니스 성공 여부 반영</pre><p><strong>효과:</strong></p><ul><li>✅ 오탐 알림 <strong>매일 10회 → 0회</strong> (100% 제거)</li><li>✅ 실제 비즈니스 실패는 즉시 탐지</li><li>✅ Error Budget이 실제 서비스 품질을 정확히 반영</li></ul><p><strong>”HTTP 상태 코드가 아닌, 실제 비즈니스 성공 여부를 측정해야 한다”</strong>는 것을 깨달았습니다.</p><h4>6단계 표준화 프로세스</h4><pre>1. 서비스 특성 분석 (1일)<br>   → 각 서비스별 Critical Path 정의<br>2. 과거 장애 분석 (1일)<br>   → 반복 문제 패턴 추출 (6개월 이력)<br>3. 측정 정확도 개선 (2일)<br>   → APM error 기반 전환<br>4. 데이터 기반 임계값 설정 (3일)<br>   → 90일 APM 데이터 분석 (AI 활용)<br>5. Burn Rate 계산 (1일)<br>   → Error Budget 소진 속도 경보<br>6. 명명 규칙 통일 및 자동화 (1일)<br>   → 27개 SLO + 54개 모니터 표준화 + ArgoCD Hooks 구현</pre><h4>서비스별 특성</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*F_lz008OlfKurG0RkrKCEA.png\" /></figure><blockquote><strong><em>SLO vs 모니터의 차이</em></strong></blockquote><blockquote><strong>- SLO</strong>: 서비스 수준 목표 (예: 가용성 99.9%, 레이턴시 p99 &lt; 500ms)<br><strong>- 모니터</strong>: SLO를 감시하는 알림 설정 (Burn Rate 알림, 임계값 알림 등)<br>- 하나의 SLO에 여러 모니터가 연결됨 (긴급/주의 등 단계별 알림)</blockquote><h4>측정 정확도 개선</h4><p><strong>문제: HTTP 상태 코드 기반의 한계</strong></p><p><strong>실제 사례: moss-api 중복 SLO 정리</strong></p><p>동일한 위 사례에서 <strong>문제가 있던 SLO 삭제했습니다.</strong></p><pre>측정 방식: HTTP 2xx만 성공<br>- 400 Bad Request → 실패로 처리 (❌ 오판)<br>- 404 Not Found → 실패로 처리 (❌ 오판)<br>→ 결과: 매일 10회 이상 False Positive 알림</pre><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*CUomFEO01NTtVGhGJPLmZw.png\" /></figure><p><strong>유지한 SLO의 측정 쿼리:</strong></p><pre>성공 요청 = 전체 요청 - APM error 요청<br>sum:trace.servlet.request.hits - sum:trace.servlet.request.errors</pre><h4>개선 효과</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*433PwcIqRLQkyT3yyOXepA.png\" /></figure><blockquote><strong><em>교훈</em></strong><em>: 오탐이 발생하면 민감도 조정이 아니라 </em><strong><em>측정 방식부터 재검토</em></strong><em>해야 합니다.</em></blockquote><h4>데이터 기반 임계값 설정</h4><p><strong>원칙: 추측 금지, 데이터로 증명<br></strong>처음에는 몇 개월간 운영한 감으로 “이 API는 1s면 충분하지 않을까?”라고 추측했습니다. 하지만 실제 데이터를 확인하니 전혀 달랐습니다. <br>90일간의 APM 데이터를 분석하여 각 서비스의 실제 응답 시간 분포를 파악했습니다. 추측이 아닌 데이터 기반으로 임계값을 설정해야 오탐을 방지할 수 있습니다.</p><p><strong>데이터 분석 과정:</strong></p><ol><li>Datadog API로 90일간 APM 메트릭 조회</li><li>pandas로 p50/p95/p99 백분위수 계산</li><li>p99 값에 10% 여유를 더해 임계값 설정</li></ol><blockquote><strong><em>💡 교훈</em></strong><em>: “이 정도면 되겠지”라는 추측은 금물입니다. 데이터가 진실을 말해줍니다.</em></blockquote><h4>설정 근거 (서비스 유형별 임계값)</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*HgDD4URgEQpatAa4CtNY6w.png\" /></figure><h4>Burn Rate 설정</h4><pre># Datadog Monitor 설정<br>monitors:<br>  - name: &quot;[SLO][sales-api] Latency - Burn Rate (긴급)&quot;<br>    type: slo<br>    burn_rate: 14.4  # 12시간 내 소진<br>    window: 12h<br>    alert: pagerduty + slack<br>- name: &quot;[SLO][sales-api] Latency - Burn Rate (주의)&quot;<br>    type: slo<br>    burn_rate: 6.0   # 28시간 내 소진<br>    window: 28h<br>    alert: slack</pre><h4>시행착오와 교훈</h4><p><strong>우리가 겪은 5가지 실수 (다른 팀은 반복하지 마세요!)</strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*gDyR5-tfREcfnu0wHjU7FQ.png\" /></figure><p><strong>핵심 교훈</strong></p><p><strong>처음부터 완벽할 필요 없습니다. </strong>1개 SLO 로 시작해서 점진적으로 확장해나갔습니다. 그리고 실제 데이터를 기반으로 적절한 수치를 확인하고 <strong>팀원과 임계값 합의</strong>를 통해 최종 설정값을 적용했습니다. 또한, <strong>문서화는 필수</strong>입니다. AI 를 통해 자동화하기 수월해진 요즈음 더욱더 잘 작성된 문서화는 큰 도움이 되었습니다.</p><h3>PART 3: 기술 혁신 — 배포 중 Error Budget 보호</h3><h4>문제: 배포할 때마다 SLO가 깨진다</h4><h4><strong>상황</strong></h4><pre>매주 수요일 오전 8시 정기 배포<br>→ Kubernetes Rolling Update (Pod 재시작)<br>→ 일시적 지연/오류 발생 (30초~2분)<br>→ Error Budget 차감 😭<br>→ 1주일 후에 SLO 99.95% 미달</pre><h4><strong>실제 데이터</strong></h4><p>배포 1회당 0.02% 정도 Error Budget 이 소진되었습니다. 주 2회 배포 시: 0.4% 소진으로 목표 99.95% (Budget 0.05%) 에 근접하는 불필요한 소진이었습니다.</p><p><strong>문제의 핵심</strong>은<strong> </strong>계획된 배포(Planned Downtime)인데 실제 장애(Unplanned Downtime)처럼 취급되었습니다.</p><h4><strong>기존 해결책의 한계</strong></h4><p><strong>방법 1: 수동 Correction</strong></p><pre>배포 전: Datadog UI → SLO Correction 생성<br>배포 후: 종료 시간 수동 업데이트</pre><p><strong>문제점:<br></strong>배포 종료 시각 예측 불가로 과다 또는 과소 제외되거나 휴먼 에러 가능성이 높습니다. 그리고 무엇보다 귀찮습니다.</p><p><strong>방법 2: 고정 시간 제외</strong></p><pre>매주 수요일 08:00-09:00 고정 제외</pre><p><strong>문제점:<br></strong>이 또한, 배포 실패 시에도 제외되서 Budget 왜곡되고, 비정기 배포(핫픽스) 미지원해서 정정하려면 수기로 정정해야 하고, 무엇보다 실제 배포 시간과 불일치합니다.</p><h4>우리의 해결책: 동적 Correction 자동화</h4><p><strong>원리</strong></p><pre>1. 배포 시작 (08:00)<br>   → SLO Correction 생성 (End: 09:00, 1시간 여유)<br>2. 배포 진행 (08:00-08:03)<br>   → 실제 배포 작업<br>3. 배포 완료 (08:03)<br>   → Correction End를 08:03로 업데이트<br>결과: 08:00~08:03 (실제 3분)만 제외 ✅</pre><p><strong>핵심 Python 스크립트<br>배포 시작할 때 Correction 생성하고, 배포 끝나면 종료 시간 업데이트하는 것</strong>입니다. ArgoCD Hook 과 Datadog API 를 활용하여 Correction 을 자동화했습니다.</p><p><strong>보안 고려사항:</strong></p><ul><li>⚠️ API 키를 절대 코드에 하드코딩하지 마세요.</li><li>✅ AWS Secrets Manager 또는 환경변수 사용</li><li>✅ Kubernetes Secret으로 주입 (권장)</li></ul><pre>#!/usr/bin/env python3<br>&quot;&quot;&quot;<br>SLO Correction Manager<br>배포 시 Datadog SLO Correction을 자동으로 생성/종료하는 스크립트<br>&quot;&quot;&quot;<br>import os<br>import sys<br>import json<br>import requests<br>from datetime import datetime, timezone, timedelta<br>from typing import List, Optional<br><br>class SLOCorrectionManager:<br>    &quot;&quot;&quot;Datadog SLO Correction 관리 클래스&quot;&quot;&quot;<br><br>def __init__(self, service_name: str, slo_tags: List[str]):<br>        &quot;&quot;&quot;<br>        초기화<br>        Args:<br>            service_name: 서비스 이름 (예: &#39;o4o-sales-api&#39;)<br>            slo_tags: SLO 필터링 태그 리스트 (예: [&#39;service:sales-api&#39;, &#39;env:prd&#39;])<br>        &quot;&quot;&quot;<br>        self.service_name = service_name<br>        self.slo_tags = slo_tags<br>        # 보안: AWS Secrets Manager 또는 환경변수에서 API 키 로드<br>        self.dd_api_key = self._get_secret(&#39;DD_API_KEY&#39;)<br>        self.dd_app_key = self._get_secret(&#39;DD_APP_KEY&#39;)<br>        if not self.dd_api_key or not self.dd_app_key:<br>            raise ValueError(&quot;Datadog API 키가 설정되지 않았습니다. DD_API_KEY, DD_APP_KEY 환경변수를 확인하세요.&quot;)<br>        self.headers = {<br>            &#39;DD-API-KEY&#39;: self.dd_api_key,<br>            &#39;DD-APPLICATION-KEY&#39;: self.dd_app_key,<br>            &#39;Content-Type&#39;: &#39;application/json&#39;<br>        }<br><br>    def _get_secret(self, key: str) -&gt; Optional[str]:<br>        &quot;&quot;&quot;<br>        보안: AWS Secrets Manager 또는 환경변수에서 시크릿 로드<br>        우선순위:<br>        1. 환경변수 (로컬 개발/테스트용)<br>        2. AWS Secrets Manager (프로덕션 권장)<br>        &quot;&quot;&quot;<br>        # 방법 1: 환경변수 (간단, 로컬 개발용)<br>        value = os.environ.get(key)<br>        if value:<br>            return value<br>        # 방법 2: AWS Secrets Manager (프로덕션 권장)<br>        try:<br>            import boto3<br>            from botocore.exceptions import ClientError<br>            secret_name = f&quot;datadog/{self.service_name}&quot;<br>            region_name = os.environ.get(&#39;AWS_REGION&#39;, &#39;ap-northeast-2&#39;)<br>            session = boto3.session.Session()<br>            client = session.client(service_name=&#39;secretsmanager&#39;, region_name=region_name)<br>            response = client.get_secret_value(SecretId=secret_name)<br>            secrets = json.loads(response[&#39;SecretString&#39;])<br>            return secrets.get(key)<br>        except (ImportError, ClientError) as e:<br>            print(f&quot;⚠️ AWS Secrets Manager에서 {key} 로드 실패: {e}&quot;)<br>            return None<br><br>    def get_slo_ids_by_tags(self) -&gt; List[str]:<br>        &quot;&quot;&quot;태그로 SLO 목록 조회&quot;&quot;&quot;<br>        print(f&quot;🔍 태그로 SLO 검색: {self.slo_tags}&quot;)<br>        url = &#39;https://api.datadoghq.com/api/v1/slo&#39;<br>        response = requests.get(url, headers=self.headers)<br>        if response.status_code != 200:<br>            print(f&quot;❌ SLO 목록 조회 실패: {response.status_code}&quot;)<br>            print(f&quot;응답: {response.text}&quot;)<br>            sys.exit(1)<br>        all_slos = response.json().get(&#39;data&#39;, [])<br>        slo_ids = []<br>        for slo in all_slos:<br>            slo_tags = slo.get(&#39;tags&#39;, [])<br>            # 모든 태그가 포함된 SLO만 선택<br>            if all(tag in slo_tags for tag in self.slo_tags):<br>                slo_ids.append(slo[&#39;id&#39;])<br>                print(f&quot;   ✓ {slo[&#39;name&#39;]} ({slo[&#39;id&#39;]})&quot;)<br>        return slo_ids<br><br>    def create_correction(self, slo_id: str, duration_hours: int = 1) -&gt; str:<br>        &quot;&quot;&quot;<br>        배포 시작 시 Correction 생성 (넉넉하게 1시간)<br>        Returns:<br>            correction_id: 생성된 Correction ID<br>        &quot;&quot;&quot;<br>        now = datetime.now(timezone.utc)<br>        end_time = now + timedelta(hours=duration_hours)  # 넉넉하게 설정<br>        payload = {<br>            &#39;data&#39;: {<br>                &#39;type&#39;: &#39;correction&#39;,<br>                &#39;attributes&#39;: {<br>                    &#39;category&#39;: &#39;Deployment&#39;,<br>                    &#39;description&#39;: f&#39;{self.service_name} 배포 ({now.strftime(&quot;%Y-%m-%d %H:%M:%S UTC&quot;)})&#39;,<br>                    &#39;slo_id&#39;: slo_id,<br>                    &#39;start&#39;: int(now.timestamp()),<br>                    &#39;end&#39;: int(end_time.timestamp()),  # 나중에 업데이트됨<br>                    &#39;timezone&#39;: &#39;Asia/Seoul&#39;<br>                }<br>            }<br>        }<br>        url = &#39;https://api.datadoghq.com/api/v1/slo/correction&#39;<br>        response = requests.post(url, headers=self.headers, json=payload)<br>        if response.status_code in [200, 201]:<br>            correction_id = response.json()[&#39;data&#39;][&#39;id&#39;]<br>            print(f&quot;✅ Correction 생성: {slo_id} → {correction_id}&quot;)<br>            return correction_id<br>        else:<br>            print(f&quot;❌ Correction 생성 실패: {response.status_code}&quot;)<br>            print(f&quot;응답: {response.text}&quot;)<br>            return None<br><br>    def end_correction(self, slo_id: str) -&gt; bool:<br>        &quot;&quot;&quot;<br>        배포 완료 시 종료 시간을 현재로 업데이트<br>        Returns:<br>            성공 여부<br>        &quot;&quot;&quot;<br>        now = datetime.now(timezone.utc)<br>        # 해당 SLO의 최근 Correction 조회<br>        url = f&#39;https://api.datadoghq.com/api/v1/slo/correction?slo_id={slo_id}&#39;<br>        response = requests.get(url, headers=self.headers)<br>        if response.status_code != 200:<br>            print(f&quot;❌ Correction 목록 조회 실패: {response.status_code}&quot;)<br>            return False<br>        corrections = response.json().get(&#39;data&#39;, [])<br>        # Deployment 카테고리의 최근 진행 중인 correction 찾기<br>        for correction in corrections:<br>            attrs = correction[&#39;attributes&#39;]<br>            # 조건: Deployment 카테고리 + 현재 서비스 + 진행 중(end가 미래)<br>            if (attrs.get(&#39;category&#39;) == &#39;Deployment&#39; and<br>                self.service_name in attrs.get(&#39;description&#39;, &#39;&#39;) and<br>                attrs.get(&#39;end&#39;, 0) &gt; int(now.timestamp())):<br>                correction_id = correction[&#39;id&#39;]<br>                # 종료 시간을 현재로 업데이트<br>                patch_url = f&#39;https://api.datadoghq.com/api/v1/slo/correction/{correction_id}&#39;<br>                patch_payload = {<br>                    &#39;data&#39;: {<br>                        &#39;type&#39;: &#39;correction&#39;,<br>                        &#39;attributes&#39;: {<br>                            &#39;end&#39;: int(now.timestamp())  # 실제 종료 시간으로 업데이트<br>                        }<br>                    }<br>                }<br>                patch_response = requests.patch(patch_url, headers=self.headers, json=patch_payload)<br>                if patch_response.status_code == 200:<br>                    print(f&quot;✅ Correction 종료: {correction_id}&quot;)<br>                    return True<br>                else:<br>                    print(f&quot;⚠️ Correction 업데이트 실패: {patch_response.status_code}&quot;)<br>                    return False<br>        print(f&quot;⚠️ 진행 중인 Correction을 찾지 못했습니다.&quot;)<br>        return False<br><br>    def start_deployment(self):<br>        &quot;&quot;&quot;배포 시작 - 모든 SLO에 Correction 생성&quot;&quot;&quot;<br>        slo_ids = self.get_slo_ids_by_tags()<br>        if not slo_ids:<br>            print(f&quot;⚠️ 태그에 해당하는 SLO가 없습니다: {self.slo_tags}&quot;)<br>            return<br>        print(f&quot;\\n📊 {len(slo_ids)}개 SLO에 Correction 생성&quot;)<br>        for slo_id in slo_ids:<br>            self.create_correction(slo_id)<br>        print(f&quot;\\n🚀 SLO Correction 생성 완료 ({self.service_name})&quot;)<br><br>    def end_deployment(self):<br>        &quot;&quot;&quot;배포 완료 - 모든 Correction 종료&quot;&quot;&quot;<br>        slo_ids = self.get_slo_ids_by_tags()<br>        if not slo_ids:<br>            print(f&quot;⚠️ 태그에 해당하는 SLO가 없습니다: {self.slo_tags}&quot;)<br>            return<br>        print(f&quot;\\n📊 {len(slo_ids)}개 SLO Correction 종료&quot;)<br>        success_count = 0<br>        for slo_id in slo_ids:<br>            if self.end_correction(slo_id):<br>                success_count += 1<br>        print(f&quot;\\n✅ SLO Correction 종료 완료 ({success_count}/{len(slo_ids)})&quot;)<br><br><br># 사용 예시<br>if __name__ == &#39;__main__&#39;:<br>    if len(sys.argv) &lt; 2:<br>        print(&quot;사용법: python slo_correction_manager.py [start|end]&quot;)<br>        sys.exit(1)<br>    # 환경변수에서 서비스 정보 로드<br>    service_name = os.environ.get(&#39;SERVICE_NAME&#39;, &#39;o4o-sales-api&#39;)<br>    slo_tags = os.environ.get(&#39;SLO_TAGS&#39;, &#39;service:sales-api,env:prd&#39;).split(&#39;,&#39;)<br>    manager = SLOCorrectionManager(service_name, slo_tags)<br>    command = sys.argv[1]<br>    if command == &#39;start&#39;:<br>        manager.start_deployment()<br>    elif command == &#39;end&#39;:<br>        manager.end_deployment()<br>    else:<br>        print(f&quot;❌ 알 수 없는 명령어: {command}&quot;)<br>        sys.exit(1)</pre><p><strong>설정 내용:<br></strong>처음 1시간으로 넉넉하게 생성하고 나중에 Hook 을 통해 실제 시간으로 업데이트됩니다. 배포 실패해도 ArgoCD PostSync Hook에서 자동으로 종료됩니다. 고정값을 사용하지 않고 태그 기반으로 조회하여 27개 SLO를 한 번에 관리할 수 있었습니다. <strong>AWS Secrets Manager로 API 키를 안전하게 관리</strong>했습니다. 특히 프로덕션 환경에서는 권장됩니다.</p><h4>CI/CD 통합: ArgoCD Hooks</h4><p>ArgoCD는 Kubernetes 배포를 직접 관리하니까, 배포 라이프사이클에 정확히 연동할 수 있었습니다.</p><h4>ArgoCD Hooks 구조</h4><pre># PreSync Hook - 배포 시작 직전 실행<br>apiVersion: batch/v1<br>kind: Job<br>metadata:<br>  annotations:<br>    argocd.argoproj.io/hook: PreSync           # 배포 시작 직전<br>    argocd.argoproj.io/sync-wave: &quot;-1&quot;         # 가장 먼저 실행<br>spec:<br>  template:<br>    spec:<br>      containers:<br>        - name: slo-correction-start<br>          image: python:3.11-slim<br>          command: [&quot;python3&quot;, &quot;/scripts/slo_correction_manager.py&quot;, &quot;start&quot;]<br><br>---<br># PostSync Hook - 배포 완료 후 실행<br>apiVersion: batch/v1<br>kind: Job<br>metadata:<br>  annotations:<br>    argocd.argoproj.io/hook: PostSync          # 배포 성공 후<br>    argocd.argoproj.io/sync-wave: &quot;10&quot;         # 마지막에 실행<br>spec:<br>  template:<br>    spec:<br>      containers:<br>        - name: slo-correction-end<br>          command: [&quot;python3&quot;, &quot;/scripts/slo_correction_manager.py&quot;, &quot;end&quot;]</pre><blockquote><em>💡 </em><strong><em>Tip</em></strong><em>: SyncFail Hook도 추가하면 배포 실패 시에도 Correction이 자동으로 종료됩니다. 위 YAML에 argocd.argoproj.io/hook: SyncFail만 추가하면 됩니다.</em></blockquote><p><strong>ArgoCD Hooks의 장점:</strong></p><ul><li>✅ Kubernetes 네이티브: 배포 상태를 정확히 추적</li><li>✅ 자동 재시도: Hook 실패 시 자동으로 재시도</li><li>✅ SyncFail Hook: 배포 실패 시에도 Correction 자동 종료</li></ul><h4>효과: Before/After 비교</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*VeCBgufZpMeEQxXGo-tMIA.png\" /></figure><h4>실제 개선 사례</h4><pre>MPOS-API (2025년 12월 적용):<br>- 자동화 적용 후 배포 중 오탐 알림 0건<br>- Error Budget 정확도: ±10초 이내로 개선<br><br>MOSS/SALES-API (2026년 1월 중순 적용):<br>- 적용 2주차, 배포 중 SLO 위반 없음<br>- 수동 대비 운영 시간 100% 절감</pre><blockquote><em>🚀 </em><strong><em>핵심 개선 포인트</em></strong></blockquote><blockquote>- <strong>ArgoCD</strong> <strong>PreSync/PostSync Hooks</strong>로 완전 자동화</blockquote><blockquote>- 전사 모든 팀에 즉시 적용 가능</blockquote><h3>결론: 다른 팀을 위한 가이드</h3><h4>핵심 배운 점 — 3가지 원칙</h4><p><strong>1. 데이터로 시작, 추측은 금지<br></strong>저희 팀은 최소 90일치 APM 데이터를 쭉 분석해서 p99 임계값을 설정했습니다. “이 정도면 되지 않을까?”라는 감으로 정하는 건 절대 금지입니다. 데이터가 답을 알려주니까요.</p><p><strong>2. 측정 정확도가 모든 것을 결정<br></strong>처음엔 HTTP 상태 코드로 성공/실패를 판단했는데, 이게 오탐의 주범이었습니다. APM error 기반으로 전환하자마자 오탐이 싹 사라졌습니다. 측정 방식만 바꿨는데 오탐 100% 제거되었습니다.</p><p><strong>3. 자동화하지 않으면 유지되지 않는다<br></strong>배포할 때마다 SLO Correction을 수동으로 등록하는 건 말이 안 됩니다. (일단 너무 귀찮습니다.) 까먹기도 하고, 시간도 틀리고… ArgoCD Hooks로 완전 자동화하니까 휴먼 에러가 0%가 됐습니다.</p><h4>체크리스트: 다른 팀 적용 시</h4><pre>Phase 1: 준비 (1-2일)<br>□ 서비스 Critical Path 정의 (비즈니스 영향 큰 API)<br>□ APM 도구 설정 완료 (Datadog, New Relic 등)<br>□ 팀원 교육 (SLO/SLI/Error Budget 개념)<br><br>Phase 2: 데이터 수집 및 분석 (2-3일)<br>□ 90일 APM 데이터 확보 (p50/p95/p99)<br>□ 과거 장애 이력 분석 (반복 패턴 추출)<br>□ 서비스 의존성 맵 작성<br><br>Phase 3: SLO 설정 (1-2일)<br>□ 3-5개 핵심 SLO 선정 (처음부터 완벽할 필요 없음)<br>□ APM error 기반 측정 설정<br>□ Burn Rate 알림 설정 (긴급/주의 2단계)<br><br>Phase 4: 자동화 (1~3일)<br>□ 배포 파이프라인에 Correction 통합<br>□ CI/CD 또는 ArgoCD Hooks 연동<br>□ 테스트 배포로 검증<br><br>Phase 5: 운영 (지속)<br>□ 주간 리뷰: Error Budget 잔여량 확인<br>□ 월간 리뷰: 임계값 재조정<br>□ 문서화: Wiki에 설정 근거 기록</pre><h4>당장 시작할 수 있는 리소스</h4><p><strong>1. 이 글에 포함된 전체 코드</strong></p><ul><li>위에 작성된 Python 스크립트를 그대로 사용 가능</li><li>AWS Secrets Manager 통합 포함</li><li>환경변수 fallback 지원</li></ul><p><strong>2. Datadog 공식 문서</strong></p><ul><li><a href=\"https://docs.datadoghq.com/api/latest/service-level-objectives/#create-an-slo-correction\">SLO Correction API</a></li><li><a href=\"https://docs.datadoghq.com/api/latest/service-level-objectives/\">SLO API 전체 문서</a></li></ul><p><strong>3. Google SRE 참고 자료</strong></p><ul><li><a href=\"https://sre.google/workbook/slo-engineering-case-studies/\">SLO Engineering Case Studies</a></li><li><a href=\"https://sre.google/workbook/implementing-slos/\">Implementing SLOs</a></li><li><a href=\"https://sre.google/workbook/alerting-on-slos/\">Alerting on SLOs</a> — Burn Rate 계산 방법</li></ul><p><strong>4. ArgoCD Resource Hooks</strong></p><ul><li><a href=\"https://argo-cd.readthedocs.io/en/stable/user-guide/resource_hooks/\">ArgoCD Hooks 공식 문서</a></li><li>PreSync, PostSync, SyncFail Hook 사용법</li></ul><p><strong>5. 실제 대시보드 예시</strong> (참고용)</p><ul><li><a href=\"https://app.datadoghq.com/dashboard/txv-kcm-w5n\">O4O sales-api SLO Dashboard</a></li><li><a href=\"https://app.datadoghq.com/dashboard/k89-xsh-bxb\">O4O moss-api SLO Dashboard</a></li><li><a href=\"https://app.datadoghq.com/dashboard/7i3-nth-7ve\">O4O mpos-api SLO Dashboard</a></li></ul><h3>고객에게 미치는 긍정적 영향</h3><p>장애 발생 전 경고 알림 등을 통해 사전에 서비스 안정성을 점검할 수 있습니다.</p><p><strong>오프라인 매장에서:<br></strong>MPOS의 안정성이 좋아지면서 가장 먼저 체감되는 건 계산 대기 시간이 줄어든다는 겁니다. 결제 오류로 “고객님, 잠시만 대기해주시겠어요?” 하는 상황이 거의 사라지니까 고객 불편이 최소화됩니다. 그리고 매장 직원 입장에서도 시스템 장애 대응하느라 허둥대지 않고 고객 응대에 집중할 수 있게 됩니다.</p><h3>우리 팀과 함께 일하기</h3><p><a href=\"https://medium.com/@gunpyo.park/%EB%AC%B4%EC%8B%A0%EC%82%AC-%EC%98%A4%ED%94%84%EB%9D%BC%EC%9D%B8-%EC%9C%A0%EB%8B%88%EB%B2%84%EC%8A%A4%EB%A5%BC-%EB%A7%8C%EB%93%9C%EB%8A%94-%ED%8C%80-o4o%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A7%81-5a57ed4c635e\">O4O 팀은 이렇게 일합니다</a>:</p><p><strong>문제 해결 중심</strong></p><ul><li>“왜 이런 알림이 오는가?”에서 출발</li><li>데이터로 검증하고, 코드로 자동화</li><li>AI를 적극 활용해 생산성 향상</li></ul><p><strong>빠른 실행</strong></p><ul><li>2주 만에 27개 SLO + 완전 자동화 완성</li><li>실패를 두려워하지 않고 빠르게 시도</li><li>문서화와 공유로 팀 전체 역량 향상</li></ul><p><strong>성장하는 문화</strong></p><ul><li>신규입사자도 첫날부터 대시보드 이해 가능</li><li>PBO 기술조직 Tech Talk로 지식 공유</li><li>다른 팀의 SLO 도입 지원</li></ul><p><strong>이런 분을 찾습니다:</strong></p><ul><li>문제를 데이터로 분석하고 싶은 분</li><li>자동화로 반복 작업을 줄이고 싶은 분</li><li>팀의 성장에 기여하고 싶은 분</li></ul><p>무신사 O4O 팀에서 함께 더 나은 서비스를 만들어가실 분을 기다립니다.<br>🔗 <a href=\"https://kr.linkedin.com/posts/tantol-hansol-kang_%EB%AC%B4%EC%8B%A0%EC%82%AC-%EC%B1%84%EC%9A%A9%ED%99%88%ED%8E%98%EC%9D%B4%EC%A7%80-activity-7415260465129312257-xgrA?utm_source=li_share&amp;utm_content=feedcontent&amp;utm_medium=g_dt_web&amp;utm_campaign=copy\">무신사 PBO 조직 채용</a><br>🔗 무신사 채용 페이지: <a href=\"https://corp.musinsa.com/ko/\">https://corp.musinsa.com/ko/</a></p><h3>참고 링크</h3><p><strong>SLO/SRE 관련</strong></p><ul><li><a href=\"https://sre.google/workbook/implementing-slos/\">Google SRE Workbook — Implementing SLOs</a></li><li><a href=\"https://sre.google/workbook/alerting-on-slos/\">Google SRE Workbook — Alerting on SLOs (Burn Rate 계산 방법)</a></li><li><a href=\"https://sre.google/workbook/slo-engineering-case-studies/\">Google SRE Workbook — SLO Engineering Case Studies</a></li><li><a href=\"https://www.datadoghq.com/blog/establishing-service-level-objectives/\">Datadog — SLO Best Practices</a></li></ul><p><strong>Datadog API 공식 문서</strong></p><ul><li><a href=\"https://docs.datadoghq.com/api/latest/service-level-objectives/#create-an-slo-correction\">SLO Correction API</a></li><li><a href=\"https://docs.datadoghq.com/api/latest/service-level-objectives/\">Service Level Objectives API</a></li><li><a href=\"https://docs.datadoghq.com/tracing/error_tracking/\">APM Error Tracking</a></li></ul><p><strong>ArgoCD &amp; Kubernetes</strong></p><ul><li><a href=\"https://argo-cd.readthedocs.io/en/stable/user-guide/resource_hooks/\">ArgoCD Resource Hooks</a></li><li><a href=\"https://kubernetes.io/docs/concepts/workloads/controllers/job/\">Kubernetes Jobs</a></li></ul><p><strong>AWS 보안</strong></p><ul><li><a href=\"https://docs.aws.amazon.com/secretsmanager/\">AWS Secrets Manager</a></li><li><a href=\"https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/secretsmanager.html\">AWS Secrets Manager Python SDK</a></li></ul><p><strong>글쓴이</strong></p><p><strong>성주현 — </strong>데이터 기반 의사결정, 자동화와 개발 생산성 향상, AI를 활용한 소프트웨어 개발을 하고 있습니다.</p><p>#musinsa #pbo #o4o #Backend #sre</p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=8043957a74f0\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://techblog.musinsa.com/%EC%B6%94%EC%B8%A1%EC%9D%B4-%EC%95%84%EB%8B%8C-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A1%9C-3%EA%B0%9C-%EC%84%9C%EB%B9%84%EC%8A%A4-27%EA%B0%9C-slo%EC%99%80-54%EA%B0%9C-%EB%AA%A8%EB%8B%88%ED%84%B0%EB%A5%BC-%EC%84%A4%EC%A0%95%ED%95%98%EA%B3%A0-%EB%B0%B0%ED%8F%AC-%EC%9E%90%EB%8F%99%ED%99%94%EA%B9%8C%EC%A7%80-%EA%B5%AC%EC%B6%95%ED%95%9C-2%EC%A3%BC%EC%9D%98-%EC%A7%91%EC%A4%91-%EC%9E%91%EC%97%85-8043957a74f0\">추측이 아닌 데이터로: 3개 서비스 27개 SLO와 54개 모니터를 설정하고 배포 자동화까지 구축한 2주의 집중 작업</a> was originally published in <a href=\"https://techblog.musinsa.com\">MUSINSA techblog — 무신사 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2026-02-22T22:01:00.000Z",
    "url": "https://techblog.musinsa.com/%EC%B6%94%EC%B8%A1%EC%9D%B4-%EC%95%84%EB%8B%8C-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A1%9C-3%EA%B0%9C-%EC%84%9C%EB%B9%84%EC%8A%A4-27%EA%B0%9C-slo%EC%99%80-54%EA%B0%9C-%EB%AA%A8%EB%8B%88%ED%84%B0%EB%A5%BC-%EC%84%A4%EC%A0%95%ED%95%98%EA%B3%A0-%EB%B0%B0%ED%8F%AC-%EC%9E%90%EB%8F%99%ED%99%94%EA%B9%8C%EC%A7%80-%EA%B5%AC%EC%B6%95%ED%95%9C-2%EC%A3%BC%EC%9D%98-%EC%A7%91%EC%A4%91-%EC%9E%91%EC%97%85-8043957a74f0?source=rss----f107b03c406e---4"
  },
  {
    "publisherId": "musinsa",
    "publisherName": "무신사 테크블로그",
    "specTitle": "e커머스 개발",
    "categories": [
      "backend"
    ],
    "specUrl": "https://medium.com/feed/musinsa-tech",
    "title": "무신사 오프라인 제품팀이 슬랙 대신 무전기를 들게된 사연",
    "partialText": "<p>무신사의 오프라인/리테일 제품을 담당하는 O4O(Online for Offline) 팀 17명의 무신사 스탠다드 매장 파트타임 체험기를 들려드려요.</p><h3>오프라인 확장기의 무신사</h3><p>O4O팀에 프로덕트 디자이너로 입사 후 <em>“오프라인 사업에서 지금 중요한건 뭘까?” </em>라는 질문에 답하기 위해 오프라인 사업부문 임직원분들과 인터뷰를 여러 차례 진행했어요. 이 과정을 통해 오프라인 사업은 크게 3가지 단계가 있다는 것을 알게 되었습니다.</p><ul><li><strong>도입기</strong> : 확장을 위한 재무/시스템적 구조를 갖추는 단계.</li><li><strong>확장기</strong> : 공격적으로 매장을 확장하는 단계.</li><li><strong>성숙기 </strong>: 안정적인 운영 위에 리뉴얼, 재배치 관리 등을 진행하는 단계.</li></ul><p>무신사는 이 중 확장기 단계로 진입하고 있었기에, 매장을 수십개 오픈하더라도 이슈가 없는 ‘확장성/안정성 있는 시스템’이 매우 중요한 시점이었습니다.</p><h3>오프라인은 저희도 처음인데요..</h3><p>하지만 저를 포함해 O4O 팀의 대부분은 온라인 제품 경력만 가지고 있는 상황.. 매장이 어떻게 돌아가는지, 그곳에서는 무엇이 가장 중요한지 소통할 수 있는 창구는 슬랙 채널 뿐이었어요.</p><p>슬랙으로는 현장 최전선에 계신 분들에게 온전히 이입하기 어렵다는 판단으로, 팀 채널에 파트타임 체험 모집을 열었는데..</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/800/1*00E81uWuicawwxWe-v41dQ.png\" /></figure><p>PM, PD, FE, BE, QA 직군을 가리지 않고 많은 팀원들이 앞다퉈(?) 신청을 해주셨고, 그룹의 부문장님이나 PM 조직의 실장님까지 참여하게되었어요. 감사하게도 무신사 리테일 서비스팀의 도움을 받아 전원이 무신사 스탠다드 매장 4곳에 배치가 되었습니다.</p><h3>본격적으로 무전기를 들다</h3><p>O4O팀이 배정된 매장은 잠실, 용산 메가스토어, 홍대, 명동점이었는데요. 각 매장마다 입점 조건, 층수, 고객 비율 등의 특징이 달랐어요.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/800/1*Eo8KUYmNGCaHddq9C-UwQQ.png\" /></figure><p>매장에서는 1인 당 이름표와 워키(무전기)도 나눠 주시고 꼼꼼하게 여러 업무의 온보딩도 진행해주셨습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/400/1*Pti-8CmQiU1u7OHyS2THAw.png\" /><figcaption>이름표 배부와 온보딩 시간</figcaption></figure><p>온보딩 후에는 시간대별로 다양한 매장 업무에 집중했어요.</p><ul><li><strong>오픈 전</strong> : 입고된 재고의 스타일별 소팅 및 창고 적재 등 업무</li><li><strong>오픈 후</strong> : POS 결제, 피팅룸, DP 상품 리필, 재고 반출 등 업무</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*qnlgX9TkXCoAg6x6v3JZbQ.png\" /><figcaption>열심히 파트타임중인 팀원들</figcaption></figure><p>실제 현장 경험을 해보니.. 그냥 잘 돌아가는줄만 알았던 매장이 사실은 수많은 매니저와 크루 분들의 피땀과 노하우로 돌아가고 있다는 사실을 알게됐어요. 동시에 제품의 관점에서 최전선에 계신 분들의 업무 효율을 어떻게 향상시킬 수 있는지에 대한 아이디어도 많이 얻을 수 있었습니다.</p><h3>발견했던 주요 문제들</h3><p>온라인 커머스와 달리, 오프라인 매장은 장바구니에 넣어놨다가 몇일 후 다시 구매할 수 없어요. 즉시성이 중요한 매장에서 발생하는 허들 하나 하나가 모두 결제까지의 흐름을 방해하는 원인이 되기 때문에 주의깊게 문제를 관찰했습니다.</p><h4>수기/수동 작업으로 인한 운영 비효율</h4><ul><li>RFID를 도입하기 위해 변경된 신규 바코드 체계와 그 이전 구 바코드 체계가 매장 내에 혼용되면서, 같은 상품이지만 다른 바코드를 가진 케이스 존재. 숙련된 크루들만 구별 가능하고, 신규 크루들은 재고 조회/적재가 어려워지는 구간 발생.</li><li>매일 아침 수십 개의 박스를 일일이 열어 DP용과 창고용 등 분류 작업을 수기로 작업하는 상황.</li><li>판매된 DP 상품을 채우기 위해 시간별로 변경되는 Top 상품, 품목별 리필 개수, 재고 유무 등 여러 정보를 각기 다른 곳에서 확인해야 하는 번거로움 발생.</li></ul><h4>재고 정합성 오차</h4><ul><li>레거시 시스템의 재고 오차와 재고 실사의 휴먼에러 등으로 재고 조회 화면의 신뢰도를 높여야 하는 상황.</li></ul><h4>낮은 PDA 보급율</h4><ul><li>공용 PDA 보급율이 낮아 필요한 사람이 직접 정보를 조회하기보다 음질이 좋지 않은 워키(무전기)를 통해 다른 크루에게 요청하는 불편함 발생.</li></ul><p>발견한 주요 문제들은 제품 자동화나 정합성 보정, PDA용 제품 고도화 및 보급율 향상 등을 통해 해결해 나갈 예정이에요.</p><h3>파트타임 경험이 휘발되지 않도록</h3><p>팀원들의 경험이 날아가지 않도록 파트타임 종료 이후 회고 시간을 잡아두었는데요. 이게 웬걸.. 참여한 팀원들이 매장별로 문제점/인사이트/해결방안 등을 wiki 문서로 정리를 해와버렸습니다.. (감동)</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/800/1*p2tkPDxOBmXJiWuPq5mrfA.png\" /></figure><p>이후 리더분들을 포함한 회고를 진행해 빠르게 해결할 수 있는 일과 이후의 OKR로 진행해봐야할 일, 물류 등 O4O 팀을 너머 고민해봐야할 일로 나눠 관리하고있습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/333/1*Fxvk94E-3GOVO1W-y_MD_w.png\" /><figcaption>파트타임 체험 수료증도 제작했다</figcaption></figure><h4>프로덕트 디자이너의 시선으로 본 온라인 vs 오프라인 디자인</h4><p>온라인 제품의 디자인 영역이 ‘화면’까지라면, 오프라인 제품은 ‘동선’까지가 디자인 영역이라고 볼 수 있을 것 같아요. 사무실에서 PC를 보거나 집에서 앱을 쓰는 사용성과는 다릅니다. 매장을 누비며 일하거나 길게 줄서있는 고객들 앞에서 응대해야하는 사용성은 훨씬 더 입체적인 디자인 고려가 필요하다고 생각해요. 이와 관련된 내용은 다음 포스트에서 상세하게 다뤄볼 예정입니다.</p><h3>마무리</h3><p>유니클로, 자라 등 오프라인에서부터 시작한 타 브랜드와 온라인에서부터 시작한 무신사는 태생적인 차이가 있어요. 이미 오프라인 운영이 안정화 되어있는 브랜드들을 단시간에 뛰어넘어, 무신사만의 차별화를 만들기 위해 O4O팀의 책임은 막중합니다. 하지만 그만큼 회사에 기여할 수 있는 팀이라는 점이 매력적이기도 해요.</p><p>이번 파트타임 체험을 가능하게 해주신 무신사 리테일 서비스팀과 오프라인 사업부, 그리고 초보 파트타임 실수에도 인내로 지도해주신 매장에 다시한번 감사드리며.. 오프라인 비즈니스를 더 견인하는 O4O팀이 되도록 노력하겠습니다.</p><p>O4O팀에 대해 더 궁금하신 분들은 아래 글들도 참고해보세요 :)</p><ul><li><a href=\"https://medium.com/u/8811144aa51b\">Gunpyo Park</a>님의 <a href=\"https://medium.com/@gunpyo.park/무신사-오프라인-유니버스를-만드는-팀-o4o엔지니어링-5a57ed4c635e\">O4O 엔지니어링팀에 대한 소개글</a></li><li><a href=\"https://medium.com/u/bcccbc1c79df\">Brian Lim</a>님의 <a href=\"https://medium.com/@djadla/왜-무신사에-합류했나요-2e711ede4ded\">무신사에 합류한 이유와 O4O를 바라보는 관점에 대한 글</a></li></ul><h3>Platform Business Operation 조직 및 팀 소개</h3><blockquote><em>무신사 플랫폼 비즈니스 오퍼레이션 조직은 국내외 물류 서비스, 재고 관리, 스토어 운영을 위한 물류 프로덕트를 구축하고 다양한 오프라인 비즈니스 모델에 맞춘 스토어 관리 시스템을 개발·고도화하고 있습니다.<br>또한, 무배당발 서비스를 포함한 무신사의 차별화된 고객 경험을 브랜딩하고 확장할 수 있는 멤버십 구조를 설계하며, 온·오프라인을 넘나드는 통합 커머스 경험을 기술로 실현하고 있습니다.</em></blockquote><blockquote><em>저희 팀은 OMS(주문관리시스템)를 기반으로 온라인 주문부터 재고·출고·배송·정산에 이르는 전 과정을 유기적으로 연결하고, 무신사의 다양한 오프라인 스토어를 효과적으로 운영할 수 있는 관리 시스템을 구축하여 고객이 온라인(무신사 스토어, 29CM 등)과 오프라인(무신사 스탠다드, 편집숍 등)에서 끊김 없는 쇼핑 경험을 누릴 수 있도록 지원합니다.</em></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/pbo\"><em>🚀 Platform Business Operation 한걸음 더 알아보기</em></a></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/home\"><em>🚀 팀 무신사 채용 페이지</em></a><em> (무신사/29CM 전체 포지션 확인이 가능해요)</em></blockquote><blockquote><em>🚀 </em><a href=\"https://kr.linkedin.com/company/musinsacom\"><em>팀 무신사 테크 소식을 받아보는 링크드인</em></a></blockquote><blockquote><em>🚀 </em><a href=\"https://newsroom.musinsa.com/\"><em>팀 무신사 뉴스룸</em></a></blockquote><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=1e5aa0ad45f7\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://techblog.musinsa.com/%EB%AC%B4%EC%8B%A0%EC%82%AC-%EC%98%A4%ED%94%84%EB%9D%BC%EC%9D%B8-%EC%A0%9C%ED%92%88%ED%8C%80%EC%9D%B4-%EC%8A%AC%EB%9E%99-%EB%8C%80%EC%8B%A0-%EB%AC%B4%EC%A0%84%EA%B8%B0%EB%A5%BC-%EB%93%A4%EA%B2%8C%EB%90%9C-%EC%82%AC%EC%97%B0-1e5aa0ad45f7\">무신사 오프라인 제품팀이 슬랙 대신 무전기를 들게된 사연</a> was originally published in <a href=\"https://techblog.musinsa.com\">MUSINSA techblog — 무신사 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2026-02-20T09:01:02.000Z",
    "url": "https://techblog.musinsa.com/%EB%AC%B4%EC%8B%A0%EC%82%AC-%EC%98%A4%ED%94%84%EB%9D%BC%EC%9D%B8-%EC%A0%9C%ED%92%88%ED%8C%80%EC%9D%B4-%EC%8A%AC%EB%9E%99-%EB%8C%80%EC%8B%A0-%EB%AC%B4%EC%A0%84%EA%B8%B0%EB%A5%BC-%EB%93%A4%EA%B2%8C%EB%90%9C-%EC%82%AC%EC%97%B0-1e5aa0ad45f7?source=rss----f107b03c406e---4"
  },
  {
    "publisherId": "musinsa",
    "publisherName": "무신사 테크블로그",
    "specTitle": "e커머스 개발",
    "categories": [
      "backend"
    ],
    "specUrl": "https://medium.com/feed/musinsa-tech",
    "title": "무신사의 AI 코드 리뷰 프로세스 구축기",
    "partialText": "<p>안녕하세요. 무신사 Core Engineering/Personalization 팀에서 프론트엔드 개발을 맡고 있는 김의중입니다.<br>이 글은 LLM 기반 코드 리뷰를 무신사에 도입하고, 운영 가능한 수준의 인프라와 표준화된 프로세스로 구축해온 과정을 담고 있습니다. 단순히 “AI를 도입했습니다”가 아니라, <strong>도입 과정에서 마주한 시행착오와 이를 해결해 나간 방법</strong>을 공유합니다. 무신사의 여러 엔지니어들이 함께 아이디어를 모으고, 각자의 경험과 관찰을 공유하며 어떻게 AI 인프라로 발전시켰는지 그 과정의 기록입니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*YGFe1UTiYSTgwDOB71g-2w.png\" /><figcaption>출처: ChatGPT</figcaption></figure><h3>1. 왜 지금 AI 코드 리뷰인가?</h3><h4>과거의 한계 — “높은 진입장벽”</h4><p>AI를 활용한 코드 리뷰 는 새로운 아이디어가 아닙니다. 다만 과거에는 실무에 도입하기에는 ‘구축 비용’ 이라는 장벽이 다소 높았습니다. EKS(Kubernetes)에 Ollama 같은 LLM 서버를 직접 띄워서 운영 한다던지, PR이 생성될 때마다 diff를 추출해, 전송하고, 응답을 파싱해서 다시 코멘트로 작성하는 전체 파이프라인을 직접 설계 운영 해야 했습니다.</p><h4>전환점: anthropics/claude-code-action@v1 정식 출시</h4><p>Anthropic에서 GitHub Actions을 공식 지원하면서 이러한 문제들이 해소되었습니다. 이제 복잡한 인프라 구축 없이 몇 줄의 YAML만으로 고품질 코드 리뷰를 도입할 수 있게 되었습니다. 기술적 진입 장벽이 허물어지면서, <strong>‘구축’이 아닌 ‘활용’</strong>에 집중할 수 있는 시점을 맞이했습니다.</p><h4>AI 코드 리뷰의 가치 “워크플로우 증강하는 AI”</h4><p>AI를 단순히 코드를 생성하는 도구에 머무르기보다, <strong>협업 과정 전체를 매끄럽게 만드는 워크플로우 증강 도구</strong>로 활용하는 것이 중요합니다. 복잡한 변경 사항을 자동으로 요약해 리뷰어가 빠르게 맥락을 파악하도록 도울 뿐만 아니라, <strong>코드 라인 단위의 인라인 코멘트로 개선 방향을 구체적으로 제안하고, 누락된 예외 처리나 잠재적 버그까지 짚어주는 역할</strong>도 수행합니다.<br>이러한 기능들은 자연스럽게 리뷰 병목을 줄여주고, 팀 전체의 품질 기준을 일정 수준 이상으로 유지하는 데 큰 도움을 줍니다. 그 결과, 개인 개발자의 작업 속도만 빨라지는 것이 아니라 <strong>팀 전체의 개발 사이클이 더 유연하게 연결되는 구조적 효율성</strong>이 생깁니다.<br>결국 지금 LLM 코드 리뷰가 중요한 이유는 “코드를 대신 짓는 AI”가 등장해서가 아니라, <strong>AI가 팀의 워크플로우를 근본적으로 재설계하며 조직의 생산성을 실질적으로 끌어올리는 핵심 기술로 자리 잡았기 때문</strong>입니다.</p><h3>2. AI 코드 리뷰가 효과적인 이유</h3><h4>AI가 코드 리뷰를 잘하는 이유: 규칙과 패턴을 ‘꾸준히’ 잡아낸다</h4><p>코드는 자연어보다 훨씬 <strong>규칙적</strong>이고, 좋은 코드에는 반복되는 <strong>베스트 프랙티스 패턴</strong>이 있습니다. AI는 이런 패턴을 대량으로 학습해 두었기 때문에, 사람이 피곤하거나 바쁜 상황에서 놓치기 쉬운 것들을 <strong>일관된 기준으로</strong> 찾아냅니다.</p><ul><li>사소한 오타/휴먼 에러</li><li>흔한 성능 실수(불필요한 렌더/루프/쿼리 등)</li><li>스타일/컨벤션 불일치</li></ul><p>즉, AI에게 “고차원 의사결정”을 기대하기보다, <strong>반복적으로 발생하는 실수와 패턴 기반 이슈를 먼저 걸러서 리뷰어의 시간을 아끼는 것</strong>이 가장 큰 가치입니다.</p><h4>인라인 코멘트: 사람이 받기 좋은 형태로 피드백하기</h4><p>코드 리뷰에서 중요한 건 “요약”이 아니라 <strong>어디를 왜 고쳐야 하는지</strong>입니다.<br>anthropics/claude-code-action@v1은 인라인 코멘트를 공식 지원해서, 문제가 있는 라인에 바로 코멘트를 남기고:</p><ul><li>버그/성능/구조/스타일 같은 <strong>카테고리</strong>를 명확히 하고</li><li>“왜 문제인지 + 어떻게 바꾸면 좋은지”를 함께 제시합니다.</li></ul><p>그래서 작성자는 해당 라인에서 바로 맥락을 잡고, “AI가 뭘 근거로 말하는지”도 빠르게 확인할 수 있습니다.</p><h4>커밋 Suggestion: 리뷰를 넘어 실제 ‘패치’까지 자동 제안</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*OZVyUyHmtzG0az9912UQ0w.png\" /></figure><p>단순히 의견을 말하는 수준을 넘어서 <strong>GitHub의 Suggestion 블록을 활용해 실제 적용 가능한 수정안(diff)를 생성합니다</strong>. 즉, 리뷰 중 발견한 문제를 <strong>바로 적용 가능한 패치 형태로 만들어줍니다.</strong></p><p>이런 제안을 클릭 한 번으로 커밋에 반영할 수 있어, 사실상 <em>AI가 자동으로 작은 리팩토링과 안전한 수정 작업을 PR 과정에서 도와주는 흐름</em>이 만들어집니다. 결국 <strong>팀 전체의 리뷰 속도와 코드 품질이 자연스럽게 올라가는 구조</strong>가 됩니다</p><h3>3. “몇 줄의 YAML”로 끝나는 AI 코드 리뷰 도입</h3><h4>도입은 3단계면 끝납니다.</h4><p><strong>1단계: 토큰 발급</strong></p><pre>claude setup-token</pre><p>Claude Pro/Max 구독자라면 터미널에서 위 명령어 한줄로 인증 토큰을 발급받을 수 있습니다.</p><p><strong>2단계: GitHub Secrets 등록</strong></p><p>발급받은 토큰을 Organization의 Secrets에 CLAUDE_CODE_OAUTH_TOKEN으로 등록합니다.</p><p><strong>3단계: Workflow 파일 추가</strong></p><p>.github/workflows/claude-review.yml 파일을 생성하고 설정을 붙여 넣습니다.</p><h4>자주 묻는 질문: 토큰 비용</h4><blockquote><strong><em>Q. 토큰 발급과 사용은 유료인가요?</em></strong></blockquote><p>많은 분들이 오해하시는 부분으로 Pro/Max 플랜에 한하여 추가 API 비용은 없습니다. claude setup-token으로 생성하는 것은 <strong>API 키가 아닌 Claude 구독 인증 토큰</strong>입니다. 따라서 플랜의 사용량 <strong>한도 내에서 무료로 사용 가능</strong>합니다. 이 부분 때문에 도입을 망설이셨다면 안심하고 시작하셔도 됩니다.</p><h3>4. 함께 다듬다: 전사 프로세스 시스템 구축</h3><h4>공유 하나가 시작된 연쇄 반응</h4><p><strong>AI 코드 리뷰 가이드</strong>를 만들어 전사에 공유하자, 슬랙 스레드에는 <strong>43개의 댓글</strong>이 달렸습니다. 각 팀에서 자발적으로 “우리 팀은 이렇게 쓰고 있다”, “이런 문제가 있었는데 이렇게 해결했다”, “이건 이렇게 바꾸면 더 좋지 않을까”라는 논의가 이어졌습니다. 이 논의들은 <strong>LLM 코드 리뷰가 단순 스크립트에서 견고한 사내 인프라로 발전</strong>하는데 중요한 계기가 되었습니다.</p><h4>사례1: 개인 토큰에서 전사 공용 토큰으로(확장성)</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Mcp4Ee05YuX6-JW0MSgljA.png\" /></figure><p>처음에는 각자 개인 Claude 토큰을 발급받아 사용했습니다. 하지만 <strong>송정훈</strong>(<strong>29CM Engineering)님</strong> 은 <strong>모든 개발 조직이 더 안정적으로 사용할 수 있는 구조를 고민해</strong> “개인 토큰과 리뷰용 계정을 분리하여 관리하자”는 제안을 주셨습니다. 이 제안 덕분에 코드 리뷰 전용 전사 Claude 토큰을 발급받았고, 이를 GitHub Organization Secret(secrets.CLAUDE_CODE_TOKEN)으로 등록했습니다. 덕분에 무신사의 모든 레포지토리에서는 개별적인 키 발급 없이 안전하고 편리하게 AI 리뷰를 적용할 수 있는 기반이 만들어졌습니다.</p><h4>사례2: 기록은 남기고, 노이즈만 지운다(사용성)</h4><p>LLM 코드 리뷰를 PR에 붙이면 흔히 겪는 문제가 있습니다. <strong>커밋할 때마다 코멘트가 쌓여 PR이 지저분해지는 현상</strong>입니다.<br>처음에는 “그냥 전부 삭제하면 되지 않나?”라고 생각하기 쉽지만, 그렇게 하면 사람이 남긴 중요한 논의까지 같이 사라져 버립니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*TXM_XTunFttKi1uaiQtdRw.png\" /></figure><p><strong>임영태(MSS Engagement Frontend)</strong>님은 이 문제를 “무조건 삭제”가 아니라 ‘가치 있는 기록은 남기고, 봇이 만든 노이즈만 정리’하는 방식으로 풀었습니다. 핵심은 상태 기반 정책입니다.</p><ul><li><strong>보존:</strong> 사람이 답글을 달았거나, 이미 <strong>Resolved</strong> 처리된 스레드 → 팀이 의미 있게 소비한 기록</li><li><strong>삭제:</strong> 아무 상호작용 없이 방치된 미해결 봇 코멘트 → 반복 생성되는 노이즈</li></ul><p>이 방식 덕분에 PR 타임라인은 사람이 남긴 의미 있는 논의 중심으로 깔끔하게 유지되면서도, AI의 피드백은 적시에 필요한 만큼만 제공되는 쾌적한 리뷰 환경이 완성되었습니다.</p><h4>사례3: “Composite Action”으로 사내 플랫폼 구축</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*oMvz_DiEgMXvzJeqET_bXw.png\" /></figure><p>여러 레포지토리에 스크립트를 복사해서 쓰다 보니, 프롬프트 한 줄을 고치려 해도 모든 저장소를 수정해야 하는 ‘파편화 문제’가 발생했습니다. <strong>최용한(MSSnE Backend/Campaign) </strong>님은 이 비효율을 개선하기 위해, 무신사 공용 워크플로우 저장소(musinsa/workflows)에 액션을 추가했습니다. 그리고 <strong>홍일선(MSS Engineering/MSSnE Backend)</strong> 님의 제언이 더해져, 단순 공유를 넘어선 <strong>Composite Action</strong> 기반의 표준화된 구조로 고도화되었습니다. <strong>복잡한 로직은 중앙 저장소에 캡슐화하고, 각 서비스 레포에서는 몇 줄의 설정만 가져다 사용하는 구조</strong>입니다.</p><ul><li><strong>복잡함은 숨기고, 편의성은 높이다</strong> <br>리뷰 실행, 이전 코멘트 정리 같은 로직을 공용 레포지토리에 <strong>Composite Action</strong> 형태로 패키징했습니다. 덕분에 각 서비스 레포지토리에서는 내부 구현을 알 필요 없이, 마치 오픈소스 액션을 쓰듯, 단 몇 줄의 YAML로 모든 기능을 호출할 수 있습니다.</li><li><strong>“전사 표준”과 “팀별 커스텀”의 유연한 분리 </strong><br>“다 똑같이 해”가 아니라 <strong>공통 규칙은 지키되, 팀별 특성은 남길 수 있게</strong>. Composite Action의 inputs 기능을 활용해 인터페이스를 설계했습니다.</li><li><strong>고정 영역 (전사 표준):</strong> 이전 리뷰 자동 정리(Resolved 보존), 중복 코멘트 제거 로직, 기본 프롬프트 골격과 출력 포맷등은 중앙에서 관리하여 조직 전체 품질 표준을 유지합니다.</li><li><strong>가변 영역:</strong> review_language, project_context_path(CLAUDE.md 등), extra_prompt 등 팀별로 특화가 필요한 부분만 파라미터(with)로 열어두었습니다.</li></ul><p>이 구조 덕분에 “전사 공통 규칙”을 안전하게 지키면서도, 도메인 특성에 맞는 “팀별 유연성”을 확보했습니다.</p><p><strong>인프라 버전 관리 투트랙 전략 (@main vs @v1.0)</strong><br>‘지속적으로 진화하는 사내 제품’ 을 위한 두 가지 버전 관리 전략을 사용합니다. LLM의 응답 품질은 프롬프트 엔지니어링에 달려 있기 때문입니다.</p><ul><li>@main: 매 순간 업데이트되는 고도화된 프롬프트와 기능을 실시간으로 사용합니다.</li><li>@v1.x: 안정적인 운영이 중요한 서비스 팀이 사용하여, 프롬프트 변경에 따른 예기치 않은 부작용을 방지 합니다.</li></ul><p>결과적으로 사내 플랫폼 구축으로, 단순 스크립트 실행을 넘어 버전 관리와 배포가 가능한 하나의 <strong>‘사내 인프라 플랫폼’</strong>으로 자리 잡게 되었습니다. 이제 무신사 전체 레포지토리에서 단 몇 줄의 YAML 코드만으로 AI 리뷰 환경을 즉시 구축할 수 있습니다.</p><h3>5. 팀 단위 도입: Personalization 팀 전체로의 확장</h3><h4>다양한 직군, 하나의 협업 방식</h4><p>무신사 Personalization 팀은 Frontend, Backend, ML Engineer가 한곳에 모여 일하는 목적 조직(Cross-functional Team)입니다. 사용하는 기술 스택과 역할은 다르지만, 모두 GitHub PR 을 사용합니다. 그래서 AI 코드 리뷰는 특정 직군만의 도구가 아니라, 팀 전체가 같은 지점에서 효용을 체감할 수 있는 개선이었습니다. 아래는 팀 구성원이 남긴 실제 피드백 입니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*7DtPVT22-TJt_HMo43HaCA.png\" /><figcaption>ML 엔지니어 김윤태 님</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*E2Vz-kDAOLU9EDk8TIqxHg.png\" /><figcaption>Backend 엔지니어 정재호 님</figcaption></figure><h4>자연스러운 확장</h4><p>이처럼 각 직군 모두가 명확한 개선 효과를 경험하면서, 팀 전체 레포지토리로 범위를 확장하는 것이 자연스럽게 결정되었습니다. 무신사가 추구하는 “AI First”와 “자동화된 생산성 향상” 가치에 따라 Personalization 팀은 <strong>관리하는 모든 레포지토리에 AI 코드 리뷰를 기본 탑재</strong>하게 되었습니다.</p><h3>6. 최적화 전략 “PR은 깔끔하게, 프롬프트는 가볍게”</h3><p>다음은 팀에서 실제 사용 중인 설정입니다. 임영태 님이 제안주신 <strong>이전 코멘트 자동 정리</strong>와 최신 LLM의 추론 능력을 극대화 하기 위한 <strong>‘Minimalist Prompting’</strong> 전략 입니다.</p><h4>전략 1. 스마트 클린업: “봇의 노이즈는 지우되, 사람의 대화는 지킨다”</h4><p>PR에 커밋을 추가할 때마다 이전 코멘트와 새 코멘트가 뒤섞이는문제를 해결하기 위해 GraphQL을 활용한 <strong>맥락 보존 삭제 (Context-Aware Deletion) 규칙</strong>을 적용했습니다.</p><p><strong>보존 규칙 (Whitelist):</strong></p><ul><li><strong>Resolved(해결됨):</strong> 사용자가 ‘Resolve conversation’을 체크한 스레드는 이미 수정이 완료된 유의미한 기록이므로 보존합니다.</li><li><strong>Conversation(대화 중):</strong> 봇의 지적에 사람이 답글(Reply)을 달았다면, 이는 진행 중인 토론이므로 맥락 유지를 위해 보존합니다.</li></ul><p><strong>삭제 대상:</strong></p><ul><li>결국 “미해결(Unresolved) 상태”이면서 + <strong>“사람의 개입 없이 봇 혼자 떠들고 있는”</strong> 고립된 코멘트만 노이즈로 간주하여 제거합니다.</li></ul><p>이로써 개발자의 코멘트와 히스토리는 보호하면서, 더 이상 유효하지 않은 봇의 리뷰만 제거합니다.</p><h4>전략 2. Minimalist Prompting: “최고의 프롬프트는 가장 짧은 프롬프트”</h4><p>prompt 섹션은 놀라울 정도로 짧습니다. 이는 <strong>최신 파운데이션 모델의 제로샷(Zero-shot)능력을 극대화 하기 위한 선택입니다.</strong></p><p><strong>왜 짧은 프롬프트가 더 강력한가? “Less is More”</strong><br>흔히들 프롬프팅이 길고 정교할수록 잘 짜여진 프롬프트라고 생각하기 쉽습니다. 하지만 모델의 성능이 비약적으로 향상된 지금, 핵심 목표만 명확히 주고 나머지는 모델이 자연스럽게 판단하도록 두는 편이 오히려 안정적인 경우가 많습니다.</p><ul><li><strong>신호 대 잡음비(Signal-to-Noise) 악화:</strong> 프롬프트가 길어질수록 핵심 지시(Signal)가 부가적인 규칙(Noise)에 묻혀, 모델이 정작 중요한 요청을 놓칠 확률이 높아집니다.</li><li><strong>추론 능력 제한:</strong> 구체적인 예시를 강제하면, 모델은 자신이 가진 방대한 지식과 추론 능력을 사용하는 대신 좁은 예시를 단순히 흉내 내는 데 그칠 수 있습니다.</li></ul><p><strong>따라서 최소한의 프롬프트로 시작하고, 반복적으로 발생하는 이슈만 점진적으로 추가하는 방식으로 운영합니다.</strong></p><pre>name: &quot;Claude Code Review&quot;<br>on:<br>  pull_request:<br>    types: [ opened, reopened, synchronize ]<br>jobs:<br>  review:<br>    runs-on: ubuntu-latest<br>    permissions:<br>      contents: read<br>      pull-requests: write<br>    steps:<br>      - name: Checkout Code<br>        uses: actions/checkout@v4<br>      - name: Delete Previous Claude Reviews<br>        if: github.event.action == &#39;synchronize&#39;<br>        env:<br>          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}<br>        run: |<br>          set +e  # Continue on error<br>          PR_NUMBER=${{ github.event.pull_request.number }}<br>          REPO=${{ github.repository }}<br>          echo &quot;🔍 이전 Claude 리뷰 검색 중...&quot;<br>          # 1. PR 코멘트(요약) 삭제 - github-actions[bot]이 작성한 코멘트<br>          gh api &quot;repos/$REPO/issues/$PR_NUMBER/comments&quot; \\<br>            --jq &#39;.[] | select(.user.login == &quot;github-actions[bot]&quot;) | .id&#39; \\<br>            | while read comment_id; do<br>                if [ -n &quot;$comment_id&quot; ]; then<br>                  echo &quot;🗑️  PR 코멘트 삭제: $comment_id&quot;<br>                  gh api -X DELETE &quot;repos/$REPO/issues/comments/$comment_id&quot; 2&gt;/dev/null || echo &quot;⚠️  삭제 실패 (무시)&quot;<br>                  sleep 0.3<br>                fi<br>              done<br>          # 2. 인라인 리뷰 코멘트 삭제<br>          # - 미해결 스레드 중 bot 코멘트만 있는 스레드만 삭제<br>          # - 사용자 답글이 있는 스레드는 삭제하지 않음 (코드만 덩그러니 남는 문제 방지)<br>          OWNER=${REPO%/*}<br>          NAME=${REPO#*/}<br>          gh api graphql -F owner=&quot;$OWNER&quot; -F name=&quot;$NAME&quot; -F number=$PR_NUMBER -f query=&#39;<br>            query($owner: String!, $name: String!, $number: Int!) {<br>              repository(owner: $owner, name: $name) {<br>                pullRequest(number: $number) {<br>                  reviewThreads(last: 100) {<br>                    nodes {<br>                      isResolved<br>                      comments(first: 50) {<br>                        nodes {<br>                          databaseId<br>                          author {<br>                            login<br>                          }<br>                        }<br>                      }<br>                    }<br>                  }<br>                }<br>              }<br>            }&#39; \\<br>            --jq &#39;.data.repository.pullRequest.reviewThreads.nodes[] | select(.isResolved == false) | select([.comments.nodes[].author.login] | all(. == &quot;github-actions&quot;)) | .comments.nodes[].databaseId&#39; \\<br>            | while read comment_id; do<br>                if [ -n &quot;$comment_id&quot; ]; then<br>                  echo &quot;🗑️  인라인 코멘트 삭제: $comment_id&quot;<br>                  gh api -X DELETE &quot;repos/$REPO/pulls/comments/$comment_id&quot; 2&gt;/dev/null || echo &quot;⚠️  삭제 실패 (무시)&quot;<br>                  sleep 0.3<br>                fi<br>              done<br>          echo &quot;✅ 이전 리뷰 삭제 완료&quot;<br>      - name: Run Claude Code Review<br>        uses: anthropics/claude-code-action@v1<br>        with:<br>          show_full_output: true<br>          claude_code_oauth_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}<br>          github_token: ${{ secrets.GITHUB_TOKEN }}<br>          prompt: |<br>            REPO: ${{ github.repository }}<br>            PR NUMBER: ${{ github.event.pull_request.number }}<br>            이 PR을 리뷰하고 코멘트로 작성해주세요.<br>          claude_args: |<br>            --allowedTools &quot;mcp__github_inline_comment__create_inline_comment,Bash(gh pr comment:*),Bash(gh pr diff:*),Bash(gh pr view:*)&quot;</pre><h3>7. 마무리 — 함께 만들어가는 AI First</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*9pvOK3sHwjjvv4GEG03irQ.png\" /><figcaption>출처: ChatGPT</figcaption></figure><p>무신사 테크 조직은 ‘AI First’를 슬로건이 아닌 실천으로 만들어가고 있습니다. 실제 업무 속에서 <strong>반복되는 비효율을 줄이고 더 높은 가치</strong>를 만드는 데 집중하고 있습니다. 중요한건 ‘AI를 붙였다’가 아니라, <strong>운영 가능한 형태로 만들기 위해 무엇을 고민했고 어떻게 다듬었는가</strong> 였습니다.</p><h4>각자의 자리에서, 같은 방향으로</h4><p>엔지니어들은 각자의 자리에서 최적화를 고민했습니다. 그리고 해결책을 제안하고, 동료들과 논의하며 개선해 나갔습니다. 이렇게 서로 다른 관점의 개선이 쌓이면서 <strong>개인의 노하우는 곧 팀의 규칙이 되고, 팀의 규칙은 다시 전사적인 프로세스</strong>로 확장되었습니다.</p><h4>작은 실천이 프로세스가 되고, 프로세스가 문화가 된다</h4><p>이런 노력들이 모이자, 자연스럽게 <strong>시스템화가</strong> 이루어졌습니다. 흩어져 있던 스크립트는 Composite Action으로 표준화되었고, 개인의 토큰은 전사 인프라가 되었습니다. 이제 무신사의 어떤 팀이든 몇 줄의 YAML만으로 AI 코드 리뷰를 도입할 수 있으며, 누군가 더 좋은 방법을 찾아 기여하면 그 혜택이 전사로 전파되는 <strong>선순환 플랫폼</strong>이 구축되었습니다.</p><h4>앞으로의 격차: ‘과정의 밀도’</h4><p>향후 기술 조직 간의 격차는 단순히 “AI를 도입했는가”가 아니라, “AI를 내재화하는 과정을 어떻게 겪어냈는가”에서 벌어질 것입니다. 기술의 맹목적 수용이 아닌, 개발 프로세스에 깊숙이 녹여 자동화하고 시스템으로 정착시키는 ‘과정의 밀도’가 중요하기 때문입니다.<br>무신사는 오늘도 각자의 작은 실천을 집단 지성으로 모아, <strong>조직 전체의 AI 활용 능력</strong>을 체계적으로 성장시켜 나가고 있습니다. 이 글이 비슷한 고민을 하고 계신 분들께 의미 있는 참고가 되기를 바랍니다.</p><h3>TEAM MUSINSA CAREER</h3><blockquote><em>무신사는 2001년 온라인 커뮤니티로 시작해 2005년 무신사 매거진, 2009년 무신사 스토어를 오픈하며 빠르게 성장하고 있는 국내 대표 온라인 패션 스토어입니다. ‘입점 브랜드와 동반성장’이라는 경영 철학을 바탕으로 브랜드가 안정적으로 사업을 전개할 수 있도록 무신사가 보유한 노하우와 인프라를 지원합니다. 고객에게는 풍성한 패션 콘텐츠와 패션에 특화된 차별화된 서비스로 최상의 온라인 쇼핑 경험을 제공하고 있습니다. 글로벌 №1 패션 기업으로 성장할 무신사와 함께 새로운 도전과 혁신을 만들 인재를 기다립니다.</em></blockquote><blockquote><em>29CM는 ‘고객의 더 나은 선택을 돕는다’라는 미션으로 출발했습니다. 우리는 우리만의 방식으로 콘텐츠를 제공하며, 브랜드와 고객 모두에게 대체 불가능한 커머스 플랫폼을 만들어가고 있습니다. 이 미션을 이루기 위해 우리는 흥미로우면서도 복잡한 문제들을 해결하고 있습니다. 만약 우리와 함께 이 문제들을 해결해 보고 싶다면, 주저하지 말고 29CM에 합류하세요!</em></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/home\"><em>🚀 팀 무신사 채용 페이지</em></a><em> (무신사/29CM 전체 포지션 확인이 가능해요)</em></blockquote><blockquote><em>🚀 </em><a href=\"https://kr.linkedin.com/company/musinsacom\"><em>팀 무신사 테크 소식을 받아보는 링크드인</em></a></blockquote><blockquote><em>🚀 </em><a href=\"https://newsroom.musinsa.com/\"><em>팀 무신사 뉴스룸</em></a></blockquote><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=3ddb3c674e56\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://techblog.musinsa.com/%EB%AC%B4%EC%8B%A0%EC%82%AC%EC%9D%98-ai-%EC%BD%94%EB%93%9C-%EB%A6%AC%EB%B7%B0-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4-%EA%B5%AC%EC%B6%95%EA%B8%B0-3ddb3c674e56\">무신사의 AI 코드 리뷰 프로세스 구축기</a> was originally published in <a href=\"https://techblog.musinsa.com\">MUSINSA techblog — 무신사 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2026-02-09T22:01:01.000Z",
    "url": "https://techblog.musinsa.com/%EB%AC%B4%EC%8B%A0%EC%82%AC%EC%9D%98-ai-%EC%BD%94%EB%93%9C-%EB%A6%AC%EB%B7%B0-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4-%EA%B5%AC%EC%B6%95%EA%B8%B0-3ddb3c674e56?source=rss----f107b03c406e---4"
  },
  {
    "publisherId": "musinsa",
    "publisherName": "무신사 테크블로그",
    "specTitle": "e커머스 개발",
    "categories": [
      "backend"
    ],
    "specUrl": "https://medium.com/feed/musinsa-tech",
    "title": "질풍노도의 AI(Claude)에게 엄격한 선생님 장착하기",
    "partialText": "<h3>질풍노도의 AI(Claude)에게 엄격한 선생님 장착하기 — ArchUnit으로 아키텍처 규칙 자동 검증</h3><h3>들어가며</h3><p>무신사 물류플랫폼팀에서 백엔드 개발을 담당하고 있는 이상호입니다.</p><p>어느 날 코드 리뷰를 하다가 익숙한 장면을 마주했습니다. Claude가 생성한 코드에서 Repository 클래스가 Controller를 직접 참조하고 있었습니다. 레이어 의존성 위반. 리뷰 코멘트를 남겼습니다. 다음 PR에서도, 그다음 PR에서도 비슷한 위반이 보였습니다.</p><p><em>“AI한테 아키텍처 규칙을 매번 알려줬는데, 왜 자꾸 어기는 걸까?”</em></p><p>Claude Skill에 규칙을 정리해두기도 하고, 컨텍스트로 아키텍처 문서를 넘겨보기도 했습니다. 하지만 hit률은 기대에 한참 못 미쳤습니다. AI는 “알겠습니다”라고 대답하면서도 종종 규칙을 빠뜨렸습니다.</p><p>사실 이건 AI만의 문제가 아닙니다 사람도 마찬가지입니다. 아키텍처 규칙이라는 것은 한두 번 읽어서 되는 게 아니라, 매번 일관되게 지켜야 하는 규약입니다. 읽은 것과 지키는 것은 전혀 다른 이야기입니다.</p><p>그렇다면 접근을 바꿔야 했습니다. AI에게 규칙을 “알려주는” 것이 아니라, 규칙을 “어기면 안 되게 만드는” 방법은 없을까?</p><h3>기존 방식의 한계: 부탁은 강제가 아니다</h3><h3>첫 번째 시도 — 코드 리뷰에서 잡자</h3><p>모든 PR에서 리뷰어가 아키텍처 규칙 준수 여부를 눈으로 확인했습니다. 레이어 간 의존성 방향이 올바른지, 패키지 구조가 컨벤션에 맞는지를 한 줄 한 줄 살폈습니다.</p><p>문제는 AI의 코드 생성량이 늘수록 리뷰어의 부담도 비례해서 커진다는 점이었습니다. 비즈니스 로직을 검토해야 하는데, 아키텍처 위반을 찾느라 시간을 쓰고 있었습니다. 게다가 사람인 이상 누락은 불가피했습니다.</p><h3>두 번째 시도 — AI에게 교과서를 읽어주자</h3><p>Claude Skill과 컨텍스트에 아키텍처 규칙을 상세히 기술했습니다. “이 프로젝트는 Controller → Service → Repository 방향으로만 의존합니다. 역방향 의존은 금지입니다.”</p><p>AI는 이 내용을 잘 이해했습니다. 대부분의 경우 규칙을 따랐습니다. 하지만 대부분이 문제였습니다. 복잡한 기능을 구현할 때, 여러 파일을 동시에 생성할 때, 간혹 규칙이 빠졌습니다. 컨텍스트 기반의 접근은 “참고 자료”일 뿐, 강제력이 없었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*xLn6x_FtIuaZbsMppb3gmg.png\" /></figure><p>두 방식의 공통점이 보였습니다. 결국 누군가가 나중에 확인해야 한다는 것. 위반을 사전에 차단하는 것이 아니라, 사후에 발견하는 구조였습니다.</p><p>저희가 원한 것은 이것이었습니다:</p><ul><li>아키텍처 규칙 위반을 빌드 단계에서 자동 감지</li><li>AI가 스스로 위반을 인지하고 자동 수정</li><li>코드 리뷰에서 아키텍처 검증에 쏟는 시간을 0으로 만들기</li></ul><h3>교과서의 한계, 시험지의 가능성</h3><p>여기서 한 발 물러나 생각해보았습니다. 왜 교과서(컨텍스트)는 한계가 있을까?</p><p>교과서는 학습을 위한 도구입니다. AI는 교과서를 읽고 이해합니다. 하지만 이해한 것과 매번 정확하게 수행하는 것은 별개의 문제입니다. 사람도 교과서를 읽었다고 해서 시험에서 만점을 받지는 못합니다. AI도 마찬가지입니다. 교과서는 “이렇게 하면 좋겠다”는 방향을 제시할 뿐, 지금 이 코드가 규칙을 지키고 있는지 판단해주지 않습니다.</p><p>반면 시험지는 다릅니다. 시험지는 옳고 그름을 직접 판단합니다. “이 답은 맞다”, “이 답은 틀렸다” — 이 명확한 피드백이 핵심입니다. AI에게 “네가 방금 생성한 코드, 여기가 틀렸어”라고 구체적으로 알려줄 수 있습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*5srhGu55DIGL2OQncxNT9w.png\" /></figure><p>결국 필요한 것은 “더 좋은 교과서”가 아니라 “시험지”였습니다. AI가 생성한 코드를 즉시 검증하고, 위반이 있으면 명시적으로 “틀렸다”고 알려주는 자동화된 장치. 이 관점에서 도구를 찾기 시작했습니다.</p><h3>후보 비교와 선택: 선생님을 찾아서</h3><h3>먼저 떠오른 것: Java Lint</h3><p>“Java에도 Lint 도구가 있지 않나? Checkstyle이나 PMD로 규칙을 검증하면 되는 거 아닌가?”</p><p>결론부터 말하면, 기존의 Java Lint 도구로는 아키텍처 규칙을 검증하는 데 근본적인 한계가 있습니다.</p><p>Checkstyle이나 PMD 같은 Lint 도구는 단일 파일 수준에서 동작합니다. 변수 네이밍이 카멜케이스를 따르는지, 메서드 길이가 적정한지, 사용하지 않는 import가 있는지 — 이런 것들은 파일 하나만 보고 판단할 수 있습니다.</p><p>하지만 아키텍처 규칙은 다릅니다. “Repository가 Controller를 참조하면 안 된다”는 규칙을 생각해보겠습니다. 이 규칙을 검증하려면 OrderRepository.java 파일 하나만 봐서는 알 수 없습니다. 이 클래스가 어떤 패키지에 있는지, import하는 클래스가 어떤 레이어에 속하는지, 프로젝트 전체의 패키지 구조가 어떻게 되어 있는지를 함께 알아야 합니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*5yly8cVwowGWs4CusHgrlA.png\" /></figure><p>비유하자면, Lint는 글자 맞춤법 검사기입니다. 각 문장의 띄어쓰기와 문법은 잡아주지만, “3장의 내용이 1장의 결론과 모순된다”는 것은 발견하지 못합니다. 아키텍처 검증은 글 전체의 구조적 일관성을 보는 일이고, 이를 위해서는 프로젝트 전체를 하나의 단위로 분석할 수 있는 도구가 필요했습니다.</p><h3>아키텍처 검증 도구 3가지 비교</h3><p>Lint의 한계를 확인한 후, 아키텍처 규칙을 코드 레벨에서 자동 검증할 수 있는 도구 3가지를 검토했습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*byYGoHg7QeLqla9zaGbYwQ.png\" /></figure><h3>최종 선택: ArchUnit</h3><p>세 가지 후보 중 ArchUnit을 선택한 결정적 이유는 AI 연동 친화성이었습니다.</p><p>ArchUnit은 일반 JUnit 테스트처럼 동작합니다. 아키텍처 위반이 있으면 테스트가 실패하고, 무엇이 왜 잘못되었는지 명확한 에러 메시지를 출력합니다. 여기서 핵심적인 발견이 있었습니다. Claude는 테스트 실패 메시지를 매우 잘 이해합니다. 실패 원인을 읽고, 위반을 파악하고, 스스로 코드를 수정합니다.</p><p>즉, ArchUnit은 AI에게 “엄격한 선생님” 역할을 할 수 있었습니다.</p><p>교과서를 건네주며 “이렇게 해주세요”라고 부탁하는 것과, 시험을 보게 하며 “이것을 어기면 탈락입니다”라고 알려주는 것. 이 두 가지 사이에는 근본적인 차이가 있습니다.</p><h3>도입 과정: 선생님 세팅하기</h3><h3>1. ArchUnit 프로젝트 세팅</h3><p>첫 번째로 놀란 점은 도입이 너무 간단하다는 것이었습니다. Gradle 의존성 하나만 추가하면 끝입니다.</p><pre>dependencies {<br>    testImplementation(&quot;com.tngtech.archunit:archunit-junit5:1.3.0&quot;)<br>}</pre><p>별도의 서버를 구축하거나 인프라를 변경할 필요가 전혀 없었습니다. 기존 테스트 프레임워크 위에서 바로 동작했습니다.</p><h3>2. 시험지도 AI가 만든다</h3><p>여기서 재미있는 장면이 연출됩니다. ArchUnit 테스트 코드를 누가 작성할까요? 사람이 ArchUnit API를 공부해서 하나하나 작성할 수도 있습니다. 하지만 저희는 이 과정도 AI에게 맡겼습니다.</p><p>방법은 간단합니다. 사람은 자연어로 규칙을 설명하면 됩니다.</p><blockquote>“Repository 레이어는 Controller 레이어에 의존하면 안 됩니다” “Service 클래스는 반드시 service 패키지 안에 위치해야 합니다” “infrastructure 패키지는 domain 패키지에 접근할 수 있지만, 그 반대는 안 됩니다”</blockquote><p>Claude에게 이런 규칙을 자연어로 전달하면, AI가 해당 규칙에 대응하는 ArchUnit 테스트 코드를 생성합니다. 아키텍처에 대한 도메인 지식은 사람이, 그것을 코드로 옮기는 작업은 AI가 담당하는 셈입니다.</p><p>아이러니하게도, AI가 스스로 응시할 시험지를 AI가 만드는 구조입니다. 하지만 이것이 정확히 의도한 바입니다. 시험지를 만드는 것과 시험을 통과하는 것은 전혀 다른 일입니다. 시험지는 한 번만 만들면 되지만, 시험은 코드를 생성할 때마다 매번 치러야 합니다. 한 번 잘 만들어진 ArchUnit 테스트는 이후 생성되는 모든 코드에 대해 일관된 검증을 수행합니다.</p><h3>3. AI와의 연동: 질풍노도에서 절도 있는 행군으로</h3><p>선생님 세팅이 끝났습니다. 이제 실제로 AI와 어떻게 동작하는지가 중요합니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*lJuIaooI3-0ncUcMiqr-Aw.png\" /></figure><p>이전에는 이런 흐름이었습니다:</p><blockquote>개발자: “레이어 의존성을 지켜서 코드를 작성해줘” Claude: “네, 알겠습니다” (대부분 지키지만, 가끔 빠뜨림) 개발자: (코드 리뷰에서 발견) “여기 의존성 방향이 반대야” Claude: “죄송합니다, 수정하겠습니다”</blockquote><p>ArchUnit 도입 후에는 이렇게 바뀌었습니다:</p><blockquote>Claude가 코드를 생성합니다. 테스트를 실행합니다. ArchUnit: “Architecture Violation — Repository is not allowed to access Controller” Claude: (실패 메시지를 읽고) “레이어 의존성 위반이 있습니다. Service를 통해 접근하도록 수정하겠습니다.” 테스트를 재실행합니다. 통과.</blockquote><p>사람이 개입할 틈이 없습니다. AI가 코드를 생성하고, 테스트가 위반을 잡고, AI가 스스로 수정합니다. <strong>부탁에서 강제로, 사후 검증에서 사전 차단으로</strong> 전환된 것입니다.</p><p>흥미로운 점은 Claude가 ArchUnit 실패 메시지에 대응하는 방식이었습니다. 단순히 에러를 회피하는 것이 아니라, 위반 원인을 이해하고 올바른 아키텍처 패턴으로 코드를 재구성했습니다. 교과서를 읽었을 때는 가끔 빠뜨리던 AI가, 시험을 보게 하니 틀린 문제를 스스로 교정하기 시작한 셈입니다.</p><h3>적용한 규칙들: 선생님의 훈련 과목</h3><h3>1. 레이어 의존성 규칙 정의</h3><p>가장 먼저 잡고 싶었던 규칙은 레이어 간 의존성 방향이었습니다. Controller → Service → Repository 방향으로만 의존해야 하며, 역방향 의존은 허용하지 않습니다. 처음 코드 리뷰에서 발견했던 바로 그 문제입니다.</p><p>자연어로 설명한 규칙이 ArchUnit 코드로 변환되면 다음과 같은 모습이 됩니다:</p><pre>@ArchTest<br>val `레이어 의존성 규칙` = layeredArchitecture()<br>    .consideringAllDependencies()<br>    .layer(&quot;Controller&quot;).definedBy(&quot;..controller..&quot;)<br>    .layer(&quot;Service&quot;).definedBy(&quot;..service..&quot;)<br>    .layer(&quot;Repository&quot;).definedBy(&quot;..repository..&quot;)<br>    .layer(&quot;Domain&quot;).definedBy(&quot;..domain..&quot;)<br>    .whereLayer(&quot;Controller&quot;).mayOnlyBeAccessedByLayers(&quot;Controller&quot;)<br>    .whereLayer(&quot;Service&quot;).mayOnlyBeAccessedByLayers(&quot;Controller&quot;, &quot;Service&quot;)<br>    .whereLayer(&quot;Repository&quot;).mayOnlyBeAccessedByLayers(&quot;Service&quot;)<br>    .whereLayer(&quot;Domain&quot;).mayOnlyBeAccessedByLayers(&quot;Service&quot;, &quot;Repository&quot;, &quot;Controller&quot;)</pre><p>이 테스트가 실패하면 다음과 같은 메시지가 출력됩니다:</p><pre>Architecture Violation [Rule &#39;Layered architecture ...&#39;] -<br>Layer &#39;Repository&#39; is not allowed to access layer &#39;Controller&#39;,<br>but class com.musinsa.warehouse.repository.OrderRepository<br>accesses com.musinsa.warehouse.controller.OrderController</pre><p>메시지가 구체적입니다. 어떤 클래스가 어떤 레이어를 잘못 참조했는지 정확히 알려줍니다. 사람이 읽어도, AI가 읽어도 즉시 원인을 파악할 수 있습니다.</p><p>실제 프로젝트에서는 멀티 모듈 구조에 맞춰 모듈별로 레이어 규칙을 정의합니다. 예를 들어, API 모듈이 다른 모듈의 내부 구현에 직접 접근하는 것을 차단하는 규칙은 이렇게 작성됩니다</p><pre>@Test<br>@DisplayName(&quot;API 패키지만 접근해야 한다&quot;)<br>void adminShouldOnlyAccessAllowedApiPackages() {<br>    ArchRule rule = noClasses()<br>            .that()<br>            .resideInAPackage(&quot;com.musinsalogistics.sampleproject.admin..&quot;)<br>            .should()<br>            .accessClassesThat(resideInAPackage(&quot;com.musinsalogistics.sampleproject..&quot;)<br>                    .and(resideOutsideOfPackages(<br>                            &quot;com.musinsalogistics.sampleproject.admin..&quot;,<br>                            &quot;com.musinsalogistics.sampleproject..api..&quot;,<br>                            &quot;com.musinsalogistics.sampleproject..exception..&quot;)))<br>            .allowEmptyShould(true)<br>            .because(&quot;Admin은 다른 모듈의 api 패키지와 exception 패키지만 접근할 수 있습니다&quot;); <br>    rule.check(classes);<br>}<br></pre><blockquote>“다른 모듈의 api 패키지와 exception 패키지만 접근 가능&quot; — 이 한 줄의 비즈니스 규칙이 코드로 표현되면, AI가 모듈 경계를 넘어 내부 구현에 직접 의존하는 코드를 생성했을 때 즉시 테스트가 실패합니다.</blockquote><h3>2. 패키지 구조 규칙 정의</h3><p>레이어 의존성 외에도 팀의 패키지 네이밍 컨벤션을 강제했습니다. “Controller 클래스는 controller 패키지에”, “Service 클래스는 service 패키지에” — 단순하지만 AI가 종종 빠뜨리는 규칙이었습니다.</p><pre>@ArchTest<br>val `패키지 구조 규칙 - Controller는 controller 패키지에 위치` = classes()<br>    .that().haveSimpleNameEndingWith(&quot;Controller&quot;)<br>    .should().resideInAPackage(&quot;..controller..&quot;)<br>@ArchTest<br>val `패키지 구조 규칙 - Service는 service 패키지에 위치` = classes()<br>    .that().haveSimpleNameEndingWith(&quot;Service&quot;)<br>    .should().resideInAPackage(&quot;..service..&quot;)<br>@ArchTest<br>val `패키지 구조 규칙 - Repository는 repository 패키지에 위치` = classes()<br>    .that().haveSimpleNameEndingWith(&quot;Repository&quot;)<br>    .should().resideInAPackage(&quot;..repository..&quot;)</pre><h3>3. 순환 의존성 감지 규칙</h3><p>레이어 의존성과 패키지 구조 외에도, AI가 복잡한 기능을 구현하다 보면 의도치 않게 <strong>패키지 간 순환 참조</strong>를 만들어내는 경우가 있었습니다. A 패키지가 B를 참조하고, B가 다시 A를 참조하는 구조. 사람이 코드 리뷰에서 이런 순환을 발견하기란 쉽지 않습니다. 하지만 ArchUnit에게는 간단한 일입니다.</p><blockquote>“패키지 간 순환 의존이 발생하면 안 됩니다”</blockquote><p>이 한 줄의 자연어가 다음 테스트 코드가 됩니다:</p><pre>@ArchTest<br>val `패키지 간 순환 의존 금지` = slices()<br>    .matching(&quot;com.musinsa.warehouse.(*)..&quot;)<br>    .should().beFreeOfCycles()</pre><p>단 세 줄로, 프로젝트 전체의 패키지 순환을 감지합니다. 앞서 설명한 Lint가 절대 할 수 없는 영역입니다. 파일 하나만 봐서는 순환인지 알 수 없고, 전체 의존 그래프를 그려봐야 비로소 드러나는 문제이기 때문입니다.</p><p>ArchUnit의 검증 범위는 클래스 구조에 그치지 않습니다. 메서드 레벨의 규칙도 작성할 수 있습니다. 예를 들어, API URL이 팀에서 정한 형식을 따르는지 검증하는 규칙입니다:</p><pre>@Test<br>@DisplayName(&quot;Controller의 API는 /api/sampleproject/public/v{버전}/{비즈니스}... 형식을 준수해야 한다&quot;)<br>void controllerApiUrlShouldFollowPublicApiFormat() {<br>    ArchRule rule = ArchRuleDefinition.methods()<br>            .that().areDeclaredInClassesThat().resideInAPackage(&quot;..publicapi.controller..&quot;)<br>            .and().areDeclaredInClassesThat().haveSimpleNameEndingWith(&quot;Controller&quot;)<br>            .and().areAnnotatedWith(isHttpMappingAnnotation())<br>            .should(haveValidPublicApiUrlFormat())<br>            .allowEmptyShould(true)<br>            .because(&quot;Public API는 /api/sampleproject/public/v{버전번호}/{비즈니스}... 형식을 준수해야 합니다&quot;);</pre><p>AI가 새 API 엔드포인트를 생성할 때 URL 형식을 자유롭게 만들어버리는 경우가 있습니다. 이 규칙이 있으면 /api/sampleproject/public/v1/... 형식에 맞지 않는 URL은 즉시 감지됩니다. 사소해 보이지만, API URL의 일관성은 외부 시스템 연동에서 매우 중요합니다.</p><h3>4. 도메인 순수성 보호 규칙</h3><p>저희 팀이 특히 신경 쓰는 규칙이 하나 더 있습니다. 도메인 레이어는 외부 프레임워크에 의존하지 않아야 한다는 것입니다. Spring의 @Autowired, JPA의 @Entity 같은 프레임워크 어노테이션이 도메인 모델에 침투하면, 도메인이 특정 기술에 종속되어 버립니다.</p><blockquote>“domain 패키지의 클래스는 Spring이나 JPA 프레임워크에 의존하면 안 됩니다”</blockquote><pre>@ArchTest<br>val `도메인은 프레임워크에 의존하지 않는다` = classes()<br>    .that().resideInAPackage(&quot;..domain..&quot;)<br>    .should().onlyDependOnClassesThat()<br>    .resideInAnyPackage(<br>        &quot;..domain..&quot;,<br>        &quot;java..&quot;,<br>        &quot;kotlin..&quot;,<br>        &quot;org.slf4j..&quot;<br>    )</pre><p>이 규칙이 없을 때, AI는 가끔 도메인 클래스에 @Component를 붙이거나 JpaRepository를 직접 주입하는 코드를 생성했습니다. 테스트가 이를 잡아내면서, AI는 &quot;도메인은 순수해야 한다&quot;는 원칙을 코드 레벨에서 학습하게 되었습니다.</p><p>의존성 역전 원칙(DIP)도 ArchUnit으로 강제할 수 있습니다. 예를 들어, Security 모듈에서 provider 패키지가 component 패키지의 구체 클래스에 직접 의존하지 않도록 하는 규칙입니다.</p><p>먼저 DIP 위반과 준수가 어떤 구조인지 살펴보겠습니다:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*UOv8AaB-s-Q9XK51NFofoQ.png\" /></figure><p>Provider가 Component의 구체 클래스를 직접 참조하면 두 패키지가 강하게 결합됩니다. 대신 security.api 패키지의 인터페이스를 통해 소통하면, Component의 내부 구현이 바뀌어도 Provider는 영향을 받지 않습니다. 이 설계 원칙을 ArchUnit으로 강제하면:</p><pre>@Test<br>void securityProviderShouldNotDependOnComponentClasses() {<br>    ArchRule rule = noClasses()<br>            .that().resideInAnyPackage(&quot;..security.internal.provider..&quot;)<br>            .should().dependOnClassesThat()<br>            .resideInAnyPackage(&quot;..security.internal.component..&quot;)<br>            .because(&quot;의존성 역전 원칙(DIP)을 준수하여 추상화(인터페이스)에 의존해야 합니다&quot;);<br>    rule.check(securityModuleClasses);<br>}</pre><p>AI가 Provider 클래스에서 Component의 구체 클래스를 직접 import하면 즉시 테스트가 실패합니다.</p><blockquote><strong>“구체 클래스가 아닌 인터페이스에 의존하라”</strong>는 SOLID 원칙이 코드 레벨에서 자동 검증되는 셈입니다.</blockquote><h3>5. 어노테이션과 클래스 네이밍 일관성 규칙</h3><p>AI가 은근히 자주 저지르는 실수가 하나 더 있습니다. @Service 어노테이션을 Service가 아닌 클래스에 붙이는 것입니다. 예를 들어 OrderHelper나 PriceCalculator 같은 유틸리티 클래스에 습관적으로 @Service를 달아버립니다. 컴파일도 되고 동작도 합니다. 하지만 팀 컨벤션에서는 @Service는 ~Service로 끝나는 클래스에만 사용해야 합니다. 어노테이션과 클래스 이름이 일치하지 않으면, 코드를 읽는 사람이 역할을 오해하게 됩니다.</p><blockquote>“@Service 어노테이션은 이름이 Service로 끝나는 클래스에만 붙여야 합니다”</blockquote><pre>@ArchTest<br>val `@Service는 Service 클래스에만 사용` = classes()<br>    .that().areAnnotatedWith(Service::class.java)<br>    .should().haveSimpleNameEndingWith(&quot;Service&quot;)<br>@ArchTest<br>val `@Repository는 Repository 클래스에만 사용` = classes()<br>    .that().areAnnotatedWith(Repository::class.java)<br>    .should().haveSimpleNameEndingWith(&quot;Repository&quot;)<br>@ArchTest<br>val `@Controller는 Controller 클래스에만 사용` = classes()<br>    .that().areAnnotatedWith(RestController::class.java)<br>    .should().haveSimpleNameEndingWith(&quot;Controller&quot;)</pre><p>이 규칙의 효과는 생각보다 컸습니다. AI는 “빈으로 등록해야 하니까 @Service를 붙이자&quot;라는 판단을 자주 합니다. 기능적으로는 맞지만, 팀의 네이밍 컨벤션과는 어긋납니다. 테스트가 실패하면 AI는 @Service 대신 @Component를 사용하거나, 클래스 이름을 컨벤션에 맞게 변경합니다.</p><p>어노테이션 규칙은 여기서 한 단계 더 깊어질 수 있습니다. 저희 팀에서는 @Transactional의 readOnly 속성에 따라 Service 클래스의 네이밍까지 강제합니다</p><pre>@ArchTest<br>void Transactional_readOnly_false인_클래스는_FacadeService_또는_WriteService_이름을_가져야_한다(JavaClasses classes) {<br>    classes()<br>            .that().resideInAPackage(&quot;..domain..&quot;)<br>            .and().areAnnotatedWith(Transactional.class)<br>            .should(haveWriteServiceNaming())<br>            .allowEmptyShould(true)<br>            .because(&quot;쓰기 트랜잭션 서비스는 FacadeService 또는 WriteService 네이밍을 따라야 합니다&quot;)<br>            .check(classes);<br>}<br><br>@ArchTest<br>void Transactional_readOnly_true인_클래스는_ReadService_이름을_가져야_한다(JavaClasses classes) {<br>    classes()<br>            .that().resideInAPackage(&quot;..domain..&quot;)<br>            .and().areAnnotatedWith(Transactional.class)<br>            .should(haveReadServiceNaming())<br>            .allowEmptyShould(true)<br>            .because(&quot;읽기 전용 서비스는 ReadService 또는 SearchService 네이밍을 따라야 합니다&quot;)<br>            .check(classes);<br>}</pre><p>@Transactional(readOnly = true)인데 WriteService라는 이름을 가진 클래스가 있다면? 테스트가 실패합니다. 트랜잭션 속성과 클래스 이름이 일치해야 한다는 규칙은, 코드를 읽는 사람이 &quot;이 서비스가 읽기 전용인지, 쓰기도 하는지&quot;를 이름만으로 즉시 판단할 수 있게 해줍니다.</p><h3>왜 사람이 읽을 수 있는 코드여야 하는가</h3><p>“기능만 돌아가면 되는 거 아닌가?”라고 생각할 수도 있습니다. 하지만 여기서 한 가지 잊지 말아야 할 것이 있습니다. 코드를 생성하는 것은 AI지만, 그 코드를 감독하고, 유지보수하고, 장애에 책임지는 것은 사람입니다.</p><p>AI가 만든 코드는 결국 사람이 읽어야 합니다. 새로운 팀원이 합류했을 때, 장애가 터져서 새벽에 코드를 열었을 때, 반년 뒤 요구사항이 바뀌어 로직을 수정해야 할 때 — 그 코드를 마주하는 것은 사람입니다. OrderHelper에 @Service가 붙어 있으면, 사람은 &quot;이게 비즈니스 서비스인가?&quot;라고 오해합니다. 작은 혼란이 쌓이면 코드베이스 전체의 가독성이 무너집니다.</p><p>어노테이션과 클래스 이름의 일관성은 사소해 보이지만, <strong>사람이 코드를 빠르고 정확하게 이해하기 위한 최소한의 약속</strong>입니다.</p><blockquote>AI 시대에도 코드의 최종 독자는 여전히 사람이기 때문입니다.</blockquote><h3>도입 후 변화</h3><h3>정량적 변화</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*B_1Hgo-TwOUMC6cCc0JGpA.png\" /></figure><p>가장 체감이 컸던 변화는 코드 리뷰의 질이었습니다. 아키텍처 위반을 더 이상 눈으로 찾을 필요가 없으니, 리뷰어는 비즈니스 로직의 정확성과 엣지 케이스 처리에 온전히 집중할 수 있게 되었습니다.</p><h3>팀 피드백</h3><p>팀원들의 반응은 긍정적이었습니다. 특히 두 가지 목소리가 인상적이었습니다:</p><blockquote>“이제 아키텍처 위반은 ArchUnit이 잡아주니, 리뷰에서 비즈니스 로직에만 집중할 수 있어서 좋습니다”</blockquote><blockquote>“AI가 생성한 코드도 테스트를 통과해야 하니까, 예전보다 안심하고 AI를 활용할 수 있게 됐습니다”</blockquote><p>AI 활용에 대한 심리적 안전망이 생긴 것도 큰 변화였습니다. “AI가 혹시 규칙을 어기면 어쩌지?”라는 불안감이, “어겨도 테스트에서 잡히니까 괜찮아”로 바뀌었습니다.</p><h3>마무리</h3><h3>AI에게 부탁하지 말고, 시험을 보게 하라</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Kk0_qwVuPzw3VXqplJW56w.png\" /></figure><p>이번 도입 과정에서 가장 크게 깨달은 것은 AI에게 규칙을 전달하는 방식의 차이입니다.</p><blockquote>컨텍스트는 가이드라인입니다. 테스트는 제약 조건입니다. AI는 “이렇게 해주세요”라는 부탁보다 <strong>“이것을 어기면 빌드가 실패합니다”</strong>라는 명확한 피드백에 훨씬 잘 반응합니다.</blockquote><blockquote>이 관점은 아키텍처 규칙에만 국한되지 않습니다. 코딩 컨벤션, 네이밍 규칙, 모듈 경계 — <strong>팀이 일관되게 지키고 싶은 모든 규약</strong>을 “테스트로 검증 가능한 형태”로 만들 수 있다면, AI와의 협업 품질은 한 단계 올라갈 수 있습니다.</blockquote><h3>향후 과제</h3><p>현재는 레이어 의존성과 패키지 구조라는 가장 기본적인 규칙만 적용한 상태입니다. 앞으로 두 가지 방향으로 확장을 계획하고 있습니다.</p><ul><li>규칙 확대: 도메인 이벤트 발행 규칙, DTO 변환 위치 규칙, 외부 라이브러리 사용 범위 제한 등 더 세밀한 아키텍처 규칙을 추가할 예정입니다. 선생님의 훈련 과목을 늘리는 셈입니다.</li><li>다른 프로젝트 확산: 물류플랫폼팀 내 다른 프로젝트에도 동일한 ArchUnit 규칙 세트를 적용하여, 프로젝트가 달라져도 아키텍처의 일관성을 유지하려 합니다.</li></ul><p>AI 코드 생성 도구를 적극 활용하면서도 아키텍처 품질에 대한 고민이 있으신 분들에게, ArchUnit이 좋은 출발점이 될 수 있을 것입니다.</p><p>질풍노도의 AI에게 필요한 것은 더 많은 교과서가 아니라,</p><blockquote>시험지 한 장이었습니다.</blockquote><h3>Platform Business Operation 조직 및 팀 소개</h3><blockquote><em>무신사 플랫폼 비즈니스 오퍼레이션 조직은 국내외 물류 서비스, 재고 관리, 스토어 운영을 위한 물류 프로덕트를 구축하고 다양한 오프라인 비즈니스 모델에 맞춘 스토어 관리 시스템을 개발·고도화하고 있습니다.<br>또한, 무배당발 서비스를 포함한 무신사의 차별화된 고객 경험을 브랜딩하고 확장할 수 있는 멤버십 구조를 설계하며, 온·오프라인을 넘나드는 통합 커머스 경험을 기술로 실현하고 있습니다.</em></blockquote><blockquote><em>저희 팀은 OMS(주문관리시스템)를 기반으로 온라인 주문부터 재고·출고·배송·정산에 이르는 전 과정을 유기적으로 연결하고, 무신사의 다양한 오프라인 스토어를 효과적으로 운영할 수 있는 관리 시스템을 구축하여 고객이 온라인(무신사 스토어, 29CM 등)과 오프라인(무신사 스탠다드, 편집숍 등)에서 끊김 없는 쇼핑 경험을 누릴 수 있도록 지원합니다.</em></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/pbo\"><em>🚀 Platform Business Operation 한걸음 더 알아보기</em></a></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/home\"><em>🚀 팀 무신사 채용 페이지</em></a><em> (무신사/29CM 전체 포지션 확인이 가능해요)</em></blockquote><blockquote><em>🚀 </em><a href=\"https://kr.linkedin.com/company/musinsacom\"><em>팀 무신사 테크 소식을 받아보는 링크드인</em></a></blockquote><blockquote><em>🚀 </em><a href=\"https://newsroom.musinsa.com/\"><em>팀 무신사 뉴스룸</em></a></blockquote><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=61c3d533fc40\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://techblog.musinsa.com/%EC%A7%88%ED%92%8D%EB%85%B8%EB%8F%84%EC%9D%98-ai-claude-%EC%97%90%EA%B2%8C-%EC%97%84%EA%B2%A9%ED%95%9C-%EC%84%A0%EC%83%9D%EB%8B%98-%EC%9E%A5%EC%B0%A9%ED%95%98%EA%B8%B0-61c3d533fc40\">질풍노도의 AI(Claude)에게 엄격한 선생님 장착하기</a> was originally published in <a href=\"https://techblog.musinsa.com\">MUSINSA techblog — 무신사 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2026-02-09T08:01:02.000Z",
    "url": "https://techblog.musinsa.com/%EC%A7%88%ED%92%8D%EB%85%B8%EB%8F%84%EC%9D%98-ai-claude-%EC%97%90%EA%B2%8C-%EC%97%84%EA%B2%A9%ED%95%9C-%EC%84%A0%EC%83%9D%EB%8B%98-%EC%9E%A5%EC%B0%A9%ED%95%98%EA%B8%B0-61c3d533fc40?source=rss----f107b03c406e---4"
  },
  {
    "publisherId": "musinsa",
    "publisherName": "무신사 테크블로그",
    "specTitle": "e커머스 개발",
    "categories": [
      "backend"
    ],
    "specUrl": "https://medium.com/feed/musinsa-tech",
    "title": "“스케줄이 또 안 돌았어요” — 우리가 Temporal을 선택한 이유",
    "partialText": "<h3>“스케줄이 또 안 돌았어요” — 우리가 Temporal을 선택한 이유</h3><p>어느 날 아침, 슬랙 알림이 울렸습니다. <br>“출고지시 스케줄이 실행 안 된 것 같은데 확인 부탁드려요.”</p><p>Jenkins 콘솔을 열어보니 job이 멈춰있었고, 모니터링 job마저 함께 멈춰있었습니다. 급하게 수동으로 출고지시를 트리거하고 나서야 물류센터 작업이 시작될 수 있었습니다. 이런 일이 반복되면서 우리는 고민하게 되었습니다.</p><p><strong>“스케줄 하나 도는 게 왜 이렇게 불안할까?”</strong></p><h3>출고지시, 그리고 우리가 마주한 문제들</h3><p>무신사 풀필먼트의 OMS는 주문부터 출고까지 물류 전반을 책임지는 시스템입니다. 그 중에서도 <strong>출고지시는 물류센터의 하루를 시작하는 신호</strong>와도 같습니다. 정해진 시간에 출고지시가 생성되지 않으면 물류센터 작업이 지연되고, 그것은 곧 배송 지연으로 이어집니다.</p><p>초기에는 Jenkins crontab으로 충분했습니다. 정해진 시간에 실행하기만 하면 됐습니다. 하지만 화주사가 늘고 출고 물량이 커지면서, 이 구조의 한계가 하나둘 보이기 시작했습니다.</p><h3>1. 실패를 놓치는 순간들</h3><p>Jenkins 기반 스케줄은 job이 멈춰도 알려주지 않았습니다. 그래서 우리는 별도의 모니터링 job을 만들어 실행했습니다. <strong>“스케줄이 실행됐는지 확인하는 스케줄”</strong>을 또 만드는 거죠.</p><p>문제는 이 모니터링 job도 언제든 멈출 수 있다는 것이었습니다. 실제로 Jenkins 자체에 문제가 생기면 스케줄과 모니터링이 함께 멈췄고, 우리는 뒤늦게야 알게 되곤 했습니다. 모니터링을 위한 모니터링을 또 만들 수는 없었고, 이 구조 자체가 근본적인 한계를 가지고 있다는 걸 깨달았습니다.</p><h3>2. 로그 속에서 원인 찾기</h3><p>출고지시에 문제가 생기면, 저희는 Jenkins 콘솔 로그를 시작으로 애플리케이션 로그, DB 이력을 차례로 확인해야 했습니다.</p><p>“이번엔 어디서 실패한 거지?” <br>“입력값은 뭐였지?” <br>“결과는 어떻게 됐지?”</p><p>실행 이력을 한눈에 볼 수 있는 방법이 없었고, <strong>문제를 분석하는 것보다 로그를 따라가는 데 더 많은 시간</strong>이 들었습니다. 빠른 대응이 필요한 순간일수록, 이런 가시성 부족은 운영 리스크를 키우는 요인이 되었습니다.</p><h3>3. “다시 눌러주세요”</h3><p>스케줄이 실패하면 저희가 직접 재실행해야 했습니다. 단순히 일시적인 네트워크 오류로 실패한 경우에도, 원인을 확인하고 수동으로 재실행하는 과정에서 시간이 소요되었습니다.</p><p>대응이 조금만 늦어도 출고 SLA에 영향을 주는 경우가 생겼고, 담당자의 부담은 자연스럽게 커질 수밖에 없었습니다. 실제로는 단순 재시도만으로 해결될 수 있는 케이스도 많았지만, 원인을 확인하는 절차 자체가 출고 지연으로 이어지는 경우가 반복되었습니다.</p><p>결국 이러한 구조에서는 안정적인 운영을 기대하기 어려워졌습니다.</p><h3>4. 이벤트 기반으로의 확장</h3><p>출고 도메인에서는 정해진 스케줄 외에도, 특정 이벤트를 기점으로 Workflow를 실행해야 하는 요구가 늘어나고 있었습니다. 하지만 Jenkins는 cron 기반 실행에 최적화되어 있었고, 이벤트 기반 트리거를 자연스럽게 처리하기에는 구조적인 한계가 있었습니다.</p><p>결국 저희는 깨달았습니다. <br><strong>“출고 물량과 요구사항이 늘어날수록, 기존 구조로는 안정적인 운영을 기대하기 어렵다.”</strong></p><p>구조 자체를 다시 고민해야 할 시점이었습니다.</p><h3>대안을 찾아서</h3><p>저희는 여러가지 가능성을 열어두고 대안을 비교해보기 시작했습니다.</p><h4>Jenkins + 모니터링 Job 개선</h4><p>이미 운영 중인 구조라 리스크는 적었지만, 근본적인 한계를 해결하기는 어려웠습니다. 모니터링을 아무리 촘촘하게 만들어도, Jenkins 자체의 고가용성 문제는 해결되지 않았습니다.</p><h4>Spring Batch + Quartz</h4><p>Spring Batch + Quartz는 배치 처리에 최적화된 구조였고, 팀에서도 익숙한 스택이었습니다. 하지만 Batch Job 실행 이력은 확인할 수 있어도, “주문이 어디서 멈췄고, 왜 실패했는지”와 같은 비즈니스 흐름은 보이지 않았습니다. 재시도 로직 구현은 가능했지만, “이 조건이면 재시도, 저 조건이면 스킵” 같은 의사결정 로직이 코드 곳곳에 흩어지면서 전체 워크플로우를 파악하기 어려워졌습니다. 결국 “배치 Job”이 아닌 “비즈니스 워크플로우” 단위로 실행과 상태를 추적하고 싶었습니다.</p><h4>Temporal</h4><p>Temporal은 장기 실행되는 비즈니스 프로세스를 코드로 표현하고, 실패·재시도·상태 관리를 플랫폼 레벨에서 보장해주는 Workflow Engine입니다. Uber에서 만든 Cadence를 기반으로 개발되었으며, 서버 장애가 발생해도 중단된 지점부터 자동 복구됩니다.</p><p>생소한 이름이었습니다. 러닝 커브가 높다는 것도 부담이었습니다. 하지만 회의실에서 Temporal 문서를 보며 이야기를 나누다 보니, 저희가 원하던 것들이 하나하나 눈에 들어왔습니다.</p><ul><li>스케줄 기반 실행</li><li>Workflow 전체 흐름에 대한 가시성</li><li>자동 재시도와 복구</li><li>이벤트 기반 트리거</li></ul><p>어느 순간 팀 모두가 적합해 보인다고 생각했고, <strong>단순히 스케줄을 실행하는 기능을 넘어, 출고 도메인 전반의 흐름을 안정적으로 오케스트레이션할 수 있는 플랫폼</strong>이 될 수 있겠다고 판단했습니다.</p><h3>설계하면서 고민한 것들</h3><h4>무엇을 목표로 설계하는가</h4><p>기존 Jenkins crontab 기반 스케줄링 방식은 운영 안정성, 실행 가시성, 복구 가능성 측면에서 여러 한계를 갖고 있었습니다.</p><p>이에 따라 스케줄 실행 방식을 보다 안정적이고 자동화된 구조로 전환하고, 운영자가 수행하던 수동 확인과 재실행 작업을 최소화하는 것을 목표로 했습니다.</p><h4>Workflow와 Activity, 어떻게 나눌 것인가</h4><p>Temporal 공식 문서는 이렇게 말합니다.</p><blockquote><em>Workflow는 전체 비즈니스 프로세스의 오케스트레이션을 담당하고, Activity는 외부 시스템과의 상호작용이나 단위 작업을 수행한다.</em></blockquote><p>Workflow와 Activity의 경계를 정하는 데 가장 어려웠던 점은, 단순히 “외부 시스템을 호출하는가”가 아니라 “이 분기가 비즈니스 정책인가, 실행 세부사항인가”를 판단하는 일이었습니다. 예를 들어 “중복 주문이면 스킵한다”는 비즈니스 정책이므로 Workflow에서 분기하고, “DB에서 중복 여부를 조회한다”는 실행 세부사항이므로 Activity로 분리했습니다.</p><p>논의 끝에 저희가 세운 기준은 이렇습니다:</p><ul><li>Workflow: 비즈니스 정책에 따른 분기와 흐름 제어</li><li>Activity: 멱등성이 보장되는 단위 작업, 외부 시스템 호출</li></ul><p>출고지시의 경우, Workflow는 “정책 조회 → 중복 체크 → 차수 생성 → 파이프라인 트리거” 흐름을 조율하고, 각 단계의 실제 작업은 Activity가 수행합니다. 이 구분이 명확할수록 향후 출고 파이프라인 전체를 Workflow로 확장할 때도 일관성 있게 설계할 수 있을 거라 생각했습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*iO5YSi38Zj2O5Ue3f43rbQ.png\" /></figure><ul><li>앞서 정의한 기준에 따라, Workflow는 출고지시 트리거의 전체 흐름과 분기·의사결정을 조율하고 Activity는 정책 조회, 중복 체크, 차수 생성 등 실제 작업을 수행합니다.</li><li>Temporal 내 정의된 스케줄을 기반으로 Workflow가 실행되며, 각 단계는 Activity로 위임되어 상태를 명확히 관리하고 출고지시 흐름을 조율합니다.</li></ul><h3>출고지시 Workflow 구현</h3><p>최종적으로 <strong>1개의 Workflow</strong>와 <strong>5개의 Activity</strong>로 구성했습니다. (아래는 간략화된 코드입니다.)</p><pre>@WorkflowImplement<br>class CutOffTriggerWorkflowImpl : CutOffTriggerWorkflow {<br>    override fun run() {<br>      <br>        // 출고지시 정책 조회<br>        val policies = getCutOffPolicies.get(now)<br><br>        policies.forEach { policy -&gt;<br>            // 출고지시 차수 생성<br>            val cutSequence = createCutSequence.create(policy)<br><br>            // 파이프라인 트리거<br>            triggerPipeline.trigger(cutSequence, now)<br>        }<br>    }<br>}</pre><h3>29CM 주문수집도 자동화하다</h3><p>출고지시 트리거를 Temporal로 전환하고 나니, 또 다른 수동 작업이 눈에 들어왔습니다. <strong>29CM 주문수집</strong>이었습니다.</p><p>담당자가 MOMS 화면에서 버튼을 눌러 수동으로 주문을 수집하고 있었는데, 물량이 늘면서 이 방식도 한계가 드러나기 시작했습니다. 버튼 클릭을 누락하는 경우도 있었고, 담당자 부재 시 주문 수집이 지연되기도 했습니다.</p><p>“출고지시와 비슷한 문제잖아?”</p><p>팀 내에서 자연스럽게 이러한 논의가 이어졌고, 29CM 주문수집도 Temporal Workflow로 자동화하기로 했습니다.</p><h3>개인정보 보호를 고려한 설계</h3><p>하지만 여기서 중요한 고민이 하나 있었습니다. 우리는 Temporal Cloud를 사용할 계획이므로 무신사 고객의 개인정보를 Temporal에 전달하는 것은 부적절했습니다.</p><p>회의실에서 여러 방안을 논의했고, 결국 다음과 같이 설계했습니다:</p><ol><li>29CM에서 받은 API Payload를 MOMS DB에 저장</li><li>Payload ID만 Temporal Workflow에 전달</li><li>Activity에서 Payload ID로 DB 조회 후 처리</li></ol><p><strong>즉, 개인정보는 우리 인프라 안에 머물고, Temporal에는 ID만 전달되는 구조</strong>입니다.</p><h3>주문수집 Workflow 시나리오</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*3ZllJ7Z8IUJJ-n4sSJFbYQ.png\" /></figure><ul><li>29CM API에서 주문을 조회해서 DB에 저장(ORDER_COLLECTED)합니다.</li><li>성공한 건에 대해 29CM에 상품준비중 상태 변경을 요청한 뒤, 상태를 ORDER_ACCEPTED로 변경하는 플로우입니다.</li></ul><h3>주문수집 Workflow 구현</h3><p><strong>1개의 Workflow</strong>와 <strong>4개의 Activity</strong>로 구성했습니다.</p><pre>@WorkflowImplement<br>class AddStandardOrderWorkflowImpl : AddStandardOrderWorkflow {<br>    override fun addOrders(payloadId: Long) {<br>        // 1. 주문 수집<br>        val upsertResults = addStandardOrderActivity.addOrders(payloadId)<br>        val successOrders = upsertResults.filter { it.success }<br>        if (successOrders.isEmpty()) return<br><br>        // 2. 상품 준비중 API 요청<br>        val shippingResults = requestPrepareShippingActivity.request(successOrders)<br><br>        // 3. 주문 상태를 ORDER_ACCEPTED로 변경<br>        if (shippingResults.items.isNotEmpty()) {<br>            val request = convertActivity.convert(shippingResults)<br>            changeStatusActivity.updateToAccepted(request)<br>        }<br>    }<br>}</pre><p>주문 수집 → 29CM API 호출 → 상태 변경까지의 흐름이 하나의 Workflow로 표현됩니다. 출고지시 Workflow와 비슷한 구조지만, 도메인의 특성에 맞게 Activity를 구성했습니다.</p><h3>운영하면서 느낀 것들</h3><h4>좋았던 점들</h4><h4>1. 장애 대응이 ‘케이스 바이 케이스’에서 ‘시스템’으로</h4><p>가장 먼저 체감한 변화는 <strong>자동 재시도</strong>였습니다. Activity에 정의한 Retry/Backoff/Timeout 규칙에 따라 자동으로 재시도되는 걸 보면서, “아, 이제 Spring Batch에 복잡하게 구현하지 않아도 되겠구나”라는 생각이 들었습니다.</p><p>실제로 운영 중 일시적인 네트워크 오류로 출고지시가 실패한 적이 있었는데, Temporal UI를 보니 자동으로 3번 재시도하고 성공한 걸 확인할 수 있었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*xRR-OkSmY4zf8tIl_XvT1A.png\" /><figcaption>EventID 12 : 재시도 후 성공한 케이스</figcaption></figure><h4>2. Workflow 단위로 보이는 실행 이력</h4><p>이전에는 Jenkins 로그, 애플리케이션 로그를 모두 열어봐야 했지만, <strong>Temporal UI에서 타임라인을 한눈에 확인</strong>할 수 있게 되었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*GbkPp4FK89-3N4aff2Xllg.png\" /><figcaption>하단부터 시간순 타임라인</figcaption></figure><p>특히 Activity 단위로 input, output을 빠르게 확인할 수 있어 원인 파악이 훨씬 쉬워졌습니다. “이 시점에 어떤 정책이 들어왔고, 어떤 결과가 나왔는지”를 클릭 몇 번으로 확인할 수 있게 되니, 장애 대응 시간이 크게 줄었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*nynJLox02b6lW5mbMBDJvg.png\" /><figcaption>특정 Activity의 Input, Output</figcaption></figure><h4>3. 부분 도입만으로도 체감된 변화</h4><p>출고지시 전체 파이프라인이 아닌 <strong>“트리거 + 특정 화주 주문수집”만 Temporal로 옮겼는데도</strong>, 해당 구간의 장애 대응과 모니터링 편의성은 즉시 체감할 수 있었습니다.</p><p>또한, 동일 도메인을 Spring Batch + Jenkins와 Temporal 두 체계에서 비교해보면서, 어떤 유형의 작업이 Temporal에 더 적합한지 기준을 잡는 데 도움이 되었습니다.</p><h4>고려해봐야 할 것들</h4><h4>1. Workflow·Activity 경계 설정의 어려움</h4><p>“무엇을 하나의 Workflow로 보고, 어느 단위를 Activity로 분리할 것인가”에 대한 기준을 잡는 게 쉽지 않았습니다. 팀 내에서도 의견이 엇갈릴 때가 많았고, 결국 “실제로 만들어보고 조정하자”는 방식으로 진행했습니다.</p><p>이번에는 일부에만 적용했지만, 향후 출고 전체 파이프라인으로 확장하려면 <strong>더 명확한 설계 원칙</strong>이 필요할 것 같습니다.</p><h4>2. 디버깅 포인트의 증가</h4><p>Temporal을 도입하면서 애플리케이션 로그 외에 Temporal History, Worker 메트릭까지 함께 봐야 해서 디버깅 지점이 늘어난 것은 사실입니다. 하지만 이는 단순히 복잡도가 증가했다기보다, 실행 상태를 구조적으로 관측할 수 있게 된 결과라고 느끼고 있습니다.</p><p>다만 이 장점을 살리기 위해서는, 로그·메트릭·Workflow History를 어떤 순서로 확인할지에 대한 팀 차원의 디버깅 가이드가 반드시 필요하다는 점도 함께 깨달았습니다. 현재는 이슈 대응 시 “애플리케이션 로그 → Temporal History → Worker 메트릭” 순으로 확인하는 기준을 정리 중이며, Datadog/Slack 알림 임계값도 함께 다듬어가고 있습니다.</p><h4>3. Batch와 Temporal의 공존</h4><p>Batch와 Temporal이 공존하는 현재 상태는 운영 부담이 분명 존재합니다. “이 배치는 Jenkins에서 보고, 저 워크플로우는 Temporal에서 본다”는 식으로 운영하다 보니 온콜 대응 가이드도 두 체계로 작성해야 했습니다.</p><p>하지만 이 공존은 모든 파이프라인을 한 번에 전환하지 않기 위한 의도적인 과도기이기도 합니다. 이 기간 동안 동일 도메인을 두 체계에서 비교해보면서, “장기 실행·재시도·이력 추적이 중요한 작업”은 Temporal에, “단순 반복 처리”는 Batch에 적합하다는 기준을 점점 명확히 하고 있습니다. 이러한 기준이 쌓이면 전환 시점에 대한 판단도 훨씬 명확해질 것으로 기대하고 있습니다.</p><h3>다음 여정: 출고지시 파이프라인 전체를 Temporal로</h3><p>이제 저희는 더 큰 그림을 그리고 있습니다. 출고지시 트리거와 주문수집을 Temporal로 전환하면서, 다음 단계가 분명해졌습니다.</p><p><strong>출고지시 파이프라인 전체를 Workflow로 전환하는 것.</strong></p><p>현재 출고지시는 대용량 처리 시 약 30분이 소요됩니다 (2만 건 기준). 이를 Workflow 기반 병렬 처리 구조로 전환하면 <strong>평균 90% 이상 단축</strong>할 수 있을 것으로 예상하고 있습니다.</p><p>또한 출고 전 구간의 상태, 처리 속도, 실패 지점을 실시간으로 가시화하여 문제의 원인과 영향 범위를 신속하게 파악할 수 있는 Observability 체계를 구축하려 합니다.</p><p>지금은 Child Workflow, Signal 기반 접근 방식 등 다양한 방법을 테스트하고 있습니다. 만만치 않은 도전이겠지만, 트리거와 주문수집을 통해 얻은 경험이 큰 자산이 되고 있습니다.</p><h4>AS-IS</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*UWukKCCNJBhQrh_sCo_aMw.png\" /></figure><h4>TO-BE</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*5BuNX8-EiwvfJ1Pn_BVhsw.png\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*1q4EV4qdgzZjN1HD2ClhOg.png\" /></figure><h3>마치며</h3><p>“스케줄이 또 안 돌았어요”라는 알림에서 시작된 이 여정은, 단순히 기술 스택을 바꾸는 것 이상의 의미를 가졌습니다.</p><p>저희는 <strong>“실패하지 않는 시스템”을 만드는 게 아니라, “실패해도 스스로 복구되는 시스템”</strong>을 만들고 있습니다. Temporal을 도입하면서 가장 크게 느낀 건, 기술 선택이 단순히 “어떤 라이브러리를 쓸 것인가”가 아니라 <strong>“우리가 어떻게 운영할 것인가”</strong>를 결정한다는 점이었습니다.</p><p>물론 아직 갈 길이 멉니다. Workflow 설계 기준도 계속 다듬어야 하고, 모니터링 체계도 개선해야 합니다. 출고 파이프라인 전체를 Workflow로 전환하는 것도 쉽지 않은 도전이 될 것입니다.</p><p>하지만 새벽에 출고지시 알림을 받고 급하게 수동 실행하던 날들이 조금씩 줄어들고 있습니다. 그리고 그 시간에 저희는 더 중요한 문제를 고민할 수 있게 되었습니다.</p><p>긴 글 읽어주셔서 감사합니다. <br>저희의 경험이 비슷한 고민을 하고 계신 분들께 조금이나마 도움이 되었으면 좋겠습니다.</p><h3>Platform Business Operation 조직 및 팀 소개</h3><blockquote>무신사 플랫폼 비즈니스 오퍼레이션 조직은 국내외 물류 서비스, 재고 관리, 스토어 운영을 위한 물류 프로덕트를 구축하고 다양한 오프라인 비즈니스 모델에 맞춘 스토어 관리 시스템을 개발·고도화하고 있습니다.<br>또한, 무배당발 서비스를 포함한 무신사의 차별화된 고객 경험을 브랜딩하고 확장할 수 있는 멤버십 구조를 설계하며, 온·오프라인을 넘나드는 통합 커머스 경험을 기술로 실현하고 있습니다.</blockquote><blockquote>저희 팀은 OMS(주문관리시스템)를 기반으로 온라인 주문부터 재고·출고·배송·정산에 이르는 전 과정을 유기적으로 연결하고, 무신사의 다양한 오프라인 스토어를 효과적으로 운영할 수 있는 관리 시스템을 구축하여 고객이 온라인(무신사 스토어, 29CM 등)과 오프라인(무신사 스탠다드, 편집숍 등)에서 끊김 없는 쇼핑 경험을 누릴 수 있도록 지원합니다.</blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/pbo\">🚀 Platform Business Operation 한걸음 더 알아보기</a></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/home\">🚀 팀 무신사 채용 페이지</a> (무신사/29CM 전체 포지션 확인이 가능해요)</blockquote><blockquote>🚀 <a href=\"https://kr.linkedin.com/company/musinsacom\">팀 무신사 테크 소식을 받아보는 링크드인</a></blockquote><blockquote>🚀 <a href=\"https://newsroom.musinsa.com/\">팀 무신사 뉴스룸</a></blockquote><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=f491e79a0f8f\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://techblog.musinsa.com/%EC%8A%A4%EC%BC%80%EC%A4%84%EC%9D%B4-%EB%98%90-%EC%95%88-%EB%8F%8C%EC%95%98%EC%96%B4%EC%9A%94-%EC%9A%B0%EB%A6%AC%EA%B0%80-temporal%EC%9D%84-%EC%84%A0%ED%83%9D%ED%95%9C-%EC%9D%B4%EC%9C%A0-f491e79a0f8f\">“스케줄이 또 안 돌았어요” — 우리가 Temporal을 선택한 이유</a> was originally published in <a href=\"https://techblog.musinsa.com\">MUSINSA techblog — 무신사 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2026-02-05T02:17:35.000Z",
    "url": "https://techblog.musinsa.com/%EC%8A%A4%EC%BC%80%EC%A4%84%EC%9D%B4-%EB%98%90-%EC%95%88-%EB%8F%8C%EC%95%98%EC%96%B4%EC%9A%94-%EC%9A%B0%EB%A6%AC%EA%B0%80-temporal%EC%9D%84-%EC%84%A0%ED%83%9D%ED%95%9C-%EC%9D%B4%EC%9C%A0-f491e79a0f8f?source=rss----f107b03c406e---4"
  },
  {
    "publisherId": "musinsa",
    "publisherName": "무신사 테크블로그",
    "specTitle": "e커머스 개발",
    "categories": [
      "backend"
    ],
    "specUrl": "https://medium.com/feed/musinsa-tech",
    "title": "“이번 달도 밤샘 정산입니다.” — 더 이상 밤샘하지 않아도 됩니다 (운영편)",
    "partialText": "<h3>“이번 달도 밤샘 정산입니다.” — 더 이상 밤샘하지 않아도 됩니다 (운영편)</h3><p>“이번 달도 밤샘 정산입니다.” 시리즈</p><ol><li><a href=\"https://techblog.musinsa.com/%EC%9D%B4%EB%B2%88-%EB%8B%AC%EB%8F%84-%EB%B0%A4%EC%83%98-%EC%A0%95%EC%82%B0%EC%9E%85%EB%8B%88%EB%8B%A4-%EC%A0%95%EC%82%B0-%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%80-%EC%96%B4%EB%96%BB%EA%B2%8C-%EB%A7%8C%EB%93%A4%EC%97%88%EC%9D%84%EA%B9%8C-%EC%8B%A4%EC%A0%84%ED%8E%B8-74d8a5d22ba1\">정산 시스템은 어떻게 만들었을까 (실전편)</a></li><li><a href=\"https://techblog.musinsa.com/%EC%9D%B4%EB%B2%88-%EB%8B%AC%EB%8F%84-%EB%B0%A4%EC%83%98-%EC%A0%95%EC%82%B0%EC%9E%85%EB%8B%88%EB%8B%A4-%EC%A0%95%EC%82%B0-%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%80-%EC%96%B4%EB%96%BB%EA%B2%8C-%EB%A7%8C%EB%93%A4%EC%97%88%EC%9D%84%EA%B9%8C-%EC%8B%A4%EC%A0%84%ED%8E%B8-74d8a5d22ba1\">정산 시스템은 왜 필요했을까 (설계편)</a></li><li><a href=\"https://techblog.musinsa.com/이번-달도-밤샘-정산입니다-더-이상-밤샘하지-않아도-됩니다-운영편-4f09ae3bdf5d\"><strong>더 이상 밤샘하지 않아도 됩니다 (운영편)</strong></a></li></ol><h3>들어가며</h3><p>앞선 두 편에서는 정산 시스템이 왜 어려운 문제인지, 그리고 그 문제를 어떤 구조와 기술로 풀어냈는지를 다뤘습니다. <br>마지막 글에서는 MASS 정산 시스템을 실제 운영 환경에 단계적으로 오픈하며 어떤 변화와 성과를 만들어냈는지를 정리합니다.</p><h3>단계적 오픈 전략</h3><p>정산 시스템은 한 번에 완성해서 오픈하기에는 리스크가 너무 큰 시스템입니다.<br>그래서 MASS는 기능이 아닌 <strong>데이터를 기준으로 단계적 오픈 전략</strong>을 선택했습니다.</p><ol><li><strong>원천 데이터 적재 모듈 선배포<br></strong>a. 실제 운영 환경에서 발생하는 모든 케이스를 먼저 수집<br>b. 수집 과정에서 드러난 데이터 품질 이슈와 처리 오류를 사전에 식별/수정<br>c. 정산 정책 결정이 필요한 엣지 케이스들을 정리하고 기준을 확정<br>ㅤi. 예외 데이터 처리 기준<br>ㅤii. 경계 조건에서의 금액 산정 방식 등</li><li><strong>실데이터 기반 QA/시뮬레이션<br></strong>a. 실제 데이터를 기준으로 정산 배치를 반복 실행하며 리허설</li><li><strong>검증 완료 후 전체 정산 오픈<br></strong>a. 한 달 단위 정산을 처음부터 끝까지 무결하게 수행</li></ol><p>이 전략 덕분에 시스템 오픈과 동시에 실제 정산을 안정적으로 마칠 수 있었습니다.</p><h4>단계적 오픈 전략 (데이터 적재 → QA/시뮬레이션 → 전체 오픈)</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Pcq6TxN82czZdu5eoZYe-w.png\" /></figure><h4>실데이터 기반 QA / 시뮬레이션</h4><p>정산 시스템은 실제 데이터로 검증하지 않으면, 오픈 이후에 반드시 예상하지 못한 불일치가 발생합니다.<br>그래서 MASS는 <strong>실제 운영 데이터를 기준으로 한 리허설</strong>에 집중했습니다.</p><blockquote>리허설 환경 구성</blockquote><p>QA 및 시뮬레이션은 <strong>운영 환경과 동일한 스키마를 가진 개발 환경</strong>에서 수행되었습니다.<br>운영 DB를 직접 사용하는 방식이 아니라,</p><ul><li>8월부터 10월까지 발생한 <strong>실제 원천 데이터를 개발 환경으로 마이그레이션</strong></li><li>정산 로직, 배치 설정, 기준 데이터는 운영과 동일하게 유지</li><li>운영과 분리된 환경에서 반복 실행이 가능하도록 구성</li></ul><p>이를 통해 운영 데이터의 현실적인 복잡성을 그대로 가져오면서도, 정산 배치를 <strong>수차례 재실행할 수 있는 안전한 실험 환경</strong>을 확보했습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*X28LQEXpzlOIiBpF0JzJhA.png\" /></figure><blockquote>검증 방식: 수기 정산 결과와의 비교</blockquote><p>정산 결과 검증은 <strong>수기 정산 결과와의 직접 비교</strong>를 기준으로 진행했습니다.</p><ul><li>기존 수기 정산으로 확정된 결과를 기준 데이터로 사용</li><li>동일 기간, 동일 조건으로 MASS 정산 배치를 반복 실행</li><li>업체별·항목별 금액을 단위까지 대조하며 결과 비교</li></ul><p>초기 단계에서는 일부 수동 대조가 필요했지만, 반복되는 검증 구간에 대해서는 <strong>리포트 형태로 검증을 자동화</strong>해 불일치 여부를 빠르게 식별할 수 있도록 했습니다.</p><blockquote>리허설 범위와 데이터 규모</blockquote><p>리허설은 <strong>단일 케이스가 아닌, 수개월치 실데이터</strong>를 대상으로 수행되었습니다.</p><ul><li><strong>8월 ~ 10월, 총 3개월치 실제 원천 데이터</strong></li><li>일 정산, 월 정산 시나리오 모두 반복 실행</li><li>프로모션 적용, 예외 케이스, 경계 조건 포함</li></ul><p>이를 통해 “정상 케이스”뿐 아니라, 실제 운영에서 발생하는 <strong>복합적인 케이스들까지 충분히 검증</strong>할 수 있었습니다.</p><blockquote>불일치 발생 시 원인 추적 프로세스</blockquote><p>정산 결과와 수기 결과 간 불일치가 발견되면, 단순히 결과를 맞추는 것이 아니라 <strong>원인을 끝까지 추적하는 방식</strong>으로 접근했습니다.</p><p>불일치 발생 시 다음 순서로 원인을 분석했습니다.</p><ol><li>원천 데이터 자체의 차이 여부 확인</li><li>단가/프로모션 기준 적용 여부 점검</li><li>정책적으로 정의되지 않았던 엣지 케이스 식별</li></ol><p>기술적인 오류인 경우 로직을 수정했고, 정책적으로 판단이 필요한 경우에는 <strong>정산 기준을 명시적으로 정리한 뒤 시스템에 반영</strong>했습니다.</p><p>이 과정을 반복하면서 정산 로직의 안정성뿐 아니라, <strong>정산 기준 자체의 모호함도 함께 해소</strong>할 수 있었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*jvK_Iqus0EJPHI6PIlKu1w.png\" /></figure><blockquote>이 단계의 의미</blockquote><p>이 실데이터 기반 리허설 단계는 단순한 QA가 아니라,</p><ul><li>정산 로직의 정확성을 검증하고</li><li>기준을 명확히 정의하며</li><li>오픈 이후 재처리 가능성까지 점검하는</li></ul><p><strong>정산 시스템의 ‘예행 연습’에 해당하는 단계</strong>였습니다.</p><p>이 과정을 충분히 거쳤기 때문에, MASS는 시스템 오픈과 동시에 <strong>실제 정산을 안정적으로 마칠 수 있었습니다.</strong></p><h3>오픈 이후 시스템 지표와 운영 결과</h3><p>MASS 구축 시점에 팀이 설정한 목표는 명확했습니다.</p><ul><li><strong>정산은 반드시 회계 마감 기한 내에 끝나야 한다</strong></li><li><strong>재처리·재실행 상황에서도 정산 결과는 흔들리지 않아야 한다</strong></li><li><strong>정산 규모가 증가해도 운영 방식이 복잡해지지 않아야 한다</strong></li><li><strong>수기 보정 없이 시스템 결과만으로 정산을 마칠 수 있어야 한다</strong></li><li><strong>일 정산은 운영 관점에서 부담 없이 반복 실행할 수 있도록, 평균 처리 시간을 10분 이내로 유지해야 한다</strong></li></ul><p>이러한 목표를 기준으로 시스템을 설계했고, 시스템 오픈 이후 현재까지 수행된 정산은 다음과 같은 결과를 보였습니다.</p><h4>정산 처리 성공률과 결과 확정 안정성</h4><p>MASS에서 말하는 “정산 성공”은 단순히 배치가 오류 없이 종료되었다는 의미가 아닙니다.</p><p>본 문서에서의 정산 성공은 다음 조건을 모두 만족하는 경우를 의미합니다.</p><ul><li>정산 배치가 <strong>중단 없이 완료</strong></li><li>모든 정산 대상 데이터가 <strong>정합성 검증을 통과</strong></li><li>수기 보정 없이 <strong>시스템 계산 결과만으로 정산 결과 확정</strong></li><li>회계 마감 기한 내 모든 <strong>정산 상태가 COMPLETED로 전이</strong></li></ul><p>이 기준으로 시스템 오픈 이후 수행된 정산 결과는 다음과 같습니다.</p><ul><li><strong>일 정산 성공률: 100%</strong></li><li><strong>월 정산 성공률: 100%</strong></li><li><strong>월 정산 마감 확정 성공률: 100%</strong></li></ul><p>모든 정산은 마감 기한 내 정상적으로 완료되었으며, 정산 결과 확정 과정에서도 <strong>정합성 이슈나 수기 개입 없이 </strong>시스템 결과만으로 정산을 마무리할 수 있었습니다.</p><h4>정산 처리 시간</h4><ul><li><strong>일 정산 평균 소요 시간:</strong> 약 <strong>8분 26초</strong></li><li><strong>월 정산 평균 소요 시간:</strong> 약 <strong>2분 27초</strong></li></ul><p>일 정산의 경우, 초기 목표로 설정했던 <strong>‘10분 이내 처리’ 기준을 안정적으로 만족</strong>하고 있으며, 정산 대상 규모와 관계없이 일정한 처리 시간을 유지하고 있습니다.</p><p>이는 정산 배치가</p><ul><li>데이터 규모 증가</li><li>재실행</li><li>반복 실행</li></ul><p>과 같은 운영 시나리오에서도 부담 없이 실행될 수 있도록 설계되었음을 의미합니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/548/1*iSeBKNxGUiSUG_hswfYe3A.png\" /></figure><h4>재처리 상황에서도 유지되는 정합성</h4><p>12월 3일, upstream 시스템의 재고 스냅샷 이슈로 인해 해당 일자의 정산 데이터를 다시 계산해야 하는 상황이 발생했습니다.</p><p>정산 도메인에서 이와 같은 상황은 단순한 기술적 오류를 넘어, <strong>중복 청구, 과소·과대 정산, 파트너 업체 신뢰 훼손</strong>으로 직결될 수 있는 명확한 비즈니스 리스크를 동반합니다.<br>특히 월 마감 직전이었다면, 회계 마감 지연이나 수기 보정으로 이어질 가능성도 있었습니다.</p><p>이 상황에서 MASS는 기존 정산 결과를 임의로 수정하거나 덮어쓰는 대신,</p><ul><li>해당 일자의 정산 대상 원천 데이터만을 기준으로 재처리를 수행했고</li><li>멱등성 기반 처리로 <strong>중복 정산 없이 안전하게 재계산</strong>했으며</li><li>재처리 이후에도 <strong>정산 결과는 기존 기준과 동일하게 유지</strong>되었습니다.</li></ul><p>그 결과, 최초 정산 시점과 재처리 이후의 금액 차이에 대해서는 파트너 업체에 <strong>변경 사유와 함께 정산 결과를 다시 공유</strong>해야 했지만,</p><ul><li>변경된 금액이 어떤 기준에서 발생했는지 명확하게 설명할 수 있었고</li><li>수기 계산이나 임시 보정 없이 <strong>시스템 결과만으로 정산을 확정</strong>할 수 있었으며</li><li>회계 마감 일정 역시 영향을 받지 않았습니다.</li></ul><p>이 사례는 재처리와 복구를 전제로 한 설계가 단순히 “다시 계산할 수 있다”는 수준을 넘어, <strong>장애 상황에서도 정산 변경을 통제 가능한 방식으로 관리하며 비즈니스 리스크를 최소화했음을 보여주는 사례</strong>였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*MrJnJCWQWmq5WrvdMVZBaw.png\" /></figure><h4>수기 정산 프로세스 변화</h4><p>시스템 도입 전후의 정산 프로세스는 다음과 같이 변화했습니다.</p><p><strong>As-Is (수기 정산 — 6단계)</strong></p><ul><li>물류 데이터 추출</li><li>금액 산정(정산)</li><li>정산서 작성</li><li>품의 상신</li><li>품의 승인</li><li>세금계산서 반영</li></ul><p><strong>To-Be (시스템 정산 — 2단계)</strong></p><ul><li>정산 금액 확인</li><li>세금계산서 반영</li></ul><p>기존 <strong>6단계에 달하던 수기 정산 프로세스는 </strong>단 <strong>2단계의 확인 중심 프로세스로 축소</strong>되었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*PStZqs6VZ_2Jj1OQwB6Mzg.png\" /></figure><h4>정산 마감 소요 시간 변화</h4><p>정산 대상 업체 수가 증가함에 따라, 기존 수기 정산 방식은 <strong>업체 수에 정비례하여 작업 시간이 증가하는 구조</strong>였습니다.</p><ul><li><strong>정산 대상 40개 업체 기준</strong></li><li>수기 정산 마감 소요 시간: 약 <strong>23시간</strong></li><li><strong>정산 대상 100개 업체 기준</strong></li><li>수기 정산 마감 소요 시간: 약 <strong>30시간 이상</strong></li></ul><p>정산 마감은 영업일 기준 <strong>D+2(총 16 근무시간)</strong> 내 완료가 필요했기 때문에, 담당자 1명 기준으로는 <strong>40개 업체가 사실상 처리 가능한 한계</strong>였습니다.</p><p>반면, MASS 도입 이후에는 정산 방식이 근본적으로 달라졌습니다.</p><ul><li>정산 대상 업체 수와 무관하게</li><li><strong>월 정산 마감 확정까지 약 1시간 내 완료</strong></li></ul><p>즉,</p><ul><li>40개 업체 기준: <strong>23시간 → 1시간</strong></li><li>100개 업체 기준: <strong>30시간 → 1시간</strong></li></ul><p>정산 시스템 도입을 통해 <strong>정산 규모가 증가해도 마감 기한을 안정적으로 지킬 수 있는 구조</strong>를 확보했습니다.</p><blockquote>정산 방식에 따른 마감 소요 시간 비교</blockquote><p>아래 그래프는 정산 대상 업체 수 증가에 따른 <strong>수기 정산 방식과 시스템 정산 방식의 차이</strong>를 직관적으로 보여줍니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*YoHHgxcg181mGeTNOLjI1A.png\" /><figcaption>(베이지: 수기 / 주황: MASS)</figcaption></figure><p>이 그래프가 보여주듯,</p><ul><li>수기 정산은 <strong>업체 수 증가 = 마감 리스크 증가</strong></li><li>MASS 정산은 <strong>업체 수 증가와 무관한 일정한 처리 시간</strong></li></ul><p>이라는 차이를 가집니다.</p><p>이는 단순한 자동화 효과가 아니라, 정산 업무를 <strong>사람의 처리 한계에서 시스템 처리 한계로 전환</strong>한 결과였습니다.</p><h4>정산 데이터 제공 주기 변화</h4><p>정산 결과의 가시성 역시 크게 개선되었습니다.</p><ul><li><strong>정산 데이터 제공 주기:</strong> 월 1회 → <strong>매일</strong></li><li><strong>파트너 업체 조회 가능 시점:</strong> 매일 <strong>오전 11시</strong></li></ul><p>이를 통해 파트너 업체는 월 마감 이후가 아니라, 운영 중에도 매일 비용을 확인하고 관리할 수 있게 되었습니다.</p><h3>마치며</h3><p>정산 자동화의 진짜 가치는 단순한 시간 단축에 있지 않습니다. MASS는 정산을 사람의 경험과 기억이 아닌, 시스템의 책임으로 옮겼습니다.</p><p>이번 시리즈를 통해 정산이라는 어려운 도메인을 어떻게 설계하고, 구현하고, 운영으로 안착시켰는지를 공유했습니다. <br>MASS의 정산 자동화는 시작에 불과하며, 앞으로도 다양한 정산 도메인으로 확장해 나갈 예정입니다.</p><h3>Platform Business Operation 조직 및 팀 소개</h3><blockquote><em>무신사 플랫폼 비즈니스 오퍼레이션 조직은 국내외 물류 서비스, 재고 관리, 스토어 운영을 위한 물류 프로덕트를 구축하고 다양한 오프라인 비즈니스 모델에 맞춘 스토어 관리 시스템을 개발·고도화하고 있습니다.<br>또한, 무배당발 서비스를 포함한 무신사의 차별화된 고객 경험을 브랜딩하고 확장할 수 있는 멤버십 구조를 설계하며, 온·오프라인을 넘나드는 통합 커머스 경험을 기술로 실현하고 있습니다.</em></blockquote><blockquote><em>저희 팀은 OMS(주문관리시스템)를 기반으로 온라인 주문부터 재고·출고·배송·정산에 이르는 전 과정을 유기적으로 연결하고, 무신사의 다양한 오프라인 스토어를 효과적으로 운영할 수 있는 관리 시스템을 구축하여 고객이 온라인(무신사 스토어, 29CM 등)과 오프라인(무신사 스탠다드, 편집숍 등)에서 끊김 없는 쇼핑 경험을 누릴 수 있도록 지원합니다.</em></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/pbo\"><em>🚀 Platform Business Operation 한걸음 더 알아보기</em></a></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/home\"><em>🚀 팀 무신사 채용 페이지</em></a><em> (무신사/29CM 전체 포지션 확인이 가능해요)</em></blockquote><blockquote><em>🚀 </em><a href=\"https://kr.linkedin.com/company/musinsacom\"><em>팀 무신사 테크 소식을 받아보는 링크드인</em></a></blockquote><blockquote><em>🚀 </em><a href=\"https://newsroom.musinsa.com/\"><em>팀 무신사 뉴스룸</em></a></blockquote><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=4f09ae3bdf5d\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://techblog.musinsa.com/%EC%9D%B4%EB%B2%88-%EB%8B%AC%EB%8F%84-%EB%B0%A4%EC%83%98-%EC%A0%95%EC%82%B0%EC%9E%85%EB%8B%88%EB%8B%A4-%EB%8D%94-%EC%9D%B4%EC%83%81-%EB%B0%A4%EC%83%98%ED%95%98%EC%A7%80-%EC%95%8A%EC%95%84%EB%8F%84-%EB%90%A9%EB%8B%88%EB%8B%A4-%EC%9A%B4%EC%98%81%ED%8E%B8-4f09ae3bdf5d\">“이번 달도 밤샘 정산입니다.” — 더 이상 밤샘하지 않아도 됩니다 (운영편)</a> was originally published in <a href=\"https://techblog.musinsa.com\">MUSINSA techblog — 무신사 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2026-02-02T09:01:05.000Z",
    "url": "https://techblog.musinsa.com/%EC%9D%B4%EB%B2%88-%EB%8B%AC%EB%8F%84-%EB%B0%A4%EC%83%98-%EC%A0%95%EC%82%B0%EC%9E%85%EB%8B%88%EB%8B%A4-%EB%8D%94-%EC%9D%B4%EC%83%81-%EB%B0%A4%EC%83%98%ED%95%98%EC%A7%80-%EC%95%8A%EC%95%84%EB%8F%84-%EB%90%A9%EB%8B%88%EB%8B%A4-%EC%9A%B4%EC%98%81%ED%8E%B8-4f09ae3bdf5d?source=rss----f107b03c406e---4"
  },
  {
    "publisherId": "musinsa",
    "publisherName": "무신사 테크블로그",
    "specTitle": "e커머스 개발",
    "categories": [
      "backend"
    ],
    "specUrl": "https://medium.com/feed/musinsa-tech",
    "title": "“이번 달도 밤샘 정산입니다.” — 정산 시스템은 어떻게 만들었을까 (실전편)",
    "partialText": "<h3>“이번 달도 밤샘 정산입니다.” — 정산 시스템은 어떻게 만들었을까 (실전편)</h3><p>“이번 달도 밤샘 정산입니다.” 테크 블로그 시리즈</p><ol><li><a href=\"https://techblog.musinsa.com/%EC%9D%B4%EB%B2%88-%EB%8B%AC%EB%8F%84-%EB%B0%A4%EC%83%98-%EC%A0%95%EC%82%B0%EC%9E%85%EB%8B%88%EB%8B%A4-%EC%A0%95%EC%82%B0-%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%80-%EC%96%B4%EB%96%BB%EA%B2%8C-%EB%A7%8C%EB%93%A4%EC%97%88%EC%9D%84%EA%B9%8C-%EC%8B%A4%EC%A0%84%ED%8E%B8-74d8a5d22ba1\"><strong>정산 시스템은 어떻게 만들었을까 (실전편)</strong></a></li><li><a href=\"https://techblog.musinsa.com/22732a4a607f\">정산 시스템은 왜 필요했을까 (설계편)</a></li><li><a href=\"https://techblog.musinsa.com/이번-달도-밤샘-정산입니다-더-이상-밤샘하지-않아도-됩니다-운영편-4f09ae3bdf5d\">더 이상 밤샘하지 않아도 됩니다 (운영편)</a></li></ol><h3>들어가며</h3><p>앞선 글에서는 정산 시스템이 왜 본질적으로 어려운 문제인지, 그리고 MASS가 멱등성과 결정적 계산이라는 설계 원칙을 선택한 이유를 살펴보았습니다. <br>이번 글에서는 그 설계가 실제로 어떤 기술 선택과 구조를 통해 구현되었는지, MASS 정산 시스템의 실전 구축 과정을 이야기합니다.</p><h3>멱등성을 전제로 한 이벤트 처리</h3><p>정산에 사용되는 원천 데이터는 이벤트 형태로 유입됩니다.<br>이벤트 기반 시스템에서 중복 수신이나 재처리는 피할 수 없는 상황이기 때문에, MASS에서는 이를 <strong>전제 조건</strong>으로 두었습니다.</p><ul><li>이벤트 재시도(Retry)와 격리(DLT)를 분리해 처리</li><li>트랜잭션 식별자를 기준으로 서비스 레벨에서 멱등 갱신</li><li>동일 이벤트가 여러 번 처리되어도 결과는 항상 동일</li></ul><p>이를 통해 장애 상황에서도 안전하게 재처리할 수 있는 기반을 마련했습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*WVBTqEPRTnxzFRF5ux3o_Q.png\" /></figure><p>(⬆️ 1편 내용)</p><h4>DLT 메시지 모니터링과 처리 방식</h4><p>DLT로 전달된 이벤트는 <strong>정산 흐름에서 즉시 제외</strong>되며, 별도의 모니터링과 운영 프로세스를 통해 관리됩니다.</p><ul><li>DLT 발생 시 즉시 알림을 통해 운영자가 인지할 수 있도록 구성</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*jeNo9FnMmvUBNGb-NoSXtw.png\" /></figure><ul><li>DLT 메시지는 원본 이벤트와 동일한 컨텍스트를 유지한 채 저장</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*EMx-OyThRv5VNbvZEdccLQ.png\" /></figure><ul><li>이벤트 페이로드, 트랜잭션 식별자, 실패 사유를 기준으로 원인 분석 가능</li><li>정책 오류, 데이터 품질 문제 등 원인이 명확한 경우 기준 정리 후 재처리 수행</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/818/1*2u_Johv6F-ibbNFJZYBGDg.png\" /></figure><p>이를 통해 <strong>문제 있는 이벤트가 전체 정산 흐름을 멈추는 상황을 방지</strong>하면서도, 사후 분석과 재처리를 위한 정보는 모두 보존합니다.</p><h4>실제 운영 중 DLT 발생 현황</h4><p>시스템 오픈 이후 실제 운영 환경에서 발생한 DLT 이벤트는 전체 이벤트 대비 <strong>극히 낮은 비율</strong>로 유지되고 있습니다.</p><ul><li>DLT 발생 비율: <strong>전체 이벤트 중 0.001% 미만</strong></li><li>DLT로 격리된 이벤트 역시 정산 결과에는 영향을 주지 않음</li></ul><p>정산과 같이 결과의 정합성이 중요한 도메인에서 “실패를 격리하되, 전체 흐름은 멈추지 않는다”는 설계 의도가 운영 단계에서도 그대로 유지되고 있습니다.</p><h3>MASS의 모듈 구성</h3><p>MASS는 크게 세 개의 독립적인 애플리케이션 모듈로 나뉩니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*CiuUuW5tzyBNchxaGptz4A.png\" /></figure><h4>mass-consumer</h4><ul><li>물류 서비스 유형별 원천 데이터를 메시지로 수신하는 애플리케이션</li><li>Kafka를 통해 이벤트를 소비</li><li>멱등 처리 후 정산 원천 데이터로 저장</li><li>이벤트 기반 처리 영역의 진입점 역할</li></ul><h4>mass-batch</h4><ul><li>일/월 정산을 수행하는 배치 애플리케이션</li><li>정산 집계, 마감, 리포트 생성</li><li>Kafka 복구 잡 등 운영 유틸리티 배치 포함</li><li>재처리와 복구를 전제로 한 실행 구조</li></ul><h4>mass-api</h4><ul><li>내부 운영자와 파트너 업체를 위한 REST API 제공</li><li>정산, 프로모션 등의 데이터 조회 및 관리 기능</li><li>정산 결과를 외부에 안전하게 노출하는 인터페이스</li></ul><h4>재처리와 복구를 전제로 한 실행 구조</h4><p>정산 배치는 실패 가능성을 전제로 설계되었습니다.<br>중요한 것은 배치가 실패했을 때 <strong>어디서부터 다시 실행할 수 있는가</strong>가 아니라, <strong>어떤 상태를 기준으로 정산을 다시 정의할 수 있는가</strong>였습니다.</p><p>MASS에서는 이를 위해 정산 대상 원천 데이터에 명시적인 <strong>정산 상태 컬럼</strong>을 두고 배치 실행 흐름을 관리합니다.</p><p>정산 상태는 다음과 같이 관리됩니다.</p><ul><li><strong>PENDING</strong>: 정산 대상 후보 상태</li><li><strong>PROCESSING</strong>: 현재 정산 배치에서 처리 중인 상태</li><li><strong>COMPLETED</strong>: 정산이 정상 완료된 상태</li></ul><blockquote><strong>배치 실행 흐름과 상태 전이</strong></blockquote><p>정산 배치는 다음 순서로 수행됩니다.</p><ol><li>배치 시작 시점에 해당 실행의 정산 대상 원천 데이터만 <strong>PENDING → PROCESSING</strong> 상태로 마킹</li><li>마킹된 데이터만을 기준으로 step 별 <strong>chunk 단위 처리</strong> 수행</li><li>모든 step이 정상 완료되면 처리된 데이터의 상태를 <strong>COMPLETED</strong>로 전이</li><li>배치가 중간에 실패할 경우 해당 실행에서 <strong>PROCESSING 상태로 마킹되었던 데이터들을 다시 PENDING으로 롤백</strong></li></ol><p>이 구조를 통해 배치는 chunk 단위로 실행되지만, <strong>복구와 재처리의 기준은 항상 “정산 대상 전체”로 유지</strong>됩니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*v7YCvHYRi9pg9BFpq3F6Vw.png\" /></figure><blockquote><strong>재시도 시 처리 방식</strong></blockquote><p>배치 재시도 시에는 이전 실행 결과를 이어서 처리하지 않습니다.</p><ul><li>이전 실행에서 PROCESSING 상태였던 데이터는 모두 롤백</li><li>재시도 시점에 다시 정산 대상 데이터를 선정해 <strong>PROCESSING으로 재마킹</strong></li><li>이후 멱등성을 전제로 한 <strong>upsert 방식</strong>으로 정산 재수행</li></ul><p>이를 통해 재실행 시에도</p><ul><li>중복 정산 없이</li><li>동일한 기준으로</li><li>항상 동일한 결과를 얻을 수 있습니다.</li></ul><blockquote><strong>실제 재처리 사례: 12월 3일 재고 스냅샷 이슈</strong></blockquote><p>12월 3일, upstream 시스템의 재고 스냅샷 이슈로 인해 해당 일자의 정산 데이터에 대해 재처리가 필요했습니다.</p><p>이 경우 MASS에서는</p><ul><li>12월 3일 정산 대상 원천 데이터만 <strong>PENDING 상태로 롤백</strong></li><li>이슈 해결 후 동일 날짜의 정산 재실행</li></ul><p>재처리는 chunk 단위로 수행되었지만, 정산 대상 상태를 기준으로 재정의했기 때문에 중복 반영이나 부분 정산 없이 <strong>정산 결과를 처음부터 다시 계산</strong>할 수 있었습니다.</p><p>그 결과,</p><ul><li>다른 날짜의 정산 결과에는 영향을 주지 않았고</li><li>재처리 이후에도 <strong>정산 금액은 기존 기준과 동일하게 유지</strong>되었습니다.</li></ul><h3>이벤트 + 배치 하이브리드 구조</h3><p>MASS는 정산 도메인의 특성에 맞게, <strong>이벤트 기반 처리와 배치 기반 처리를 목적에 따라 분리한 하이브리드 구조</strong>로 설계되어 있습니다.</p><p>실시간에 가까운 데이터 반영이 필요한 영역과, 회계 마감처럼 안정성과 재현성이 중요한 영역의 요구사항이 다르기 때문입니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*cGARaSH-ca10vR3LYjUU1g.png\" /></figure><h4>이벤트 기반 처리 영역</h4><p>이벤트 기반 영역은 <strong>정산의 ‘원천 데이터’를 책임지는 영역</strong>입니다.</p><ul><li>물류 서비스 유형별로 발생하는 원천 이벤트를 수신</li><li>이벤트 중복이나 재처리를 고려한 멱등 저장</li></ul><p>이 영역은 <em>데이터를 빠르게 수집</em>하는 데 초점을 둡니다.</p><h4>배치 기반 처리 영역</h4><p>배치 기반 영역은 <strong>정산의 ‘확정’과 ‘마감’을 책임지는 영역</strong>입니다.</p><ul><li>일/월 단위 정산 대상 집계</li><li>정산 마감 처리</li><li>정산 리포트 생성</li><li>실패 시 재처리를 고려한 복구용 배치 운영</li></ul><p>이 영역은 속도보다는 <strong>안정성과 재현성</strong>을 우선하며, 동일 조건에서 언제 실행해도 같은 결과를 내는 것을 목표로 합니다.</p><h3>왜 이런 구조를 선택했는가</h3><p>이 구조를 통해 MASS는 다음 두 가지를 동시에 만족시킬 수 있었습니다.</p><ul><li>이벤트 기반 구조로 <strong>실시간에 가까운 데이터 가시성 확보</strong></li><li>배치 기반 구조로 <strong>회계 마감의 안정성과 재현성 보장</strong></li></ul><p>결과적으로 MASS는 <strong>“빠르게 변하는 데이터”와 “확정되어야 하는 숫자”를 하나의 시스템 안에서 충돌 없이 다룰 수 있는 구조</strong>를 갖추게 되었습니다.</p><h3>기술 선택과 그 배경</h3><p>앞선 섹션에서 MASS가 이벤트 기반과 배치 기반을 혼합한 구조를 선택한 이유를 설명했습니다.<br>이 섹션에서는 그 구조를 실제로 구현하기 위해 <strong>어떤 기술 스택을 선택했고, 그 선택이 정산 도메인에 왜 적합했는지</strong>를 정리합니다.</p><p>MASS에서의 기술 선택은 “어떤 기술이 더 최신인가”가 아니라 <strong>정산이라는 도메인의 핵심 요구사항인 ‘정합성, 재처리 가능성, 운영 안정성’을 얼마나 잘 만족시키는가</strong>를 기준으로 이루어졌습니다.</p><h4>전체 기술 스택 요약</h4><p>MASS는 JVM 기반의 안정적인 기술 스택 위에서 다음과 같이 구성되어 있습니다.</p><p><strong>언어 / 런타임</strong></p><ul><li>JVM 기반 (Kotlin)</li></ul><p><strong>애플리케이션 프레임워크</strong></p><ul><li>Spring Boot</li><li>Spring Batch (정산 배치 및 마감 처리)</li></ul><p><strong>메시징</strong></p><ul><li>Kafka (원천 데이터 이벤트 수신)</li></ul><p><strong>데이터베이스</strong></p><ul><li>MySQL (정산 결과의 Source of Truth)</li></ul><p><strong>운영 / 모니터링</strong></p><ul><li>배치 실행 상태 및 실패 로그 기반 모니터링</li><li>DLT 이벤트 및 배치 실패 시 알림 연계</li><li>에러, Latency, 인프라 모니터링</li></ul><p>이 스택은 고성능보다는 <strong>예측 가능성, 재현성, 장애 대응 용이성</strong>을 우선한 선택입니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*VN591bZIeeRGbdtCTpbxaw.png\" /></figure><h4>Kafka를 통한 원천 데이터 수신</h4><p>정산에 사용되는 원천 데이터는 다음과 같은 특성을 가집니다.</p><ul><li>입·출고, 재고 스냅샷 등 <strong>트래픽이 특정 시점에 집중</strong></li><li>동일 이벤트의 <strong>중복 수신, 재전송, 재처리 가능성</strong></li><li>일시적인 장애가 있더라도 <strong>데이터 유실은 절대 허용 불가</strong></li></ul><p>이러한 특성 때문에, 원천 데이터를 API 호출 방식으로 동기 수신하는 구조는 적합하지 않다고 판단했습니다.</p><p>Kafka 기반 이벤트 수신 방식은</p><ul><li>원천 데이터를 <strong>비동기로 안정적으로 적재</strong>할 수 있고</li><li>소비자 장애와 무관하게 이벤트를 보존할 수 있으며</li><li>동일 이벤트를 다시 소비하는 방식으로 <strong>재처리를 자연스럽게 지원</strong>합니다</li></ul><p>정산 데이터는 “빨리 처리되는 데이터”보다 <strong>“언제든 다시 처리할 수 있어야 하는 데이터”</strong>였기 때문에, MASS는 Kafka를 원천 데이터 수신 방식으로 선택했습니다.</p><h4>Spring Batch 기반의 정산 처리</h4><p>정산 처리에서 가장 중요한 요구사항은 실시간성이 아니라 다음과 같았습니다.</p><ul><li>회계 마감 기준에 맞는 <strong>명확한 실행 시점</strong></li><li>실패를 전제로 한 <strong>재처리·복구 구조</strong></li><li>실행 이력과 결과를 추적할 수 있는 <strong>감사 가능성</strong></li></ul><p>이를 위해 정산 집계와 마감 처리는 Spring Batch 기반으로 설계했습니다.</p><blockquote><strong>배치 실행 환경과 제어 방식</strong></blockquote><p>MASS는 Kubernetes 기반의 <strong>EKS 환경</strong>에서 운영되고 있으며, 정산 배치 역시 이 환경에 맞는 실행 구조를 갖도록 설계했습니다.</p><p>정산 배치는 애플리케이션 내부 스케줄러에 의해 자동 실행되는 방식이 아니라,</p><ul><li><strong>Spring Batch 기반의 batch 애플리케이션</strong>을 컨테이너로 구성하고</li><li>배치 실행 시점과 흐름은 <strong>Argo Workflow</strong>를 통해 외부에서 제어하는 방식으로 운영됩니다</li></ul><p>즉, Spring Batch는 <em>정산 로직과 실행 상태 관리</em>를 담당하고, 배치의 실행 시점과 재실행 제어는 <strong>Argo Workflow가 책임지는 구조</strong>입니다.</p><p>이를 통해 정산 배치는 “코드 안에 숨어 있는 백그라운드 작업”이 아니라, <strong>EKS 환경에서 명시적으로 관리되는 워크플로우 단계</strong>가 되었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/496/1*LAdmMX51xIOBKN3RHUGWRg.png\" /></figure><blockquote><strong>Job Parameter 기반 실행</strong></blockquote><p>Argo Workflow는 정산 배치를 실행할 때,</p><ul><li>정산 기준 날짜</li><li>정산 기준 타입</li></ul><p>등을 <strong>Job Parameter로 전달</strong>합니다.</p><p>이를 통해 MASS의 정산 배치는</p><ul><li>동일한 코드로</li><li>서로 다른 기간과 기준을</li><li>실행 이력으로 명확히 구분된 형태로 수행할 수 있습니다</li></ul><p>“어떤 기준으로, 언제 실행된 정산인지”가 로그가 아니라 <strong>Batch Execution 이력 자체로 추적 가능</strong>해졌습니다.</p><blockquote><strong>Spring Batch 선택 이유와 실행 모델</strong></blockquote><p>Spring Batch는</p><ul><li>Job / Step / Execution 단위로 <strong>실행 상태와 이력 관리</strong></li><li>대용량 데이터를 <strong>chunk 단위로 안정적으로 처리</strong></li><li>실패 시 <strong>재실행 시점 제어</strong></li></ul><p>를 기본적으로 제공합니다.</p><p>이 특성은 정산 배치를 “한 번 실행하고 끝나는 작업”이 아니라, <strong>실패와 재실행을 전제로 운영되는 작업</strong>으로 만드는 데 적합했습니다.</p><blockquote><strong>정산 대상 마킹 기반 실행 흐름</strong></blockquote><p>MASS에서는 배치 실행 시 다음과 같은 흐름을 따릅니다.</p><ol><li>배치 시작 시 해당 실행의 <strong>정산 대상 원천 데이터만 선별</strong></li><li>선별된 데이터의 정산 상태를 PENDING → PROCESSING으로 일괄 마킹</li><li>마킹된 데이터만을 기준으로 Step 별 <strong>chunk 단위 처리 수행</strong></li><li>모든 Step이 정상 완료되면 정산 상태를 COMPLETED로 전이</li><li>중간 실패 시 PROCESSING 상태 데이터를 다시 PENDING으로 롤백</li></ol><p>이 구조를 통해 배치는 chunk 단위로 실행되지만, <strong>재처리의 기준은 항상 ‘정산 대상 전체’로 유지</strong>됩니다.</p><p>즉, 배치가 어느 지점에서 실패하더라도 이전 실행 결과에 의존하지 않고 정산 대상 단위로 <strong>처음부터 다시 실행할 수 있는 구조</strong>를 만들었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*85NH0_qvf4s9kq_9hal8KQ.png\" /></figure><blockquote><strong>운영 관점에서의 의미</strong></blockquote><p>Spring Batch와 Argo Workflow를 결합한 이 실행 환경을 통해, 정산 배치는</p><ul><li>EKS 환경에서 <strong>운영자가 명시적으로 제어 가능한 작업</strong>이 되었고</li><li>실행 실패 역시 <strong>운영 이벤트로 인지하고 대응할 수 있는 대상</strong>이 되었으며</li><li>재실행이 두려운 배치가 아니라 <strong>언제든 다시 돌릴 수 있는 배치</strong>가 되었습니다</li></ul><p>그 결과 MASS의 정산 배치는 회계 마감이라는 높은 안정성이 요구되는 영역에서도 안전하게 운영될 수 있는 기반을 갖추게 되었습니다.</p><h4>데이터베이스 선택과 정합성 보장</h4><p>정산 결과는 반드시 <strong>하나의 기준(Source of Truth)</strong>으로 관리되어야 했기 때문에, MASS는 트랜잭션 처리가 명확한 <strong>RDB(MySQL)</strong>를 정산 결과 저장소로 선택했습니다.</p><p>RDB를 선택함으로써 다음을 명확히 할 수 있었습니다.</p><ul><li>정산 결과의 <strong>정합성 보장</strong></li><li>트랜잭션 단위의 상태 전이 관리</li><li>트랜잭션 식별자를 기준으로 한 <strong>멱등성 갱신(upsert)</strong></li></ul><p>이는 이벤트 중복, 재처리, 장애 복구 상황에서도 정산 결과가 흔들리지 않도록 하는 핵심 기반이 되었습니다.</p><h4>운영 / 모니터링 체계</h4><p>정산 시스템에서 운영과 모니터링은 “장애를 없애는 것”보다 <strong>장애를 빠르게 인지하고, 영향 범위를 통제하는 것</strong>이 더 중요했습니다.</p><p>MASS에서는 이를 위해 실시간 모니터링과 함께 <strong>주기적인 점검을 결합한 운영 체계</strong>를 구성했습니다.</p><p><strong>배치 실행 상태 및 실패 로그 기반 모니터링</strong></p><ul><li>일/월 정산 배치의 실행 성공 여부</li><li>Step 단위 실패 지점 및 재시도 여부</li><li>마감 미완료 상태에 대한 조기 감지</li></ul><p><strong>DLT 이벤트 및 배치 실패 시 알림 연계</strong></p><ul><li>재시도 한계를 초과한 이벤트는 DLT로 격리</li><li>DLT 발생 및 배치 실패 시 즉시 알림을 통해 인지</li><li>장애 상황에서도 원천 데이터 유실 없이 후속 조치 가능</li></ul><p><strong>에러, Latency, 인프라 지표 모니터링</strong></p><ul><li>이벤트 소비 지연(Lag) 및 처리 Latency 관측</li><li>애플리케이션 에러율과 비정상 트래픽 감지</li><li>인프라 리소스(CPU, Memory) 사용량을 통한 병목 사전 인지</li></ul><p><strong>주 단위 시스템 상태 점검</strong></p><ul><li>주 단위로 트래픽, 에러, Latency, 인프라 지표 추이 점검</li><li>잠재적인 성능 저하나 이상 징후를 사전에 식별하고 개선</li></ul><p>이러한 운영 체계를 통해 MASS는 장애가 발생한 이후에 대응하는 방식이 아니라, <strong>문제가 되기 전에 신호를 감지하고 선제적으로 조치하는 운영 방식</strong>을 갖추게 되었습니다.</p><h3>마치며</h3><p>정산 시스템의 구현에서 중요한 것은 최신 기술의 조합이 아니라, 실패와 재실행을 자연스럽게 받아들이는 구조였습니다. <br>MASS는 Kafka, Spring Batch, Argo Workflow를 통해 정산을 안정적으로 구현했고, 실패해도 다시 실행할 수 있는 시스템을 만들 수 있었습니다.</p><p>다음 글에서는 이 시스템을 어떻게 단계적으로 오픈했고, 실제 운영에서 어떤 변화와 성과를 만들었는지 살펴보겠습니다.</p><h3>Platform Business Operation 조직 및 팀 소개</h3><blockquote><em>무신사 플랫폼 비즈니스 오퍼레이션 조직은 국내외 물류 서비스, 재고 관리, 스토어 운영을 위한 물류 프로덕트를 구축하고 다양한 오프라인 비즈니스 모델에 맞춘 스토어 관리 시스템을 개발·고도화하고 있습니다.<br>또한, 무배당발 서비스를 포함한 무신사의 차별화된 고객 경험을 브랜딩하고 확장할 수 있는 멤버십 구조를 설계하며, 온·오프라인을 넘나드는 통합 커머스 경험을 기술로 실현하고 있습니다.</em></blockquote><blockquote><em>저희 팀은 OMS(주문관리시스템)를 기반으로 온라인 주문부터 재고·출고·배송·정산에 이르는 전 과정을 유기적으로 연결하고, 무신사의 다양한 오프라인 스토어를 효과적으로 운영할 수 있는 관리 시스템을 구축하여 고객이 온라인(무신사 스토어, 29CM 등)과 오프라인(무신사 스탠다드, 편집숍 등)에서 끊김 없는 쇼핑 경험을 누릴 수 있도록 지원합니다.</em></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/pbo\"><em>🚀 Platform Business Operation 한걸음 더 알아보기</em></a></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/home\"><em>🚀 팀 무신사 채용 페이지</em></a><em> (무신사/29CM 전체 포지션 확인이 가능해요)</em></blockquote><blockquote><em>🚀 </em><a href=\"https://kr.linkedin.com/company/musinsacom\"><em>팀 무신사 테크 소식을 받아보는 링크드인</em></a></blockquote><blockquote><em>🚀 </em><a href=\"https://newsroom.musinsa.com/\"><em>팀 무신사 뉴스룸</em></a></blockquote><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=74d8a5d22ba1\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://techblog.musinsa.com/%EC%9D%B4%EB%B2%88-%EB%8B%AC%EB%8F%84-%EB%B0%A4%EC%83%98-%EC%A0%95%EC%82%B0%EC%9E%85%EB%8B%88%EB%8B%A4-%EC%A0%95%EC%82%B0-%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%80-%EC%96%B4%EB%96%BB%EA%B2%8C-%EB%A7%8C%EB%93%A4%EC%97%88%EC%9D%84%EA%B9%8C-%EC%8B%A4%EC%A0%84%ED%8E%B8-74d8a5d22ba1\">“이번 달도 밤샘 정산입니다.” — 정산 시스템은 어떻게 만들었을까 (실전편)</a> was originally published in <a href=\"https://techblog.musinsa.com\">MUSINSA techblog — 무신사 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2026-01-27T05:01:27.000Z",
    "url": "https://techblog.musinsa.com/%EC%9D%B4%EB%B2%88-%EB%8B%AC%EB%8F%84-%EB%B0%A4%EC%83%98-%EC%A0%95%EC%82%B0%EC%9E%85%EB%8B%88%EB%8B%A4-%EC%A0%95%EC%82%B0-%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%80-%EC%96%B4%EB%96%BB%EA%B2%8C-%EB%A7%8C%EB%93%A4%EC%97%88%EC%9D%84%EA%B9%8C-%EC%8B%A4%EC%A0%84%ED%8E%B8-74d8a5d22ba1?source=rss----f107b03c406e---4"
  },
  {
    "publisherId": "musinsa",
    "publisherName": "무신사 테크블로그",
    "specTitle": "e커머스 개발",
    "categories": [
      "backend"
    ],
    "specUrl": "https://medium.com/feed/musinsa-tech",
    "title": "2025년 제 1회 29QA Con 진행 후기 (29QA Conference)",
    "partialText": "<p>29CM QE팀은 연말에 팀 자체적으로 Conference를 진행하였습니다.</p><p>2024년까지는 연 2회 워크샵을 진행해서 각자 레슨런을 공유하는 자리를 가졌는데 2025년에는 상반기 워크샵을 진행하지 못하여 하반기에만 진행하게 되었고 이렇게 된 김에 연 행사처럼 고유의 컨퍼런스를 개최해 보자는 생각에 29QA Con을 계획하였습니다.</p><p>나중에는 점점 규모가 커져서 다른 회사의 QA 분들도 모시고 싶다고 생각해서 처음부터 어느 정도 형식을 갖추자는 판단을 했습니다. 그래서 굿즈도 만들고 홍보 배너도 만들었는데 만들고 나니 정말 컨퍼런스 분위기가 물씬 풍겨 진행하기를 잘했다는 생각이 들었습니다.</p><p>한 달가량의 촉박한 일정이었지만 4명의 팀원이 3개 이상씩의 세션을 준비해서 총 13개의 세션이 진행되었습니다. 짧은 기간 동안 열심히 양질의 자료를 만들어서 공유해 준 팀원분들 덕분에 훌륭한 하나의 Conference가 진행될 수 있었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*a_kRGeIIOTyukVPti6WlgA.jpeg\" /><figcaption>컨퍼런스 느낌이 나도록 X배너도 제작해서 걸어두었습니다.</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*FBDeSTwJS4pZ3GP3eITbjA.jpeg\" /><figcaption>팀 마스코트인 ‘큐엉이&#39; 가 포함된 굿즈도 여러개 제작하였습니다. 스티커 빼고 완판(?) 되었답니다.</figcaption></figure><p>식순은 아래와 같이 진행되었습니다. <br>발표 15분, 쉬는 시간 5분 정도를 계획해 두었습니다.</p><pre>1.  29CM에서의 팀 셋팅, 지금의 신뢰받는 QE팀은 어떻게 만들어졌나 (박현준)<br>2.  차세대 테스트 자동화 - Vibium(조진현)<br>3.  25년 자동화 유지보수 여정 (정다정)<br>4.  iOS 자동화 1년 여정 + 코드리뷰의 중요성 (강보민)<br>5.  귀찮음을 해결했더니 팀이 빨라졌다: QA 업무 자동화 사례 (정다정)<br>6.  아무도 궁금하지 않은 QA Weekly 작성 vlog (박현준)<br>7.  혼자 할 때는 몰랐던 것들: 2인 이상의 QA로 얻은 교훈 (강보민)<br>8.  질문을 잘하는 것이 곧 살아남는 방법이다 (조진현)<br>9.  눈물과 분노없이 볼 수 없는 Cursor를 사용한 29TMS 제작기 (박현준)<br>10. 대 AI 시대 Testcase 생성 찍먹해보기 (강보민)<br>11. 글로벌 서비스 QA 시에는 무엇이 달라지나 (정다정)<br>12. 2025년 회고 (조진현)<br>13. 2025년 한해 돌아보기 (+팀 회고) (박현준)</pre><p>하지만 발표가 시작되면 어김없이 기존 발표시간이 초과되는 사태가 발생하여서 발표자분들의 열정을 느낄 수 있었지만 시간관리에는 어려움이 있었습니다. 😅</p><p>쉬는시간을 타이트하게 가져가면서 열심히 진행했던 기억이 남습니다.</p><p>1️⃣ 첫번째 세션으로는 <br>“29CM에서의 팀 셋팅, 지금의 신뢰받는 QE팀은 어떻게 만들어졌나” 가 진행되었습니다.</p><p>제가 처음으로 29CM에 입사하여 QA팀을 신설하고 지금의 조직으로 만들기까지의 과정을 팀원분들께 공유하는 시간이었습니다. 초반에 조직의 신뢰를 얻기 위해서 결과로 증명하기 위한 노력과 이후 팀 방향성을 견고히 하기 위해 어떤 액션들을 했는지에 대한 과정들을 공유하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*N4w85aXBj-lebCKf2w1wyw.jpeg\" /></figure><p>2️⃣ 두번째 세션으로는 <br>“차세대 테스트 자동화 — Vibium” 이 진행되었습니다.</p><p>Selenium을 세상에 나오게 하여 테스트 자동화의 발전을 가속화 시킨 Jason Huggins에 대한 이야기와 그가 현재 개발하고 있는 Vibium은 어떤 것이고 어떤 것이 가능하게 되는지에 대한 것을 공유하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*5eTtGCw4N-n0VjT4J316qQ.jpeg\" /></figure><p>3️⃣ 세번째 세션으로는 <br>“25년 자동화 유지보수 여정” 이 진행되었습니다.</p><p>29CM에서는 App 테스트 자동화를 2023년부터 운영하고 있는데 이 과정에서 점점 시나리오는 증가하고 기술 복잡도가 증가함으로 인해서 여러 가지 자동화 Fail 건들이 발생했습니다. 이 중에 주요 원인 3대장을 분석하였고 이를 해결하여 Fail율을 극적으로 낮출 수 있었던 과정을 공유하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*XHFZKjJC2YR9zZGYQj5tWA.jpeg\" /></figure><p>4️⃣ 네번째 세션으로는 <br>“iOS 자동화 1년 여정 + 코드 리뷰의 중요성” 이 진행되었습니다.</p><p>보민님은 최근에 iOS 자동화 Owner가 되시면서 어떻게 하면 더 효율적이고 개선된 환경으로 유지보수를 할 수 있는지에 대한 고민을 많이 하셨습니다. <br>그 과정에서 코드 리뷰의 중요성을 느끼시고 그곳에서 받은 도움과 효과를 공유하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*EhOzw8F7BhlRQlrEn1hlYQ.png\" /></figure><p>🍚 원래는 다섯번째 세션 완료 후 점심시간이였지만 시간이 좀 지나 점심시간 확보를 위해 약간 빠르게 점심식사를 하러 이동하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/816/1*2E5uOfWSn2jwqlOmg009tw.png\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/917/1*jHMYW29UTBmjlM0lY6Rcqg.png\" /><figcaption>냠냠냠!</figcaption></figure><p>5️⃣ 다섯번째 세션으로는 <br>“귀찮음을 해결했더니 팀이 빨라졌다: QA 업무 자동화 사례” 가 진행되었습니다.</p><p>QE팀은 현재 다양한 Slack bot을 사용 중에 있습니다. 테스트 결과 리포트를 도와주는 Daily Report Bot과 Google 문서들을 공유해 주는 Bot등 여러 가지의 Bot이 있는데, 이 Bot들을 개발하면서 진행하게 된 개선 활동에 대한 레슨런을 공유하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*EUy-GsVpgGAtwMQSpbAZPw.png\" /></figure><p>6️⃣ 여섯번째 세션으로는 <br>“아무도 궁금하지 않은 QA Weekly 작성 vlog” 가 진행되었습니다.</p><p>제가 매주 작성하고 있는 QA Weekly에 관한 내용입니다. 이것을 작성하기 위해 제가 어떤 과정을 진행하고 있는지에 대한 이야기였는데, 모두 궁금하지는 않았겠지만 의외로(?) 많은 시간과 노력이 들어가고 있다는 내용을 공유하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*A0Q8OS4seRa3dgPVJIy6OQ.png\" /></figure><p>7️⃣ 일곱번째 세션으로는 <br>“혼자 할 때는 몰랐던 것들: 2인 이상의 QA로 얻은 교훈” 이 진행되었습니다.</p><p>작년 상반기까지만 해도 1인 QA로 진행하는 업무들이 많았습니다. 하반기부터는 외주 QA분들과 함께하게 되면서 이제 2인 이상 QA업무를 같이 진행하는 경우가 많이 생겼는데, 이러한 과정에서 어떤 레슨런이 있었는지에 대한 내용을 공유하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*-XjOLHm2jIC0bnr3uE0DYQ.png\" /></figure><p>8️⃣ 여덟번째 세션으로는 <br>“질문을 잘하는 것이 곧 살아남는 방법이다” 가 진행되었습니다.</p><p>사내에서도 AI을 적극적으로 사용하는 것을 권장하기 때문에 작년에 QE팀도 다양한 AI 도구들을 사용할 수 있었습니다. 이 과정에서 프롬프트 엔지니어링에 대해 고민을 하였고, 내가 원하는 방향의 답변과 결과를 얻기 위해서 어떠한 질문들을 해야 하는지에 대한 고민과 연구를 진행한 내용을 공유하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*359U7U9nuXb0nrLMQK0TVA.png\" /></figure><p>9️⃣ 아홉번째 세션으로는 <br>“눈물과 분노 없이 볼 수 없는 Cursor를 사용한 29TMS 제작기” 가 진행되었습니다.</p><p>이건 아쉽게도 영상으로 찍히지 않아서 세션 진행 자료가 없습니다. 😢 그래서 발표 자료로 대체해야 할 것 같습니다.</p><p>AI 에이전트 관련 세션인 만큼 발표자료는 AI를 활용한 이미지 생성으로 진행하였는데, 각 사례에 맞는 이미지를 생성하면서 제가 생각한 이미지가 정확히 나왔을때 즐거워하며 작업던 기억이 있습니다.</p><p>테스트케이스 관리 도구의 불편함을 개선하기 위해 초반에는 Cursor로 개발을 시작하였고 후반부에는 Claude code로 전환하여 개발을 완료하게 된 29TMS (Testcase Management System)에 관련된 이야기입니다. 현재는 1.9 버전이 업데이트 되어서 초기에 비해 사용성이 대폭 증가하였고 3개월 넘는 기간 동안 실무에서 잘 사용중입니다.</p><blockquote>관련 블로그: <a href=\"https://techblog.musinsa.com/ai와의-성공적인-첫-co-work-바이브-코딩으로-탄생된-맞춤형-testcase-management-system-29tms-74062a620119\">AI와의 성공적인 첫 Co Work — 바이브 코딩으로 탄생된 맞춤형 Testcase Management System (29TMS)</a></blockquote><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/996/1*IPlQRzqXZX5tsIpuPNkd_w.png\" /><figcaption>나노바나나야 고마워</figcaption></figure><p>🔟 열번째 세션으로는 <br>“대 AI 시대 Testcase 생성 찍먹해보기” 가 진행되었습니다.</p><p>3가지의 생성형 AI 도구를 대상으로 테스트케이스 생성에 대한 품질 테스트를 진행한 내용입니다. 어떤 AI는 어느 부분에 강점이 있었고 최종적으로는 어떤 AI 도구가 가장 높은 점수의 테스트케이스 생성 능력을 보여주었는지에 대한 과정을 공유하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*WDYEbaAPJPl1EQN3RvYmvA.png\" /></figure><p>1️⃣1️⃣ 열한번째 세션으로는<br>“글로벌 서비스 QA 시에는 무엇이 달라지나” 가 진행되었습니다.</p><p>이전 회사에서 경험했었던 글로벌 서비스에 대한 경험을 가지고 실사례를 기반으로 하여 우리 서비스가 글로벌 진출을 하게 된다면 어떤 것을 고려해야 하고 유의해야 하는지에 대한 내용과 진행하면서 어려웠던 점들을 공유하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*lcfT8oVoAKvK63gvlbaG4A.png\" /></figure><p>1️⃣2️⃣ 열두번째 세션으로는<br>“2025년 회고 (조진현)” 가 진행되었습니다.</p><p>2024년 9월 입사 이후 2025년은 온전한 1년을 모두 보낸 해였습니다. 2025년에는 어떤 경험과 성장을 이루었는지 한해를 돌아보며 회고한 내용을 공유하였습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*MIhsntTkY0Ayl_dVSUu_IQ.png\" /></figure><p>1️⃣3️⃣ 열세번째 마지막 세션으로는<br>“2025년 한해 돌아보기 (+팀 회고)” 가 진행되었습니다.</p><p>2025년 저는 어떻게 팀을 운영하며 개인에 대한 성장을 이뤄냈고 어떠한 변화를 맞이하여 그것에 적응하고 또 팀을 운영해 나갔는지에 대한 내용을 공유하였습니다. 많은 일들이 있었던 한 해였던 것 같습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*2toHaPvkWj43c5eNl074vw.png\" /></figure><p>이렇게 준비한 모든 세션이 완료되고 준비한 모든 팀원분들이 서로에게 박수를 보내며 제1회 29QA Con은 마무리가 되었습니다.</p><p>인원수는 많지 않았지만 풍부한 세션과 레슨런이 있었고 중간에 참석해서 자리를 빛내주신 MUSINSA QE팀 분들 덕분에 더 풍부한 컨퍼런스가 될 수 있었던것 같습니다.</p><p>바쁘신 와중에 참석해주신 MUSINSA QE팀 분들 감사합니다 :)</p><p>저희 QE팀은 연말에 고유 행사가 있습니다. 제가 팀원분들께 연말 선물을 드리는 것인데요 2023년은 장식용 캘린더, 2024년은 드래곤볼 7성구 (소원이루시라는 뜻으로 ^^), 그리고 2025년은 각자의 얼굴을 팝아트로 다시 그려낸 캔버스 그림을 선물로 드렸습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*3HOVjowbc36PfzHj8I2LRA.png\" /><figcaption>짠</figcaption></figure><p>그리고는 맛있는 저녁회식을 떠났습니다.</p><p>모두 열심히 준비하고 진행해준 만큼 회식도 더 맛있고 즐거웠을것으로 예상해봅니다 :)</p><p>올해에도 잘 준비해서 다른 QA분들이 발표도 하실수 있고, 참여도 하실 수 있는 행사로 만들어 보도록 하겠습니다.</p><h3>TEAM MUSINSA CAREER</h3><blockquote><em>무신사는 2001년 온라인 커뮤니티로 시작해 2005년 무신사 매거진, 2009년 무신사 스토어를 오픈하며 빠르게 성장하고 있는 국내 대표 온라인 패션 스토어입니다. ‘입점 브랜드와 동반성장’이라는 경영 철학을 바탕으로 브랜드가 안정적으로 사업을 전개할 수 있도록 무신사가 보유한 노하우와 인프라를 지원합니다. 고객에게는 풍성한 패션 콘텐츠와 패션에 특화된 차별화된 서비스로 최상의 온라인 쇼핑 경험을 제공하고 있습니다. 글로벌 №1 패션 기업으로 성장할 무신사와 함께 새로운 도전과 혁신을 만들 인재를 기다립니다.</em></blockquote><blockquote><em>29CM는 ‘고객의 더 나은 선택을 돕는다’라는 미션으로 출발했습니다. 우리는 우리만의 방식으로 콘텐츠를 제공하며, 브랜드와 고객 모두에게 대체 불가능한 커머스 플랫폼을 만들어가고 있습니다. 이 미션을 이루기 위해 우리는 흥미로우면서도 복잡한 문제들을 해결하고 있습니다. 만약 우리와 함께 이 문제들을 해결해 보고 싶다면, 주저하지 말고 29CM에 합류하세요!</em></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/home\"><em>🚀 팀 무신사 채용 페이지</em></a><em> (무신사/29CM 전체 포지션 확인이 가능해요)</em></blockquote><blockquote><em>🚀 </em><a href=\"https://kr.linkedin.com/company/musinsacom\"><em>팀 무신사 테크 소식을 받아보는 링크드인</em></a></blockquote><blockquote><em>🚀 </em><a href=\"https://newsroom.musinsa.com/\"><em>팀 무신사 뉴스룸</em></a></blockquote><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=610644aaf27b\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://techblog.musinsa.com/2025%EB%85%84-%EC%A0%9C-1%ED%9A%8C-29qa-con-%EC%A7%84%ED%96%89-%ED%9B%84%EA%B8%B0-29qa-conference-610644aaf27b\">2025년 제 1회 29QA Con 진행 후기 (29QA Conference)</a> was originally published in <a href=\"https://techblog.musinsa.com\">MUSINSA techblog — 무신사 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2026-01-26T22:02:56.000Z",
    "url": "https://techblog.musinsa.com/2025%EB%85%84-%EC%A0%9C-1%ED%9A%8C-29qa-con-%EC%A7%84%ED%96%89-%ED%9B%84%EA%B8%B0-29qa-conference-610644aaf27b?source=rss----f107b03c406e---4"
  },
  {
    "publisherId": "musinsa",
    "publisherName": "무신사 테크블로그",
    "specTitle": "e커머스 개발",
    "categories": [
      "backend"
    ],
    "specUrl": "https://medium.com/feed/musinsa-tech",
    "title": "“이번 달도 밤샘 정산입니다.” — 정산 시스템은 왜 필요했을까 (설계편)",
    "partialText": "<h3>“이번 달도 밤샘 정산입니다.” — 정산 시스템은 왜 필요했을까 (설계편)</h3><p>“이번 달도 밤샘 정산입니다.” 테크 블로그 시리즈</p><ol><li><a href=\"https://techblog.musinsa.com/이번-달도-밤샘-정산입니다-정산-시스템은-어떻게-만들었을까-실전편-74d8a5d22ba1\">정산 시스템은 어떻게 만들었을까 (실전편)</a></li><li><a href=\"https://techblog.musinsa.com/%EC%9D%B4%EB%B2%88-%EB%8B%AC%EB%8F%84-%EB%B0%A4%EC%83%98-%EC%A0%95%EC%82%B0%EC%9E%85%EB%8B%88%EB%8B%A4-%EC%A0%95%EC%82%B0-%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%80-%EC%96%B4%EB%96%BB%EA%B2%8C-%EB%A7%8C%EB%93%A4%EC%97%88%EC%9D%84%EA%B9%8C-%EC%8B%A4%EC%A0%84%ED%8E%B8-74d8a5d22ba1?source=collection_home_page----f107b03c406e-----0-----------------------------------\"><strong>정산 시스템은 왜 필요했을까 (설계편)</strong></a></li><li><a href=\"https://techblog.musinsa.com/이번-달도-밤샘-정산입니다-더-이상-밤샘하지-않아도-됩니다-운영편-4f09ae3bdf5d\">더 이상 밤샘하지 않아도 됩니다 (운영편)</a></li></ol><h3>들어가며</h3><p>정산 업무를 경험해 본 조직이라면 익숙한 문장입니다.</p><p>정산은 매달 반드시 마감되어야 하지만, 그 과정은 늘 사람의 손과 기억에 크게 의존해 왔습니다. 데이터는 흩어져 있고, 기준은 상황마다 조금씩 달라지며, 한 번 계산한 결과도 다시 믿기 어려운 경우가 많습니다.</p><p>MASS는 이러한 문제의식에서 출발했습니다.</p><p>단순히 수기 작업을 자동화하는 것을 넘어, <strong>정산이라는 행위를 시스템이 책임질 수 있도록 만들고자 했습니다.</strong><br>이번 연재의 1편에서는 MASS를 설계하며 가장 먼저 고민했던 질문들, 그리고 그에 대한 설계 원칙을 공유합니다.</p><h3>MASS란 무엇인가</h3><p><strong>MASS는 Musinsa Accounting &amp; Settlement System의 약자</strong>로, <br>물류/운영 과정에서 발생하는 비용을 기준으로 파트너 업체와의 물류비 정산을 자동화하는 시스템입니다.</p><p>MASS는 다음 역할을 수행합니다.</p><ul><li>물류 운영 시 발생하는 입고/출고/반품/재고에 대한 <strong>원천 데이터를 수집</strong></li><li>조건과 단가를 기준으로 <strong>정산 금액을 계산</strong></li><li>일/월 단위로 <strong>정산을 집계하고 마감</strong></li><li>내부 담당자와 외부 파트너 업체가 <strong>동일한 기준의 정산 결과를 확인</strong>할 수 있도록 제공</li></ul><p>즉, MASS는 단순히 정산 금액을 계산하는 도구가 아니라, 정산 결과에 대한 논쟁이 생겼을 때 최종 기준이 되는 시스템을 목표로 설계되었습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*e051S3n4IrpKebneSIYzDA.png\" /></figure><h3>정산 시스템이 어려운 이유</h3><p>정산은 단순히 숫자를 더하는 문제가 아닙니다.</p><ul><li>회계 마감이라는 <strong>절대적인 데드라인</strong></li><li>단 한 건의 오류도 허용되지 않는 <strong>정합성 요구</strong></li><li>과거 기준으로 언제든 다시 계산할 수 있어야 하는 <strong>재현성</strong></li></ul><p>기존에는 여러 단계의 수기 작업과 엑셀 검증을 통해 이를 처리하고 있었고, 이 방식은 높은 업무 부담과 오류 가능성을 동시에 안고 있었습니다.</p><p>MASS는 이 문제를 “정산을 더 빨리 하자”가 아니라 <strong>“정산을 시스템이 책임지게 하자”</strong>는 관점에서 접근했습니다.</p><h3>설계 원칙: 속도보다 신뢰성</h3><p>MASS를 설계하면서 가장 먼저 합의한 원칙은 다음과 같습니다.</p><blockquote><em>정산 시스템은 빠르게 계산하는 시스템이 아니라 </em><strong><em>실패해도 다시 계산할 수 있는 시스템이어야 합니다.</em></strong></blockquote><p>이를 위해 아래 원칙을 아키텍처 전반에 반영했습니다.</p><ul><li><strong>정합성과 멱등성</strong></li><li><strong>결정적 계산(재현성)</strong><br><em>(결정적 계산: 같은 원천 데이터와 계산 기준을 사용하면 언제 다시 계산해도 동일한 결과가 나오도록 설계된 계산)</em></li><li><strong>감사 가능성(추적성)</strong></li><li><strong>배치 실패 복구 및 재시작성</strong></li></ul><h3>멱등성을 전제로 한 이벤트 처리</h3><p>정산에 사용되는 원천 데이터는 이벤트 형태로 유입됩니다.</p><p>이벤트 기반 시스템에서 중복 수신이나 재처리는 피할 수 없는 상황이기 때문에, MASS에서는 이를 <strong>전제 조건</strong>으로 두었습니다.</p><ul><li>이벤트 재시도(Retry)와 격리(DLT)를 분리해 처리</li><li>트랜잭션 식별자를 기준으로 서비스 레벨에서 멱등 갱신</li><li>동일 이벤트가 여러 번 처리되어도 결과는 항상 동일</li></ul><p>이를 통해 장애 상황에서도 안전하게 재처리할 수 있는 기반을 마련했습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*xENmTFP7ucjwQzf10heeyg.png\" /></figure><h4>이벤트 재시도(Retry)와 격리(DLT)를 분리해 처리</h4><p>이벤트 기반 정산 시스템에서는 일시적인 실패와 구조적인 실패를 구분해 다루는 것이 중요합니다.</p><p>MASS에서는 이를 위해 <strong>이벤트 재시도(Retry)</strong>와 <strong>격리(DLT, Dead Letter Topic)</strong>를 명확히 분리해 처리합니다.</p><p>일시적인 네트워크 오류나 외부 의존성 문제로 인한 실패는 재시도를 통해 정상 흐름으로 복귀시키고, 반복 재시도 이후에도 처리할 수 없는 이벤트는 정상 파이프라인에서 분리해 DLT로 격리합니다.</p><h4>트랜잭션 식별자를 기준으로 한 서비스 레벨 멱등 갱신</h4><p>MASS에서는 모든 원천 이벤트에 대해 업스트림 시스템에서 이미 존재하는 고유 식별자를 활용합니다. <br>입·출고, 재고 스냅샷 이벤트에 포함된 식별자를 조합해 정산 도메인 관점의 트랜잭션 식별자로 사용합니다.</p><p>이 식별자는 단순한 DB Unique Key가 아니라, <strong>정산 관점에서 이미 처리된 이벤트인지 판단하는 기준</strong>입니다.</p><ul><li>동일 식별자가 처음 들어오면 신규 정산 데이터로 처리</li><li>이미 처리된 이벤트라면 결과를 유지하거나(no-op)</li><li>정책 변경 등 의도적인 경우에만 갱신</li></ul><p>이를 통해 MASS는 DB 예외에 의존하지 않고, 도메인 규칙에 기반한 멱등성을 확보했습니다.</p><h3>결정적 계산을 위한 정산 로직</h3><p>정산 금액 계산은 가능한 한 단순하고 결정적으로 설계했습니다.</p><ul><li>계산기 모듈은 입력값에만 의존</li><li>금액 스케일과 반올림 정책을 고정</li><li>계산 단계를 명확히 분리해 추론 가능성 확보</li></ul><p>이 구조의 핵심은 <strong>“같은 입력이면 언제 계산해도 같은 결과가 나온다”</strong>는 점입니다.<br>덕분에 이의 제기, 기준 변경, 재처리 상황에서도 동일한 기준으로 다시 계산할 수 있습니다.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*ESdtMRhioW0uIXh6o5EH-g.png\" /></figure><h4>계산기 모듈은 입력값에만 의존</h4><p>정산 계산 로직은 외부 상태나 실행 시점에 따라 결과가 달라지지 않도록, <strong>입력값만으로 결과가 결정되는 순수 함수 형태</strong>로 설계했습니다.</p><p>정산 계산에 필요한 모든 정보는 CalculateCommand와 그 안의 SettlementContext에 명시적으로 포함됩니다.</p><pre>data class SettlementContext(<br>    val settlementDate: LocalDate,<br>    val settlementBaseType: SettlementBaseType,<br>)</pre><p>SettlementContext는 “언제, 어떤 기준으로 정산하는가”를 명확히 표현하는 최소 단위의 컨텍스트로, 정산 계산 과정에서 <strong>현재 시각, 실행 환경, 전역 상태</strong>와 같은 외부 요인을 참조하지 않도록 만든 장치입니다.</p><p>이를 단순화하면 일 정산 계산 로직은 다음과 같은 형태를 가집니다.</p><pre># pseudo code<br><br>function calculateDailySettlement(command):<br>    # command includes:<br>    # - settlementContext (settlementDate, settlementBaseType)<br>    # - serviceType, partnerId, brandId<br>    # - logisticsCategoryCode, quantity, policy flags<br><br>    # 1) 정산 기준일 기준으로 단가 조회<br>    base = findBasePrice(command)<br>    unitPrice = base.baseUnitPrice<br><br>    # 2) 정산 기준일 기준으로 할인 정책 적용<br>    discountedUnitPrice = applyDiscount(<br>        unitPrice,<br>        base.serviceChargeBase,<br>        command.settlementContext.settlementDate,<br>        command.partnerId,<br>        command.brandId<br>    )<br><br>    # 3) 수량 반영<br>    originAmount     = unitPrice * command.quantity<br>    discountedAmount = discountedUnitPrice * command.quantity<br><br>    # 4) 정산 결과 반환<br>    return {<br>        unitPrice,<br>        discountedUnitPrice,<br>        originAmount,<br>        discountedAmount,<br>        remoteAreaUnitPrice (optional)<br>    }</pre><p>이 구조에서 계산 결과는 오직 다음 입력에 의해서만 결정됩니다.</p><ul><li><strong>정산 기준일(settlementDate)</strong></li><li><strong>정산 기준 유형(settlementBaseType)</strong></li><li>정책 정보(단가, 할인 조건)</li><li>원천 데이터(수량 등)</li></ul><p>덕분에 동일한 정산 컨텍스트와 입력이 주어지면 <strong>언제, 몇 번을 실행하더라도 동일한 정산 결과가 보장</strong>됩니다.</p><p>이는 이의 제기 대응, 기준 변경 이후의 재계산, 장애 복구 후 재처리 상황에서도 <strong>과거 정산을 동일한 기준으로 다시 계산할 수 있는 재현성</strong>을 확보하는 핵심 전제였습니다.</p><h4>금액 스케일과 반올림 정책을 고정</h4><p>정산 도메인에서 반올림은 “표현 방식”이 아니라 <strong>결과 자체를 바꾸는 규칙</strong>입니다.<br>특히 할인/수수료처럼 소수점이 개입되는 계산은 <strong>반올림 시점과 방식이 조금만 달라도 최종 금액이 달라질 수 있습니다.</strong><br>일 단위로는 몇 원 수준의 차이처럼 보여도, 월 단위 집계로 누적되면 <strong>정산 금액 불일치</strong>로 이어질 수 있습니다.</p><p>그래서 MASS에서는 다음을 원칙으로 두었습니다.</p><ul><li>모든 금액 계산은 BigDecimal로 수행해 <strong>부동소수점 오차를 원천 차단</strong></li><li>할인 적용 시 <strong>스케일(MONEY_SCALE)을 강제로 고정</strong></li><li>반올림은 <strong>항상 동일한 정책(RoundingMode.DOWN)</strong>을 사용</li></ul><p>예를 들어 비율 할인(RATE)의 경우, 할인율을 퍼센트에서 실제 rate로 변환한 뒤 곱셈을 수행하고, 그 결과를 <strong>반드시 동일한 스케일로 내림(DOWN) 처리</strong>해 할인 적용 단가를 결정합니다.</p><pre>// RATE 할인: percent -&gt; rate 변환 후 곱셈, 그리고 스케일/반올림 정책 강제<br>val percent = discount.discountValue.max(BigDecimal.ZERO).min(MAX_RATE_VALUE)<br>val rate = BigDecimal.ONE.subtract(percent.movePointLeft(RATE_SCALE))<br><br>val discountedUnitPrice =<br>    unitPrice<br>        .multiply(rate)<br>        .setScale(MONEY_SCALE, RoundingMode.DOWN)<br>        .max(BigDecimal.ZERO)</pre><p>이처럼 “소수점이 생길 수 있는 지점”에서 <strong>정책을 코드로 강제</strong>해두면,</p><ul><li>계산 경로가 달라져도(일 정산/월 정산/재처리)</li><li>실행 환경이 달라져도(다른 서비스/다른 배치)</li></ul><p>항상 동일한 금액 산출이 가능해지고, 결과적으로 <strong>정산 결과의 재현성</strong>을 확보할 수 있습니다.</p><blockquote><em>정산 시스템에서 반올림 정책은 구현 디테일이 아니라, “같은 입력이면 같은 결과가 나와야 한다”는 신뢰를 지키는 핵심 규칙입니다.</em></blockquote><h3>마치며</h3><p>정산 시스템의 어려움은 계산식이 아니라, <strong>다시 계산해야 하는 현실</strong>에 있습니다. <br>MASS는 멱등성과 결정적 계산이라는 설계 원칙을 통해 정산을 사람의 기억이 아닌 시스템의 책임으로 옮기고자 했습니다.</p><p>다음 글에서는 이러한 설계가 실제로 어떤 기술 선택과 구조로 구현되었는지, Kafka와 Spring Batch, Argo Workflow를 활용한 정산 시스템의 실전 이야기를 다룰 예정입니다.</p><h3><strong>Platform Business Operation 조직 및 팀 소개</strong></h3><blockquote><em>무신사 플랫폼 비즈니스 오퍼레이션 조직은 국내외 물류 서비스, 재고 관리, 스토어 운영을 위한 물류 프로덕트를 구축하고 다양한 오프라인 비즈니스 모델에 맞춘 스토어 관리 시스템을 개발·고도화하고 있습니다.<br>또한, 무배당발 서비스를 포함한 무신사의 차별화된 고객 경험을 브랜딩하고 확장할 수 있는 멤버십 구조를 설계하며, 온·오프라인을 넘나드는 통합 커머스 경험을 기술로 실현하고 있습니다.</em></blockquote><blockquote><em>저희 팀은 OMS(주문관리시스템)를 기반으로 온라인 주문부터 재고·출고·배송·정산에 이르는 전 과정을 유기적으로 연결하고, 무신사의 다양한 오프라인 스토어를 효과적으로 운영할 수 있는 관리 시스템을 구축하여 고객이 온라인(무신사 스토어, 29CM 등)과 오프라인(무신사 스탠다드, 편집숍 등)에서 끊김 없는 쇼핑 경험을 누릴 수 있도록 지원합니다.</em></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/pbo\"><em>🚀 Platform Business Operation 한걸음 더 알아보기</em></a></blockquote><blockquote><a href=\"https://www.musinsacareers.com/ko/home\"><em>🚀 팀 무신사 채용 페이지</em></a><em> (무신사/29CM 전체 포지션 확인이 가능해요)</em></blockquote><blockquote><em>🚀 </em><a href=\"https://kr.linkedin.com/company/musinsacom\"><em>팀 무신사 테크 소식을 받아보는 링크드인</em></a></blockquote><blockquote><em>🚀 </em><a href=\"https://newsroom.musinsa.com/\"><em>팀 무신사 뉴스룸</em></a></blockquote><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=22732a4a607f\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://techblog.musinsa.com/22732a4a607f\">“이번 달도 밤샘 정산입니다.” — 정산 시스템은 왜 필요했을까 (설계편)</a> was originally published in <a href=\"https://techblog.musinsa.com\">MUSINSA techblog — 무신사 테크 블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
    "date": "2026-01-21T22:22:08.000Z",
    "url": "https://techblog.musinsa.com/22732a4a607f?source=rss----f107b03c406e---4"
  }
]