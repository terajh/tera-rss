<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>dev RSS - Google Developers Blog</title>
    <link>https://developers.googleblog.com</link>
    <description>Google Developers Blog RSS 피드</description>
    <lastBuildDate>Fri, 20 Feb 2026 16:15:00 GMT</lastBuildDate>
    <item>
      <title>Turn creative prompts into interactive XR experiences with Gemini</title>
      <link>https://developers.googleblog.com/turn-creative-prompts-into-interactive-xr-experiences-with-gemini/</link>
      <guid>https://developers.googleblog.com/turn-creative-prompts-into-interactive-xr-experiences-with-gemini/</guid>
      <pubDate>Fri, 20 Feb 2026 15:39:55 GMT</pubDate>
      <content:encoded>The Android XR team is using Gemini&apos;s Canvas feature to make creating immersive extended reality (XR) experiences more accessible. This allows developers to rapidly prototype interactive 3D environments and models on a Samsung Galaxy XR headset using simple creative prompts.</content:encoded>
    </item>
    <item>
      <title>Get ready for Google I/O 2026</title>
      <link>https://developers.googleblog.com/get-ready-for-google-io-2026/</link>
      <guid>https://developers.googleblog.com/get-ready-for-google-io-2026/</guid>
      <pubDate>Fri, 20 Feb 2026 15:39:55 GMT</pubDate>
      <content:encoded>Google I/O returns May 19-20. Watch the livestreams for updates on Android, AI, Chrome, and Cloud. Registration is open on the Google I/O website.</content:encoded>
    </item>
    <item>
      <title>Conductor Update: Introducing Automated Reviews</title>
      <link>https://developers.googleblog.com/conductor-update-introducing-automated-reviews/</link>
      <guid>https://developers.googleblog.com/conductor-update-introducing-automated-reviews/</guid>
      <pubDate>Fri, 20 Feb 2026 15:39:55 GMT</pubDate>
      <content:encoded>Conductor for the Gemini CLI has introduced a new Automated Review feature designed to verify the quality and accuracy of AI-generated code. This update addresses the challenge of validating agentic development by automatically checking implementations against original plans, enforcing style guides, and identifying security risks or bugs. by incorporating test-suite validation and providing actionable reports, Conductor helps developers ensure that their AI agents deliver safe, predictable, and architecturally sound code before it is finalized.</content:encoded>
    </item>
    <item>
      <title>Making Gemini CLI extensions easier to use</title>
      <link>https://developers.googleblog.com/making-gemini-cli-extensions-easier-to-use/</link>
      <guid>https://developers.googleblog.com/making-gemini-cli-extensions-easier-to-use/</guid>
      <pubDate>Fri, 20 Feb 2026 15:39:55 GMT</pubDate>
      <content:encoded>To simplify the user experience and prevent startup failures, the Gemini CLI has introduced structured extension settings that eliminate the need for manual environment variable configuration. This update enables extensions to automatically prompt users for required details during installation and securely stores sensitive information, such as API keys, directly in the system keychain. Users can now easily manage and override these configurations globally or per project using the new Gemini extensions config command.</content:encoded>
    </item>
    <item>
      <title>Access public data insights faster: Data Commons MCP is now hosted on Google Cloud</title>
      <link>https://developers.googleblog.com/access-public-data-insights-faster-data-commons-mcp-is-now-hosted-on-google-cloud/</link>
      <guid>https://developers.googleblog.com/access-public-data-insights-faster-data-commons-mcp-is-now-hosted-on-google-cloud/</guid>
      <pubDate>Fri, 20 Feb 2026 15:39:55 GMT</pubDate>
      <content:encoded>Data Commons has launched a free, hosted Model Context Protocol (MCP) service on Google Cloud Platform, eliminating the need for users to manage complex local server installations. This update simplifies connecting AI agents and the Gemini CLI to Data Commons, allowing Google to handle security, updates, and resource management while users query data natively.</content:encoded>
    </item>
    <item>
      <title>Introducing the Developer Knowledge API and MCP Server</title>
      <link>https://developers.googleblog.com/introducing-the-developer-knowledge-api-and-mcp-server/</link>
      <guid>https://developers.googleblog.com/introducing-the-developer-knowledge-api-and-mcp-server/</guid>
      <pubDate>Fri, 20 Feb 2026 15:39:55 GMT</pubDate>
      <content:encoded>Google is launching the Developer Knowledge API and MCP Server in public preview. This new toolset provides a canonical, machine-readable way for AI assistants and agentic platforms to search and retrieve up-to-date documentation across Firebase, Google Cloud, Android, and more. By using the official MCP server, developers can connect tools directly to Google’s documentation corpus, ensuring that AI-generated code and guidance are based on authoritative, real-time context.</content:encoded>
    </item>
    <item>
      <title>Easy FunctionGemma finetuning with Tunix on Google TPUs</title>
      <link>https://developers.googleblog.com/easy-functiongemma-finetuning-with-tunix-on-google-tpus/</link>
      <guid>https://developers.googleblog.com/easy-functiongemma-finetuning-with-tunix-on-google-tpus/</guid>
      <pubDate>Fri, 20 Feb 2026 15:39:55 GMT</pubDate>
      <content:encoded>Finetuning the FunctionGemma model is made fast and easy using the lightweight JAX-based Tunix library on Google TPUs, a process demonstrated here using LoRA for supervised finetuning. This approach delivers significant accuracy improvements with high TPU efficiency, culminating in a model ready for deployment.</content:encoded>
    </item>
    <item>
      <title>Beyond the Chatbot: A Blueprint for Trustable AI</title>
      <link>https://developers.googleblog.com/beyond-the-chatbot-a-blueprint-for-trustable-ai/</link>
      <guid>https://developers.googleblog.com/beyond-the-chatbot-a-blueprint-for-trustable-ai/</guid>
      <pubDate>Fri, 20 Feb 2026 15:39:55 GMT</pubDate>
      <content:encoded>At Thunderhill Raceway Park, a team of Google Developer Experts (GDEs) put a new &quot;Trustable AI Framework&quot; to the test. Here is how they used GCP, Gemini and Antigravity to turn high-velocity racing into a masterclass for agentic architecture.</content:encoded>
    </item>
    <item>
      <title>Tailor Gemini CLI to your workflow with hooks</title>
      <link>https://developers.googleblog.com/tailor-gemini-cli-to-your-workflow-with-hooks/</link>
      <guid>https://developers.googleblog.com/tailor-gemini-cli-to-your-workflow-with-hooks/</guid>
      <pubDate>Fri, 20 Feb 2026 15:39:55 GMT</pubDate>
      <content:encoded>New Gemini CLI hooks (v0.26.0+) let you tailor the agentic loop. Add context, enforce policies, and block secrets with custom scripts that run at predefined points in your workflow.</content:encoded>
    </item>
    <item>
      <title>LiteRT: The Universal Framework for On-Device AI</title>
      <link>https://developers.googleblog.com/litert-the-universal-framework-for-on-device-ai/</link>
      <guid>https://developers.googleblog.com/litert-the-universal-framework-for-on-device-ai/</guid>
      <pubDate>Fri, 20 Feb 2026 15:39:55 GMT</pubDate>
      <content:encoded>LiteRT, the evolution of TFLite, is now the universal framework for on-device AI. It delivers up to 1.4x faster GPU, new NPU support, and streamlined GenAI deployment for models like Gemma.</content:encoded>
    </item>
    <item>
      <title>A Guide to Fine-Tuning FunctionGemma</title>
      <link>https://developers.googleblog.com/a-guide-to-fine-tuning-functiongemma/</link>
      <guid>https://developers.googleblog.com/a-guide-to-fine-tuning-functiongemma/</guid>
      <pubDate>Fri, 20 Feb 2026 15:39:55 GMT</pubDate>
      <content:encoded>FunctionGemma is a specialized AI model for function calling. This post explains why fine-tuning is key to resolving tool selection ambiguity (e.g., internal vs. Google search) and achieving ultra-specialization, transforming it into a strict, enterprise-compliant agent. A case study demonstrates the improved logic. It also introduces the &quot;FunctionGemma Tuning Lab,&quot; a no-code demo on Hugging Face Spaces, which streamlines the entire fine-tuning process for developers.</content:encoded>
    </item>
    <item>
      <title>Under the Hood: Universal Commerce Protocol (UCP)</title>
      <link>https://developers.googleblog.com/under-the-hood-universal-commerce-protocol-ucp/</link>
      <guid>https://developers.googleblog.com/under-the-hood-universal-commerce-protocol-ucp/</guid>
      <pubDate>Fri, 20 Feb 2026 15:39:55 GMT</pubDate>
      <content:encoded>The Universal Commerce Protocol (UCP) is a new, open-source standard for agentic commerce, co-developed by Google and industry leaders. It establishes a common, secure language to connect consumer surfaces (like Gemini and AI Mode in Search) with business backends, enabling seamless shopping from product discovery to purchase. UCP simplifies integration for businesses, supports various payment providers, and is designed to power the next generation of conversational commerce experiences.</content:encoded>
    </item>
    <item>
      <title>A Developer&apos;s Guide to Debugging JAX on Cloud TPUs: Essential Tools and Techniques</title>
      <link>https://developers.googleblog.com/a-developers-guide-to-debugging-jax-on-cloud-tpus-essential-tools-and-techniques/</link>
      <guid>https://developers.googleblog.com/a-developers-guide-to-debugging-jax-on-cloud-tpus-essential-tools-and-techniques/</guid>
      <pubDate>Fri, 20 Feb 2026 15:39:55 GMT</pubDate>
      <content:encoded>A practical guide to debugging and profiling JAX on Cloud TPUs. It outlines core components (libtpu, JAX/jaxlib) and essential techniques. Tools covered include: Verbose Logging (via libtpu env vars), TPU Monitoring Library for performance metrics, tpu-info for real-time utilization, XLA HLO Dumps for compiler debugging, and the XProf suite for in-depth performance analysis.</content:encoded>
    </item>
    <item>
      <title>Real-World Agent Examples with Gemini 3</title>
      <link>https://developers.googleblog.com/real-world-agent-examples-with-gemini-3/</link>
      <guid>https://developers.googleblog.com/real-world-agent-examples-with-gemini-3/</guid>
      <pubDate>Fri, 20 Feb 2026 15:39:55 GMT</pubDate>
      <content:encoded>Gemini 3 is powering the next generation of reliable, production-ready AI agents. This post highlights 6 open-source framework collaborations (ADK, Agno, Browser Use, Eigent, Letta, mem0), demonstrating practical agentic workflows for tasks like deep search, multi-agent systems, browser and enterprise automation, and stateful agents with advanced memory. Clone the examples and start building today.</content:encoded>
    </item>
    <item>
      <title>Gemini 3 Flash is now available in Gemini CLI</title>
      <link>https://developers.googleblog.com/gemini-3-flash-is-now-available-in-gemini-cli/</link>
      <guid>https://developers.googleblog.com/gemini-3-flash-is-now-available-in-gemini-cli/</guid>
      <pubDate>Fri, 20 Feb 2026 15:39:55 GMT</pubDate>
      <content:encoded>Gemini 3 Flash is now available in Gemini CLI. It delivers Pro-grade coding performance with low latency and a lower cost, matching Gemini 3 Pro&apos;s SWE-bench Verified score of 76%. It significantly outperforms 2.5 Pro, improving auto-routing and agentic coding. It&apos;s ideal for high-frequency development tasks, handling complex code generation, large context windows (like processing 1,000 comment pull requests), and generating load-testing scripts quickly and reliably.</content:encoded>
    </item>
    <item>
      <title>Conductor: Introducing context-driven development for Gemini CLI</title>
      <link>https://developers.googleblog.com/conductor-introducing-context-driven-development-for-gemini-cli/</link>
      <guid>https://developers.googleblog.com/conductor-introducing-context-driven-development-for-gemini-cli/</guid>
      <pubDate>Fri, 20 Feb 2026 15:39:55 GMT</pubDate>
      <content:encoded>Conductor is a new Gemini CLI extension that promotes context-driven development. It shifts project context from chat logs to persistent Markdown files for formal specs and plans, ensuring AI agents adhere to project goals, style, and tech stack. This structured workflow is great for &quot;brownfield&quot; projects and teams, allowing for safe iteration and consistent code contributions while keeping the human developer in control.</content:encoded>
    </item>
    <item>
      <title>Introducing Agent Development Kit for TypeScript: Build AI Agents with the Power of a Code-First Approach</title>
      <link>https://developers.googleblog.com/introducing-agent-development-kit-for-typescript-build-ai-agents-with-the-power-of-a-code-first-approach/</link>
      <guid>https://developers.googleblog.com/introducing-agent-development-kit-for-typescript-build-ai-agents-with-the-power-of-a-code-first-approach/</guid>
      <pubDate>Fri, 20 Feb 2026 15:39:55 GMT</pubDate>
      <content:encoded>Introducing the Agent Development Kit (ADK) for TypeScript, an open-source framework for building complex, multi-agent AI systems with a code-first approach. Developers can define agent logic in TypeScript, applying traditional software development best practices (version control, testing). ADK offers end-to-end type safety, modularity, and deployment-agnostic functionality, leveraging the familiar TypeScript/JavaScript ecosystem.</content:encoded>
    </item>
    <item>
      <title>Developer’s guide to multi-agent patterns in ADK</title>
      <link>https://developers.googleblog.com/developers-guide-to-multi-agent-patterns-in-adk/</link>
      <guid>https://developers.googleblog.com/developers-guide-to-multi-agent-patterns-in-adk/</guid>
      <pubDate>Fri, 20 Feb 2026 15:39:55 GMT</pubDate>
      <content:encoded>Learn how to build modular and reliable agentic applications using 8 effective multi-agent design patterns with the Agent Development Kit (ADK).</content:encoded>
    </item>
    <item>
      <title>Introducing A2UI: An open project for agent-driven interfaces</title>
      <link>https://developers.googleblog.com/introducing-a2ui-an-open-project-for-agent-driven-interfaces/</link>
      <guid>https://developers.googleblog.com/introducing-a2ui-an-open-project-for-agent-driven-interfaces/</guid>
      <pubDate>Fri, 20 Feb 2026 15:39:55 GMT</pubDate>
      <content:encoded>A2UI is an open-source project for agent-driven, cross-platform, and generative UI. It provides a secure, declarative data format for agents to compose bespoke interfaces from a trusted component catalog, allowing for native styling and incremental updates. Designed for the multi-agent mesh (A2A), it offers a framework-agnostic solution to safely render remote agent UIs, with integrations in AG UI, Flutter&apos;s GenUI SDK, Opal, and Gemini Enterprise.</content:encoded>
    </item>
    <item>
      <title>Building agents with the ADK and the new Interactions API</title>
      <link>https://developers.googleblog.com/building-agents-with-the-adk-and-the-new-interactions-api/</link>
      <guid>https://developers.googleblog.com/building-agents-with-the-adk-and-the-new-interactions-api/</guid>
      <pubDate>Fri, 20 Feb 2026 15:39:55 GMT</pubDate>
      <content:encoded>The new Gemini Interactions API enables stateful, multi-turn AI agent workflows, providing a single interface for raw models and the Gemini Deep Research Agent. It can be integrated with existing ADK systems as a superior inference engine with simplified state management, or used as a transparent remote A2A agent via InteractionsApiTransport, allowing seamless expansion of multi-agent systems with minimal refactoring.</content:encoded>
    </item>
  </channel>
</rss>