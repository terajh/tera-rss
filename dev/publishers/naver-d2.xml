<?xml version="1.0" encoding="UTF-8"/>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>dev RSS - 네이버 D2</title>
    <link>https://d2.naver.com</link>
    <description>네이버 D2 RSS 피드</description>
    <lastBuildDate>Sun, 08 Feb 2026 08:09:03 GMT</lastBuildDate>
    <item>
      <title>스마트스토어센터 Oracle에서 MySQL로의 무중단 전환기</title>
      <link>https://d2.naver.com/helloworld/6512234</link>
      <guid>https://d2.naver.com/helloworld/6512234</guid>
      <pubDate>Sun, 08 Feb 2026 08:02:45 GMT</pubDate>
      <content:encoded>
        &lt;p&gt;스마트스토어 플랫폼 내 여러 파트가 공동으로 사용하던 Oracle DBMS는 비즈니스 성장에 따라 리소스 경합이 심화되면서 서비스 성능 불안정을 초래했습니다. 기존 Oracle 인프라의 확장은 막대한 라이선스 비용 증가로 이어지기 때문에, 스마트스토어 회원 파트는 운영 비효율성과 비용 압박을 해소하고자 오픈소스인 MySQL로 DBMS 마이그레이션을 결정했습니다.&lt;/p&gt;
        
        &lt;p&gt;이 글에서는 10년 이상의 레거시 프로젝트가 서비스 중단 없이 Oracle 공동 환경에서 벗어나 MySQL로 전환하며 채택한 전략과 기술적 해결 과정을 공유합니다.&lt;/p&gt;
        
        &lt;h2 id=&quot;&quot;&gt;마이그레이션 준비 및 전략 수립&lt;/h2&gt;
        
        &lt;p&gt;기존 서비스는 Oracle DBMS 환경에서 JPA와 MyBatis를 사용하고 있었습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2026/01/1-1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;기존 서비스 아키텍처&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;회원 파트의 모듈은 타 부서 시스템과 광범위하게 연계되어 있어 서비스 중단이 불가능했습니다. 따라서 Oracle에서 MySQL로의 DB 전환에는 무중단 배포가 필수였습니다. 또한 사소한 기능 버그에는 핫픽스로 대응할 수 있지만, DB 전환 후 치명적인 성능 저하나 서비스 장애가 발생하는 경우에는 재배포만으로 해결할 수 없으므로 신속한 롤백 능력도 확보해야 했습니다.&lt;/p&gt;
        
        &lt;h3 id=&quot;&quot;&gt;전환 전략: 이중 쓰기&lt;/h3&gt;
        
        &lt;p&gt;Kubernetes 환경에서 MyBatis 및 Spring JPA를 사용하는 기존 Oracle DB 기반 서비스를 MySQL로 무중단 전환하고 롤백 가능성을 확보하기 위해 이중 쓰기(dual write) 기법을 채택했습니다. 이중 쓰기란 모든 쓰기 트랜잭션을 기존 데이터베이스와 새 데이터베이스에 동시에 반영하는 기법으로, 신규 시스템의 안정성을 검증하는 기간 동안 두 DB가 완벽하게 동기화된 상태를 유지하는 것을 보장해, 데이터 손실이나 서비스 중단 없이 안전하게 신규 환경으로 전환하기 위한 안전장치가 되었습니다.&lt;/p&gt;
        
        &lt;p&gt;전환 과정은 다음과 같이 진행됩니다.&lt;/p&gt;
        
        &lt;ol&gt;
        &lt;li&gt;전환 전 단계: 구버전 애플리케이션은 모든 Read/Write 트래픽을 Oracle에서 처리하되, CUD(Create, Update, Delete) 작업 시에만 백그라운드에서 MySQL에도 이중 쓰기를 수행합니다.  &lt;/li&gt;
        &lt;li&gt;데이터 마이그레이션: 신버전 애플리케이션 배포 전에 Oracle의 전체 데이터를 MySQL로 마이그레이션해 정합성을 맞춥니다.  &lt;/li&gt;
        &lt;li&gt;전환 후 단계: 신버전 애플리케이션은 모든 Read/Write 트래픽을 MySQL에서 처리하며, CUD 작업 시 백그라운드에서 Oracle에도 이중 쓰기를 수행합니다.&lt;/li&gt;
        &lt;/ol&gt;
        
        &lt;p&gt;이 구조를 통해 데이터 정합성을 유지하면서 무중단 배포가 가능해지며, Oracle 방향으로 이중 쓰기가 지속되므로 롤백이 필요한 경우에도 별도의 데이터 복구 과정 없이 즉시 롤백할 수 있습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2026/01/2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;이중 쓰기 아키텍처&lt;/span&gt;&lt;/p&gt;
        
        &lt;h2 id=&quot;&quot;&gt;기술적 도전과 해결 과정&lt;/h2&gt;
        
        &lt;h3 id=&quot;jpa&quot;&gt;JPA 이중 쓰기&lt;/h3&gt;
        
        &lt;p&gt;저희 서비스에서 JPA로 수행하는 CUD 작업은 대부분 단순한 SQL 조합으로 이루어져, Oracle과 MySQL 간 CUD 쿼리 차이는 거의 없었습니다. 따라서 실제 수행되는 쿼리를 가져와 MySQL에서도 동일하게 실행하면 JPA 이중 쓰기를 큰 문제 없이 구현할 수 있을 것이라고 생각했습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;a href=&quot;https://jdbc-observations.github.io/datasource-proxy/docs/current/user-guide/&quot;&gt;datasource-proxy&lt;/a&gt; 라이브러리를 활용해 Oracle에서 수행되는 쿼리를 가져온 뒤 별도의 MySQL DataSource로 해당 쿼리를 실행하도록 JPA용 DataSource를 구성했습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2026/01/3-1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;Proxy DataSource 구조&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;code&gt;LocalContainerEntityManagerFactoryBean&lt;/code&gt; 빈 등록 시점에 Proxy DataSource 구현체를 설정했습니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;@Primary
        public LocalContainerEntityManagerFactoryBean entityManagerFactory() {  
        LocalContainerEntityManagerFactoryBean factory = getLocalContainerEntityManagerFactoryBean();
        factory.setDataSource(dualWriteProxyDatasource);    // Proxy DataSource 구현체
        return factory;
        }
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;p&gt;이렇게 설정하면 &lt;code&gt;EntityManager&lt;/code&gt;에서 Oracle DB로 쿼리가 flush될 때 MySQL DB에도 쿼리가 수행됩니다. 다만 몇 가지 해결해야 할 문제가 있습니다.&lt;/p&gt;
        
        &lt;h4 id=&quot;&quot;&gt;트랜잭션 처리&lt;/h4&gt;
        
        &lt;p&gt;한 트랜잭션 내에서 여러 쿼리가 수행되던 중 오류가 발생하면 두 DB 간의 정합성이 유지될까요?&lt;/p&gt;
        
        &lt;p&gt;저희 서비스에서는 트랜잭션 매니저로 &lt;code&gt;JpaTransactionManager&lt;/code&gt;를 사용하고 있습니다. 이중 쓰기 Proxy DataSource에서 두 DB의 DataSource를 참조하더라도, 실제 트랜잭션에 사용되는 쪽은 메인 DB인 Oracle DataSource이고 MySQL DataSource는 트랜잭션으로 관리되지 않습니다. 따라서 롤백 과정에서 두 DB의 정합성이 깨질 수 있으므로 이중 쓰기 수행 시 트랜잭션 대응을 별도로 구성해야 합니다.&lt;/p&gt;
        
        &lt;p&gt;단, &lt;code&gt;ChainedTransactionManager&lt;/code&gt;를 사용하거나 분산 트랜잭션으로 MySQL 쿼리를 트랜잭션에 포함시키면 안 됩니다. 그 이유는 다음과 같습니다.&lt;/p&gt;
        
        &lt;ul&gt;
        &lt;li&gt;이중 쓰기를 구현하는 시점에는 Oracle과 MySQL 간 데이터 정합성이 대부분 맞지 않습니다.&lt;/li&gt;
        &lt;li&gt;서비스 내 JPA의 모든 Oracle CUD 쿼리가 MySQL에서 오류 없이 동작하는지 아직 검증되지 않았습니다.&lt;/li&gt;
        &lt;li&gt;테이블 인덱스 구성이나 커넥션 풀 등 환경 설정이 아직 최적화되지 않았습니다.&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;p&gt;실제 Read 전환이 이루어지기 전까지 다양한 이유로 MySQL 쿼리만 실패하는 상황이 발생할 수 있습니다. 따라서 MySQL 쿼리는 트랜잭션에 따라 원자적으로 수행하되, 실패하더라도 트랜잭션이 롤백되지 않고 무시되어야 합니다.&lt;/p&gt;
        
        &lt;p&gt;이에 MySQL 쿼리만 실패하는 케이스를 용인하고, 주기적으로 마이그레이션과 검증(아래 &lt;a href=&quot;#정합성-검증&quot;&gt;정합성 검증&lt;/a&gt; 참고)을 반복하며 불일치 원인을 찾아 제거해 나가는 방식을 선택했습니다.&lt;/p&gt;
        
        &lt;p&gt;Oracle 쿼리 수행에 영향을 주지 않는 가장 확실한 방법은 트랜잭션 도중 수행되는 쿼리를 모아두었다가 커밋 후 한꺼번에 MySQL에서 수행하는 것입니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2026/01/4-1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;트랜잭션 처리 흐름&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;트랜잭션이 롤백되더라도 MySQL에서는 수행된 쿼리가 없으므로 신경 쓰지 않아도 됩니다. Oracle 커넥션을 점유하는 시간이 늘어나지도 않고 예외 처리 및 추적도 용이합니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;code&gt;TransactionSynchronizationManager&lt;/code&gt;를 활용해 이 동작을 구현할 수 있습니다. 다음은 datasource-proxy 라이브러리 사용을 가정한 예입니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;public void execute(ExecutionInfo execInfo, List&amp;lt;QueryInfo&amp;gt; queryInfoList) throws SQLException {  
        // 트랜잭션이 있으면 커밋 시점에 한 번에 이중 쓰기 수행
        if (TransactionSynchronizationManager.isSynchronizationActive()) {
        List&amp;lt;Pair&amp;lt;ExecutionInfo, List&amp;lt;QueryInfo&amp;gt;&amp;gt;&amp;gt; queryExecInfos = (List&amp;lt;Pair&amp;lt;ExecutionInfo, List&amp;lt;QueryInfo&amp;gt;&amp;gt;&amp;gt;)TransactionSynchronizationManager.getResource(OBJECT);
        // 트랜잭션에서 첫 호출 시 동기화 및 리소스 등록
        if (Objects.isNull(queryExecInfos)) {
        queryExecInfos = Lists.newArrayList();
        initDualWriteQueryAccumulationInTransaction(queryExecInfos);
        }
        // 리스트에 쿼리 저장
        queryExecInfos.add(Pair.of(execInfo, queryInfoList));
        } else {
        // 트랜잭션이 없으면 바로 이중 쓰기 수행
        }
        }
        
        private void initDualWriteQueryAccumulationInTransaction(List&amp;lt;Pair&amp;lt;ExecutionInfo, List&amp;lt;QueryInfo&amp;gt;&amp;gt;&amp;gt; queryExecInfos) {  
        TransactionSynchronizationManager.registerSynchronization(new TransactionSynchronizationAdapter() {
        @Override
        public void afterCommit() {
        try {
        // MySQL 커넥션을 열어서 queryExecInfos에 쌓인 쿼리를 한 번에 실행
        } catch (SQLException e) {
        // 쿼리 로깅해 실패 원인 분석
        }
        }
        
        @Override
        public void afterCompletion(int status) {
        TransactionSynchronizationManager.unbindResourceIfPossible(OBJECT);
        queryExecInfos.clear();
        }
        });
        TransactionSynchronizationManager.bindResource(property, queryExecInfos);
        }
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;h4 id=&quot;&quot;&gt;엔티티 설정&lt;/h4&gt;
        
        &lt;p&gt;Oracle에서는 Primary Key 생성 전략으로 시퀀스를 사용했으나, MySQL에서는 시퀀스가 없으므로 auto increment를 사용하도록 변경해야 합니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;@Id
        // @SequenceGenerator(name = &quot;SQ_ID&quot;, sequenceName = &quot;SQ_ID&quot;, allocationSize = 1)
        // @GeneratedValue(strategy = GenerationType.SEQUENCE, generator = &quot;SQ_ID&quot;)
        @GeneratedValue(strategy = GenerationType.IDENTITY)
        @Column(name = &quot;ID_PK&quot;, nullable = false)
        private Long id;  
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;p&gt;이렇게 설정하면 MySQL INSERT 쿼리에는 PK가 없기 때문에, Read 전환 후 MySQL에서 Oracle 방향으로 이중 쓰기할 때 쿼리를 그대로 사용할 수 없습니다. 이 문제를 해결하려면 MySQL INSERT 쿼리 수행 시 generated key 정보를 별도로 가져와 PK를 채우도록 쿼리를 수정한 후 Oracle에서 수행해야 합니다.(UUID v7이나 Snowflake ID 등 DB에 의존하지 않는 방식으로 PK를 생성했다면 이런 고민은 필요 없습니다.)&lt;/p&gt;
        
        &lt;p&gt;일부 경우에는 엔티티 클래스의 칼럼 구성에서 &lt;code&gt;columnDefinition&lt;/code&gt;을 MySQL 칼럼 타입에 맞게 지정해야 합니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;// Oracle VARCHAR2(n) -&amp;gt; MySQL TEXT 변경 시
        // @Column(name = &quot;TEXT1&quot;) - Oracle
        @Column(name = &quot;TEXT1&quot;, columnDefinition = &quot;text&quot;)
        private String text1;
        
        // Oracle CLOB -&amp;gt; MySQL LONGTEXT 변경 시
        // @Column(name = &quot;LONGTEXT1&quot;) - Oracle
        @Column (name = &quot;LONGTEXT1&quot;, columnDefinition = &quot;longtext&quot;)
        private String longtext1;
        
        // Oracle NUMBER(n,m) -&amp;gt; MySQL DECIMAL(n,m) 변경 시
        // @Column(name = &quot;DECIMAL1&quot;, columnDefinition = &quot;NUMBER(11, 2)&quot;) - Oracle
        @Column(name = &quot;DECIMAL1&quot;, columnDefinition = &quot;decimal(11, 2)&quot;)
        private Double decimal1;  
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;h3 id=&quot;mybatis&quot;&gt;MyBatis 이중 쓰기&lt;/h3&gt;
        
        &lt;p&gt;MyBatis 이중 쓰기를 구현할 때, 기존 Oracle DataSource와 신규 MySQL DataSource를 처리하는 MyBatis 인터페이스를 각각 분리해 호출하는 방식은 소스 코드 변경 범위가 지나치게 넓다는 문제가 있었습니다.&lt;/p&gt;
        
        &lt;p&gt;다음과 같은 코드를 모든 쓰기 로직에 추가하려면 10년 넘은 서비스의 비즈니스 로직 전체에 걸쳐 수백, 수천 곳을 수정해야 합니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;mybatisRepository.updateData(i); // oracle mybatis  
        mybatisForMySQLRepository.updateData(i); // mysql mybatis  
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;p&gt;이는 휴먼 에러 발생 가능성 증대와 개발 기간 대폭 증가로 이어져 위험성이 높다고 판단해, 비즈니스 로직 코드 수정 없이 Oracle과 MySQL 양쪽으로 쓰기 작업을 수행하는 방법을 고민했습니다. 비즈니스 로직의 순수성을 유지하면서 이중 쓰기 로직을 단일 위치에 중앙 집중화해 관리하고, 마이그레이션 완료 시점에 이중 쓰기 코드를 쉽게 제거할 수 있는 유연성과 유지보수성을 확보하기 위한 것이기도 합니다.&lt;/p&gt;
        
        &lt;h4 id=&quot;mybatis&quot;&gt;MyBatis 동작 구조&lt;/h4&gt;
        
        &lt;p&gt;MyBatis의 동작 구조를 간단히 설명하면, &lt;code&gt;@Mapper&lt;/code&gt; 애너테이션이 붙은 인터페이스가 XML 등에 정의된 QueryId와 Query를 참조하는 구조입니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2026/01/5-1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;MyBatis 동작 구조&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;code&gt;SqlSession&lt;/code&gt;은 &lt;code&gt;Configuration&lt;/code&gt; 객체를 참조합니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;// https://github.com/mybatis/mybatis-3/blob/master/src/main/java/org/apache/ibatis/session/SqlSession.java#L360
        
        /**
        * Retrieves current configuration.
        *
        * @return Configuration
        */
        Configuration getConfiguration();  
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;p&gt;&lt;code&gt;Configuration&lt;/code&gt; 객체 안에는 XML 등에 정의된 쿼리가 QueryId와 함께 &lt;code&gt;MappedStatement&lt;/code&gt; 객체로 변환되어 저장됩니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;// https://github.com/mybatis/mybatis-3/blob/master/src/main/java/org/apache/ibatis/session/Configuration.java#L158
        
        protected final Map&amp;lt;String, MappedStatement&amp;gt; mappedStatements = new StrictMap&amp;lt;MappedStatement&amp;gt;(  
        &quot;Mapped Statements collection&quot;)
        .conflictMessageProducer((savedValue, targetValue) -&amp;gt; &quot;. please check &quot; + savedValue.getResource() + &quot; and &quot;
        + targetValue.getResource());
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;p&gt;&lt;code&gt;@Mapper&lt;/code&gt; 애너테이션이 붙은 MyBatis용 인터페이스는 &lt;code&gt;MapperProxy&lt;/code&gt; 빈으로 등록되고, &lt;code&gt;mybatisRepository.findById()&lt;/code&gt; 등의 메서드 호출은 &lt;code&gt;MapperProxy&lt;/code&gt; 객체의 &lt;code&gt;invoke&lt;/code&gt; 함수가 호출되는 구조입니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;// https://github.com/mybatis/mybatis-3/blob/master/src/main/java/org/apache/ibatis/binding/MapperProxy.java
        
        @Override
        public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {  
        if (Object.class.equals(method.getDeclaringClass())) {
        try {
        return method.invoke(this, args);
        } catch (Throwable t) {
        throw ExceptionUtil.unwrapThrowable(t);
        }
        }
        // ...
        final MapperMethod mapperMethod = cachedMapperMethod(method);
        return mapperMethod.execute(sqlSession, args);
        }
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;p&gt;&lt;code&gt;MapperProxy&lt;/code&gt;의 &lt;code&gt;invoke&lt;/code&gt;는 &lt;code&gt;MapperMethod&lt;/code&gt;의 &lt;code&gt;execute&lt;/code&gt;를 수행합니다. &lt;code&gt;MapperMethod&lt;/code&gt;의 &lt;code&gt;execute&lt;/code&gt;는 쿼리 타입에 맞게 &lt;code&gt;SqlSession&lt;/code&gt;의 메서드를 수행합니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;// https://github.com/mybatis/mybatis-3/blob/master/src/main/java/org/apache/ibatis/binding/MapperMethod.java
        
        public Object execute(SqlSession sqlSession, Object[] args) {  
        Object result;
        switch (command.getType()) {
        case INSERT: {
        Object param = method.convertArgsToSqlCommandParam(args);
        result = rowCountResult(sqlSession.insert(command.getName(), param));
        break;
        }
        case UPDATE: {
        Object param = method.convertArgsToSqlCommandParam(args);
        result = rowCountResult(sqlSession.update(command.getName(), param));
        break;
        }
        // ...
        }
        }
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;p&gt;즉, XML에 정의된 SQL은 &lt;code&gt;MappedStatement&lt;/code&gt; 객체가 되고, &lt;code&gt;SqlSession&lt;/code&gt;은 MyBatis 설정 시 주입된 DataSource를 참조하면서 이 &lt;code&gt;MappedStatement&lt;/code&gt; 객체를 보유했다가 필요할 때 실행합니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;code&gt;MybatisRepository&lt;/code&gt;는 &lt;code&gt;MapperMethod&lt;/code&gt;를 invoke하고, &lt;code&gt;MapperMethod&lt;/code&gt;는 &lt;code&gt;SqlSession&lt;/code&gt;의 메서드를 invoke합니다. 따라서 &lt;code&gt;SqlSession&lt;/code&gt;의 invoke 시 Oracle과 MySQL 양쪽으로 실행할 수 있다면 원하는 바를 이룰 수 있습니다.&lt;/p&gt;
        
        &lt;h4 id=&quot;&quot;&gt;구현 방법&lt;/h4&gt;
        
        &lt;p&gt;이 구조를 활용하기 위해, 쿼리 문법 차이를 고려해 MySQL 문법에 맞는 SQL로 작성된 MyBatis XML을 한 벌 더 만들어야 합니다.&lt;/p&gt;
        
        &lt;p&gt;XML 내의 SQL을 보유하는 &lt;code&gt;SqlSession&lt;/code&gt;은 &lt;code&gt;SessionTemplate&lt;/code&gt;이 &lt;code&gt;SqlSessionFactory&lt;/code&gt;에 위임해서 만드는 구조입니다. &lt;code&gt;SqlSessionFactory&lt;/code&gt;를 추상화해서 Oracle과 MySQL 두 개의 &lt;code&gt;SqlSession&lt;/code&gt;이 모두 수행하게 구현하면 됩니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2026/01/6.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;CombinedSqlSessionFactory 구조&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;code&gt;CombinedSqlSessionFactory&lt;/code&gt;라는 이름으로 다음과 같이 구현했습니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;public class CombinedSqlSessionFactory implements SqlSessionFactory {
        
        private SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) {
        SqlSession primarySession = openPrimarySessionFromDataSource(execType, level, autoCommit);
        SqlSession secondarySession = openSecondarySessionFromDataSource(execType, level, autoCommit);
        
        return (SqlSession) Proxy.newProxyInstance(
        // 세션을 만들 때 양쪽으로 쓰는 로직을 사용하도록 Proxy 객체로 리턴
        SqlSession.class.getClassLoader(),
        new Class[]{SqlSession.class},
        // CombinedSqlSessionHandler는 원하는 로직을 보유하고,
        // 양쪽에 써야 하기 때문에 Oracle과 MySQL 세션을 모두 보유
        new CombinedSqlSessionHandler(primarySession, secondarySession, applicationEventPublisher)
        );
        }
        // ...
        }
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;public class CombinedSqlSessionHandler implements InvocationHandler {
        
        private SqlSession oracleSqlSession;
        private SqlSession mysqlSqlSession;
        
        @Override
        public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
        final String methodName = method.getName();
        
        if (CUD액션인_경우(methodName, maybeStatement)) {
        Object oracleResult = method.invoke(oracleSqlSession, args);
        Object mysqlResult = method.invoke(mysqlSqlSession, args);
        
        log.warn(&quot;primaryResult: {}&quot;, primaryResult);
        log.warn(&quot;secondary: {}&quot;, secondaryResult);
        // 쓰기 자체가 목적이므로 쓰기 액션의 결과 값은 Oracle의 결과를 반환
        return oracleResult;
        }
        
        // READ인 경우 Oracle의 결과를 사용
        Object oracleResult = method.invoke(oracleSqlSession, args);
        return oracleResult;
        }
        }
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;p&gt;Oracle과 MySQL 간에는 근본적인 문법 차이가 있습니다. 특히 날짜/시간 처리 함수(&lt;code&gt;SYSDATE&lt;/code&gt; vs &lt;code&gt;NOW()&lt;/code&gt;, &lt;code&gt;TO_CHAR&lt;/code&gt; vs &lt;code&gt;DATE_FORMAT&lt;/code&gt;), NULL 값 처리(&lt;code&gt;NVL&lt;/code&gt; vs &lt;code&gt;IFNULL&lt;/code&gt;), 페이징 처리(&lt;code&gt;ROWNUM&lt;/code&gt; vs &lt;code&gt;LIMIT&lt;/code&gt;) 방식이 다릅니다. 따라서 모든 MyBatis XML 쿼리를 MySQL 문법에 맞게 재작성해 위 구조로 MyBatis 이중 쓰기를 수행했습니다.&lt;/p&gt;
        
        &lt;h3 id=&quot;dbms&quot;&gt;쿼리/DBMS 성능 검증&lt;/h3&gt;
        
        &lt;p&gt;새로운 MySQL 데이터베이스로의 전환을 추진할 때, 기존 Oracle 환경에서 안정적으로 처리되던 대규모 트랜잭션과 복잡한 쿼리가 MySQL 환경에서도 동일한 성능을 보장하는지 검증하는 것이 핵심 과제였습니다. Oracle과 MySQL 간의 쿼리 실행 계획 및 최적화 엔진 차이로 인해, 특정 고부하 쿼리가 신규 MySQL의 CPU, 메모리, I/O 등 핵심 DB 자원에 예상치 못한 과부하를 초래해 서비스 안정성을 저해할 위험이 있었습니다.&lt;/p&gt;
        
        &lt;p&gt;따라서 이중 쓰기 기간 동안 실제 운영 트래픽을 신규 DB에 반영하면서 MySQL 데이터베이스의 CPU 사용률, 메모리 사용량, 연결 수(connection count) 등의 자원 지표를 정밀하게 측정하고 모니터링하는 작업은 마이그레이션의 안정성을 확보하고 성능 저하 위험을 사전에 방지하기 위한 필수 단계였습니다.&lt;/p&gt;
        
        &lt;h4 id=&quot;&quot;&gt;성능 검증 전략&lt;/h4&gt;
        
        &lt;p&gt;운영과 동일한 부하를 주기 위해 HTTP 트래픽 복사나 Kafka 토픽 복제 같은 방식을 사용하면 비즈니스 로직 호출 시 타 부서 시스템에 중복 호출 부하를 야기하거나, 예상치 못한 부작용으로 운영에 영향을 줄 위험이 매우 높습니다.&lt;/p&gt;
        
        &lt;p&gt;타 부서와 연관된 시스템에 영향을 주지 않고 성능 검증이라는 목표를 달성하기 위해, 이미 수행 중인 이중 쓰기 로직을 유지하면서 오직 내부 서비스 로직에서 발생하는 Read 트래픽만 신규 MySQL DB로 복제해 호출하는 전략을 채택했습니다.&lt;/p&gt;
        
        &lt;p&gt;MyBatis나 JPA 같은 영속성 프레임워크의 특성상, 대부분의 Read 메서드는 매개변수가 쿼리로 변환되기 전에는 원시 타입이나 직렬화가 가능한 객체를 매개변수로 사용합니다. 이 특성을 활용해 기존 Oracle로 향하는 Repository 계층의 Read 메서드 호출이 발생할 때 해당 메서드의 실행 시간과 함께 이름, 매개변수 값을 캡처하고 JSON으로 직렬화했습니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-json&quot;&gt;{
        &quot;repositoryInterfaceName&quot;: &quot;com.example.DataRepository&quot;,
        &quot;methodName&quot;: &quot;findByKey&quot;,
        &quot;parameterList&quot;: [
        {
        &quot;index&quot;: 0,
        &quot;className&quot;: &quot;java.lang.Class&quot;,
        &quot;valueString&quot;: &quot;com.example.ParamVO&quot;
        },
        {
        &quot;index&quot;: 1,
        &quot;className&quot;: &quot;com.example.KeyVO&quot;,
        &quot;valueString&quot;: &quot;{\&quot;key\&quot;:1234}&quot;
        }
        ],
        &quot;oracleExecutionTime&quot;: 71
        }
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;p&gt;직렬화된 데이터를 Kafka 같은 메시지 큐로 전송했습니다. 메시지를 수신한 별도의 성능 측정 Consumer 모듈은 수신된 데이터를 역직렬화해 원본 메서드 이름과 매개변수 리스트를 복원했습니다. 이후 Java Reflection API를 사용해 신규 MySQL을 바라보는 Repository 인터페이스의 동일한 메서드를 찾아 매개변수를 주입하고 호출함으로써, 마치 실제 서비스가 호출한 것처럼 읽기 작업을 MySQL에서 수행할 수 있었습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2026/01/7-1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;Read 트래픽 복제 아키텍처&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;각 토픽 메시지마다 실행 시간이 있으므로, 이를 시각화해 각 쿼리의 성능도 확인할 수 있었습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2026/01/8-1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;쿼리 실행 시간 분포&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2026/01/9-1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;성능 모니터링 대시보드&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;위 지표를 활용해 성능이 좋지 않은 쿼리를 수정하고 인덱스 추가 등을 수행해 안정적인 성능을 확보할 수 있었습니다.&lt;/p&gt;
        
        &lt;h3 id=&quot;&quot;&gt;정합성 검증&lt;/h3&gt;
        
        &lt;p&gt;프로젝트의 중요한 목표는 &lt;strong&gt;데이터 정합성의 완벽한 확보&lt;/strong&gt;였습니다. 이중 쓰기로 실시간 쓰기 동기화는 이루었지만, 이중 쓰기 로직에 문제가 있어 데이터가 다르게 쓰이고 있지는 않은지, 최종 전환 전에 두 DBMS 간의 데이터 일치 여부를 &lt;strong&gt;정량적으로&lt;/strong&gt; 검증하는 과정이 필수였습니다.&lt;/p&gt;
        
        &lt;p&gt;워크플로 관리 도구인 Airflow로 정합성 검증 프로세스를 자동화했습니다. Airflow 파이프라인으로 주기적으로 기존 Oracle DB와 신규 MySQL DB의 주요 테이블 데이터를 추출해 Hive 데이터 웨어하우스로 통합했습니다. Hive 환경에서 고성능의 분산 쿼리를 실행해 두 데이터셋을 비교했으며, 레코드 수 비교, 핵심 칼럼 값의 해시 비교, 주요 비즈니스 통계 값의 차이를 검출했습니다.&lt;/p&gt;
        
        &lt;p&gt;이 과정에서 발견된 불일치 건은 상세 분석 및 수정을 거쳐 최종적으로 두 데이터베이스 간의 정합성이 100% 보장되도록 조치했습니다. 이 엄격한 검증 단계는 신규 MySQL 환경으로의 최종 컷오버를 위한 결정적인 안전장치가 되었습니다. 테이블별 row의 추출 시간 차이 때문에 발생하는 불일치 건은 수동으로 검증하는 과정을 거쳤습니다.&lt;/p&gt;
        
        &lt;p&gt;약 6개월간 테이블별 불일치 데이터 건수와 그 내용을 분석해 로직을 수정한 끝에 이중 쓰기 환경에서 데이터 정합성을 확보했습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2026/01/10.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;테이블별 불일치 건수 리포트&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2026/01/11.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;불일치 내용 상세&lt;/span&gt;&lt;/p&gt;
        
        &lt;h2 id=&quot;&quot;&gt;마이그레이션 후 아키텍처 및 검증&lt;/h2&gt;
        
        &lt;h3 id=&quot;&quot;&gt;서비스 테스트 및 전환&lt;/h3&gt;
        
        &lt;p&gt;데이터베이스를 Oracle에서 MySQL로 전환하는 과제에서 중요한 것은 사용자가 이용하는 기능을 이전과 완전히 동일하게 유지하는 것이었습니다. 단순히 데이터만 옮기는 것이 아니라, DBMS 변화가 기존 비즈니스 로직에 예기치 못한 영향을 주지 않도록 약 3개월간의 QA 기간을 거쳤습니다.&lt;/p&gt;
        
        &lt;p&gt;이 과정에서 쿼리 실행 결과의 미세한 차이부터 트랜잭션 처리 방식까지 철저히 검증함으로써, 내부 인프라의 변화에도 불구하고 서비스의 모든 기능이 기존과 변함없이 안정적으로 작동함을 확인했습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2026/01/12.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;QA 진행 현황&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;전환이 제대로 되었다는 것은 회원 부서가 발행하는 쿼리가 더 이상 Oracle로 유입되지 않고 MySQL로 유입된다는 의미입니다.&lt;/p&gt;
        
        &lt;p&gt;이를 검증하기 위해 모든 기존의 전환 대상 쿼리에 사전에 &lt;code&gt;\*\*회원개발쿼리\*\*&lt;/code&gt;와 같은 임의의 주석을 추가했습니다. 전환 후 해당 주석이 포함된 쿼리가 Oracle 데이터베이스에 더 이상 인입되지 않는지 모니터링했습니다. 기존 Oracle로 향하던 트래픽이 완전히 차단되었음을 확인해, 모든 데이터 요청이 의도한 대로 신규 MySQL로 정상 전환되었음을 확인했습니다.&lt;/p&gt;
        
        &lt;h2 id=&quot;&quot;&gt;트러블슈팅 및 기타 고려 사항&lt;/h2&gt;
        
        &lt;p&gt;전환 과정에서 겪은 몇 가지 트러블슈팅 사례와 성능을 위해 고려한 요소를 소개합니다.&lt;/p&gt;
        
        &lt;h3 id=&quot;mysqlindexmergeoptimizationhttpsdevmysqlcomdocrefman80enindexmergeoptimizationhtml&quot;&gt;MySQL의 &lt;a href=&quot;https://dev.mysql.com/doc/refman/8.0/en/index-merge-optimization.html&quot;&gt;Index Merge Optimization&lt;/a&gt;&lt;/h3&gt;
        
        &lt;p&gt;Index Merge는 MySQL에서 WHERE 절에 여러 인덱스 칼럼이 OR 조건으로 연결되는 경우, 각 인덱스를 독립적으로 검색한 후 결과를 합치는 전략입니다.&lt;/p&gt;
        
        &lt;p&gt;다만 nesting OR 등 조건이 조금만 복잡해지면 최적화하지 못하고 풀스캔을 사용합니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2026/01/13.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;Index Merge 실행 계획&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;다음 조건문의 &lt;code&gt;KEY&lt;/code&gt;, &lt;code&gt;KEY2&lt;/code&gt;, &lt;code&gt;TP&lt;/code&gt;, &lt;code&gt;TP2&lt;/code&gt;에 모두 인덱스가 있을 때 Oracle에서는 성능이 좋았으나, MySQL에서는 최적화하지 못해 풀스캔을 사용했습니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;TABLE.KEY = 11  
        AND TABLE.TP = &apos;ALPHA&apos;  
        OR TABLE.KEY2 = 22  
        AND TABLE.TP2 IN (&apos;ALPHA2&apos;, &apos;BETA2&apos;)  
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;p&gt;이러한 경우 다음과 같이 UNION으로 쿼리를 변경해 대응했습니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;SELECT *  
        FROM TABLE  
        WHERE KEY = 11  
        AND TP = &apos;ALPHA&apos;
        
        UNION
        
        SELECT *  
        FROM TABLE  
        WHERE KEY2 = 22  
        AND TP2 IN (&apos;ALPHA2&apos;, &apos;BETA2&apos;);
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;h3 id=&quot;&quot;&gt;마이그레이션 배치 성능 이슈&lt;/h3&gt;
        
        &lt;p&gt;마이그레이션 배치는 Spring Batch로 작성했으며, 크기가 큰 테이블은 &lt;code&gt;JdbcPagingItemReader&lt;/code&gt;로 Oracle 전체 데이터를 가져와 MySQL로 쓰기를 수행합니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;code&gt;QueryProvider&lt;/code&gt;로 &lt;code&gt;OraclePagingQueryProvider&lt;/code&gt;를 사용했을 때, 조회 시 수행되는 페이징 쿼리는 다음과 같습니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;-- page size = 100, 이전 조회에서 마지막 TABLE_ID = 500일 때
        SELECT *  
        FROM (  
        SELECT TABLE_ID
        FROM SOURCE_TABLE
        ORDER BY TABLE_ID ASC
        )
        WHERE ROWNUM &amp;lt;= 100 AND (TABLE_ID &amp;gt; 500)  
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;p&gt;페이징 시 사용되는 sortKey(위 쿼리에서 &lt;code&gt;TABLE_ID&lt;/code&gt;)는 반드시 정의되어야 합니다.&lt;/p&gt;
        
        &lt;p&gt;여러 개의 sortKey가 필요한 다중 PK 테이블의 경우 다음과 같이 페이징 쿼리가 생성됩니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;-- page size = 100, 이전 조회에서 마지막 (TABLE_ID1, TABLE_ID2) = (300, 8)일 때
        SELECT *  
        FROM (  
        SELECT TABLE_ID1, TABLE_ID2
        FROM SOURCE_TABLE2
        ORDER BY TABLE_ID1 ASC, TABLE_ID2 ASC
        )
        WHERE ROWNUM &amp;lt;= 100 AND (TABLE_ID1 &amp;gt; 300 OR (TABLE_ID1 = 300 AND TABLE_ID2 &amp;gt; 8))  
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;p&gt;위 쿼리들은 과연 빠르게 수행될 수 있을까요?&lt;/p&gt;
        
        &lt;p&gt;테이블 크기가 충분히 클 때 위의 단일 PK 페이징 쿼리는 옵티마이저가 INDEX RANGE SCAN + COUNT STOPKEY로 최적화해 주기도 하지만, 아래의 다중 PK 페이징 쿼리는 거의 항상 전체 정렬이 발생합니다. 서브쿼리 내 정렬 + OR 조건으로 인해 인덱스 시작 지점을 특정할 수 없기 때문에, 옵티마이저가 최적화하지 못하고 &apos;전체 정렬 후 조건에 맞는 데이터 100건을 조회&apos;하는 가장 비효율적인 방식으로 동작합니다.&lt;/p&gt;
        
        &lt;p&gt;이를 해결하려면 &apos;PK 순서로 조건을 만족하는 상위 100건을 조회&apos;할 수 있도록 쿼리 튜닝이 필요합니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;-- page size = 100, 이전 조회에서 마지막 (TABLE_ID1, TABLE_ID2) = (300, 8)일 때
        SELECT TABLE_ID1, TABLE_ID2  
        FROM SOURCE_TABLE2  
        WHERE TABLE_ID1 &amp;gt; 300 OR (TABLE_ID1 = 300 AND TABLE_ID2 &amp;gt; 8)  
        ORDER BY TABLE_ID1 ASC, TABLE_ID2 ASC  
        FETCH NEXT 100 ROWS ONLY  
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;p&gt;OR 조건으로 INDEX FULL SCAN이 발생할 수 있으므로, 다음과 같이 UNION ALL 구문으로 변경합니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;-- page size = 100, 이전 조회에서 마지막 (TABLE_ID1, TABLE_ID2) = (300, 8)일 때
        SELECT * FROM  
        (
        SELECT TABLE_ID1, TABLE_ID2
        FROM SOURCE_TABLE2
        WHERE TABLE_ID1 = 300 AND TABLE_ID2 &amp;gt; 8
        ORDER BY TABLE_ID1 ASC, TABLE_ID2 ASC
        FETCH NEXT 100 ROWS ONLY
        )
        UNION ALL  
        (
        SELECT TABLE_ID1, TABLE_ID2
        FROM SOURCE_TABLE2
        WHERE TABLE_ID1 &amp;gt; 300
        ORDER BY TABLE_ID1 ASC, TABLE_ID2 ASC
        FETCH NEXT 100 ROWS ONLY
        )
        FETCH NEXT 100 ROWS ONLY  
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;p&gt;인덱스를 탄 두 번의 Top-N 조회 후 최종적으로 page size만큼의 row를 가져옵니다. 이와 같이 쿼리를 생성하도록 커스텀 &lt;code&gt;QueryProvider&lt;/code&gt;를 구현해 사용하면 조회 성능을 최적화할 수 있습니다.&lt;/p&gt;
        
        &lt;h3 id=&quot;mysqlhikaricp&quot;&gt;MySQL의 HikariCP 설정&lt;/h3&gt;
        
        &lt;p&gt;Oracle과 달리 MySQL에서만 권고되는 설정값이 있습니다. &lt;a href=&quot;https://github.com/brettwooldridge/hikaricp/wiki/MYSQL-Configuration&quot;&gt;HikariCP MySQL Configuration&lt;/a&gt;에서 권장하는 설정입니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-properties&quot;&gt;dataSource.cachePrepStmts=true  
        dataSource.prepStmtCacheSize=250  
        dataSource.prepStmtCacheSqlLimit=2048  
        dataSource.useServerPrepStmts=true  
        dataSource.useLocalSessionState=true  
        dataSource.rewriteBatchedStatements=true  
        dataSource.cacheResultSetMetadata=true  
        dataSource.cacheServerConfiguration=true  
        dataSource.elideSetAutoCommits=true  
        dataSource.maintainTimeStats=false  
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;h4 id=&quot;cacheprepstmtsuseserverprepstmts&quot;&gt;cachePrepStmts, useServerPrepStmts&lt;/h4&gt;
        
        &lt;p&gt;쿼리를 수행하는 객체에는 &lt;code&gt;Statement&lt;/code&gt;, &lt;code&gt;PreparedStatement&lt;/code&gt; 등이 있습니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;// Statement
        stmt = connection.createStatement();  
        rs = stmt.executeQuery(&quot;SELECT * FROM car WHERE car_id = 1&quot;);
        
        // Prepared Statement
        connection = DriverManager.getConnection(jdbcUrl + properties, id, password);  
        // prepareStatement() 메서드 실행
        stmt = connection.prepareStatement(&quot;SELECT * FROM car WHERE car_id = ?&quot;);  
        // 쿼리에 전달할 파라미터 세팅
        stmt.setLong(1, 1L);  
        rs = stmt.executeQuery();  
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;pre&gt;&lt;code&gt;// https://docs.oracle.com/en/java/javase/21/docs/api/java.sql/java/sql/Statement.html
        The object used for executing a static SQL statement and returning the results it produces.
        
        // https://docs.oracle.com/en/java/javase/21/docs/api/java.sql/java/sql/PreparedStatement.html
        An object that represents a precompiled SQL statement.  
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;p&gt;&lt;code&gt;Statement&lt;/code&gt;는 정적인 쿼리를 실행할 때, &lt;code&gt;PreparedStatement&lt;/code&gt;는 동적인 쿼리를 실행할 때 주로 사용합니다.&lt;/p&gt;
        
        &lt;p&gt;JDBC 인터페이스로 DBMS(MySQL)의 &lt;code&gt;PreparedStatement&lt;/code&gt;를 사용하므로 JDBC 없이 MySQL만 사용해도 &lt;code&gt;PreparedStatement&lt;/code&gt;를 사용할 수 있습니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;-- prepared statement 생성
        PREPARE pstmt1 FROM &apos;SELECT * FROM car WHERE car_id = ?&apos;;
        
        -- 파라미터를 지정해 prepared statement 실행
        SET @a = 1;  
        EXECUTE pstmt1 USING @a;
        
        -- prepared statement 제거
        DEALLOCATE PREPARE pstmt1;  
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;p&gt;&lt;code&gt;cachePrepStmts&lt;/code&gt;와 &lt;code&gt;useServerPrepStmts&lt;/code&gt;는 &lt;code&gt;PreparedStatement&lt;/code&gt; 캐시를 DBMS에서 할지, 클라이언트에서 할지 결정하는 값입니다.&lt;/p&gt;
        
        &lt;p&gt;MySQL Connector/J는 &lt;code&gt;PreparedStatement&lt;/code&gt;의 구현을 &lt;code&gt;ClientPreparedStatement&lt;/code&gt;와 &lt;code&gt;ServerPreparedStatement&lt;/code&gt;로 하고 있으며, &lt;code&gt;useServerPrepStmts&lt;/code&gt; 속성값에 따라 어떤 구현체를 사용할지 결정합니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;// https://github.com/mysql/mysql-connector-j/blob/release/9.x/src/main/user-impl/java/com/mysql/cj/jdbc/ConnectionImpl.java#L1631
        
        ClientPreparedStatement pStmt = null;  
        if (this.useServerPrepStmts.getValue()) {  
        if (this.cachePrepStmts.getValue()) {
        pStmt = // 캐시에서 ServerPreparedStatement 조회
        } else {
        pStmt = ServerPreparedStatement.getInstance()
        }
        } else {
        if (this.cachePrepStmts.getValue()) {
        pStmt = // 캐시에서 ClientPreparedStatement 조회
        } else {
        pStmt = ClientPreparedStatement.getInstance()
        }
        }
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;h4 id=&quot;uselocalsessionstate&quot;&gt;useLocalSessionState&lt;/h4&gt;
        
        &lt;p&gt;&lt;code&gt;useLocalSessionState&lt;/code&gt;가 false면 임의 세션의 상태를 매번 DB로 전송하고, true면 로컬에서 관리해 네트워크 오버헤드를 제거합니다.&lt;/p&gt;
        
        &lt;h4 id=&quot;rewritebatchedstatements&quot;&gt;rewriteBatchedStatements&lt;/h4&gt;
        
        &lt;p&gt;INSERT나 UPDATE를 배치로 실행할 때, 여러 개의 쿼리를 하나의 쿼리(&lt;code&gt;INSERT INTO ... VALUES (...), (...), (...)&lt;/code&gt;)로 묶어서 보냅니다. 대량 데이터 삽입 시 성능이 수십 배 차이 날 수 있습니다.&lt;/p&gt;
        
        &lt;h4 id=&quot;cacheresultsetmetadata&quot;&gt;cacheResultSetMetadata&lt;/h4&gt;
        
        &lt;p&gt;&lt;code&gt;ResultSet&lt;/code&gt; 객체의 &lt;code&gt;getMetadata()&lt;/code&gt; 메서드가 반환하는 객체를 캐시할지에 대한 설정입니다. true로 설정하면 쿼리 결과의 메타데이터(칼럼 이름, 타입 등)를 캐싱해 매번 서버에 요청하지 않습니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code&gt;getColumnCount()              - Returns the number of columns in this ResultSet object.  
        getColumnName(int column)     - Get the designated column&apos;s name.  
        getColumnTypeName(int column) - Retrieves the designated column&apos;s database-specific type  
        name.
        getPrecision(int column)      - Get the designated column&apos;s specified column size.  
        getTableName()                - Returns the qualifier for the underlying table of the  
        ResultSet
        getSchemaName()               - Returns the the designated column&apos;s table&apos;s schema name  
        getColumnDisplaySize()        - Returns column display length  
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;h4 id=&quot;cacheserverconfiguration&quot;&gt;cacheServerConfiguration&lt;/h4&gt;
        
        &lt;p&gt;MySQL 서버의 구성 정보를 클라이언트 측에서 캐싱할지 여부입니다.&lt;/p&gt;
        
        &lt;h4 id=&quot;elidesetautocommits&quot;&gt;elideSetAutoCommits&lt;/h4&gt;
        
        &lt;p&gt;JDBC 클라이언트에서 &lt;code&gt;setAutoCommit()&lt;/code&gt;이 호출될 때마다 MySQL 서버로 &lt;code&gt;SET autocommit=?&lt;/code&gt; 명령을 전송합니다. true로 설정하면 현재 상태와 불일치할 때만 전송합니다.&lt;/p&gt;
        
        &lt;h4 id=&quot;maintaintimestats&quot;&gt;maintainTimeStats&lt;/h4&gt;
        
        &lt;p&gt;MySQL JDBC 드라이버에서 제공하는 설정 옵션으로, SQL 쿼리 실행 시간 통계를 유지할지 여부입니다.&lt;/p&gt;
        
        &lt;h3 id=&quot;oraclemysqlautoincrement&quot;&gt;Oracle 시퀀스와 MySQL auto increment&lt;/h3&gt;
        
        &lt;p&gt;Oracle 시퀀스를 사용하던 환경에서 MySQL auto increment로 변경하면서, JPA의 식별자 생성 시점 차이로 인해 연관관계 객체 저장 로직을 수정해야 했습니다.&lt;/p&gt;
        
        &lt;p&gt;기존 Oracle 환경에서는 SEQUENCE 기반으로 식별자가 INSERT 이전에 생성되므로 &lt;code&gt;persist()&lt;/code&gt; 호출 직후에도 ID를 활용할 수 있어 연관관계 설정과 저장 로직이 자연스럽게 동작했습니다. 반면 MySQL의 IDENTITY 전략에서는 INSERT 이후에야 식별자가 생성되기 때문에, 동일한 로직을 그대로 적용하면 연관관계 설정 시점에 ID가 존재하지 않아 의도하지 않은 동작이 발생할 수 있었습니다.&lt;/p&gt;
        
        &lt;p&gt;따라서 &lt;code&gt;flush()&lt;/code&gt; 호출 시점 조정이나 저장 순서 변경이 필요했습니다. 이 과정에서 식별자에 의존하던 로직을 정리하고 연관관계의 주인 설정을 명확히 하는 등 코드를 수정했습니다. 로직 수정이 불가능한 경우에는 채번용 MySQL 테이블을 별도로 두어 테이블에서 ID를 채번하도록 수정했습니다.&lt;/p&gt;
        
        &lt;h2 id=&quot;&quot;&gt;마치며&lt;/h2&gt;
        
        &lt;p&gt;성공적인 이관 작업의 결과, Oracle 데이터베이스의 세션 수가 감소하면서 시스템의 PGA 메모리 사용량이 줄어들었습니다. 이로 인해 PagingSpace Used(swap)가 감소하고 메모리 자원이 추가로 확보되었습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2026/01/14.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;Oracle 세션 수 및 메모리 사용량 변화&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;이 리소스 여유분은 공용 장비를 사용하는 타 부서에 자원적 안정성을 제공하는 동시에, 서비스 측면에서는 확보된 별도 장비 환경에서 기존 공용 장비 제약(타 부서 영향 및 부하 우려) 없이 파드 개수를 늘려 안정적인 서비스 확장 및 운영의 토대를 마련하게 되었습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2026/01/15.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;서비스 확장 후 아키텍처&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;또한 과제 수행 중 성능 모니터링을 통해 데이터베이스 쿼리 튜닝을 포함한 시스템 최적화를 수행한 결과, 서비스 API의 Latency(응답 지연 시간)가 유의미하게 개선되었습니다.&lt;/p&gt;
      </content:encoded>
    </item>
    <item>
      <title>네이버 통합검색 AIB 도입과 웹 성능 변화 분석</title>
      <link>https://d2.naver.com/helloworld/4241703</link>
      <guid>https://d2.naver.com/helloworld/4241703</guid>
      <pubDate>Sun, 08 Feb 2026 08:02:45 GMT</pubDate>
      <content:encoded>
        &lt;p&gt;AIB(AI Briefing)는 네이버 통합검색에서 AI 기반 요약·브리핑 경험을 제공하는 기능입니다. 2025년 3월부터 단계적으로 도입되었으며, 초기에는 정적인 요약 형태 중심이었고 2025년 7월 채팅 UI 기반의 애니메이션 인터페이스가 추가되면서 상호작용 요소가 확장되었습니다.&lt;/p&gt;
        
        &lt;p&gt;이러한 변화와 함께 트래픽에서 AIB가 차지하는 비중도 점차 증가하고 있습니다. 현재 네이버 통합검색에서 LCP(Largest Contentful Paint)로 측정되는 영역 중 AIB 영역이 약 10%를 차지하며, LCP 후보 영역으로 선택되는 빈도 또한 상위권입니다. 즉, AIB는 더 이상 일부 사용자에게만 노출되는 부가 기능이 아니라, 그 렌더링 방식이 검색 성능 지표 전반에 영향을 주는 단계라고 볼 수 있습니다.&lt;/p&gt;
        
        &lt;p&gt;이 글에서는 AIB의 UI 특성이 LCP에 어떤 영향을 주는지 정리하고, 채팅 UI에서 성능 지표를 해석할 때 주의할 점과 개선 방향을 제안합니다.&lt;/p&gt;
        
        &lt;h2 id=&quot;aib&quot;&gt;AIB 도입 이후 성능 지표 변화&lt;/h2&gt;
        
        &lt;p&gt;최근 네이버 통합검색의 LCP p95는 약 3.1초 수준으로 관측됩니다. 95%의 경우 뷰포트에서 가장 큰 콘텐츠가 3.1초 이내에 그려진다는 의미입니다. 이는 목표인 ‘LCP p95 2.5초 이하’를 상회하는 값입니다. 특히 AIB 노출량이 증가하는 시점과 LCP p95가 악화되는 시점이 비슷한 흐름을 보입니다.&lt;/p&gt;
        
        &lt;p&gt;다음 그래프는 네이버 통합검색 LCP p95와 AIB 노출량(QC) 추이입니다. 두 지표가 매우 유사한 패턴을 보이는 것을 확인할 수 있습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2026/01/1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;네이버 통합검색 LCP p95 추이&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2026/01/3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;AIB 노출량(QC) 추이&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;분포(distribution) 관점에서도 변화가 보입니다. AIB 도입 이후 Good 구간(LCP &amp;lt; 2.5초)에 해당하는 사용자 비율이 줄고, 상대적으로 느린 구간에 해당하는 사용자의 비율이 늘었습니다. 이는 AIB가 전체 LCP 분포의 뒤쪽, 즉 tail 영역에 영향을 주고 있음을 의미합니다. 구글 검색에서도 유사한 현상을 확인할 수 있습니다. 구글은 2024년 12월 AI Overview를 도입했고, 2025년 서비스 지역을 확대했습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2026/01/4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;네이버 통합검색과 구글 검색의 LCP 분포 변화&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;다만 두 서비스의 악화 양상에는 차이가 있습니다. 차이는 주로 렌더링 단위와 애니메이션 적용 방식에서 비롯됩니다. 구글 AI Overview는 비교적 큰 텍스트 블록 단위로 렌더링하며 애니메이션도 블록 단위로 제한적으로 적용됩니다. 반면 네이버 통합검색의 AIB는 텍스트를 어절 단위로 쪼개 점진적으로 표시하는 구조를 채택하고, 노출 애니메이션도 상대적으로 적극적으로 사용합니다. 콘텐츠가 화면에 노출되는 애니메이션 속도에도 차이가 있습니다. 이러한 요소는 사용자 경험뿐만 아니라, LCP와 같은 렌더링 기반 성능 지표가 측정되는 방식에도 영향을 미칩니다.&lt;/p&gt;
        
        &lt;p&gt;이제 네이버 통합검색의 AIB 영역이 실제로 어느 정도의 지연을 유발하는지, 그리고 이러한 구조적 특성을 고려했을 때 어떤 개선 가능성이 있는지를 더욱 구체적으로 살펴보겠습니다.&lt;/p&gt;
        
        &lt;h2 id=&quot;aib&quot;&gt;AIB가 얼마나 느린지 확인&lt;/h2&gt;
        
        &lt;p&gt;LCP 악화가 AIB 서버 성능 저하를 의미하는지 확인하기 위해 서버 응답과 클라이언트 렌더링을 나눠 살펴보았습니다. 도입 전후를 비교했을 때 서버 응답 시간이나 초기 콘텐츠 전달 구간에서 유의미한 차이는 없었습니다. 즉, 네트워크 지연이나 서버 처리 성능이 LCP 악화의 직접적인 원인이라고 보기는 어려웠습니다.&lt;/p&gt;
        
        &lt;p&gt;반면 클라이언트 렌더링 과정에서는 분명한 특이점을 확인했습니다. AIB는 채팅 UI를 사용해, 여러 줄의 텍스트가 순차적으로 등장하는 애니메이션을 포함합니다. 이 과정에서 약 900ms 수준의 스켈레톤 UI 노출과 텍스트 애니메이션이 발생해, 해당 영역의 최종 렌더링 시점이 뒤로 밀리고 있었습니다.&lt;/p&gt;
        
        &lt;p&gt;지표를 보면, 일반적으로 가장 느린 LCP 영역으로 알려진 지도 영역과 비교해도 p75 값이 3.3초 이상 길었습니다. 다만 단순히 스켈레톤 UI와 텍스트 애니메이션만으로 설명하기에는 지나치게 격차가 커, LCP 측정 시점이 구조적으로 지연되고 있다고 의심하게 되었습니다.&lt;/p&gt;
        
        &lt;table&gt;  
        &lt;thead&gt;  
        &lt;tr&gt;  
        &lt;th scope=&quot;col&quot;&gt;구분&lt;/th&gt;  
        &lt;th scope=&quot;col&quot;&gt;p75&lt;/th&gt;  
        &lt;th scope=&quot;col&quot;&gt;p95&lt;/th&gt;  
        &lt;/tr&gt;  
        &lt;/thead&gt;  
        &lt;tbody&gt;  
        &lt;tr&gt;  
        &lt;td&gt;AIB 영역이 LCP인 경우&lt;/td&gt;  
        &lt;td&gt;4,573ms&lt;/td&gt;  
        &lt;td&gt;6,921ms&lt;/td&gt;  
        &lt;/tr&gt;  
        &lt;tr&gt;  
        &lt;td&gt;지도 영역이 LCP인 경우&lt;/td&gt;  
        &lt;td&gt;1,270ms&lt;/td&gt;  
        &lt;td&gt;3,369ms&lt;/td&gt;  
        &lt;/tr&gt;  
        &lt;/tbody&gt;  
        &lt;/table&gt;
        
        &lt;h2 id=&quot;uilcp&quot;&gt;채팅 UI에서 LCP가 실제 사용자 경험을 반영하지 못하는 이유&lt;/h2&gt;
        
        &lt;p&gt;AIB 영역의 LCP가 비정상적으로 길게 측정되는 원인을 분석한 결과, 채팅 UI 특유의 DOM 구조와 상호작용 기능이 주요한 영향을 미치는 것을 확인했습니다. AIB는 텍스트가 한 글자 또는 어절 단위로 점진적으로 나타나는 텍스트 애니메이션을 포함하며, 특히 PC 환경에서는 각주에 마우스 포인터를 올리면 해당 텍스트가 하이라이트되는 인터랙션을 제공합니다.&lt;/p&gt;
        
        &lt;p&gt;이 하이라이트 기능 구현 과정에서, 텍스트 애니메이션이 모두 끝난 뒤 AIB 영역의 DOM을 한 번 더 재구성하는 로직이 존재했습니다. 초기 렌더링 이후에 하이라이트에 적합한 구조로 DOM이 다시 변경되면서 LCP 후보가 포함된 영역이 뒤늦게 렌더링되어, LCP의 renderTime이 실제 사용자 경험보다 크게 늦춰진 것입니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2026/01/5.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;텍스트 애니메이션 완료 후 AIB 영역의 텍스트가 재정렬되는 모습&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2026/01/5.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;하이라이트 인터랙션&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;모바일 환경에서는 하이라이트 기능이 직접적으로 사용되지는 않지만, PC·모바일이 공통 렌더링 로직을 공유했기 때문에 동일한 LCP 지연이 발생했습니다. 즉, AIB 영역의 LCP는 실제로 콘텐츠가 사용자에게 의미 있게 전달된 시점이 아니라, DOM 재구성까지 완료된 시점을 기준으로 측정되고 있었습니다.&lt;/p&gt;
        
        &lt;p&gt;그렇다면 이 DOM 재구성 로직을 제거하거나 수정하면 AIB 영역의 LCP를 의도에 맞게 측정할 수 있을까요? 그렇게 단정하기는 어렵습니다. 일부 개선 효과는 기대할 수 있으나, 채팅 UI 특성상 여전히 주의해야 할 구조적 문제가 남아 있기 때문입니다.&lt;/p&gt;
        
        &lt;h3 id=&quot;lcp&quot;&gt;어절 단위 렌더링에 따른 LCP 후보 분산&lt;/h3&gt;
        
        &lt;p&gt;AIB는 서버로부터 텍스트를 스트리밍 방식으로 전달받아, 어절 단위로 DOM에 점진적으로 렌더링하는 방식을 사용합니다. 이 방식은 사용자 입장에서는 자연스러운 대화 흐름을 제공하지만 LCP 측정 관점에서는 새로운 문제를 만들어 냅니다.&lt;/p&gt;
        
        &lt;p&gt;LCP는 뷰포트 내에서 ‘가장 큰 텍스트 블록 또는 이미지’를 기준으로 계산됩니다. 텍스트가 어절 단위로 쪼개져 있으면 어절이 개별 후보가 되며, 사용자가 인지하는 ‘하나의 큰 응답 영역’이 아니라 그중 면적이 가장 큰 어절이나 다른 UI 요소가 LCP로 선택될 수 있습니다. 이 경우 AIB가 화면에서 중요한 콘텐츠여도 LCP가 이를 대표하지 못하거나, 상황에 따라 의미가 낮은 요소가 LCP로 선택되는 문제가 생깁니다. 이는 하이라이트 기능을 제거하더라도 피하기 어려운, 렌더링 단위 자체에서 비롯되는 한계라고 볼 수 있습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2026/01/7.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;어절 단위 렌더링에서 상대적으로 의미가 적은 요소가 LCP로 선택되는 예&lt;/span&gt;&lt;/p&gt;
        
        &lt;h3 id=&quot;chromiumpaintinvalidation&quot;&gt;Chromium 렌더링 파이프라인 특성에 따른 paint invalidation&lt;/h3&gt;
        
        &lt;p&gt;또 하나의 문제는 Chromium 기반 브라우저의 렌더링 파이프라인과 LCP 계산 방식이 채팅 UI의 점진적 렌더링 패턴과 잘 맞지 않는다는 것입니다.&lt;/p&gt;
        
        &lt;p&gt;Chromium에서는 LCP 후보가 포함된 요소가 속한 레이어에서 paint invalidation이 발생하면 레이어가 다시 페인트되고, 그 시점에 LCP 후보의 renderTime이 갱신됩니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2026/01/8.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;점진적 렌더링에서 paint invalidation이 반복되는 사례&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;채팅 UI처럼 여러 줄의 텍스트가 순차적으로 추가되는 구조에서는, 충분히 인지 가능한 콘텐츠가 이미 화면에 표시된 후에도 하위 텍스트 변경으로 인해 같은 레이어가 반복적으로 다시 그려집니다. 이 과정에서 초기에 그려진 큰 텍스트 블록도 계속해서 ‘다시 그려진 요소’로 인식되며 LCP renderTime이 프레임 단위로 뒤로 밀리게 됩니다.&lt;/p&gt;
        
        &lt;p&gt;이 현상은 특정 구현의 버그라기보다, 채팅 UI와 같은 스트리밍·점진적 렌더링 UI가 LCP의 설계 가정과 잘 맞지 않아 발생하는 구조적 한계에 가깝습니다. 관련 배경은 아래 문서를 참고할 수 있습니다.&lt;/p&gt;
        
        &lt;ul&gt;
        &lt;li&gt;페이지 무효화 관련 설명: &lt;a href=&quot;https://developer.chrome.com/docs/chromium/blinkng?hl=ko&quot;&gt;RenderingNG 심층 분석: BlinkNG&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;Chromium core의 prepaint, paint invalidation 설명: &lt;a href=&quot;https://chromium.googlesource.com/chromium/src/+/HEAD/third_party/blink/renderer/core/paint/README.md#PrePaint&quot;&gt;PrePaint&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;h2 id=&quot;aib&quot;&gt;AIB를 제외한 네이버 통합검색 성능&lt;/h2&gt;
        
        &lt;p&gt;AIB 영역을 제외한 LCP 분포를 보면 Good 비율이 약 96% 수준을 유지하는 것을 확인할 수 있습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2026/01/9.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;AIB 영역을 제외한 LCP 분포&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;즉, 네이버 통합검색의 기본 성능 품질은 안정적이며, 최근 LCP 악화는 특정 UI(AIB 채팅 UI)의 구조적 요인이 크게 작용했다고 해석할 수 있습니다.&lt;/p&gt;
        
        &lt;h2 id=&quot;&quot;&gt;향후 개선 방향&lt;/h2&gt;
        
        &lt;p&gt;네이버 검색은 채팅 UI의 특성 때문에 발생하는 LCP 왜곡 문제를 해결하기 위해, AIB 영역의 성능을 측정·관리하는 독립적인 기준을 도입할 계획입니다. 이는 단순히 특정 지표를 보정하기 위한 조치가 아니라, 서로 다른 UI 패턴을 동일한 성능 지표로 평가해 왔던 기존 방식의 한계를 인식하고, UI 특성에 맞는 측정 체계를 재정립하려는 시도입니다.&lt;/p&gt;
        
        &lt;p&gt;특히 채팅 UI에서는 페이지의 ‘완전한 렌더링 시점’보다, 사용자가 첫 번째 의미 있는 응답을 인지하는 시점이 체감 성능과 더 밀접하게 연결됩니다. 실제로 여러 연구와 사례에서도 채팅 UI 환경에서는 LCP보다 첫 번째 토큰이 사용자에게 도달하는 시점, 즉 Time to First Token(TTFT)이 사용자 경험을 설명하는 데 더 적합한 지표임이 제시되고 있습니다. 이러한 배경을 바탕으로, 네이버 검색 역시 AIB 영역에 대해 TTFT를 새로운 핵심 성능 지표로 도입하는 방안을 검토하고 있습니다.&lt;/p&gt;
        
        &lt;p&gt;LCP가 의미 없는 지표라는 뜻은 아닙니다. 전통적인 검색 결과 페이지나 정적 콘텐츠 중심의 UI에서는 여전히 LCP가 중요한 품질 지표로, 검색 전반의 기본적인 속도와 안정성을 판단하는 데 유효합니다. 중요한 것은 LCP 하나로 모든 UI를 동일하게 평가하려 하기보다, 각 UI의 특성에 맞는 해석과 활용 방식을 함께 고민하는 것입니다.&lt;/p&gt;
        
        &lt;p&gt;기존의 LCP Good 구간(LCP &amp;lt; 2.5초)을 단순히 합격/불합격 기준으로만 사용하는 대신, 구간을 더 세분화해 사용자 체감 성능을 정밀하게 분석하는 접근도 고려할 수 있습니다. 최근 웹 성능 분야에서는 최적화(optimization) 중심의 사고에서 벗어나, 실제 사용자 경험을 더 잘 예측하고 설명하기 위한 지표 해석과 분포 분석의 중요성이 강조되고 있습니다. 이러한 흐름은 검색 성능 관리에도 시사하는 바가 크다고 생각합니다.(참고: &lt;a href=&quot;https://calendar.perfplanet.com/2025/web-performance-2025-the-shift-from-optimization-to-prediction&quot;&gt;Web Performance 2025: The Shift from Optimization to Prediction&lt;/a&gt;)&lt;/p&gt;
        
        &lt;h2 id=&quot;&quot;&gt;마치며&lt;/h2&gt;
        
        &lt;p&gt;네이버 검색은 앞으로 이러한 고민을 바탕으로, AIB와 같은 새로운 UI 패턴이 기존 성능 지표에 어떤 영향을 미치는지 지속적으로 관찰하고, 지표 설계와 렌더링 구조를 함께 개선해 나갈 계획입니다. 이를 통해 단순히 수치를 개선하는 데 그치지 않고, 사용자 체감 성능과 성능 지표가 보다 일관되게 맞물리는 성능 측정·관리 체계를 고도화해 나가고자 합니다.&lt;/p&gt;
      </content:encoded>
    </item>
    <item>
      <title>FE News 26년 1월 소식을 전해드립니다!</title>
      <link>https://d2.naver.com/news/5798505</link>
      <guid>https://d2.naver.com/news/5798505</guid>
      <pubDate>Sun, 08 Feb 2026 08:02:45 GMT</pubDate>
      <content:encoded>
        &lt;p&gt;&lt;img src=https://d2.naver.com/content/images/2023/07/-----------2023-07-06------4-16-49.png&gt;&lt;/p&gt;
        
        &lt;h2 id=&quot;&quot;&gt;주요소식&lt;/h2&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2026/01/image-2026-1-7_10-23-25.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;다음과 같은 유용한 정보들을 만나보실 수 있습니다.&lt;/p&gt;
        
        &lt;h4 id=&quot;rscexplorerreactservercomponents&quot;&gt;RSC Explorer - React Server Components 시각화 도구&lt;/h4&gt;
        
        &lt;p&gt;Dan Abramov가 React Server Components(RSC) 프로토콜을 시각화하는 도구를 공개했다. 브라우저에서 RSC 스트림을 단계별로 재생하고 분해할 수 있으며, 서버·클라이언트·flight·preview 4개 패널로 데이터 흐름을 표시한다. 네트워크 요청 없이 동작하고 React가 제공하는 reader/writer를 그대로 사용하기 때문에 출력 결과는 실제 프로토콜과 동일하다. 스트리밍(Suspense), Client Reference, Server Actions, Router refresh 같은 프레임워크 내부 동작 원리를 이해할 수 있는 RSC 디버깅과 교육 자료로 활용하기 좋은 도구다..&lt;/p&gt;
        
        &lt;h4 id=&quot;webaisummit2025ai&quot;&gt;Web AI Summit 2025 - 클라이언트 사이드 AI의 새로운 흐름&lt;/h4&gt;
        
        &lt;p&gt;클라이언트 사이드 모델과 에이전트를 주제로 하는 행사다. &quot;웹에서 AI&quot; 흐름이 서버 호출 중심에서 점점 브라우저 실행과 에이전트 상호작용 쪽으로 이동하는 분위기를 보여준다. Transformers.js로 브라우저에서 100% 로컬로 ML 모델을 실행하고, webMCP로 웹 저자가 사이트 기능을 브라우저 에이전트가 사용할 수 있는 도구로 정의하며, Wasm/WebGPU/WebNN을 활용한 클라이언트 사이드 AI 구축 방법 등 WebGPU/온디바이스 추론, 에이전트 UX, 브라우저 API 연동 같은 주제를 탐색하기에 적합한 세션들로 구성되어 있다.&lt;/p&gt;
        
        &lt;h4 id=&quot;stanfordaiclubjeffdeanonimportantaitrends&quot;&gt;Stanford AI Club: Jeff Dean on Important AI Trends&lt;/h4&gt;
        
        &lt;p&gt;Stanford AI Club 스피커 시리즈에서 Jeff Dean이 중요한 AI 트렌드를 연구와 제품 양쪽 관점에서 정리한다. 모델 성능뿐 아니라 시스템·데이터·워크플로 관점의 논의를 포함한다. 프런트엔드 관점에서는 브라우저/클라이언트에서 AI를 적용하는 방법과 제품 UX 변화 지점을 탐색하는 데 힌트를 얻을 수 있다. AI를 단순한 기능 추가가 아니라 제품 구조 전체를 바꾸는 변화로 보는 시각을 정리하는 데 도움이 된다.&lt;/p&gt;
        
        &lt;h4 id=&quot;thethinkinggamedeepmind&quot;&gt;The Thinking Game - DeepMind의 여정을 담은 다큐멘터리&lt;/h4&gt;
        
        &lt;p&gt;세계에서 가장 저명한 AI 연구소이자 기업 중 하나인 DeepMind 설립과 여정을 담은 영화다. 과학자 Demis Hassabis와 그의 팀이 인공 일반 지능(AGI)의 수수께끼를 풀기 위해 끊임없이 탐구하는 과정을 담고 있다. 5년에 걸쳐 촬영된 이 영화는 Hassabis와 그의 팀이 생물학의 50년 난제를 해결한 획기적인 프로그램인 AlphaFold로 역사를 쓰는 순간을 포착한다. &lt;/p&gt;
        
        &lt;h4 id=&quot;ai&quot;&gt;디자인시스템이 AI를 만났을 때&lt;/h4&gt;
        
        &lt;p&gt;네이버파이낸셜 디자인시스템과 AI를 활용한 마크업 자동화 경험 공유. Figma Code Connect와 instruction을 활용해 AI가 컴포넌트 기반 마크업을 생성하도록 했다. 디자인 토큰과 컴포넌트 구조를 AI에 학습시켜 FE 개발 시작 가능한 수준의 마크업 생성에 성공했지만, 복잡한 레이아웃이나 반응형 처리는 여전히 사람 개입이 필요. 디자인시스템 문서화와 표준화가 AI 활용 효율을 크게 좌우한다는 인사이트를 제공한다.&lt;/p&gt;
        
        &lt;h2 id=&quot;fenews261httpsgithubcomnaverfenewsblobmasterissues202601md&quot;&gt;&lt;a href=&quot;https://github.com/naver/fe-news/blob/master/issues/2026-01.md&quot;&gt;&gt;&gt; FE News 26년 1월 소식 보러가기&lt;/a&gt;&lt;/h2&gt;
        
        &lt;p&gt;&lt;br/&gt;  &lt;/p&gt;
        
        &lt;blockquote&gt;
        &lt;p&gt;&lt;strong&gt;◎ FE News란?&lt;/strong&gt;&lt;br/&gt;
        네이버 FE 엔지니어들이 엄선한 양질의 FE 및 주요한 기술 소식들을 큐레이션해 공유하는 것을 목표로 하며, 이를 통해 국내 개발자들에게 지식 공유에 대한 가치 인식과 성장에 도움을 주고자 하는 기술소식 공유 프로젝트 입니다.&lt;/p&gt;
        
        &lt;p&gt;매월 첫째 주 수요일, 월 1회 발행 되고 있으니 많은 관심 부탁드립니다.&lt;br/&gt;
        &lt;a href=&quot;https://fenews.substack.com/embed&quot;&gt;▷ 구독하기&lt;/a&gt;&lt;/p&gt;
        &lt;/blockquote&gt;
      </content:encoded>
    </item>
    <item>
      <title>비용, 성능, 안정성을 목표로 한 지능형 로그 파이프라인 도입</title>
      <link>https://d2.naver.com/helloworld/0004394</link>
      <guid>https://d2.naver.com/helloworld/0004394</guid>
      <pubDate>Sun, 08 Feb 2026 08:02:45 GMT</pubDate>
      <content:encoded>
        &lt;p&gt;Logiss는 AIDA(Advanced Interface for Data &amp;amp; AI)라는 네이버 사내 통합 데이터 플랫폼의 일부로, 로그 수집과 실시간 검색을 통해 문제를 추적하고 데이터를 분석하도록 지원합니다. 또한 Cuve와 CQuery라는 대용량 데이터 저장소 및 분석 설루션과 데이터를 연동합니다.&lt;/p&gt;
        
        &lt;p&gt;이 글에서는 로그 파이프라인을 운영하면서 겪은 문제점과 지능형 로그 파이프라인을 도입해 이를 해결한 과정을 공유합니다.&lt;/p&gt;
        
        &lt;p&gt;관련 발표는 &lt;strong&gt;팀네이버 컨퍼런스 DAN25&lt;/strong&gt; &apos;&lt;a href=&quot;https://dan.naver.com/25/sessions/693&quot;&gt;하루 수백억 건을 처리하는 똑똑한 로그 파이프라인 만들기: 비용·성능·안정성 삼박자&lt;/a&gt;&apos;에서도 살펴보실 수 있습니다.&lt;/p&gt;
        
        &lt;h2 id=&quot;&quot;&gt;로그 파이프라인의 역할&lt;/h2&gt;
        
        &lt;p&gt;로그 파이프라인을 설명하기 전에 먼저 AIDA의 주요 컴포넌트 구성을 간단히 알아보겠습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/12/2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;AIDA의 주요 컴포넌트 구성&lt;/span&gt;&lt;/p&gt;
        
        &lt;ul&gt;
        &lt;li&gt;&lt;strong&gt;AIDA Project&lt;/strong&gt;: 각 컴포넌트의 리소스 사용 관리, 데이터 권한 관리 담당&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Cuve&lt;/strong&gt;: HBase, Kafka 기반의 검색에 필요한 모든 문서를 중심으로 데이터 저장 및 유통
        &lt;ul&gt;&lt;li&gt;&lt;strong&gt;Hades&lt;/strong&gt;: 검색 결과에서 문서 노출 여부 제어&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Deathnote&lt;/strong&gt;: 서버 실시간 문서 삭제&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;C3&lt;/strong&gt;: Apache Hadoop(+보안 패치, C3 패치) 기반의 멀티테넌트 데이터 시스템. Hadoop 모듈인 HDFS, YARN, MapReduce를 비롯해 ZooKeeper, Oozie, Spark, Hive 사용 지원&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;CQuery&lt;/strong&gt;: C3의 HDFS에 테이블 형식으로 데이터를 저장하고 SQL 분석 지원&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Logiss&lt;/strong&gt;: 로그 수집과 실시간 검색을 제공하며 Cuve, CQuery에 데이터 연동 지원&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;AiSuite&lt;/strong&gt;: GPU 인프라와 Kubeflow를 지원하고 C3의 secure HDFS, Ceph, localPath, JuiceFS 등 용도에 맞는 스토리지 지원&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;p&gt;Logiss는 OpenSearch와 OpenSearch Dashboards를 이용해 실시간 인덱싱과 검색 기능을 제공합니다. 또한 Logstash, Kafka, Storm, Java 애플리케이션으로 구성한 파이프라인을 통해 OpenSearch와 랜딩 존(landing zone)에 데이터를 실시간 전송합니다. 랜딩 존은 Cuve, CQuery 등에서 운영합니다.&lt;/p&gt;
        
        &lt;blockquote&gt;
        &lt;p&gt;랜딩 존: 실시간 로그(단순 원본 데이터)를 SQL로 활용하기 전, 단기 저장을 목적으로 운영하는 저장 공간&lt;/p&gt;
        &lt;/blockquote&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/12/3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;다양한 컴포넌트로 구성된 Logiss의 파이프라인 아키텍처&lt;/span&gt;&lt;/p&gt;
        
        &lt;ul&gt;
        &lt;li&gt;&lt;strong&gt;FEL(FrontEnd Logstash)&lt;/strong&gt;: 사용자의 로그를 다양한 프로토콜(TCP, Beats, HTTP 등)로 수신해 Front Kafka에 적재&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Traffic-Controller&lt;/strong&gt;: Storm의 두 가지 토폴로지
        &lt;ul&gt;&lt;li&gt;&lt;strong&gt;main 토폴로지&lt;/strong&gt;: Front Kafka에 적재된 데이터를 지정된 Post Kafka의 실시간 처리 토픽으로 전달. 데이터마다 설정한 최대 처리 속도를 초과하지 않도록 하며, 초과 전송 분은 Post Kafka의 후처리를 위한 별도 토픽에 저장.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;retry 토폴로지&lt;/strong&gt;: 후처리 데이터를 다시 처리해 Post Kafka의 실시간 처리 토픽으로 전송&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;BEL(BackEnd Logstash)&lt;/strong&gt;: Post Kafka에서 OpenSearch로 인덱싱할 토픽들의 데이터를 소비해 OpenSearch로 벌크 인덱싱 요청&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Kafcuve&lt;/strong&gt;: Java 앱으로, Post Kafka에서 랜딩 존으로 전송할 토픽을 소비해 랜딩 존으로 데이터 전송&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;LAP(Logiss Async Processor)&lt;/strong&gt;: Jenkins 배치(batch) 잡을 실행하는 주체. 전송 속도를 초과해 Post Kafka에 후처리 데이터로 쌓인 토픽의 데이터를 소비하고, 다시 정해진 속도로 Traffic-Controller의 retry 토폴로지로 데이터 전송.&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;p&gt;Traffic-Controller는 로그 데이터마다 설정된 최대 전송 속도를 초과하지 않도록 뒷단으로 데이터를 흘려보냅니다. 데이터마다 전송 속도를 설정하는 이유는 Logiss가 공용 플랫폼이므로 뒷단의 부하가 어느 한 데이터에 점유되는 것을 막고, 과도한 트래픽으로부터 뒷단을 보호하기 위해서입니다.&lt;/p&gt;
        
        &lt;h2 id=&quot;&quot;&gt;기존 로그 파이프라인의 문제점&lt;/h2&gt;
        
        &lt;h3 id=&quot;1trafficcontroller&quot;&gt;1. 단일 토폴로지로 운영되던 Traffic-Controller&lt;/h3&gt;
        
        &lt;p&gt;트래픽 제어를 담당하는 Traffic-Controller의 main 토폴로지는 단일 토폴로지로 구성되어 있었습니다. Storm에 swap 기능이 없어, 배포하려면 실행 중인 토폴로지를 중단하고 다시 제출해야만 했습니다(참고: &lt;a href=&quot;https://storm.apache.org/releases/2.8.2/Running-topologies-on-a-production-cluster.html&quot;&gt;Updating a running topology&lt;/a&gt;).&lt;/p&gt;
        
        &lt;p&gt;단일 토폴로지 구조에서는 무중단 배포가 불가능했고, 이로 인해 배포 시 약 3~8분 정도 파이프라인 지연이 발생했습니다.&lt;/p&gt;
        
        &lt;p&gt;다음은 서로 다른 2개의 클러스터에 단일 토폴로지로 구성된 Traffic-Controller를 배포할 때 데이터를 소비하는 Front Kafka의 랙(lag) 그래프입니다. 평상시에는 랙이 거의 발생하지 않지만, 토폴로지를 재기동하는 동안에는 데이터 처리가 멈추어 처리해야 할 데이터가 쌓이는 모습을 확인할 수 있습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/12/4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;서로 다른 2개의 클러스터에 단일 토폴로지로 구성된 Traffic-Controller를 배포할 때 발생한 Front Kafka 랙&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;실시간 파이프라인에 지연이 발생하기 때문에 항상 배포 전에는 Logiss 사용자에게 별도로 공지해야 했고, 사용자 영향이 적고 트래픽이 적은 새벽 시간에만 배포할 수 있었습니다. 예정된 상황에서는 미리 공지하고 작업할 수 있지만, 긴급 배포가 필요한 경우에는 지연을 피할 수 없다는 한계도 있었습니다.&lt;/p&gt;
        
        &lt;p&gt;또한 점진적 배포가 불가능하여, 실제 서비스 환경에서만 드러나는 부작용은 배포가 완전히 끝난 후에야 확인할 수 있었습니다.&lt;/p&gt;
        
        &lt;h3 id=&quot;2&quot;&gt;2. 낮과 새벽의 트래픽 차이&lt;/h3&gt;
        
        &lt;p&gt;Logiss는 네이버 전사 로그를 수집하기 때문에 일반적으로 낮 시간에 트래픽이 많고 새벽 시간에 적은 유입 패턴을 보입니다.&lt;/p&gt;
        
        &lt;p&gt;다음은 운영 중인 클러스터 중 하나의 7일치 Front Kafka 트래픽 유입 패턴입니다. 최대 트래픽이 최소 트래픽의 약 5배인 것을 확인할 수 있습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/12/5.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;특정 클러스터의 7일치 Front Kafka 트래픽 유입 패턴(초당 로그 개수, 초당 로그 크기를 임의 단위로 표시)&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;Logiss의 파이프라인은 물리 장비(PM)로 구성되어 있고, 실시간 트래픽 처리가 목표입니다. 따라서 낮 시간에 집중된 피크(peak) 트래픽을 여유 있게 처리할 수 있도록 클러스터 규모를 산정해야 하며, 이 기준에 따라 머신 리소스를 다소 높게 투입하여 운영해야 했습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/12/6.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;특정 클러스터의 7일치 Post Kafka 디스크 사용량, OpenSearch CPU 사용량(임의 단위로 표시)&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;이처럼 낮 시간에 트래픽이 집중되는 패턴 때문에 트래픽이 적은 새벽 시간대에는 머신 자원을 충분히 활용하지 못하는 비효율이 발생했습니다.&lt;/p&gt;
        
        &lt;h3 id=&quot;3&quot;&gt;3. 모든 로그의 공평한 처리&lt;/h3&gt;
        
        &lt;p&gt;Front Kafka는 단일 토픽으로 운영되고 있어 급작스러운 트래픽 유입이나 장비 이슈가 발생하면 트래픽 처리 지연이 발생할 수 있습니다. 이때 로그의 중요도와 상관없이 데이터마다 설정된 최대 처리 속도로 처리되었습니다.&lt;/p&gt;
        
        &lt;p&gt;급작스러운 트래픽 유입으로 지연이 발생하면, 지연된 데이터에는 실시간으로 빠르게 처리되어야 하는 사업·서비스 핵심 로그와 상대적으로 중요도가 낮아 천천히 처리해도 되는 로그가 함께 섞여 있습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/12/7.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;트래픽 지연이 발생했을 때의 Front Kafka 랙&lt;/span&gt;&lt;/p&gt;
        
        &lt;h3 id=&quot;4&quot;&gt;4. 장기 저장소와 실시간 검색을 위한 저장소에 모두 전달&lt;/h3&gt;
        
        &lt;p&gt;Logiss는 데이터의 목적이나 성격에 따라 OpenSearch에만 저장하거나, 랜딩 존에만 저장하거나, 양쪽 모두에 저장합니다. 특히 양쪽 모두 저장하도록 설정된 데이터 중에는 전체 트래픽을 저장하는 대신 일부 샘플링만으로도 충분히 유의미한 데이터를 얻을 수 있는 경우도 있었습니다.&lt;/p&gt;
        
        &lt;p&gt;하지만 전달받은 트래픽을 100% 저장하는 것이 기본 원칙이었기 때문에, 모든 트래픽을 저장할 필요가 없는 경우에도 저장소를 비효율적으로 사용했습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/12/8.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;데이터 A가 장기 저장소인 랜딩 존, 실시간 검색을 위한 저장소 OpenSearch 양쪽에 저장될 때 수신한 데이터를 100% 저장&lt;/span&gt;&lt;/p&gt;
        
        &lt;h3 id=&quot;&quot;&gt;문제점 정리&lt;/h3&gt;
        
        &lt;ol&gt;
        &lt;li&gt;단일 토폴로지로 운영되던 Traffic-Controller의 main 토폴로지 → 무중단, 점진적 배포 불가  &lt;/li&gt;
        &lt;li&gt;낮과 새벽의 트래픽 차이 → 낮 시간 트래픽을 기준으로 산정된 다소 과한 장비 리소스  &lt;/li&gt;
        &lt;li&gt;모든 로그의 공평한 처리 → 처리 지연 등 비상시, 중요한 로그와 덜 중요한 로그 모두 같이 지연  &lt;/li&gt;
        &lt;li&gt;장기 저장소와 실시간 검색을 위한 저장소에 모두 전달 → 비효율적인 저장소 사용&lt;/li&gt;
        &lt;/ol&gt;
        
        &lt;h2 id=&quot;&quot;&gt;해결 방법&lt;/h2&gt;
        
        &lt;h3 id=&quot;stormkafkaspout&quot;&gt;Storm Kafka spout의 변경 및 멀티 토폴로지 도입&lt;/h3&gt;
        
        &lt;p&gt;storm-kafka-client(spout)는 1.x에서 2.x로 버전이 변경될 때, KafkaConsumer.subscribe API 호출을 제거하고 assign 방식을 채택했습니다.&lt;/p&gt;
        
        &lt;ul&gt;
        &lt;li&gt;&lt;strong&gt;subscribe&lt;/strong&gt;: 소비할 파티션의 결정(할당)을 Kafka 브로커에게 맡기는 방식&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;assign&lt;/strong&gt;: 소비할 파티션의 결정을 KafkaConsumer(spout)가 직접 결정하는 방식&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;p&gt;2.x에서 subscribe API 호출을 제거하고 assign 방식을 채택한 이유(subscribe API의 단점)는 다음과 같습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/12/9.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;storm-kafka-client에서 주장한 subscribe API의 단점(관련 이슈: &lt;a href=&quot;https://github.com/apache/storm/issues/6324&quot;&gt;[STORM-2542] Deprecate storm-kafka-client KafkaConsumer.subscribe API subscriptions on 1.x and remove them as options in 2.x&lt;/a&gt;)&lt;/span&gt;&lt;/p&gt;
        
        &lt;ul&gt;
        &lt;li&gt;당시 cooperative sticky, sticky 등 고도화된 파티션 할당 전략이 없어, 재할당 과정 중 전체 spout의 소비가 멈춤&lt;/li&gt;
        &lt;li&gt;spout이 어떤 파티션을 처리할지 예측할 수 없음&lt;/li&gt;
        &lt;li&gt;spout이 하나의 executor에서 여러 task와 함께 실행되거나, 하나의 스레드에 여러 KafkaConsumer가 있는 경우 시스템이 멈추거나 이상 동작&lt;/li&gt;
        &lt;li&gt;executor crash가 발생하면 전체 파티션이 재할당되어 필요 이상의 중복이 발생하고, 처리하던 파티션에 커밋할 수 없음&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;p&gt;하지만 assign API 채택은 다음과 같은 이유로 Traffic-Controller에 큰 이점이 없었습니다.&lt;/p&gt;
        
        &lt;ul&gt;
        &lt;li&gt;Kafka에 고도화된 파티션 할당 전략 도입(파티션 리밸런스 시간 단축 및 최소화로 중복 최소화 가능)&lt;/li&gt;
        &lt;li&gt;Traffic-Controller의 spout은 어떤 파티션을 처리할지 예측할 필요가 없음&lt;/li&gt;
        &lt;li&gt;Traffic-Controller의 spout은 Kafka로부터 레코드를 소비하고 바로 다음 bolt로 넘겨주는 작업만 담당했으며, spout 하나에 하나의 KafkaConsumer로 동작&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;p&gt;따라서 assign 방식이 적용된 storm-kafka-client 2.x 버전을 사용하는 Traffic-Controller에는 다음과 같은 문제점만 있었습니다.&lt;/p&gt;
        
        &lt;ul&gt;
        &lt;li&gt;토폴로지 ID만 바꾸어서 여러 개 띄울 경우, 토폴로지 개수만큼 파티션 중복 소비와 처리 발생&lt;/li&gt;
        &lt;li&gt;브로커가 파티션 할당을 담당하지 않기 때문에 파티션 할당 전략을 사용할 수 없음&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;p&gt;이러한 assign 방식의 문제점 때문에 다시 subscribe 방식으로 돌아가기 위한 방법을 고민했습니다.&lt;/p&gt;
        
        &lt;h4 id=&quot;kafkaconsumersubscribestormkafkaclient&quot;&gt;KafkaConsumer.subscribe 방식 적용을 위한 storm-kafka-client 다운그레이드 시도&lt;/h4&gt;
        
        &lt;p&gt;멀티 토폴로지 도입을 위해 KafkaConsumer.assign을 subscribe로 변경하고자 시도한 첫 번째 방법은 storm-kafka-client를 2.x에서 1.1.0으로 다운그레이드하는 것이었습니다.&lt;/p&gt;
        
        &lt;p&gt;멀티 토폴로지를 구성해도 파티션 중복 소비나 처리는 발생하지 않았지만, 장애 테스트 시 중단 시간이 매우 긴 것(약 6분)을 확인했습니다. 따라서 다운그레이드는 합리적인 선택이 아니라고 판단했습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/12/10.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;storm-kafka-client 1.1.0(subscribe API)을 사용하면서 멀티 토폴로지를 구성한 후, supervisor 다운 시 발생한 Front Kafka 랙(위)과 Traffic-Controller의 소비(아래)&lt;/span&gt;&lt;/p&gt;
        
        &lt;h4 id=&quot;stormkafkaclientkafkaconsumerassignsubscribe&quot;&gt;최신의 storm-kafka-client에서 KafkaConsumer.assign → subscribe 변경&lt;/h4&gt;
        
        &lt;p&gt;그래서 최신 storm-kafka-client에서 assign API를 subscribe로 변경했습니다. Storm 2.3.0에서 변경한 사항은 다음과 같습니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-diff&quot;&gt;diff --git external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java  
        index 391aeccb6..d8b8ab0c9 100644  
        --- external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java
        +++ external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java
        @@ -325,6 +325,10 @@ public class KafkaSpout&amp;lt;K, V&amp;gt; extends BaseRichSpout {
        final int maxUncommittedOffsets = kafkaSpoutConfig.getMaxUncommittedOffsets();
        for (TopicPartition tp : assignment) {
        OffsetManager offsetManager = offsetManagers.get(tp);
        +            if (offsetManager == null) {
        +                //This partition is not assigned to this spout
        +                continue;
        +            }
        int numUncommittedOffsets = offsetManager.getNumUncommittedOffsets();
        if (numUncommittedOffsets &amp;lt; maxUncommittedOffsets) {
        //Allow poll if the partition is not at the maxUncommittedOffsets limit
        @@ -460,6 +464,9 @@ public class KafkaSpout&amp;lt;K, V&amp;gt; extends BaseRichSpout {
        LOG.trace(&quot;Emitted tuple [{}] for record [{}]&quot;, tuple, record);
        }
        } else {
        +                        if (!offsetManagers.containsKey(tp)) {
        +                            return false;
        +                        }
        emitted.add(msgId);
        offsetManagers.get(tp).addToEmitMsgs(msgId.offset());
        if (isScheduled) {  // Was scheduled for retry and re-emitted, so remove from schedule.
        @@ -620,19 +627,14 @@ public class KafkaSpout&amp;lt;K, V&amp;gt; extends BaseRichSpout {
        @Override
        public void activate() {
        try {
        -            refreshAssignment();
        +            consumer.subscribe(Collections.singletonList(getTopicsString()), rebalanceListener);
        } catch (InterruptException e) {
        throwKafkaConsumerInterruptedException();
        }
        }
        
        private void refreshAssignment() {
        -        Set&amp;lt;TopicPartition&amp;gt; allPartitions = kafkaSpoutConfig.getTopicFilter().getAllSubscribedPartitions(consumer);
        -        List&amp;lt;TopicPartition&amp;gt; allPartitionsSorted = new ArrayList&amp;lt;&amp;gt;(allPartitions);
        -        Collections.sort(allPartitionsSorted, TopicPartitionComparator.INSTANCE);
        -        Set&amp;lt;TopicPartition&amp;gt; assignedPartitions = kafkaSpoutConfig.getTopicPartitioner()
        -            .getPartitionsForThisTask(allPartitionsSorted, context);
        -        topicAssigner.assignPartitions(consumer, assignedPartitions, rebalanceListener);
        +        topicAssigner.assignPartitions(consumer);
        }
        
        @Override
        diff --git external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/subscription/TopicAssigner.java external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/subscription/TopicAssigner.java  
        index 300adecec..2942c8a20 100644  
        --- external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/subscription/TopicAssigner.java
        +++ external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/subscription/TopicAssigner.java
        @@ -34,17 +34,10 @@ public class TopicAssigner implements Serializable {
        * @param &amp;lt;K&amp;gt; The consumer key type
        * @param &amp;lt;V&amp;gt; The consumer value type
        * @param consumer The Kafka consumer to assign partitions to
        -     * @param newAssignment The partitions to assign.
        -     * @param listener The rebalance listener to call back on when the assignment changes
        */
        -    public &amp;lt;K, V&amp;gt; void assignPartitions(Consumer&amp;lt;K, V&amp;gt; consumer, Set&amp;lt;TopicPartition&amp;gt; newAssignment,
        -        ConsumerRebalanceListener listener) {
        -        Set&amp;lt;TopicPartition&amp;gt; currentAssignment = consumer.assignment();
        -        if (!newAssignment.equals(currentAssignment)) {
        -            listener.onPartitionsRevoked(currentAssignment);
        -            consumer.assign(newAssignment);
        -            listener.onPartitionsAssigned(newAssignment);
        -        }
        +    public &amp;lt;K, V&amp;gt; void assignPartitions(Consumer&amp;lt;K, V&amp;gt; consumer) {
        +        if (consumer.assignment().isEmpty())
        +            consumer.poll(0);
        }
        
        }
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;p&gt;또한 멀티 토폴로지를 적용했을 때 spout, bolt 등의 task 할당이 장비마다 고르게 일어날 수 있도록 커스텀 스케줄러를 작성했습니다.&lt;/p&gt;
        
        &lt;p&gt;Storm에서 기본으로 제공하는 스케줄러들만으로는 supervisor별로 원하는 상태의 task 구성을 만들기 어려웠습니다. 다음은 기본 스케줄러를 이용해 spout 1개, parser bolt 3개, throttle bolt 2개, kafka bolt 3개로 구성된 main 토폴로지를 6개 배포했을 때 task가 supervisor별 slot에 어떻게 할당되는지 가시화한 이미지입니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/12/11.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;spout 1개, parser bolt 3개, throttle bolt 2개, kafka bolt 3개로 구성된 main 토폴로지를 기본 스케줄러로 6개 배포했을 때 slot별 task 할당 과정&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;기본 스케줄러를 사용하면 최악의 경우 특정 spout, bolt task만으로 구성된 supervisor가 존재할 수 있습니다. 다음은 기본 스케줄러를 이용해 spout 1개, parser bolt 2개, throttle bolt 1개, kafka bolt 1개로 구성된 main 토폴로지를 10개 배포했을 때 task가 supervisor별 slot에 할당된 예입니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/12/12.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;spout 1개, parser bolt 2개, throttle bolt 1개, kafka bolt 1개로 구성된 main 토폴로지를 기본 스케줄러로 10개 배포했을 때 slot별 task 할당 할당 결과&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;supervisor2, 3의 모든 slot에는 parser bolt만 할당되었습니다. 이렇게 되면 parser bolt는 상대적으로 리소스를 많이 사용하기 때문에 supervisor2, 3에 부하가 집중되고, 전체 처리 병목이 두 장비에서 발생할 수 있습니다. 리소스를 상대적으로 덜 소비하는 spout과 bolt로 구성된 장비는 여유로운데도 말이죠.&lt;/p&gt;
        
        &lt;p&gt;따라서 spout과 bolt를 기계적으로 할당하는 기본 방식을 사용할 수 없었고, supervisor별로 이미 할당된 task를 고려하여 지능적으로 할당해야 했습니다.&lt;/p&gt;
        
        &lt;h4 id=&quot;&quot;&gt;커스텀 스케줄러 개발&lt;/h4&gt;
        
        &lt;p&gt;커스텀 스케줄러는 장비별로 특정 bolt, spout이 가장 적게 할당된 supervisor를 찾아 할당하는 방식으로 구현했습니다.&lt;/p&gt;
        
        &lt;p&gt;다음은 스케줄러의 핵심 로직입니다. 컴포넌트(Front Kafka spout, throttle bolt 등)가 가장 적게 할당된 supervisor slot을 찾고, 동일한 경우 slot이 가장 여유로운(task가 가장 적은) 노드의 slot을 선택합니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;private String findBestSupervisor(Map&amp;lt;String, Map&amp;lt;String, Integer&amp;gt;&amp;gt; supervisorComponentCounts,  
        Map&amp;lt;String, List&amp;lt;WorkerSlot&amp;gt;&amp;gt; availableSlotsBySupervisor, String component) {
        return availableSlotsBySupervisor.entrySet().stream()
        .filter(e -&amp;gt; !e.getValue().isEmpty()) // slot이 있는 supervisor만 대상
        .min(Comparator.comparingInt((Map.Entry&amp;lt;String, List&amp;lt;WorkerSlot&amp;gt;&amp;gt; e) -&amp;gt;
        supervisorComponentCounts.getOrDefault(e.getKey(), Collections.emptyMap())
        .getOrDefault(component, 0)) // 1순위: 해당 컴포넌트 개수
        .thenComparingInt(e -&amp;gt;
        supervisorComponentCounts.getOrDefault(e.getKey(), Collections.emptyMap())
        .values().stream().mapToInt(Integer::intValue).sum() // 2순위: 전체 task 수
        )
        )
        .map(Map.Entry::getKey)
        .orElse(null);
        }
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;p&gt;다음은 커스텀 스케줄러를 이용해 spout 1개, parser bolt 2개, throttle bolt 1개, kafka bolt 1개로 구성된 main 토폴로지를 10개 배포했을 때 task가 supervisor별 slot에 어떻게 할당되는지 가시화한 이미지입니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/12/13.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;spout 1개, parser bolt 2개, throttle bolt 1개, kafka bolt 1개로 구성된 main 토폴로지를 커스텀 스케줄러로 10개 배포했을 때 slot별 task 할당 과정&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;10개의 토폴로지가 모두 할당된 결과를 보면 각 장비별 bolt, spout의 개수가 최대한 같게 할당된 것을 확인할 수 있습니다. 각 supervisor에 2개의 throttle bolt가 할당되었습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/12/14.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;spout 1개, parser bolt 2개, throttle bolt 1개, kafka bolt 1개로 구성된 main 토폴로지를 커스텀 스케줄러로 10개 배포했을 때 slot별 task 할당 결과&lt;/span&gt;&lt;/p&gt;
        
        &lt;h4 id=&quot;subscribeapi&quot;&gt;subscribe API로 변경 + 커스텀 스케줄러가 적용된 멀티 토폴로지에서 다양한 장애 테스트 진행&lt;/h4&gt;
        
        &lt;p&gt;멀티 토폴로지에 커스텀 스케줄러를 적용한 후, 기존 단일 토폴로지 대비 다양한 상황에서 지연이나 중복의 정도를 비교해 보기 위해 장애 테스트를 진행했습니다.&lt;/p&gt;
        
        &lt;ul&gt;
        &lt;li&gt;supervisor 장비 다운을 모사하는 supervisor 중단&lt;/li&gt;
        &lt;li&gt;배포 상황에서 발생하는 topology kill&lt;/li&gt;
        &lt;li&gt;executor crash를 모사하는 bolt, spout executor kill&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;p&gt;단일 토폴로지(assign)와 멀티 토폴로지(subscribe with range assignor)의 장애 테스트 결과를 항목별로 비교하면 다음과 같습니다.&lt;/p&gt;
        
        &lt;table&gt;  
        &lt;thead&gt;
        &lt;tr&gt;
        &lt;th&gt;항목&lt;/th&gt;
        &lt;th&gt;단일 토폴로지 + assign&lt;/th&gt;
        &lt;th&gt;멀티 토폴로지 + subscribe(range)&lt;/th&gt;
        &lt;th&gt;멀티 토폴로지 + subscribe(range)의 특징&lt;/th&gt;
        &lt;/tr&gt;
        &lt;/thead&gt;
        &lt;tbody&gt;
        &lt;tr&gt;
        &lt;td&gt;&lt;span style=&quot;color:red;&quot;&gt;supervisor 중단&lt;/span&gt;&lt;/td&gt;
        &lt;td&gt;전체 파티션 지연(75~115초)&lt;br/&gt;약 45초 데이터에 대해 11% 중복 처리&lt;/td&gt;
        &lt;td&gt;전체 파티션 지연(30~90초)&lt;br/&gt;약 45초 데이터에 대해 36% 중복 처리&lt;/td&gt;
        &lt;td&gt;&lt;strong&gt;지연이 다소 줄었으나,&lt;/strong&gt;&lt;br/&gt;&lt;strong&gt;중복 처리 양이 더 많아짐&lt;/strong&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;&lt;span style=&quot;color:green;&quot;&gt;topology kill&lt;/span&gt;&lt;/td&gt;
        &lt;td&gt;전체 파티션 처리 중단&lt;/td&gt;
        &lt;td&gt;일부 파티션 지연(30초)&lt;/td&gt;
        &lt;td&gt;전체 파티션의 처리가 멈추지는 않게 됨&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;&lt;span style=&quot;color:blue;&quot;&gt;bolt executor kill&lt;/span&gt;&lt;/td&gt;
        &lt;td&gt;전체 파티션 지연(60초)&lt;br/&gt;약 5초 데이터에 대해 0.4% 중복 처리&lt;/td&gt;
        &lt;td&gt;일부 파티션 지연(30~60초)&lt;br/&gt;약 10초 데이터에 대해 0.4% 중복 처리&lt;/td&gt;
        &lt;td&gt;단일 토폴로지 대비 큰 차이 없음&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;&lt;span style=&quot;color:blue;&quot;&gt;spout executor kill&lt;/span&gt;&lt;/td&gt;
        &lt;td&gt;전체 파티션 지연(60초)&lt;br/&gt;약 5초 데이터에 대해 3% 중복 처리&lt;/td&gt;
        &lt;td&gt;전체 파티션 지연(30~90초)&lt;br/&gt;약 5초 데이터에 대해 3% 중복 처리&lt;/td&gt;
        &lt;td&gt;단일 토폴로지 대비 큰 차이 없음&lt;/td&gt;
        &lt;/tr&gt;
        &lt;/tbody&gt;
        &lt;/table&gt;
        
        &lt;p&gt;topology, spout executor, bolt executor kill의 세 가지 테스트에서는 일부 파티션의 처리만 지연되고, 중복 처리 양은 단일 토폴로지와 비슷하다는 큰 이점이 있었습니다. 하지만 평상시에도 흔하게 일어날 수 있는 장비 다운 등의 상황과 비슷한 supervisor 중단 테스트에서는 중복 처리가 단일 토폴로지보다 많은 것을 확인했습니다.&lt;/p&gt;
        
        &lt;p&gt;이렇게 다량의 데이터가 중복 처리되더라도, 실제 주요 로그의 경우에는 로그마다 고유 키를 부여하고, 이를 활용해서 랜딩 존 내부에서 중복 제거(deduplication) 작업이 수행되어 큰 문제가 되지는 않습니다. 그래도 OpenSearch에서의 중복이나 랜딩 존 내부의 중복 제거 작업을 최소화하기 위해 Traffic-Controller에서의 중복 처리는 최소로 줄여야 합니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/12/15.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;랜딩 존 내부에서 중복 로그 제거&lt;/span&gt;&lt;/p&gt;
        
        &lt;h4 id=&quot;&quot;&gt;중복을 줄이기 위한 파티션 할당 전략 수정&lt;/h4&gt;
        
        &lt;p&gt;subscribe + 멀티 토폴로지(range assignor)에서 supervisor 중단 시 과한 중복이 발생하는 주 원인은 전체 파티션의 소유권 변경이었습니다. 중단한 supervisor가 처리하던 파티션(A)의 소유권을 다른 supervisor의 spout이 이어받아 처리하는데, 기본 파티션 할당 전략인 range assignor에서는 A 파티션뿐만 아니라 다른 모든 파티션의 소유권이 변경되므로 과도한 중복이 발생했습니다.&lt;/p&gt;
        
        &lt;p&gt;그래서 중단한 supervisor가 처리하던 파티션의 소유권만 변경되도록, sticky assignor를 파티션 할당 전략으로 적용하고 다시 장애 테스트를 진행했습니다.&lt;/p&gt;
        
        &lt;p&gt;다음은 단일 토폴로지와 멀티 토폴로지(with sticky assignor)에서 장애 테스트 시 Front Kafka의 파티션별 랙 오프셋 그래프입니다. 빨간색 동그라미는 supervisor 다운 시, 초록색 동그라미는 토폴로지를 하나 내렸다가 올렸을 때, 파란색 사각형은 spout과 bolt 3개를 차례로 내렸을 때입니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/12/16.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;단일 토폴로지(위)와 멀티 토폴로지(with sticky assignor)(아래)에서 장애 테스트 시 Front Kafka의 파티션별 랙 오프셋&lt;/span&gt;&lt;/p&gt;
        
        &lt;ul&gt;
        &lt;li&gt;빨간색 원: supervisor 다운 시. 단일 토폴로지(위)의 처리 지연 시간이 깁니다.&lt;/li&gt;
        &lt;li&gt;초록색 원: 토폴로지 중단 시. 단일 토폴로지(위)에서는 모든 파티션의 처리가 중단되는 반면, 멀티 토폴로지(아래)에서는 일부 파티션의 처리만 중단됩니다.&lt;/li&gt;
        &lt;li&gt;파란색 사각형: spout과 bolt 3개를 차례로 내렸을 때. 단일 토폴로지(위)에서는 모든 spout, bolt가 종료될 때 모든 파티션의 처리가 중단되지만, 멀티 토폴로지(아래) bolt의 경우 일부 파티션만 처리 중단됩니다.&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;p&gt;단일 토폴로지(assign)와 멀티 토폴로지(subscribe with sticky assignor)의 장애 테스트 결과를 항목별로 비교하면 다음과 같습니다.&lt;/p&gt;
        
        &lt;table&gt;  
        &lt;thead&gt;
        &lt;tr&gt;
        &lt;th&gt;항목&lt;/th&gt;
        &lt;th&gt;단일 토폴로지 + assign&lt;/th&gt;
        &lt;th&gt;멀티 토폴로지 + subscribe(sticky)&lt;/th&gt;
        &lt;th&gt;멀티 토폴로지 + subscribe(sticky)의 특징&lt;/th&gt;
        &lt;/tr&gt;
        &lt;/thead&gt;
        &lt;tbody&gt;
        &lt;tr&gt;
        &lt;td&gt;&lt;span style=&quot;color:red;&quot;&gt;supervisor 중단&lt;/span&gt;&lt;/td&gt;
        &lt;td&gt;전체 파티션 지연(75~115초)&lt;br/&gt;약 45초 데이터에 대해 11% 중복 처리&lt;/td&gt;
        &lt;td&gt;전체 파티션 지연(30~90초)&lt;br/&gt;약 40초 데이터에 대해 13% 중복 처리&lt;/td&gt;
        &lt;td&gt;&lt;strong&gt;지연이 다소 줄고, 전체적인 중복 처리의 양이 비슷함&lt;/strong&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;&lt;span style=&quot;color:green;&quot;&gt;topology kill&lt;/span&gt;&lt;/td&gt;
        &lt;td&gt;전체 파티션 처리 중단&lt;/td&gt;
        &lt;td&gt;일부 파티션 지연(15~30초)&lt;/td&gt;
        &lt;td&gt;전체 파티션의 처리가 멈추지는 않게 됨&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;&lt;span style=&quot;color:blue;&quot;&gt;spout executor kill&lt;/span&gt;&lt;/td&gt;
        &lt;td&gt;전체 파티션 지연(60초)&lt;br/&gt;약 5초 데이터에 대해 3% 중복 처리&lt;/td&gt;
        &lt;td&gt;전체 파티션 지연(45~60초)&lt;br/&gt;약 5초 데이터에 대해 0.68% 중복 처리&lt;/td&gt;
        &lt;td&gt;단일 토폴로지 대비 중복 처리의 양이 감소함&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;&lt;span style=&quot;color:blue;&quot;&gt;bolt executor kill&lt;/span&gt;&lt;/td&gt;
        &lt;td&gt;전체 파티션 지연(60초)&lt;br/&gt;약 5초 데이터에 대해 0.4% 중복 처리&lt;/td&gt;
        &lt;td&gt;일부 파티션 지연(30~60초)&lt;br/&gt;약 10초 데이터에 대해 0.4% 중복 처리&lt;/td&gt;
        &lt;td&gt;단일 토폴로지 대비 큰 차이 없음&lt;/td&gt;
        &lt;/tr&gt;
        &lt;/tbody&gt;
        &lt;/table&gt;
        
        &lt;p&gt;이렇게 KafkaConsumer.assign을 subscribe로 변경하고, 커스텀 스케줄러를 구현하고, 비교적 최신 파티션 할당 전략인 sticky assignor를 적용하여 멀티 토폴로지를 도입했습니다. 다양한 장애 테스트 시 단일 토폴로지보다 파티션별 지연과 중복 처리 면에서 이점이 있었고, 특히 supervisor 다운 시 단일 토폴로지 대비 파티션 처리 지연이 감소하면서 중복 수준도 비슷한 수준으로 유지되었습니다.&lt;/p&gt;
        
        &lt;h3 id=&quot;&quot;&gt;데이터 처리 옵션과 클러스터 상태 개념 도입&lt;/h3&gt;
        
        &lt;p&gt;앞서 설명한 기존 로그 파이프라인의 문제점 중 단일 토폴로지 문제를 제외하면 다음 세 가지 문제점이 있었습니다.&lt;/p&gt;
        
        &lt;ul&gt;
        &lt;li&gt;&lt;strong&gt;낮과 새벽의 트래픽 차이&lt;/strong&gt;: 낮 시간의 트래픽 중 일부를 새벽에 처리할 수 있다면?&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;모든 로그의 공평한 처리&lt;/strong&gt;: 데이터의 중요도에 따라 차등 처리를 할 수 있다면?&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;장기 저장소와 실시간 검색을 위한 저장소에 모두 전달&lt;/strong&gt;: 각 저장소별로 정해진 비율만큼만 저장할 수 있는 기능이 있다면?&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;p&gt;각 문제점을 해결하기 위해 2가지 클러스터 상태 개념과 4가지 데이터 처리 옵션을 도입했습니다.&lt;/p&gt;
        
        &lt;table&gt;  
        &lt;thead&gt;
        &lt;tr&gt;
        &lt;th&gt;데이터 처리 옵션&lt;/th&gt;
        &lt;th&gt;클러스터 상태&lt;/th&gt;
        &lt;/tr&gt;
        &lt;/thead&gt;
        &lt;tbody&gt;
        &lt;tr&gt;
        &lt;td&gt;처리 중단 허용&lt;/td&gt;
        &lt;td&gt;backpressure&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;우선순위&lt;/td&gt;
        &lt;td&gt;mayday&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;실시간 보장 비율&lt;/td&gt;
        &lt;td&gt;&lt;br/&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;OpenSearch 샘플링 비율&lt;br/&gt;랜딩 존 샘플링 비율&lt;/td&gt;
        &lt;td&gt;&lt;br/&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;/tbody&gt;
        &lt;/table&gt;
        
        &lt;h4 id=&quot;backpressure&quot;&gt;처리 중단 허용, 실시간 보장 비율, backpressure를 활용한 비실시간 처리&lt;/h4&gt;
        
        &lt;p&gt;부하(backpressure) 기반 비실시간 처리의 목적은 트래픽 변화에 따라 낮 시간에 집중된 리소스 사용률을 한가한 시간대로 분산함으로써 피크 리소스 사용률을 낮춰 비용을 절감하는 것입니다.&lt;/p&gt;
        
        &lt;p&gt;동작 방식은 다음과 같습니다.&lt;/p&gt;
        
        &lt;ol&gt;
        &lt;li&gt;backpressure는 랜딩 존으로 흐르는 파이프라인과 OpenSearch로 흐르는 파이프라인의 부하 상태를 감지하여 활성화됩니다.  &lt;/li&gt;
        &lt;li&gt;backpressure가 활성화되면, 처리 중단을 허용한 데이터는 설정된 최대 처리 속도 대비 실시간 보장 비율만큼 실시간 처리하고, 나머지는 후처리를 위한 Post Kafka의 별도 토픽에 쌓습니다(Post Kafka 이후 파이프라인에서 낮 시간 부하가 감소할 것을 기대합니다).  &lt;/li&gt;
        &lt;li&gt;backpressure가 비활성화되면(주로 새벽 시간), 쌓인 토픽 데이터에 대해 설정된 최대 처리 속도의 두 배까지 후처리합니다(새벽 시간의 리소스 사용률이 높아지기를 기대합니다).&lt;/li&gt;
        &lt;/ol&gt;
        
        &lt;h4 id=&quot;mayday&quot;&gt;우선순위, 실시간 보장 비율, mayday를 활용한 데이터의 차등 처리&lt;/h4&gt;
        
        &lt;p&gt;비상(mayday 활성) 시 데이터 차등 처리의 목적은 로그별 우선순위를 설정하고 비상시 우선순위에 따라 차등 처리함으로써 서비스와 직결되어 중요도가 높은 로그의 지연을 최소화하고 상대적으로 중요도가 낮은 로그는 천천히 처리해 파이프라인 지연을 효율적으로 해소하는 것입니다.&lt;/p&gt;
        
        &lt;p&gt;Front Kafka와 Post Kafka의 컨슈머별 랙 오프셋을 주기적으로 모니터링하다가 일정 수치를 넘어가면 mayday가 활성화됩니다. 즉, 파이프라인 지연이 일정 수준을 넘으면 활성화됩니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/12/17.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;Front Kafka, Post Kafka의 컨슈머 랙 오프셋을 모니터링해 일정 수치를 넘어가면 mayday 활성화&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;mayday가 활성화되면, 각 데이터는 우선순위와 실시간 보장 비율에 따라 다음과 같이 처리됩니다.&lt;/p&gt;
        
        &lt;table&gt;  
        &lt;thead&gt;
        &lt;tr&gt;
        &lt;th&gt;우선순위&lt;/th&gt;
        &lt;th&gt;mayday 활성화 시 최대 처리 속도&lt;/th&gt;
        &lt;/tr&gt;
        &lt;/thead&gt;
        &lt;tbody&gt;
        &lt;tr&gt;
        &lt;td&gt;1&lt;/td&gt;
        &lt;td&gt;설정된 최대 처리 속도의 5배까지 처리&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;2&lt;/td&gt;
        &lt;td&gt;설정된 최대 처리 속도만큼 처리&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;3&lt;/td&gt;
        &lt;td&gt;설정된 최대 처리 속도 X 실시간 보장 비율 만큼만 실시간 처리&lt;br/&gt;예: 초당 1000개의 처리 속도, 50% 실시간 보장 → 초당 500개 처리 보장&lt;/td&gt;
        &lt;/tr&gt;
        &lt;/tbody&gt;
        &lt;/table&gt;
        
        &lt;p&gt;이렇게 비상시 데이터의 우선순위에 따라 차등 처리를 수행하고, 우선순위가 높은 데이터의 지연을 최소화하고자 했습니다.&lt;/p&gt;
        
        &lt;h4 id=&quot;&quot;&gt;저장소별 샘플링 비율을 이용한 샘플링 기능&lt;/h4&gt;
        
        &lt;p&gt;OpenSearch와 랜딩 존의 샘플링 비율(sample rate)을 각 데이터별로 설정할 수 있도록 하여, 각 저장소별 저장 비율을 제어할 수 있게 했습니다. 그 결과, 100% 저장이 필요 없는 데이터에 대해서는 전달받은 데이터 중 설정된 비율만큼만 저장해 저장소를 효율적으로 활용할 수 있습니다.&lt;/p&gt;
        
        &lt;h2 id=&quot;&quot;&gt;성과&lt;/h2&gt;
        
        &lt;h3 id=&quot;&quot;&gt;무중단, 점진적 배포 실현&lt;/h3&gt;
        
        &lt;p&gt;단일 토폴로지에서 멀티 토폴로지로 전환하면서 일부 파티션의 일시적 중단만 발생하게 되었고, 무중단에 가까운 점진적 배포가 가능해졌습니다. 그 결과, 일부 토폴로지만 변경된 상태로 유지할 수 있게 되어, 전체 토폴로지 업데이트 전 사이드 이펙트 파악과 롤백이 한층 쉬워졌습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/12/18.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;단일 토폴로지와 멀티 토폴로지 비교, 멀티 토폴로지의 롤링 리스타트&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;실제 토폴로지 롤링 리스타트 배포 시 Front Kafka의 파티션별 랙 오프셋 그래프는 다음과 같습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/12/19.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;멀티 토폴로지의 Traffic-Controller 롤링 리스타트 배포 시 Front Kafka의 파티션별 랙 오프셋&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;전체 파티션 중 일부 파티션의 랙 오프셋이 증가하는 부분은 각 토폴로지를 중단하고 처리를 재개하는 동안 일부 파티션의 일시적 지연이 발생하는 것을 의미합니다. 대부분 파티션의 랙 오프셋이 일정하게 유지되는 부분을 보면 다른 토폴로지의 처리는 일시적 중단도 없이 처리되는 것을 알 수 있습니다.&lt;/p&gt;
        
        &lt;p&gt;같은 시간에 Front Kafka 트래픽 in, out 속도는 다음과 같습니다(Front Kafka 트래픽의 out 속도 = Traffic-Controller의 소비 속도).&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/12/20.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;멀티 토폴로지의 Traffic-Controller 롤링 리스타트 배포 시 Front Kafka의 트래픽 in(왼쪽), out(오른쪽) 속도 비교&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;Front Kafka의 트래픽 in, out 속도가 대체로 같다는 것을 확인할 수 있습니다. 이는 토폴로지가 하나씩 배포(중단 → 처리 재개 반복)되는 과정에서 Traffic-Controller의 처리가 거의 지연 없이 이루어진다는 것을 의미합니다.&lt;/p&gt;
        
        &lt;h3 id=&quot;&quot;&gt;실시간/비실시간 처리의 분리&lt;/h3&gt;
        
        &lt;p&gt;처리 중단을 허용한 로그를 비실시간으로 처리할 수 있게 되어, 낮 시간 피크 트래픽을 한가한 시간으로 옮겨 처리할 수 있게 되었습니다.&lt;/p&gt;
        
        &lt;p&gt;backpressure 상태에 따라 처리 중단을 허용한 로그의 처리 양상은 다음과 같습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/12/21.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;처리 중단을 허용한 로그의 비실시간 처리&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;backpressure가 활성화되었을 때 약 35Kcps를 초과하는 트래픽은 후처리를 위해 쌓아 두고, backpressure가 해제되었을 때 쌓아 둔 트래픽을 처리하는 것을 확인할 수 있습니다.&lt;/p&gt;
        
        &lt;p&gt;비실시간 처리 전후로, 쌓아둔 데이터를 처리하는 Traffic-Controller의 retry 토폴로지의 bolt 처리량·사용률 변화를 살펴보면 다음과 같습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/12/22.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;비실시간 처리 전후의 Traffic-Controller의 retry 토폴로지의 bolt 처리량·사용률&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;처리 중단을 허용한 로그는 낮 시간에 backpressure가 활성화되면 실시간 보장 비율만큼만 실시간 처리하고 나머지는 후처리를 위해 쌓아 둡니다. 그리고 새벽 시간에 backpressure가 비활성화되면 최대 처리 속도의 두 배까지 후처리합니다. 이로 인해, 후처리를 담당하는 Traffic-Controller의 retry 토폴로지의 bolt 처리량과 사용률이 새벽 시간에 크게 증가한 것을 확인할 수 있습니다.&lt;/p&gt;
        
        &lt;h3 id=&quot;&quot;&gt;우선순위 기반 처리로 핵심 서비스 영향 최소화&lt;/h3&gt;
        
        &lt;p&gt;파이프라인을 개선한 이후 실제 장애 상황은 아직 경험하지 않았기 때문에, 장애 상황을 시뮬레이션한 결과를 공유합니다. 시뮬레이션 과정은 다음과 같습니다.&lt;/p&gt;
        
        &lt;p&gt;먼저, 다음 표와 같이 우선순위 1, 2, 3으로 지정된 네 가지 데이터를 준비했습니다. 우선순위가 3인 두 가지 데이터의 실시간 보장 비율은 각각 60%와 30%로 설정했습니다. 네 가지 데이터 모두 OpenSearch와 랜딩 존에 저장되도록 설정하고, 최대 처리 속도는 초당 1200개로 설정한 뒤 실제 로그 전송은 초당 1000개씩 발생시켰습니다.&lt;/p&gt;
        
        &lt;table&gt;  
        &lt;thead&gt;
        &lt;tr&gt;
        &lt;th&gt;우선순위&lt;/th&gt;
        &lt;th&gt;최대 처리 속도(초당 개수)&lt;/th&gt;
        &lt;th&gt;실제 전송 속도(초당 개수)&lt;/th&gt;
        &lt;th&gt;(mayday 발생 시) 실시간 보장 비율&lt;/th&gt;
        &lt;/tr&gt;
        &lt;/thead&gt;
        &lt;tbody&gt;
        &lt;tr&gt;
        &lt;td&gt;1&lt;/td&gt;
        &lt;td&gt;1200&lt;/td&gt;
        &lt;td&gt;1000&lt;/td&gt;
        &lt;td&gt;500%&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;2&lt;/td&gt;
        &lt;td&gt;1200&lt;/td&gt;
        &lt;td&gt;1000&lt;/td&gt;
        &lt;td&gt;100%&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;3&lt;/td&gt;
        &lt;td&gt;1200&lt;/td&gt;
        &lt;td&gt;1000&lt;/td&gt;
        &lt;td&gt;60%&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;3&lt;/td&gt;
        &lt;td&gt;1200&lt;/td&gt;
        &lt;td&gt;1000&lt;/td&gt;
        &lt;td&gt;30%&lt;/td&gt;
        &lt;/tr&gt;
        &lt;/tbody&gt;
        &lt;/table&gt;
        
        &lt;p&gt;위와 같이 15분 동안 로그를 전송한 후, 전송을 계속 유지한 상태에서 Traffic-Controller 중단 → Front Kafka의 컨슈머 오프셋을 10분 전으로 설정 → Traffic-Controller 재시작 작업을 수행해 mayday 상황을 모사했습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/12/23.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;mayday 상황 시뮬레이션에서 Front Kafka 랙&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;23시 55분경 Traffic-Controller를 중단한 뒤, 23시 56분경 컨슈머 오프셋을 10분 전으로 설정하는 순간 랙이 증가했고, 이후 23시 57분경 Traffic-Controller의 처리가 재개되면서 랙이 감소하는 것을 확인했습니다.&lt;/p&gt;
        
        &lt;p&gt;Traffic-Controller 중단하고 Front Kafka의 컨슈머 오프셋을 10분 전으로 설정하는 과정에서 곧바로 클러스터 상태인 mayday가 활성화되었고, Traffic-Controller 재시작과 동시에 각 데이터는 Traffic-Controller가 처리할 수 있는 최대 처리 속도(4.2Kcps)로 처리되기 시작했습니다.&lt;/p&gt;
        
        &lt;p&gt;이때, 실제 뒷단인 OpenSearch와 랜딩 존으로의 전송 속도는 우선순위에 따라 차등이 있었습니다. 우선순위가 낮은 데이터는 실시간 보장 비율만큼만 전달하고, 우선순위가 높은 데이터는 지연을 줄이고 가능한 한 실시간으로 처리하는 것을 확인했습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/12/24.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;mayday 상황에서 우선순위별 Traffic-Controller의 처리 속도(위), 우선순위별 실제 뒷단으로의 전송 속도(아래)&lt;/span&gt;&lt;/p&gt;
        
        &lt;h3 id=&quot;&quot;&gt;샘플링 기능으로 저장소 효율화&lt;/h3&gt;
        
        &lt;p&gt;저장소별로 샘플링 비율을 설정하는 기능을 제공함으로써 저장소를 효율적으로 이용할 수 있게 되었습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/12/25.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;OpenSearch 샘플링 비율 조정(8월 14일 오후) 전후의 OpenSearch 사용량(문서 수, 크기)&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;샘플링 비율을 조정한 후 실제로 저장소 사용량이 감소하는 것을 확인했습니다.(일마다 자정 이후에 문서 수와 크기가 급감하는 것은 Index State Management 정책에 의해 오래된 인덱스가 삭제되는 것과 관련이 있습니다.)&lt;/p&gt;
        
        &lt;h2 id=&quot;&quot;&gt;마치며&lt;/h2&gt;
        
        &lt;p&gt;storm-kafka-client 라이브러리를 수정하고 커스텀 스케줄러를 작성해, 단일 토폴로지로 운영하던 Storm의 토폴로지를 멀티 토폴로지로 변경했습니다. 그 결과 무중단, 점진적 배포가 가능해졌습니다.&lt;/p&gt;
        
        &lt;p&gt;또한 다양한 데이터 처리 옵션과 클러스터 상태 개념을 도입해 다음과 같은 문제점을 해결했습니다.&lt;/p&gt;
        
        &lt;ul&gt;
        &lt;li&gt;낮 시간에 집중된 트래픽을 한가한 시간에 처리&lt;/li&gt;
        &lt;li&gt;트래픽 지연 등 비상 상황에서 데이터의 우선순위에 따라 처리 속도에 차등을 두어, 우선순위가 높은 데이터의 지연을 최소화&lt;/li&gt;
        &lt;li&gt;저장소별 샘플링 비율 설정 기능을 제공해 저장소를 효율적으로 사용&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;h3 id=&quot;&quot;&gt;데이터 처리 옵션 변경의 필요성&lt;/h3&gt;
        
        &lt;p&gt;장비는 한정되어 있고, 새로 도입한 지능형 파이프라인이 비상시와 평시에 모두 효율적으로 동작하려면 데이터마다 적절한 처리 옵션을 지정해야 한다는 한계가 있습니다.&lt;/p&gt;
        
        &lt;p&gt;지능형 파이프라인 도입으로 기대하는 수준은 다음과 같습니다.&lt;/p&gt;
        
        &lt;ul&gt;
        &lt;li&gt;&lt;strong&gt;비실시간 처리&lt;/strong&gt;: 낮 시간의 피크 트래픽이 새벽으로 많이 옮겨져, 낮과 새벽에 처리되는 트래픽 규모가 비슷한 수준이 되기를 기대합니다.&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/12/26.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;낮 시간에 집중된 트래픽을 한가한 새벽 시간에 처리하는 이상적인 모습을 표현하는 애니메이션&lt;/span&gt;&lt;/p&gt;
        
        &lt;ul&gt;
        &lt;li&gt;&lt;strong&gt;비상시 우선순위 기반 처리&lt;/strong&gt;: 시뮬레이션 결과와 같이 우선순위가 높은 데이터의 지연이 최소화되기를 기대합니다.&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/12/27.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;span class=&quot;caption&quot;&gt;처리 지연 등의 mayday 상황에서 데이터가 우선순위별 차등 속도로 전송되는 이상적인 모습&lt;/span&gt;&lt;/p&gt;
        
        &lt;p&gt;비실시간 처리로 낮·새벽 시간의 트래픽 처리량이 비슷한 수준이 되려면 처리 중단을 허용한 로그가 충분히 많아야 하고, 비상시 우선순위 기반 처리가 적절히 수행되려면 데이터의 우선순위가 고르게 분포해야 한다는 한계가 있습니다.&lt;/p&gt;
        
        &lt;p&gt;그래서 사용자 데이터 특성에 맞게 데이터 처리 옵션을 잘 설정할 수 있도록 사내에 여러 가지 안내와 홍보를 진행할 예정입니다. 무분별한 우선순위 지정을 막기 위해, 우선순위는 로그 데이터가 서비스에 이용되는지(주요 지표 또는 실시간 학습·집계에 필요한 데이터) 여부 등을 고려해 로그 전송처와 운영자가 협의하여 결정합니다.&lt;/p&gt;
        
        &lt;h3 id=&quot;ai&quot;&gt;향후 계획 - AI 기반 클러스터 상태 전환&lt;/h3&gt;
        
        &lt;p&gt;현재는 지정된 임계값을 초과하거나 하회할 때 backpressure, mayday 등의 클러스터 상태가 변경됩니다. 이 방식은 임계값 근방에서 트래픽이나 지연이 유지되는 경우 상태가 너무 자주 변경될 수 있습니다.&lt;/p&gt;
        
        &lt;p&gt;또한 클러스터 규모가 변경되거나 클러스터마다 지연을 허용하는 수준이 달라지는 경우도 있습니다. 이 경우에는 운영자가 임계값을 직접 조정해야 합니다.&lt;/p&gt;
        
        &lt;p&gt;향후에는 사람의 개입 없이 트래픽과 지연 관련 시계열 데이터를 AI에게 학습시켜, 클러스터 상태를 AI가 스스로 판단하고 전환할 수 있도록 개선해 볼 계획입니다.&lt;/p&gt;
      </content:encoded>
    </item>
    <item>
      <title>[인턴십] 2026 NAVER AI CHALLENGE를 소개합니다.</title>
      <link>https://d2.naver.com/news/7477295</link>
      <guid>https://d2.naver.com/news/7477295</guid>
      <pubDate>Sun, 08 Feb 2026 08:02:45 GMT</pubDate>
      <content:encoded>
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/12/-----------2025-12-10------5-46-58.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;br/&gt;&lt;/p&gt;
        
        &lt;p&gt;네이버의 개발 문화와 함께 프로젝트 협업 방식을 체험할 수 있는 &lt;strong&gt;2026 NAVER AI CHALLENGE 인턴십 모집&lt;/strong&gt;을 시작했습니다.&lt;br/&gt;
        실무에서 다루는 AI 문제를 &lt;strong&gt;네이버의 현업 엔지니어와 함께 아이디어 설계 단계부터 기술적 방향성, 검증 과정까지 전 과정을 함께 학습하고 성장&lt;/strong&gt;할 수 있는 좋은 기회입니다. 원활한 협업과 멘토링을 위해 전용 좌석을 제공하며, 수행 기간 동안 프로젝트 활동비 및 최신 OA 장비도 지급됩니다.&lt;/p&gt;
        
        &lt;p&gt;학년, 전공 상관 없이 학/석사 재학생이면 누구나 지원할 수 있으니, 네이버와 AI 프로젝트에 관심 있는 분들은 모두 지원해보세요!&lt;/p&gt;
        
        &lt;ul&gt;
        &lt;li&gt;&lt;strong&gt;접수 기간&lt;/strong&gt;: 12.10(수) - 12.16(화) 오전 11시&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;서류 전형&lt;/strong&gt;: 12월 3주 - 12월 4주&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;직무 인터뷰&lt;/strong&gt;: 2026년 1월 1주 - 1월 2주&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;합격자 발표&lt;/strong&gt;: 2026년 1월 3주 중&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;인턴십 기간&lt;/strong&gt;: 1.19(월) - 2.13(금) / 4주&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;과제 안내&lt;/strong&gt; (아래 2개 과제 중 1개 과제 선택)
        &lt;ul&gt;&lt;li&gt;AI 기반 데이터 파이프라인 로그 분석을 통한 Data Asset 자동 매핑 및 End-to-End Data Lineage 구축 (&lt;a href=&quot;https://d2.naver.com/helloworld/5251464&quot;&gt;링크&lt;/a&gt;)&lt;/li&gt;
        &lt;li&gt;VLM 기반 사용자 경험 중심 검색/추천 품질 자동 평가 시스템 개발 (&lt;a href=&quot;https://naver.me/FXksegex&quot;&gt;링크&lt;/a&gt;)&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;h4 id=&quot;2026naveraichallengehttpsrecruitnavercorpcomrcrtviewdoannoid30004232swsubjobcdarrsyscompanycdarremptypecdarrenttypecdarrworkareacdarr&quot;&gt;&lt;a href=&quot;https://recruit.navercorp.com/rcrt/view.do?annoId=30004232&amp;amp;sw=&amp;amp;subJobCdArr=&amp;amp;sysCompanyCdArr=&amp;amp;empTypeCdArr=&amp;amp;entTypeCdArr=&amp;amp;workAreaCdArr=#&quot;&gt;&lt;strong&gt;&gt;&gt; 2026 NAVER AI CHALLENGE 세부내용 및 지원하기&lt;/strong&gt;&lt;/a&gt;&lt;/h4&gt;
      </content:encoded>
    </item>
    <item>
      <title>디자인시스템이 AI를 만났을 때: FE 개발 패러다임의 변화</title>
      <link>https://d2.naver.com/helloworld/3442203</link>
      <guid>https://d2.naver.com/helloworld/3442203</guid>
      <pubDate>Sun, 08 Feb 2026 08:02:45 GMT</pubDate>
      <content:encoded>
        &lt;p&gt;네이버 사내 기술 교류 행사인 NAVER ENGINEERING DAY 2025(10월)에서 발표되었던 세션을 공개합니다.&lt;br/&gt; &lt;/p&gt;
        
        &lt;div style=&quot;position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;&quot;&gt;
        
        &lt;iframe width=&quot;800&quot; height=&quot;450&quot; src=&quot;https://tv.naver.com/embed/89535060?autoPlay=true&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot; style=&quot;position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;&quot;&gt;&lt;/iframe&gt;  
        &lt;/div&gt;  
        
        &lt;p&gt;&lt;br/&gt;&lt;/p&gt;
        
        &lt;h4 id=&quot;&quot;&gt;발표 내용&lt;/h4&gt;
        
        &lt;p&gt;네이버파이낸셜 디자인시스템과 AI를 이용하여 마크업 자동화 작업에 대한 소소한 경험을 공유합니다.&lt;/p&gt;
        
        &lt;h4 id=&quot;&quot;&gt;발표 대상&lt;/h4&gt;
        
        &lt;p&gt;AI를 이용한 마크업 등 디자인 작업관련 관심 있으신 모든 분들&lt;/p&gt;
        
        &lt;h4 id=&quot;&quot;&gt;목차&lt;/h4&gt;
        
        &lt;ul&gt;
        &lt;li&gt;오늘 이야기의 키워드&lt;/li&gt;
        &lt;li&gt;知彼知己
        &lt;ul&gt;&lt;li&gt;네이버파이낸셜 디자인시스템
        &lt;ul&gt;&lt;li&gt;디자인 토큰&lt;/li&gt;
        &lt;li&gt;디자인 시스템 컴포넌트&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
        &lt;li&gt;우리를 도와 줄 AI 는?&lt;/li&gt;
        &lt;li&gt;百戰不殆&lt;/li&gt;
        &lt;li&gt;Let&apos;s Try&lt;/li&gt;
        &lt;li&gt;마크업 작업을 위한 사전 준비
        &lt;ul&gt;&lt;li&gt;디자인시스템 Code Connect&lt;/li&gt;
        &lt;li&gt;디자인시스템 instruction&lt;/li&gt;
        &lt;li&gt;이제 FE 개발 시작해도 될 마크업, 하지만 아쉬웠던 점&lt;/li&gt;
        &lt;li&gt;그 외로 힘들었던 점&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
        &lt;li&gt;현실 개발에서는 어떻게 해야하는가?&lt;/li&gt;
        &lt;li&gt;마크업 직업 개발했더니 어떠니?&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;blockquote&gt;
        &lt;h5 id=&quot;naverengineeringdaybr&quot;&gt;&lt;strong&gt;◎ NAVER ENGINEERING DAY란?&lt;/strong&gt;&lt;br/&gt;&lt;/h5&gt;
        
        &lt;p&gt;NAVER에서는 사내 개발 경험과 기술 트렌드를 교류를 할 수 있는 프로그램이 많이 있습니다. 그중 매회 평균 70개 이상의 발표가 이루어지는 NAVER ENGINEERING DAY를 빼놓을 수 없는데요. &lt;br /&gt;
        2016년부터 시작된 ENGINEERING DAY는 실무에서의 기술 개발 경험과 새로운 기술과 플랫폼 도입 시 유용하게 활용될 수 있는 팁 등을 공유하며 서로 배우고 성장하는 네이버의 대표적인 사내 개발자 행사입니다. &lt;br /&gt;
        올해 진행된 NAVER ENGINEERING DAY의 일부 세션을 공개합니다.&lt;/p&gt;
        &lt;/blockquote&gt;
      </content:encoded>
    </item>
    <item>
      <title>LLM이지만 PDF는 읽고 싶어: 복잡한 PDF를 LLM이 이해하는 방법</title>
      <link>https://d2.naver.com/helloworld/9036125</link>
      <guid>https://d2.naver.com/helloworld/9036125</guid>
      <pubDate>Sun, 08 Feb 2026 08:02:45 GMT</pubDate>
      <content:encoded>
        &lt;p&gt;네이버 사내 기술 교류 행사인 NAVER ENGINEERING DAY 2025(10월)에서 발표되었던 세션을 공개합니다.&lt;br/&gt; &lt;/p&gt;
        
        &lt;div style=&quot;position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;&quot;&gt;
        
        &lt;iframe width=&quot;800&quot; height=&quot;450&quot; src=&quot;https://tv.naver.com/embed/89639975?autoPlay=true&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot; style=&quot;position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;&quot;&gt;&lt;/iframe&gt;  
        &lt;/div&gt;  
        
        &lt;p&gt;&lt;br/&gt;&lt;/p&gt;
        
        &lt;h4 id=&quot;&quot;&gt;발표 내용&lt;/h4&gt;
        
        &lt;p&gt;LLM-friendly PDF parser PaLADIN을 소개합니다.&lt;/p&gt;
        
        &lt;h4 id=&quot;&quot;&gt;발표 대상&lt;/h4&gt;
        
        &lt;ul&gt;
        &lt;li&gt;AI/LLM을 적극적으로 활용하고 싶으신 분&lt;/li&gt;
        &lt;li&gt;문서 처리에 관심이 있으신 분&lt;/li&gt;
        &lt;li&gt;웹검색에 관심이 있으신 분&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;h4 id=&quot;&quot;&gt;목차&lt;/h4&gt;
        
        &lt;ol&gt;
        &lt;li&gt;PDF가 왜 중요한가요? &lt;br /&gt;
        &lt;ul&gt;&lt;li&gt;LLM-friendly PDF Parser&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
        &lt;li&gt;기술 탐색 및 PoC (with NVIDIA) &lt;br /&gt;
        &lt;ul&gt;&lt;li&gt;관련 기술 탐색&lt;/li&gt;
        &lt;li&gt;PoC with NVIDIA&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
        &lt;li&gt;PaLADIN: 표와 차트, 숫자를 정확히 이해하고 표현하는 LLM-friendly PDF Parser &lt;br /&gt;
        &lt;ul&gt;&lt;li&gt;아키텍쳐 설계 - nv-ingest&lt;/li&gt;
        &lt;li&gt;아키텍쳐 설계 - PaLADIN&lt;/li&gt;
        &lt;li&gt;Model 소개 - Element-Detector: Doclayout-Yolo&lt;/li&gt;
        &lt;li&gt;Model 소개 - Table-Extractor: nemoretriever-table-structure-v1&lt;/li&gt;
        &lt;li&gt;Model 소개 - Chart-Extractor: google/gemma3-27b-it&lt;/li&gt;
        &lt;li&gt;Model 소개 - Papago OCR&lt;/li&gt;
        &lt;li&gt;PDF parsing 예제&lt;/li&gt;
        &lt;li&gt;속도 개선 및 최적화&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
        &lt;li&gt;성능 평가 &lt;br /&gt;
        &lt;ul&gt;&lt;li&gt;Parsing 평가셋 구축&lt;/li&gt;
        &lt;li&gt;Parsing 능력 평가&lt;/li&gt;
        &lt;li&gt;속도 측정&lt;/li&gt;
        &lt;li&gt;성능 비교&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
        &lt;li&gt;서비스 적용 사례: AIB 증권사 리포트 &lt;br /&gt;
        &lt;ul&gt;&lt;li&gt;서비스 적용 예시&lt;/li&gt;
        &lt;li&gt;Summary 모델 선정: LLM as a judge&lt;/li&gt;
        &lt;li&gt;Summary 예시&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
        &lt;li&gt;Future Works &lt;br /&gt;
        &lt;ul&gt;&lt;li&gt;Table Cell 좌표 오류 개선&lt;/li&gt;
        &lt;li&gt;차트 정확도 개선&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
        &lt;/ol&gt;
        
        &lt;blockquote&gt;
        &lt;h5 id=&quot;naverengineeringdaybr&quot;&gt;&lt;strong&gt;◎ NAVER ENGINEERING DAY란?&lt;/strong&gt;&lt;br/&gt;&lt;/h5&gt;
        
        &lt;p&gt;NAVER에서는 사내 개발 경험과 기술 트렌드를 교류를 할 수 있는 프로그램이 많이 있습니다. 그중 매회 평균 70개 이상의 발표가 이루어지는 NAVER ENGINEERING DAY를 빼놓을 수 없는데요. &lt;br /&gt;
        2016년부터 시작된 ENGINEERING DAY는 실무에서의 기술 개발 경험과 새로운 기술과 플랫폼 도입 시 유용하게 활용될 수 있는 팁 등을 공유하며 서로 배우고 성장하는 네이버의 대표적인 사내 개발자 행사입니다. &lt;br /&gt;
        올해 진행된 NAVER ENGINEERING DAY의 일부 세션을 공개합니다.&lt;/p&gt;
        &lt;/blockquote&gt;
      </content:encoded>
    </item>
    <item>
      <title>VLOps:Event-driven MLOps &amp; Omni-Evaluator</title>
      <link>https://d2.naver.com/helloworld/0931890</link>
      <guid>https://d2.naver.com/helloworld/0931890</guid>
      <pubDate>Sun, 08 Feb 2026 08:02:45 GMT</pubDate>
      <content:encoded>
        &lt;p&gt;네이버 사내 기술 교류 행사인 NAVER ENGINEERING DAY 2025(10월)에서 발표되었던 세션을 공개합니다.&lt;br/&gt; &lt;/p&gt;
        
        &lt;div style=&quot;position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;&quot;&gt;
        
        &lt;iframe width=&quot;800&quot; height=&quot;450&quot; src=&quot;https://tv.naver.com/embed/89568623?autoPlay=true&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot; style=&quot;position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;&quot;&gt;&lt;/iframe&gt;  
        &lt;/div&gt;  
        
        &lt;p&gt;&lt;br/&gt;&lt;/p&gt;
        
        &lt;h4 id=&quot;&quot;&gt;발표 내용&lt;/h4&gt;
        
        &lt;ul&gt;
        &lt;li&gt;Event-driven MLOps는 학습·평가·배포를 Typed Message 단위로 정의하고, Event Sensor가 이를 감지해 자율적으로 실행하는 구조입니다.&lt;/li&gt;
        &lt;li&gt;Kubeflow 같은 파이프라인처럼 전체 버전 관리가 필요하지 않으며, 메시지를 추가하는 것만으로 기능 확장이 가능합니다.&lt;/li&gt;
        &lt;li&gt;사용자는 내부 오케스트레이션을 몰라도 메시지 발행만으로 동일한 파이프라인을 구동할 수 있습니다.&lt;/li&gt;
        &lt;li&gt;이를 통해 평가·배포 시스템 간 느슨한 결합(Loose Coupling)과 클라우드 간 호환성을 확보했습니다.&lt;/li&gt;
        &lt;li&gt;Omni-Evaluator와 Dashboard는 다양한 엔진·벤치마크를 통합하고, 실시간 모니터링과 사용자 주도 트리거 기능을 제공합니다.&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;h4 id=&quot;&quot;&gt;발표 대상&lt;/h4&gt;
        
        &lt;ul&gt;
        &lt;li&gt;MLOps 엔지니어, ML 리서처, 데이터 사이언티스트&lt;/li&gt;
        &lt;li&gt;클라우드 인프라/DevOps 개발자, 모델 배포 및 평가 담당자&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;h4 id=&quot;&quot;&gt;목차&lt;/h4&gt;
        
        &lt;ol&gt;
        &lt;li&gt;MLOps가 필요한 이유  &lt;/li&gt;
        &lt;li&gt;Event-driven MLOps의 등장  &lt;/li&gt;
        &lt;li&gt;Event Sensor: 핵심 로직  &lt;/li&gt;
        &lt;li&gt;EvalOps에서 Omni-Evaluator로  &lt;/li&gt;
        &lt;li&gt;VLOps Dashboard: 사용자 경험의 허브  &lt;/li&gt;
        &lt;li&gt;결론 및 비전&lt;/li&gt;
        &lt;/ol&gt;
        
        &lt;blockquote&gt;
        &lt;h5 id=&quot;naverengineeringdaybr&quot;&gt;&lt;strong&gt;◎ NAVER ENGINEERING DAY란?&lt;/strong&gt;&lt;br/&gt;&lt;/h5&gt;
        
        &lt;p&gt;NAVER에서는 사내 개발 경험과 기술 트렌드를 교류를 할 수 있는 프로그램이 많이 있습니다. 그중 매회 평균 70개 이상의 발표가 이루어지는 NAVER ENGINEERING DAY를 빼놓을 수 없는데요. &lt;br /&gt;
        2016년부터 시작된 ENGINEERING DAY는 실무에서의 기술 개발 경험과 새로운 기술과 플랫폼 도입 시 유용하게 활용될 수 있는 팁 등을 공유하며 서로 배우고 성장하는 네이버의 대표적인 사내 개발자 행사입니다. &lt;br /&gt;
        올해 진행된 NAVER ENGINEERING DAY의 일부 세션을 공개합니다.&lt;/p&gt;
        &lt;/blockquote&gt;
      </content:encoded>
    </item>
    <item>
      <title>FE News 25년 12월 소식을 전해드립니다!</title>
      <link>https://d2.naver.com/news/3740852</link>
      <guid>https://d2.naver.com/news/3740852</guid>
      <pubDate>Sun, 08 Feb 2026 08:02:45 GMT</pubDate>
      <content:encoded>
        &lt;p&gt;&lt;img src=https://d2.naver.com/content/images/2023/07/-----------2023-07-06------4-16-49.png&gt;&lt;/p&gt;
        
        &lt;h2 id=&quot;&quot;&gt;주요소식&lt;/h2&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/12/image-2025-12-3_10-45-38.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;다음과 같은 유용한 정보들을 만나보실 수 있습니다.&lt;/p&gt;
        
        &lt;h4 id=&quot;wasmdoesnotstandforwebassembly&quot;&gt;Wasm Does Not Stand for WebAssembly&lt;/h4&gt;
        
        &lt;p&gt;WebAssembly라는 이름 때문에 많은 개발자들이 Wasm을 웹 기술이자 어셈블리 언어로 오해한다. 하지만 웹 어셈블리는 웹만을 위한 기술도 아니고 어셈블리도 아니다. WebAssembly라는 이름은 프로젝트 펀딩을 위한 네이밍이었다. Wasm은 가상 머신에서 실행되는 바이트코드로, JVM이나 .NET 바이트코드와 더 유사하다.&lt;/p&gt;
        
        &lt;h4 id=&quot;llmreact&quot;&gt;LLM 시대, React의 자기 강화 피드백 루프&lt;/h4&gt;
        
        &lt;p&gt;LLM 훈련 데이터와 개발자 출력 사이의 피드백 루프로 React가 사실상 플랫폼이 되었다. 지난 12개월간 1,300만 개 이상의 React 사이트가 배포되었으며, Replit과 Bolt 같은 LLM 도구들은 시스템 프롬프트에 React를 명시적으로 하드코딩한다. 새로운 프레임워크가 성공하려면 LLM 훈련 데이터 포함부터 시작해야 하는데, 이는 최소 12~18개월이 소요되며 그 사이 React는 또다시 천만 개 이상의 사이트를 생성한다. 이것이 바로 &quot;dead framework theory&quot;다.&lt;/p&gt;
        
        &lt;h4 id=&quot;vercel&quot;&gt;Vercel이 재정의하는 프로그래밍 언어의 미래&lt;/h4&gt;
        
        &lt;p&gt;Vercel은 Server Actions, &apos;use cache&apos;, &apos;use workflow&apos; 같은 디렉티브를 통해 분산 시스템의 복잡성을 언어 레벨에서 관리하려는 비전을 보여준다. 직렬화 가능한 클로저, 대수적 효과, 점진적 계산이라는 세 가지 핵심 개념 위에 구축된 이 기능들은 단순한 라이브러리가 아닌 새로운 언어 구조처럼 작동한다. 프로그래밍 언어가 어셈블리에서 동시성까지 진화해온 것처럼, 다음 단계는 데이터 관리와 분산 시스템의 복잡성을 네이티브로 다루는 것이다.&lt;/p&gt;
        
        &lt;h4 id=&quot;&quot;&gt;브라우저가 프레임워크를 대체하기 시작했다&lt;/h4&gt;
        
        &lt;p&gt;최근 10년간 프런트엔드 개발의 가장 큰 변화는 Shadow DOM, ES 모듈, Navigation API, View Transitions API 등 네이티브 웹 플랫폼 기능들이 프레임워크 핵심 기능을 대체하기 시작했다는 점이다. 라우팅, 상태 관리, 컴포넌트 격리 등 프레임워크가 제공하던 기능이 이제 브라우저 표준으로 자리잡으면서, 무거운 번들과 복잡한 추상화 없이도 고성능 애플리케이션 구축이 가능해졌다. 프레임워크는 여전히 가치를 제공하지만, 이제는 필수가 아닌 의 영역으로 이동하고 있다.&lt;/p&gt;
        
        &lt;h4 id=&quot;llmcouncilai&quot;&gt;LLM Council: 집단 지성을 구현한 AI 의사결정 시스템&lt;/h4&gt;
        
        &lt;p&gt;Andrej Karpathy가 개발한 LLM Council은 여러 AI 모델이 민주적으로 협업하여 복잡한 문제를 해결하는 로컬 웹 애플리케이션이다. 독립적 의견 제시 → 상호 검토 및 순위 매김 → 의장 LLM의 최종 종합이라는 3단계 프로세스를 통해, 단일 모델의 한계를 극복하고 더 신뢰할 수 있는 답변을 생성한다. OpenRouter API로 GPT-5.1, Gemini 3 Pro, Claude Sonnet 4.5, Grok 4 등 다양한 최신 모델을 동시에 활용할 수 있으며, Python(FastAPI)과 React + Vite 기반으로 간편하게 로컬 환경에서 실행 가능하다. 이는 LLM 활용의 새로운 패러다임으로, 각 모델의 강점을 결합하고 약점을 보완하는 집단 지성 접근법을 제시한다.&lt;/p&gt;
        
        &lt;h2 id=&quot;fenews2512httpsgithubcomnaverfenewsblobmasterissues202512md&quot;&gt;&lt;a href=&quot;https://github.com/naver/fe-news/blob/master/issues/2025-12.md&quot;&gt;&gt;&gt; FE News 25년 12월 소식 보러가기&lt;/a&gt;&lt;/h2&gt;
        
        &lt;p&gt;&lt;br/&gt;  &lt;/p&gt;
        
        &lt;blockquote&gt;
        &lt;p&gt;&lt;strong&gt;◎ FE News란?&lt;/strong&gt;&lt;br/&gt;
        네이버 FE 엔지니어들이 엄선한 양질의 FE 및 주요한 기술 소식들을 큐레이션해 공유하는 것을 목표로 하며, 이를 통해 국내 개발자들에게 지식 공유에 대한 가치 인식과 성장에 도움을 주고자 하는 기술소식 공유 프로젝트 입니다.&lt;/p&gt;
        
        &lt;p&gt;매월 첫째 주 수요일, 월 1회 발행 되고 있으니 많은 관심 부탁드립니다.&lt;br/&gt;
        &lt;a href=&quot;https://fenews.substack.com/embed&quot;&gt;▷ 구독하기&lt;/a&gt;&lt;/p&gt;
        &lt;/blockquote&gt;
      </content:encoded>
    </item>
    <item>
      <title>사용자의 목소리를 AI로 재현하다: LLM기반 Multi Agent UX플랫폼 개발기</title>
      <link>https://d2.naver.com/helloworld/2678553</link>
      <guid>https://d2.naver.com/helloworld/2678553</guid>
      <pubDate>Sun, 08 Feb 2026 08:02:45 GMT</pubDate>
      <content:encoded>
        &lt;p&gt;네이버 사내 기술 교류 행사인 NAVER ENGINEERING DAY 2025(10월)에서 발표되었던 세션을 공개합니다.&lt;br/&gt; 
        해당 발표는 &lt;a href=&quot;https://dan.naver.com/25/sessions/699&quot;&gt;팀네이버 컨퍼런스 DAN25 홈페이지&lt;/a&gt;에서도 살펴보실 수 있습니다.&lt;/p&gt;
        
        &lt;div style=&quot;position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;&quot;&gt;
        
        &lt;iframe width=&quot;800&quot; height=&quot;450&quot; src=&quot;https://tv.naver.com/embed/89560941?autoPlay=true&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot; style=&quot;position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;&quot;&gt;&lt;/iframe&gt;  
        &lt;/div&gt;  
        
        &lt;p&gt;&lt;br/&gt;&lt;/p&gt;
        
        &lt;h4 id=&quot;&quot;&gt;발표 내용&lt;/h4&gt;
        
        &lt;p&gt;“사용자에 진심인 3명이 모여, Persona가 말하게 만들다”&lt;br/&gt;
        이 세션은 잘 만든 AI 시스템을. 넘어, 디자이너·AI 리서처·개발자가 경험한 AI 시대의 협업 가능성을 제안합니다.
        사용자 페르소나봇 NSona의 기획부터 구현, 평가까지 전 과정을 공유합니다. AI로 사용자 리서치 데이터를 실시간 협업 자원으로 전환하며, Multi-Party 대화 시스템에서 사용자와 함께 일하는 방식을 실험했습니다.&lt;br/&gt;
        세 명은 함께 AI를 만들며 역할과 협업 구조가 바뀌는 경험을 했습니다. 디자이너는 프롬프트를 설계하고, 리서처는 로직을 에이전트 구조로 바꾸었으며, 프론트 개발자는 AI를 비평 대상으로 다뤘습니다. 중요한 건 ‘어디까지 만들었느냐’가 아니라 ‘어디서 시작점을 찍느냐’임을 깨달았습니다.&lt;br/&gt;
        참석자분들께서 창의적, 기술적 인사이트와 함께 자신만의 AI 협업 모델을 고민할 수 있는 영감을 얻을 수 있기를 기대합니다.&lt;/p&gt;
        
        &lt;h4 id=&quot;&quot;&gt;발표 대상&lt;/h4&gt;
        
        &lt;p&gt;디자이너 / 개발자 / 기획자 / PM&lt;br/&gt;&lt;/p&gt;
        
        &lt;ul&gt;
        &lt;li&gt;사용자 조사-서비스개발 사이의 간극을 줄이는법에 관심있는 분&lt;/li&gt;
        &lt;li&gt;사용자를 재현한 페르소나봇을 기획하고 개발한 사례에 관심 있는 분&lt;/li&gt;
        &lt;li&gt;Multi-Party 대화 기반 서비스 구조에 관심 있는 분&lt;/li&gt;
        &lt;li&gt;서비스 사용 목적에 기반한 새로운 모델 품질 평가 방식이 궁금한 분&lt;/li&gt;
        &lt;li&gt;AI시대의 새로운 협업 모델의 영감을 얻고싶으신 분&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;h4 id=&quot;&quot;&gt;목차&lt;/h4&gt;
        
        &lt;ol&gt;
        &lt;li&gt;아이디어란 반짝이는 빛이 아닌, 빛을 잃지 않게 하는 힘이다 &lt;br /&gt;
        &lt;ul&gt;&lt;li&gt;AI 시대, 아이디어의 현실화를 위한 우리의 저지름&lt;/li&gt;
        &lt;li&gt;최소인원 × 빠른실행&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
        &lt;li&gt;Idea: AI 사용자를 Daily협업으로 끌어들이다 &lt;br /&gt;
        &lt;ul&gt;&lt;li&gt;기존 UX리서치의 한계&lt;/li&gt;
        &lt;li&gt;사용자 페르소나 봇 “NSona” 개발&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
        &lt;li&gt;Engineering: 페르소나 - AI 모델 서비스 개발과 UX 실현의 사이에서 &lt;br /&gt;
        &lt;ul&gt;&lt;li&gt;서비스 개발 관점에서 본 UX 요구사항과 기술적 Challenges&lt;/li&gt;
        &lt;li&gt;NSona만 기술적 특징: Agent 중심의 서비스 구조 설계와 UX 중심의 Service-specific 평가 프로세스 구축&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
        &lt;li&gt;Evaluation: 사용자를 생생히 재현하여 몰입을 일으키다 &lt;br /&gt;
        &lt;ul&gt;&lt;li&gt;UX관점에서 새롭게 구축한 모델 평가 과정&lt;/li&gt;
        &lt;li&gt;NSona 평가결과와 인사이트&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
        &lt;li&gt;Collaboration: 선이 아닌 점으로 &lt;br /&gt;
        &lt;ul&gt;&lt;li&gt;RNR은 더 이상 경계가 아니다. 중심에서 퍼지는 파장이다.&lt;/li&gt;
        &lt;li&gt;익숙하고 아늑한 틀을 넘어, AI와 함께 찍은 새로운 시작점&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
        &lt;/ol&gt;
        
        &lt;blockquote&gt;
        &lt;h5 id=&quot;naverengineeringdaybr&quot;&gt;&lt;strong&gt;◎ NAVER ENGINEERING DAY란?&lt;/strong&gt;&lt;br/&gt;&lt;/h5&gt;
        
        &lt;p&gt;NAVER에서는 사내 개발 경험과 기술 트렌드를 교류를 할 수 있는 프로그램이 많이 있습니다. 그중 매회 평균 70개 이상의 발표가 이루어지는 NAVER ENGINEERING DAY를 빼놓을 수 없는데요. &lt;br /&gt;
        2016년부터 시작된 ENGINEERING DAY는 실무에서의 기술 개발 경험과 새로운 기술과 플랫폼 도입 시 유용하게 활용될 수 있는 팁 등을 공유하며 서로 배우고 성장하는 네이버의 대표적인 사내 개발자 행사입니다. &lt;br /&gt;
        올해 진행된 NAVER ENGINEERING DAY의 일부 세션을 공개합니다.&lt;/p&gt;
        &lt;/blockquote&gt;
      </content:encoded>
    </item>
    <item>
      <title>웹툰 창작 생태계 보호를 위한 연구</title>
      <link>https://d2.naver.com/helloworld/4571155</link>
      <guid>https://d2.naver.com/helloworld/4571155</guid>
      <pubDate>Sun, 08 Feb 2026 08:02:45 GMT</pubDate>
      <content:encoded>
        &lt;p&gt;네이버 웹툰은 웹툰, 웹소설 등 다양한 창작물을 독자에게 제공하는 플랫폼을 구축하고, 이를 통해 창작자가 전 세계 독자와 만나 소통하며 안정적인 수익을 바탕으로 창작 활동에 온전히 집중할 수 있는 환경을 만들기 위해 노력하고 있습니다. 특히 하나의 스토리를 다양한 IP(intellectual property)로 확장해 글로벌 시장의 규모를 지속적으로 키우고 있으며, 창작자와 독자, 플랫폼이 상생하며 지속 가능한 가치를 창출하는 디지털 창작 생태계를 만들어 나가는 데 주력하고 있습니다.&lt;/p&gt;
        
        &lt;p&gt;하지만 창작 생태계가 활성화되고 성장할수록 이를 훼손하는 위협도 심화되고 있습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/09/e0cc9cda-5be6-4951-b42e-5e1985d2aa86.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;ul&gt;
        &lt;li&gt;&lt;p&gt;&lt;strong&gt;콘텐츠 불법 유출&lt;/strong&gt;: 저작권자의 허가 없이 디지털 콘텐츠를 무단으로 복제, 배포 또는 공유하는 행위로, 창작자의 정당한 수익을 침해할 뿐만 아니라 플랫폼의 신뢰성과 비즈니스 모델 자체를 훼손할 수 있습니다. 이로 인해 저작권자의 경제적 손실과 더불어 창작 생태계 위기가 초래될 수 있습니다.&lt;/p&gt;&lt;/li&gt;
        &lt;li&gt;&lt;p&gt;&lt;strong&gt;생성형 AI의 무단 학습&lt;/strong&gt;: 최근 생성형 AI(generative AI)의 급격한 발전과 더불어, 타인의 저작물을 허가 없이 AI 모델 학습에 사용하는 행위가 증가하고 있습니다. 비허가 샘플을 기반으로 무단 학습(파인튜닝)해 2차 저작물을 생성하거나, 원작의 콘셉트와 스타일을 벗어난 이미지를 만들어낼 수 있습니다. 이는 결과적으로 원저작물의 고유한 가치와 정체성을 왜곡하고 저작권 침해 문제를 더욱 확산시킬 우려가 있어, 해당 악용 사례에 대한 적극적인 대응이 필요한 상황입니다.&lt;/p&gt;&lt;/li&gt;
        &lt;li&gt;&lt;p&gt;&lt;strong&gt;유해 콘텐츠 업로드&lt;/strong&gt;: 플랫폼 내 사용자 생성 콘텐츠(UGC) 공간에 선정적이거나 폭력적인 콘텐츠가 무분별하게 업로드되는 경우에는 플랫폼의 건전성을 저하하고 대외 신뢰도를 떨어뜨릴 수 있습니다. 또한, 검수 및 운영에 소요되는 리소스가 과도하게 증가해 궁극적으로 이용자의 서비스 경험에 부정적인 영향을 미칩니다.&lt;/p&gt;&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;p&gt;이와 같이 창작 생태계의 건전한 순환 구조를 훼손하고, 경제적 손실, 저작권 침해, 운영 비용 증가 등의 리스크를 야기하는 위협으로부터 창작 생태계를 보호하기 위해 더욱 체계적이고 적극적인 기술이 필요합니다. 네이버 웹툰은 창작 생태계 보호를 위해 자체 설루션 연구 및 개발을 지속해왔으며, 대표적으로 다음과 같은 체계를 구축했습니다.&lt;/p&gt;
        
        &lt;ul&gt;
        &lt;li&gt;&lt;p&gt;&lt;strong&gt;TOONRADAR&lt;/strong&gt;: 불법 유출자를 추적하고 차단하는 기술로, 사전 차단과 사후 추적의 핵심 기능으로 구성되어 있습니다. 특히 사후 추적을 위해 육안으로는 식별이 불가능한 미세 신호를 콘텐츠 내부에 삽입하는 워터마킹 기술을 적용해 최초 유출 경로를 명확하게 식별합니다.&lt;/p&gt;&lt;/li&gt;
        &lt;li&gt;&lt;p&gt;&lt;strong&gt;IMPASTO&lt;/strong&gt;: 생성형 AI 무단 학습에 의한 저작권 침해에 대응하기 위한 학습 방지 기술로, 원본 이미지에 보호 왜곡(protective perturbation) 신호를 삽입해, 생성형 AI 모델이 이를 무단으로 학습하면 생성 결과가 의도대로 나오지 않도록 유도합니다.&lt;/p&gt;&lt;/li&gt;
        &lt;li&gt;&lt;p&gt;&lt;strong&gt;XPIDER&lt;/strong&gt;: UGC 공간 내 유해 콘텐츠 자동 탐지 및 차단 기술로, 특히 실사 도메인과는 다른 특성을 가진 만화 도메인에도 효과적으로 대응할 수 있도록 설계되었습니다. 이를 통해 플랫폼 운영에 필요한 검수 리소스를 대폭 절감하고, 사용자에게 안전하고 쾌적한 콘텐츠 경험을 제공합니다.&lt;/p&gt;&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/09/dabb86e8-9858-427f-aa07-15d4b2834757.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;이 글에서는 창작 생태계 보호를 위한 연구 중에서도 특히 저작권 보호를 목적으로 도입된 &lt;strong&gt;워터마킹&lt;/strong&gt;(TOONRADAR에서 사후 추적 용도로 활용)과 &lt;strong&gt;학습 방지 기술&lt;/strong&gt;(비가시성과 처리 속도에 특화된 IMPASTO의 두 가지 버전)을 소개하고자 합니다. 이 두 기술은 원본 콘텐츠에 미세한 수준의 변형을 적용함으로써 저작권 보호 효과를 달성하는 방식이라는 공통 특성이 있습니다.&lt;/p&gt;
        
        &lt;h2 id=&quot;&quot;&gt;워터마킹&lt;/h2&gt;
        
        &lt;p&gt;워터마킹은 원본 디지털 이미지의 픽셀 값에 비가시적 식별 신호(워터마크)를 삽입하고 콘텐츠 유출 시 해당 신호를 추출해 불법 유통 경로를 추적함으로써 저작권을 효과적으로 보호하는 기술입니다. 이 방식은 DRM(디지털 저작권 관리) 시스템과 달리, &lt;strong&gt;DRM-free 환경에서의 사후 추적&lt;/strong&gt;이 가능하다는 특징이 있습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/09/4b18ed8a-5648-41f5-a3c5-6a7dd0e65259.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;
        
        &lt;h3 id=&quot;&quot;&gt;요구 사항&lt;/h3&gt;
        
        &lt;p&gt;워터마킹 시스템은 불법 유통 경로 추적 과정에서 성공적으로 콘텐츠에 정보를 삽입하고 추출하면서, 이용자의 서비스 경험에는 영향을 주지 않아야 합니다. 따라서 실효성 있는 시스템 구현을 위해서는 다음 세 가지 요구 사항을 충족해야 합니다.&lt;/p&gt;
        
        &lt;ul&gt;
        &lt;li&gt;&lt;strong&gt;비가시성&lt;/strong&gt;(invisibility): 워터마크 삽입으로 인한 왜곡이 사람의 눈으로 잘 구분되지 않아야 함. 원본 이미지와 워터마크를 삽입한 이미지 간의 유사도(PSNR, SSIM 등)로 평가.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;강인성&lt;/strong&gt;(robustness): 신호 처리 공격, 기하학적 공격이 가해진 이후에도 워터마크가 정상적으로 추출되어야 함. 원본 워터마크와 공격 이후 추출된 워터마크 간의 오류율로 평가.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;삽입량&lt;/strong&gt;(capacity): 워터마크를 삽입함으로써 확보할 수 있는 정보량으로, 사후 추적이 가능하도록 충분한 정보량이 워터마크에 삽입되어야 함. 추출 성능을 일정 수준 유지하면서 삽입할 수 있는 정보가 많을수록 우수하다고 평가.&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/09/49af4fbb-5a93-445a-8150-1355af119c50.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;웹툰 도메인에서 워터마킹 기법의 적용 가능성을 비가시성과 강인성 측면에서 분석해보았습니다. 먼저 비가시성 측면에서는, 웹툰 이미지가 실사 이미지에 비해 구성이 단순하고 평탄한 영역이 많아 워터마크 삽입 흔적이 시각적으로 더 쉽게 드러날 것이라고 판단했습니다. 또한 강인성 측면에서는, 웹툰 콘텐츠의 불법 유출 과정에서 신호 처리, 기하학적 변형, 이미지 편집 공격이 복합적으로 가해지며 공격 양상 또한 다양하므로, 이에 대응 가능한 충분한 강인성을 확보하기 어려울 것이라고 판단했습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/09/883dcd70-5bdc-420b-8f9d-588d44916fb9.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;따라서 웹툰 워터마킹 연구 과정에서 다음과 같은 핵심 요구 사항을 설정했습니다.&lt;/p&gt;
        
        &lt;ul&gt;
        &lt;li&gt;비가시성: 소비자가 시각적으로 워터마크의 존재를 인지할 수 없어야 함&lt;/li&gt;
        &lt;li&gt;강인성: 불법 유출 시 발생 가능한 다양한 공격을 견딜 수 있어야 함&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;p&gt;기존의 룰 기반 워터마킹은 비가시성 측면에서 제약이 있고 구조적 한계가 존재하기 때문에, &lt;strong&gt;AI 기반 워터마킹 기법을 도입 및 연구해 비가시성과 강인성을 동시에 갖춘 워터마킹 모델&lt;/strong&gt;을 확보하고자 했습니다.&lt;/p&gt;
        
        &lt;h3 id=&quot;&quot;&gt;불법 유출 사례 조사 및 공격 유형 분석&lt;/h3&gt;
        
        &lt;p&gt;공격 유형을 분석하기 위해 국내외 불법 유출 사이트에 업로드된 이미지를 조사해 신호 처리 공격, 기하학적 공격, 편집 공격의 세 가지 유형으로 분류했습니다. 조사 결과, 원본 이미지의 세부 정보가 육안으로 확인될 정도로 훼손되어 워터마크 추출을 어렵게 하는 강도 높은 공격 사례가 다수 발견되었으며, 특히 해외 사이트에서는 대사 번역 및 재구성을 포함한 편집 공격도 빈번히 확인되었습니다.&lt;/p&gt;
        
        &lt;ul&gt;
        &lt;li&gt;&lt;strong&gt;신호 처리 공격&lt;/strong&gt;: JPEG 압축, 블러, 노이즈 추가 등&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;기하학적 공격&lt;/strong&gt;: 절삭, 크기 조정, 회전 등&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;편집 공격&lt;/strong&gt;: 대사 수정, 식자 재구성 등&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/09/85bb5828-f85d-4b6e-b6df-72abb5640ddd.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;원본 이미지와 공격받은 이미지 간의 잔차(residual) 데이터를 생성해 공격 유형을 분석했고, 미세한 신호 처리 공격에 대해서는 이미지 포렌식 모델 및 분석 도구를 도입해 더욱 정밀하게 공격을 분석했습니다.&lt;/p&gt;
        
        &lt;h3 id=&quot;&quot;&gt;네트워크 구조 설계 및 손실 함수 탐색&lt;/h3&gt;
        
        &lt;p&gt;워터마킹의 주요 요구 사항(비가시성, 강인성, 삽입량)은 상호 보완적이면서도 상충하는 특성이 있습니다. 예를 들어, 강인성을 높이기 위해 삽입 세기를 강하게 설정하면 비가시성이 저하될 수 있고, 삽입량을 늘리면 다른 두 특성이 모두 저하될 위험이 있습니다. 따라서, AI 기반 워터마킹 모델을 통해 품질 지표 간 트레이드오프를 최소화하고 보이지 않는(unseen) 공격에도 유연하게 대응하는 파이프라인을 구축했습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/09/a7468617-b53b-4998-bcb7-ea779b087e27.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;워터마킹 모델은 삽입기(embedder), 공격 레이어(attack layer), 추출기(extractor)의 세 가지 주요 모듈로 구성됩니다. 삽입기는 원본 이미지와 워터마크 패턴을 입력받아 워터마킹된 이미지를 생성합니다. 공격 레이어는 다양한 공격을 미분 가능한 네트워크 레이어로 구현해 end-to-end 학습이 가능하도록 설계되었습니다. 추출기는 공격이 가해진 이미지에서 워터마크 정보를 복원합니다.&lt;/p&gt;
        
        &lt;p&gt;모델의 학습 과정에서는 다양한 공격 조합 및 배치 구성을 실험해 목표 수준의 비가시성과 강인성을 달성했으며, 특히 불법 유출 사이트에서 관찰되었지만 유형 판별이 어려운 공격 사례나 상용 도구에 의한 공격 사례에 대응하기 위해 공격을 모사하는 모델을 추가로 자체 구축해 공격 레이어에 적용했습니다. 학습에 사용된 주요 손실 함수는 원본 이미지와 워터마킹된 이미지 간의 차이를 최소화해 비가시성을 향상시키는 IRL(image reconstruction loss)과, 원본 워터마크 패턴과 추출된 패턴 간 차이를 최소화해 강인성을 확보하는 PRL(pattern reconstruction loss)로 구성되었습니다.&lt;/p&gt;
        
        &lt;h3 id=&quot;&quot;&gt;성능 평가&lt;/h3&gt;
        
        &lt;p&gt;확보된 워터마킹 모델의 성능 평가 결과는 다음과 같습니다.&lt;/p&gt;
        
        &lt;ul&gt;
        &lt;li&gt;&lt;strong&gt;강인성&lt;/strong&gt;: 벤치마크 도구를 구성하는 10종 이상의 공격(Level 5)에 대해 1% 미만의 오류율 달성&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;비가시성&lt;/strong&gt;: PSNR 기준 46 dB 이상&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;p&gt;강인성 평가에서는 자체 개발한 벤치마크 도구로 다양한 유형의 공격에 대해 가장 강한 수준으로 테스트했으며, 1% 미만의 오류율로 높은 강인성을 입증했습니다. 평가 과정에서 적용된 대표적인 공격 유형은 다음과 같습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/09/4ec663f9-10a2-42b3-9d5d-c20c0c4d1e11.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;비가시성은 PSNR 기반으로 평가한 결과, 46dB 이상의 우수한 성능을 달성했습니다. 정량적 평가와 더불어 실제 사용자의 시각적 인지 여부를 확인하기 위해 내부 구성원을 대상으로 사용자 평가(총 약 130명 참여)를 진행했습니다. 실험 결과, 응답자의 88.5%가 원본 이미지와 워터마킹된 이미지를 구분하지 못하는 것으로 나타나, 개발 모델이 실제 서비스 환경에 적용 가능한 수준의 비가시성을 확보했음을 확인했습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/09/46a1a68d-8184-4cd1-8d09-dd95181eed8f.jpg&quot; alt=&quot;figure_유저스터디&quot; /&gt;&lt;/p&gt;
        
        &lt;h3 id=&quot;&quot;&gt;운영 현황&lt;/h3&gt;
        
        &lt;p&gt;네이버 웹툰은 최초 불법 유출자를 식별하고 차단하는 TOONRADAR 시스템을 자체 연구 개발해 2017년 7월부터 국내외 불법 웹툰 복제물 추적에 활용하고 있습니다. 이 글에서 소개한 AI 기반 워터마킹 모델은 현재 TOONRADAR의 사후 추적 모듈로 도입되어 창작 생태계 보호에 크게 기여하고 있습니다. 또한 웹툰 콘텐츠 보호뿐만 아니라 향후 AI 생성 콘텐츠의 신뢰성 확보 등 산업 및 정부 차원에서 워터마킹 기술 활용 확산에도 기여할 것으로 기대합니다.&lt;/p&gt;
        
        &lt;h2 id=&quot;&quot;&gt;학습 방지 기술&lt;/h2&gt;
        
        &lt;p&gt;생성형 AI(generative AI)란, 프롬프트에 대응해 이미지, 텍스트, 오디오 등 다양한 형식의 미디어를 생성하는 모델을 의미합니다. 특히 디퓨전(diffusion) 모델은 노이즈가 추가된 데이터에서 점진적으로 원본 이미지를 복원하는 과정을 통해 학습하는 대표적인 이미지 생성형 AI 모델로, 그중 SD(stable diffusion) 모델은 고해상도 이미지를 효율적으로 생성하며 접근성과 확장성 측면에서 우수해 다양한 애플리케이션에서 널리 활용되고 있습니다.&lt;/p&gt;
        
        &lt;p&gt;그러나 생성형 AI의 파급력이 커짐과 동시에, 타인의 저작권을 침해하기 위해 생성형 AI를 악용하는 사례가 근래 주목받고 있습니다. 예를 들어, 허가 없이 창작물을 활용해 사전 학습된 생성형 AI 모델에 파인튜닝(예: LoRA, Dreambooth)하면 해당 창작물의 스타일이나 콘텐츠를 쉽게 모방할 수 있는 모델이 생성됩니다. 이러한 모방 능력은 기존 창작물의 이미지나 가치를 훼손하는 악의적인 목적으로 악용될 가능성이 있습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/09/e5ddc616-2f86-4412-95f0-2a5ba629a7ac.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;생성형 AI를 이용한 무단 저작물 학습 및 스타일 모방 사례가 증가하면서 이에 대응 가능한 기술적 설루션의 필요성이 제기되었고, 이러한 배경에서 &lt;strong&gt;학습 방지 기술&lt;/strong&gt;이 제안되었습니다. 학습 방지 기술이란 생성형 AI 모델이 창작물의 스타일이나 콘텐츠를 모방하는 것을 방해하고 억제하는 기술로, 대표적으로는 이미지 내에 삽입된 보호 왜곡을 통해 구현됩니다. 보호 왜곡이란 모델의 정상적 동작을 방해하기 위해 입력 이미지에 미세한 수준의 변형을 추가하는 것을 의미합니다. 이는 일반 이미지 워터마킹과 유사하게 원본 이미지와 시각적 차이가 매우 적다는 특징이 있습니다.&lt;/p&gt;
        
        &lt;p&gt;학습 방지 처리된 창작물을 이용해 생성형 AI 모델을 파인튜닝하면, 학습된 모델은 다음과 같이 창작물의 스타일 모방에 실패하는 결과를 보입니다. 이를 통해 창작물의 무단 학습 및 악의적 활용을 효과적으로 방지할 수 있습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/09/2f63f4fb-d617-4b6a-9d42-b3376c524bf9.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;학습 방지 기술은 최근 활발히 연구되어, Glaze와 PhotoGuard를 위시한 다양한 기법이 학술적으로 제안되었습니다. 기존 연구는 주로 보호 왜곡을 이미지에 적용하는 방식으로, 크게 인코더 기반과 디퓨전 기반의 두 가지 접근법으로 분류할 수 있습니다. 전자는 입력 이미지와 타겟 이미지의 잠재 표현(latent code) 간 거리를 감소시켜 모델이 타겟과 유사한 스타일의 이미지를 생성하도록 유도하는 방식이고, 후자는 디퓨전 모델의 노이즈 제거(denoising) 과정을 방해해 원본 이미지와 다른 샘플을 생성하도록 유도하는 방식입니다. 근래에는 논문 발표를 넘어 자체 개발한 설루션을 공개하거나 기존 창작 도구에 학습 방지 기능을 추가하는 등, 학술적 접근뿐 아니라 실질적 활용이 가능한 다양한 기술이 지속적으로 등장하고 있습니다.&lt;/p&gt;
        
        &lt;h3 id=&quot;&quot;&gt;요구 사항&lt;/h3&gt;
        
        &lt;p&gt;창작물 보호를 위한 필수 요구 사항을 명확히 설정하기 위해 기존의 학습 방지 기술의 성능을 체계적으로 분석하고, 공개된 설루션 및 도구에 대한 창작 커뮤니티의 반응을 추가로 조사해 성능 개선이 필요한 핵심 영역을 도출했습니다.&lt;/p&gt;
        
        &lt;p&gt;다음은 기존에 공개된 학습 방지 기술을 적용한 이미지입니다. 원본 이미지와 비교해 보호 왜곡에 따른 시각적 품질 열화가 뚜렷이 관찰되었습니다. 이러한 분석을 바탕으로, 학습 방지 기술의 비가시성 개선을 최우선 과제로 설정했습니다. 더불어, 기존에 공개된 도구에 대한 창작 커뮤니티 반응을 조사해, 학습 방지 성능의 안정성을 확보하는 동시에 처리 속도를 개선하는 것을 핵심 요구 사항으로 추가 선정했습니다. 이미지 한 장을 보호하는 데 소요되는 리소스가 일반 창작자의 관점에서는 매우 크기 때문에, 이 점을 개선해 적은 리소스로 사용 가능한 버전을 만들고자 했습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/09/5ba33274-2d3f-40a2-8373-1e8ed048722e.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;
        
        &lt;h3 id=&quot;impasto&quot;&gt;네이버 웹툰 학습 방지 기술 IMPASTO&lt;/h3&gt;
        
        &lt;p&gt;네이버 웹툰에서 연구한 학습 방지 기술은 &lt;strong&gt;IMPASTO&lt;/strong&gt;라고 명명했습니다. 이 이름은 다음과 같은 두 가지 의미를 내포하고 있습니다. 첫 번째는 &lt;strong&gt;비가시성을 고려한 스타일 모방 방어 기술&lt;/strong&gt;(IMperceptible Protection Against STyle imitatiOn; IMPASTO)의 약어로서의 의미입니다. 두 번째는 유화에서 물감을 두텁게 덧칠해 입체적 효과를 표현하는 예술 기법인 &lt;strong&gt;임파스토&lt;/strong&gt;(impasto)에서 착안한 것입니다. 이미지에 미세한 추가 신호를 삽입해 학습 방지 효과를 달성하는 이 기술과 해당 예술 기법 간의 유사성을 반영해 IMPASTO라는 명칭이 선정되었습니다.&lt;/p&gt;
        
        &lt;p&gt;이 글에서는 IMPASTO의 두 가지 버전을 소개합니다. IMPASTO-v1은 기존 기법과의 호환성을 유지하면서 비가시성을 향상하는 데 중점을 두었고 IMAPSTO-v2는 기존 기법에서 보호 왜곡 계산에 소요되는 시간을 획기적으로 개선하기 위해 개발되었습니다.&lt;/p&gt;
        
        &lt;h4 id=&quot;impastov1&quot;&gt;IMPASTO-v1(비가시성 개선)&lt;/h4&gt;
        
        &lt;p&gt;기존 학습 방지 기술은 보호 왜곡을 원본 이미지에 적용하는 과정에서 비가시성이 저해되는 문제가 반복적으로 관찰되었습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/09/58ea78eb-ec97-4b15-869d-c82cb35632bc.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;왜곡에서 기인한 윤곽선 번짐 및 노이즈 패턴 등이 육안으로 쉽게 식별되었으며, 보호 강도를 낮추면 비가시성은 개선되나 학습 방지 성능이 약화되는 트레이드오프가 관찰되었습니다. 더불어, 얼굴과 같은 영역에만 국소적으로 학습 방지를 적용하는 경우, 모델이 비보호 영역에서 여전히 유효한 콘텐츠를 학습해 전체적인 학습 방지 성능이 저하되는 것을 확인했습니다.&lt;/p&gt;
        
        &lt;p&gt;IMPASTO-v1은 기존의 학습 방지 기술과 호환 가능한 형태를 유지하면서도, 영역별로 보호 강도를 적응적으로 조절하는 것이 핵심 콘셉트입니다. 이를 통해 동일하게 보호 왜곡을 적용하면서도 인지적으로 덜 민감한 영역에는 더욱 강한 학습 방지를 집중적으로 부여하고, 민감한 영역에서는 최소화해 비가시성과 학습 방지 성능의 균형을 달성하고자 했습니다. 이러한 과정에서 식별 최소차(just noticeable difference; JND) 개념을 도입해, 보호 강도 설계에 인간 시각 특성을 반영했습니다.&lt;/p&gt;
        
        &lt;p&gt;이러한 설계를 구체화하기 위해, IMPASTO-v1은 단일 JND 지표를 사용하는 대신 다음의 다섯 가지 JND 지표를 앙상블 방식으로 활용해 픽셀 단위의 인지 민감도를 추정하는 &lt;strong&gt;인지 영역 맵&lt;/strong&gt;(perceptual map)을 도입했습니다.&lt;/p&gt;
        
        &lt;ul&gt;
        &lt;li&gt;LA(luminance adaptation)&lt;/li&gt;
        &lt;li&gt;CM(contrast masking)&lt;/li&gt;
        &lt;li&gt;CSF(contrast sensitivity function)&lt;/li&gt;
        &lt;li&gt;Stdev(standard deviation)&lt;/li&gt;
        &lt;li&gt;entropy&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;p&gt;그리고 다섯 가지 JND 지표를 기반으로 인지 영역 맵을 생성할 때, 단순 산술 평균(average)을 적용하는 방식이 아닌 IWR(image-wise refinement) 방식을 채택해, 입력 이미지의 인지적 특성을 반영했습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/09/375c85d3-9240-44d9-8971-5cc7ce54e77b.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;다음으로, 이미지 혹은 작품별로 보호 난이도가 다른 것을 관찰해 &lt;strong&gt;난이도 맵&lt;/strong&gt;(difficulty map)을 생성함으로써 보호 기능을 향상시켰습니다.&lt;/p&gt;
        
        &lt;p&gt;다음 그래프는 PhotoGuard를 20개의 작품에 적용했을 때의 보호 효율을 나타낸 것으로, 작품별로 보호 효율이 크게 달라짐을 확인할 수 있습니다. 일부 이미지는 낮은 강도만으로도 충분히 보호되는 반면, 다른 이미지는 동일한 보호 수준을 확보하기 위해 더 높은 강도가 요구되는 등 보호 난이도의 편차가 뚜렷하게 나타났습니다. 즉, 평균 점수(붉은 점선)는 개별 사용자가 체감하는 보호 효과를 제대로 반영하지 못하며, 단순 평균 지표만으로는 실제 보호 성능을 설명하기 어렵다는 것을 알 수 있습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/09/53f4c5eb-cf4c-464c-899d-7ac41a0865d3.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;이러한 특성을 반영하기 위해, IMPASTO-v1은 원본 이미지와 중간 보호본 사이의 LPIPS 거리를 활용해 난이도 맵을 계산했습니다. 난이도 맵은 각 영역이 추가 보호 강도를 얼마나 필요로 하는지를 추정해 보호 강도의 효율적 분배를 가능하게 합니다. 최종 산출된 난이도 맵을 인지 영역 맵과 결합해 영역별로 최적화된 강도를 적용함으로써, 보호 성능을 유지하면서도 불필요한 왜곡을 줄일 수 있습니다.&lt;/p&gt;
        
        &lt;p&gt;또한, 추가로 비가시성을 개선하기 위해 &lt;strong&gt;인지적 제약 집합&lt;/strong&gt;(perceptual constraint bank)을 도입했습니다. 이 제약 집합은 단일 픽셀 공간에만 제약을 두는 기존 방식과 달리, 다양한 특징 공간(feature space)에 동시에 제약을 적용해 더욱 효과적인 결과를 제공합니다. 특히 masked LPIPS, masked low-pass, CLIP 제약을 포함해 다중 잠재 공간(latent space)에서 비가시성을 제어해, 시각적 충실도를 높이면서도 강인성을 유지할 수 있습니다.&lt;/p&gt;
        
        &lt;p&gt;IMPASTO-v1의 알고리즘 개요는 다음과 같습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/09/90a8c3dc-ed22-40f7-8461-aaefc7ff0b48.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;기존의 학습 방지 접근법은 대체로 보호 왜곡을 반복 최적화로 갱신하는 구조에 의존하는 반면, IMPASTO-v1은 인지 영역 맵과 난이도 맵을 기반으로 왜곡을 적응적으로 정제하고 제약 집합으로 이를 보완함으로써 더욱 정교하고 안정적으로 학습 방지를 수행합니다.&lt;/p&gt;
        
        &lt;h4 id=&quot;impastov2&quot;&gt;IMPASTO-v2(처리 속도 개선)&lt;/h4&gt;
        
        &lt;p&gt;대부분의 기존 학습 방지 기술은 추론(inference) 시 보호 왜곡을 반복 과정(iterative process)으로 업데이트하는 방식을 채택했습니다. 일반적으로 원본 이미지와 타겟 스타일 간 잠재 표현의 거리를 줄이는 손실을 사용하며, 이는 VAE 인코더 기반 표현을 예로 들 수 있습니다. 이 과정에서 입력 이미지마다 업데이트가 여러 차례 이루어지므로 처리 시간이 길어져 실사용 워크플로에 부담이 되었고, 창작 커뮤니티에서도 빠른 추론의 필요성이 꾸준히 제기되었습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/09/542c0a97-0d35-4549-b2d0-424bcacd8d0b.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;범용적 적대적 왜곡(universal adversarial perturbation; UAP)은 보호 왜곡을 사전에 학습해 두고, 학습된 단일 왜곡을 추론 시에 즉시 적용하는 방법으로, 반복 과정을 생략해 속도를 크게 향상시킬 수 있습니다. 그러나 입력 이미지의 특성과 무관한 단일 왜곡에 의존하기 때문에 이미지별, 작품별 다양성을 반영하지 못해 기존의 이미지별 최적화 방식 대비 학습 방지 성능이 저하되는 한계가 있습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/09/46561556-f186-45f3-98b1-ec52e67518ac.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;기존 기법의 반복 과정으로 인한 속도 저하와, 입력 이미지와 관계 없이 단일 왜곡을 적용함으로써 발생하는 왜곡 표현력(capacity) 부족 문제를 모두 고려해, 처리 시간을 크게 단축하면서도 충분한 표현력을 확보할 수 있는 새로운 방법론이 필요했습니다.&lt;/p&gt;
        
        &lt;p&gt;IMPASTO-v2는 단일 왜곡으로 인한 왜곡 표현력 부족을 해소하기 위해 &lt;strong&gt;다중 학습 방지 왜곡&lt;/strong&gt;(mixture of perturbation; MoP)을 도입했습니다. 입력 및 타겟 샘플을 VAE 인코더에 통과시켜 얻은 잠재 코드를 k-means 클러스터링으로 분류한 뒤, 각 클러스터에 대해 서로 다른 k개의 다중 왜곡을 학습했습니다. 그리고 추론 시에는 선택 모듈이 입력의 잠재 표현을 해당 클러스터에 할당하고, 입력 이미지에 가장 적합한 왜곡을 적응형으로 선택함으로써 학습 방지 표현력을 확대합니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/09/876f1445-90a7-42ad-9f7e-687f3c4478da.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;실험 과정에서 타겟 이미지의 복잡도에 따른 성능 편차가 뚜렷하게 관찰되었습니다. 복잡도가 서로 다른 세 종류의 타겟 이미지를 기준으로 평가한 결과, 단순한 텍스처의 웹툰 계열 입력에서는 낮은 복잡도의 타겟이 더 잘 발현되었고, 실사 계열 입력에서는 높은 복잡도의 타겟이 더 안정적으로 발현되는 경향을 확인했습니다. 이를 통해 입력과 타겟 이미지 간의 구조적 유사성을 반영한 조건부 선택 메커니즘의 필요성을 도출했습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/09/64ffaab6-d3bd-4684-8830-17ac32984f0c.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;이러한 관찰을 반영해 &lt;strong&gt;적응형 타겟 보호&lt;/strong&gt;(adaptive targeted protection) 개념을 도입했습니다. 타겟 복잡도별로 서로 다른 MoP를 별도 학습하고, 추론 시에는 입력에 최적화된 타겟과 대응되는 왜곡을 선택해 적용하는 방식입니다. 선택 함수 H는 VAE 잠재 공간에서의 엔트로피를 사용해 입력 이미지와 엔트로피가 가장 유사한 타겟을 선택하며, 선택된 타겟에 대응되는 왜곡 세트를 적용함으로써 입력 및 타겟 이미지의 정합성을 높였습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/09/a76fe664-7c1c-43d2-bd68-a1fe6296abf0.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;끝으로, 추가 비가시성 개선을 위해 추론 과정에서 먼저 선택된 MoP로 임시 보호 이미지를 1차 생성하고, LPIPS를 이용해 원본과 임시 보호본 간의 공간적 인지 맵을 계산했습니다. 이 인지 맵은 식별이 쉬운 영역을 완화하고 식별이 어려운 영역에 더 많은 예산을 배분하도록 왜곡을 가중 및 마스킹하는 데 사용되었습니다. 결과적으로, 시각적 자연스러움은 향상되면서도 보호 성능의 저하를 최소화하는 파이프라인을 구성할 수 있었습니다.&lt;/p&gt;
        
        &lt;h3 id=&quot;&quot;&gt;성능 평가&lt;/h3&gt;
        
        &lt;h4 id=&quot;impastov1&quot;&gt;IMPASTO-v1&lt;/h4&gt;
        
        &lt;p&gt;먼저 비가시성 측면에서, 기존 학습 방지 기술(예: PhotoGuard, AdvDM)에 IMPASTO-v1 add-on 모듈을 적용했을 때 시각적 품질 저하가 효과적으로 완화되는 것을 확인했습니다. 특히 웹툰과 같이 단순하고 평탄한 영역이 많은 콘텐츠에서는 미세한 보호 왜곡이 쉽게 드러나는데 IMPASTO-v1을 적용한 경우 이러한 왜곡이 현저히 줄어들어, 웹툰 도메인에서 학습 방지 기술이 충족해야 할 필수 요건인 원본 유사성 유지를 달성했습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/09/4203782b-fd2c-42c2-9cfe-4dd0fbbfe149.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;다음으로 잔차 데이터 시각화에서도 IMPASTO-v1 적용 시 에너지 레벨이 낮게 나타나, 기존 학습 방지 기술 대비 왜곡으로 인한 변화량이 적음을 확인했습니다. 또한 보호 이미지를 활용해 학습한 모델(Stable Diffusion w/ LoRA)의 재생성 결과를 비교해, IMPASTO-v1 적용 전후로 학습 방지 성능이 유지됨을 확인했습니다. 사용자 기반 A/B 테스트를 통한 정성적 평가에서도 제안 기법 적용 시 보호 이미지의 주관적 품질이 개선되었음이 입증되었습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/09/c122c1a4-1c01-4638-8bfd-1d13b8a801f8.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;정량 평가에서도 기존 네 가지 학습 방지 기술에 IMPASTO-v1을 결합하는 형태로 적용했을 때 일관된 성능 향상이 나타났습니다. DISTS, PieAPP, TOPIQ의 주요 비가시성 지표에서 비가시성에 대한 개선이 확인되었으며, NIQE, BRISQUE, FID와 같은 학습 방지 성능 지표에서도 상대적으로 더 약한 왜곡이 더해졌음에도 불구하고 학습 방지 성능은 안정적으로 유지(비슷하거나 개선)되었습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/09/1d2bd7c6-d08c-4159-bbfa-8dd24207cc1c.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;이러한 결과는 IMPASTO-v1이 범용적인 add-on 모듈로서 다양한 기법과 도메인에 적용 가능하며, 시각적 품질과 보호 효과 간의 균형을 효과적으로 달성함을 시사합니다.&lt;/p&gt;
        
        &lt;h4 id=&quot;impastov2&quot;&gt;IMPASTO-v2&lt;/h4&gt;
        
        &lt;p&gt;IMPASTO‑v2는 추론 속도 측면에서 뚜렷한 우위를 보였습니다. 512×512 해상도의 이미지 1장 처리를 기준으로 CPU 2.9초, A100 GPU 0.04초를 달성해, 기존의 학습 방지 기술(CPU/GPU 처리 시간: AdvDM 1210초/35초, PhotoGuard 370초/7초, Anti‑DB 7278초/225초, Mist 1440초/40초, SDST 1410초/24초) 대비 처리 시간을 매우 크게 단축했습니다. 해상도별 처리 시간 그래프에서도 IMPASTO‑v2의 처리 시간이 일관되게 가장 짧은 것을 확인할 수 있습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/09/5be231a2-f432-4be6-a914-a5138c266182.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;Object, Face, Painting, Cartoon의 네 가지 도메인에서 비가시성(DISTS)과 학습 방지 성능(FID)을 비교해보겠습니다. IMPASTO‑v2는 네 도메인에서 대부분 최저 혹은 최저권의 DISTS 값을 보였습니다(값이 낮을수록 좋음). FID 역시 Object와 Face 도메인에서 최고 수준을 달성했고 Painting과 Cartoon 도메인에서도 기존의 최고치와 근접한 경쟁적 성능을 보였습니다(값이 높을수록 좋음).&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/09/b11d7ccb-5597-475a-82f2-832dde0ffd28.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;요약하면, IMPASTO‑v2는 극단적으로 짧은 처리 시간을 달성하면서도 다양한 도메인에서 양호한 비가시성 및 학습 방지 성능을 동시에 유지했습니다.&lt;/p&gt;
        
        &lt;p&gt;끝으로, 정성 평가에서도 장점을 보였습니다. 확대해 비교했을 때 보호 왜곡으로 인한 시각적 열화가 타 기법 대비 완화되어 시각적 품질 저하가 크지 않았고, 재생성 결과를 비교했을 때에도 의도한 타겟 이미지의 속성(예: 샘플에서의 반복되는 작은 입자)이 안정적으로 반영되는 양상을 보였습니다. 즉, 사용자가 보기에 왜곡이 거의 눈에 띄지 않으면서도 타겟 이미지의 속성이 안정적으로 반영된다고 판단할 수 있습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/09/4aa7da49-9f31-4bee-8309-7137ac7e7269.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;
        
        &lt;h3 id=&quot;&quot;&gt;운영 현황&lt;/h3&gt;
        
        &lt;p&gt;학습 방지 연구는 현재 워터미킹에 비해 상대적으로 연구의 성숙도가 낮은 단계로, 지속적인 연구 개발과 기술적 발전이 필요합니다. IMPASTO-v1과 v2는 각각 &lt;a href=&quot;https://arxiv.org/abs/2403.19254&quot;&gt;IEEE Transactions on Multimedia 게재 승인&lt;/a&gt;과 &lt;a href=&quot;https://openaccess.thecvf.com/content/CVPR2025/papers/Ahn_Nearly_Zero-Cost_Protection_Against_Mimicry_by_Personalized_Diffusion_Models_CVPR_2025_paper.pdf&quot;&gt;CVPR 2025 발표&lt;/a&gt;라는 학술적 성과를 거둬, 학문적으로 의미 있을 뿐 아니라 실질적으로 창작자 보호라는 사회적 요구에도 부합함을 보였습니다. 네이버 웹툰은 앞으로도 자사 플랫폼에서 활동하는 창작자의 우려를 해소할 수 있는 기술 개발에 꾸준히 힘쓰고자 합니다.&lt;/p&gt;
        
        &lt;p&gt;현재는 IMPASTO-v2 데모 공개를 검토 및 준비하고 있습니다. 데모 공개 후 창작자와 사용자의 피드백을 수렴하고 이를 기반으로 지속적으로 성능을 개선해, 궁극적으로 건전한 창작 생태계 형성에 기여하는 것을 목표로 하고 있습니다.&lt;/p&gt;
        
        &lt;h2 id=&quot;&quot;&gt;마치며&lt;/h2&gt;
        
        &lt;p&gt;네이버 웹툰은 창작 생태계 보호를 위해 워터마킹과 학습 방지 기술 연구를 지속적으로 발전시킬 계획입니다.&lt;/p&gt;
        
        &lt;ul&gt;
        &lt;li&gt;&lt;p&gt;&lt;strong&gt;워터마킹&lt;/strong&gt;: 현재 TOONRADAR 시스템에서 운영 중인 워터마킹 모델을 고도화하고 확장해 동영상 등 다양한 도메인으로 워터마크 적용 범위를 확대할 예정이며, 이를 위한 실무 운영 환경과의 연동도 지속적으로 강화해 불법 유출 방지에 기여할 예정입니다.&lt;/p&gt;&lt;/li&gt;
        &lt;li&gt;&lt;p&gt;&lt;strong&gt;학습 방지 기술&lt;/strong&gt;: IMPASTO의 데모를 공개하고 사용자 피드백을 적극 수렴해 방어 성능을 고도화할 예정입니다. 또한 근래 대두되고 있는 학습 방지 무력화 공격에 대해서도 대응 가능한 방법론을 탐색할 예정입니다.&lt;/p&gt;&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;p&gt;이러한 방향성을 통해 네이버 웹툰은 창작자의 권리를 효과적으로 보호하고, 더욱 건전한 창작 생태계를 구축하는 데 기여할 것으로 기대합니다.&lt;/p&gt;
      </content:encoded>
    </item>
    <item>
      <title>Iceberg Low-Latency Queries with Materialized Views  (feat. 실시간 거래 리포트)</title>
      <link>https://d2.naver.com/helloworld/9290684</link>
      <guid>https://d2.naver.com/helloworld/9290684</guid>
      <pubDate>Sun, 08 Feb 2026 08:02:45 GMT</pubDate>
      <content:encoded>
        &lt;p&gt;네이버 사내 기술 교류 행사인 NAVER ENGINEERING DAY 2025(10월)에서 발표되었던 세션을 공개합니다.&lt;br/&gt; &lt;/p&gt;
        
        &lt;div style=&quot;position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;&quot;&gt;
        
        &lt;iframe width=&quot;800&quot; height=&quot;450&quot; src=&quot;https://tv.naver.com/embed/89476860?autoPlay=true&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot; style=&quot;position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;&quot;&gt;&lt;/iframe&gt;  
        &lt;/div&gt;  
        
        &lt;p&gt;&lt;br/&gt;&lt;/p&gt;
        
        &lt;h4 id=&quot;&quot;&gt;발표 내용&lt;/h4&gt;
        
        &lt;ul&gt;
        &lt;li&gt;본 영상에서는 “실시간 거래 리포트를 어떻게 하면 사용자가 원하는 다양한 조건으로 빠르게 조회할 수 있을까?” 라는 질문에서 출발한 기술적 여정을 다룹니다.&lt;/li&gt;
        &lt;li&gt;단순히 데이터를 쌓고 조회하는 단계를 넘어, 거래 데이터의 최신성과 응답 속도, 그리고 확장성을 동시에 확보하기 위한 여러 시도를 공유합니다.&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;h4 id=&quot;&quot;&gt;발표 대상&lt;/h4&gt;
        
        &lt;ul&gt;
        &lt;li&gt;데이터 플랫폼 엔지니어 / 데이터 아키텍트 – 대용량 실시간 데이터 처리 및 저지연 설계에 관심 있는 분&lt;/li&gt;
        &lt;li&gt;분석 플랫폼 운영자 / BI 개발자 – 다차원 필터 조회 속도 및 Freshness 향상 전략을 찾고 있는 분&lt;/li&gt;
        &lt;li&gt;Spark, Iceberg, StarRocks 활용자 – 실제 조합 운영 사례를 통해 운영 팁을 얻고자 하는 분&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;h4 id=&quot;&quot;&gt;목차&lt;/h4&gt;
        
        &lt;ol&gt;
        &lt;li&gt;소개 (Introduction)  &lt;/li&gt;
        &lt;li&gt;문제 정의 (Problem Definition)  &lt;/li&gt;
        &lt;li&gt;도전 과제 (Challenges)  &lt;/li&gt;
        &lt;li&gt;리서치 여정 (Research Journey)  &lt;/li&gt;
        &lt;li&gt;아키텍처 개요 (Architecture Overview)  &lt;/li&gt;
        &lt;li&gt;구성 요소 (Components)  &lt;/li&gt;
        &lt;li&gt;결과 및 성능 (Results &amp;amp; Performance)&lt;/li&gt;
        &lt;/ol&gt;
        
        &lt;blockquote&gt;
        &lt;h5 id=&quot;naverengineeringdaybr&quot;&gt;&lt;strong&gt;◎ NAVER ENGINEERING DAY란?&lt;/strong&gt;&lt;br/&gt;&lt;/h5&gt;
        
        &lt;p&gt;NAVER에서는 사내 개발 경험과 기술 트렌드를 교류를 할 수 있는 프로그램이 많이 있습니다. 그중 매회 평균 70개 이상의 발표가 이루어지는 NAVER ENGINEERING DAY를 빼놓을 수 없는데요. &lt;br /&gt;
        2016년부터 시작된 ENGINEERING DAY는 실무에서의 기술 개발 경험과 새로운 기술과 플랫폼 도입 시 유용하게 활용될 수 있는 팁 등을 공유하며 서로 배우고 성장하는 네이버의 대표적인 사내 개발자 행사입니다. &lt;br /&gt;
        올해 진행된 NAVER ENGINEERING DAY의 일부 세션을 공개합니다.&lt;/p&gt;
        &lt;/blockquote&gt;
      </content:encoded>
    </item>
    <item>
      <title>[DAN25] 기술세션 영상이 모두 공개되었습니다.</title>
      <link>https://d2.naver.com/news/9333656</link>
      <guid>https://d2.naver.com/news/9333656</guid>
      <pubDate>Sun, 08 Feb 2026 08:02:45 GMT</pubDate>
      <content:encoded>
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/11/---------.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;지난 11월 6일, 7일 양일간 진행된 팀네이버 컨퍼런스 DAN25에서는 네이버의 기술뿐만 아니라 크리에이티브, 서비스와 비즈니스를 유기적으로 융합해 일상의 작은 변화부터 새로운 생태계로의 도약까지, 끝없이 확장되는 경험의 로드맵을 함께 나누는 자리로 진행되었습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;strong&gt;현장에서는 AI 에이전트, 소버린 AI, AX 등 네이버가 제시하는 미래 전략과 실제 서비스·비즈니스에 적용된 다양한 사례들이 공유&lt;/strong&gt;되며, 참가자들이 변화된 사용자 경험을 직접 확인하고 인사이트를 얻을 수 있었습니다.&lt;/p&gt;
        
        &lt;p&gt;컨퍼런스에서 선보인 다양한 세션과 발표들은 많은 관심을 모았는데요, 현장의 그 생생한 분위기를 온라인에서도 만나볼 수 있도록 모든 발표영상이 &lt;a href=&quot;https://dan.naver.com/25&quot;&gt;DAN25 홈페이지&lt;/a&gt;와 &lt;a href=&quot;https://tv.naver.com/playnaver&quot;&gt;NAVER 네이버 TV 채널&lt;/a&gt;에 공개 되었습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/11/-----------2025-11-27-------11-05-01.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;h4 id=&quot;35&quot;&gt;총 35개의 기술세션 중&lt;/h4&gt;
        
        &lt;p&gt;&lt;strong&gt;오프라인 현장에서 가장 참여율(참석 및 질문)이 높았던 기술 세션 5개&lt;/strong&gt;를 뽑아보았습니다.&lt;/p&gt;
        
        &lt;h3 id=&quot;dan25techtop5&quot;&gt;&lt;strong&gt;&lt;mark&gt;[DAN25 Tech 세션 TOP 5]&lt;/mark&gt;&lt;/strong&gt;&lt;/h3&gt;
        
        &lt;h4 id=&quot;1personaaillm_naverhttpsdannavercom25sessions713&quot;&gt;&lt;a href=&quot;https://dan.naver.com/25/sessions/713&quot;&gt;&lt;strong&gt;1. 네이버 PersonA - 지금 나를 이해하는 AI (부제 : LLM 기반 사용자 메모리 구축과 실시간 사용자 로그 반영 시스템 구현)&lt;/strong&gt;_NAVER 발견/탐색 프로덕트 임홍준, 김창봉, 최수진 님&lt;/a&gt;&lt;/h4&gt;
        
        &lt;p&gt;ChatGPT, Google Gemini와 같은 대화형 AI 서비스를 사용해 보면, 바로 이전 대화만 기억하는 것이 아니라, 수개월간의 대화 기록을 요약·저장하여 사용자와의 대화 맥락을 이어가는 모습을 볼 수 있습니다. 또한 ‘메모리’ 보기 기능을 통해, AI가 나에 대해 무엇을 기억하고 있는지도 확인할 수 있습니다.&lt;/p&gt;
        
        &lt;p&gt;네이버는 대화형 AI 서비스는 아닙니다. 그럼에도 불구하고, 사용자는 네이버의 다양한 서비스를 이용하면서 자신에 대한 수많은 단서를 남기고 있습니다. 직접적인 대화는 아니지만, 이러한 파편적인 기록들을 사용자와 네이버 간의 ‘간접적인 대화’로 보고, 이를 기반으로 사용자 메모리를 구축하려는 프로젝트가 바로 네이버 PersonA입니다.&lt;/p&gt;
        
        &lt;p&gt;네이버 PersonA 프로젝트에서는 사용자 메모리를 구축하기 위해 대규모 언어모델(LLM)을 적극 활용했습니다. 또한 적절한 시점에, 사용자에게 의미 있는 제안을 전달하기 위해 LLM의 추론 능력을 결합했습니다.&lt;/p&gt;
        
        &lt;p&gt;이번 발표에서는 LLM을 활용한 네이버의 사용자 메모리 구축 과정과, 이를 기반으로 제안 서비스를 어떻게 설계하고 구현했는지 공유합니다. 그 과정에서 마주한 고민들, 여러 선택지들 사이에서 해법을 찾아간 과정, 그리고 대규모 사용자에게 실시간 로그를 반영하며 서비스를 안정적으로 제공하기 위해 어떤 기술적·서비스적 대안을 선택했는지도 함께 말씀드리겠습니다.&lt;/p&gt;
        
        &lt;p&gt;아직 초기 단계이지만, 네이버는 단계적인 로드맵을 가지고 AI 에이전트 서비스로 진화해 나가고 있습니다. 이번 프로젝트는 그 의지를 담은 실험적이면서도 중요한 시도라 할 수 있습니다.
        &lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
        
        &lt;h4 id=&quot;2llm_naverhttpsdannavercom25sessions681&quot;&gt;&lt;a href=&quot;https://dan.naver.com/25/sessions/681&quot;&gt;&lt;strong&gt;2. 데이터 속 숨은 트렌드, LLM이 답하다 : 랭킹 기반 플레이스 트렌드 분석 시스템&lt;/strong&gt;_NAVER 플레이스 프로덕트 김현우, 손재원 님&lt;/a&gt;&lt;/h4&gt;
        
        &lt;p&gt;&quot;지금 사람들이 가장 많이 찾는 장소는 어디일까요?&quot; 본 발표에서는 실시간 사용자 데이터를 기반으로 &apos;지금 뜨는 장소&apos;를 찾아내는 랭킹 기반 플레이스 트렌드 분석 시스템을 소개합니다.&lt;/p&gt;
        
        &lt;p&gt;단순히 많이 찾는 곳을 넘어, &apos;급등&apos;과 &apos;지속&apos;의 균형을 맞춘 랭킹 알고리즘을 통해 진정으로 의미 있는 트렌드를 포착하는 노하우를 공유합니다. 더 나아가 텍스트 마이닝과 LLM을 활용하여 &quot;왜 이 장소가 지금 뜨는가?&quot;에 대한 이유까지 키워드로 추출하는 과정을 살펴봅니다.&lt;/p&gt;
        
        &lt;p&gt;데이터 속 숨겨진 트렌드를 발견하고, 그 이유까지 설명 가능한 인사이트를 얻어가는 시간을 가져보세요.
        &lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
        
        &lt;h4 id=&quot;3llm_navercloudhcxapplicationnaverhttpsdannavercom25sessions724&quot;&gt;&lt;a href=&quot;https://dan.naver.com/25/sessions/724&quot;&gt;&lt;strong&gt;3. 검색 서비스에 최적화된 LLM 만들기: 데이터, 학습, 서비스 적용 사례&lt;/strong&gt;_NAVER Cloud HCX Application 신원광, 권유환 님. NAVER 검색 플랫폼 권오준, 백지혜 님&lt;/a&gt;&lt;/h4&gt;
        
        &lt;p&gt;범용 LLM은 강력하지만 매일 수십억 건의 질문과 답을 다루는 실제 검색 서비스에 그대로 적용하기에는 한계가 있다. 본 발표에서는 &quot;검색 서비스 특화 LLM&quot;을 만들고 실제 서비스에 적용해본 경험담을 공유한다. 검색 로그에서 출발한 데이터 가공 레시피 적용과 다양한 데이터 조합 실험, 특히 기존 범용 성능을 유지하면서도 서비스 맞춤 기능을 끌어올린 실험 결과와 데이터 최적화 노하우를 공유한다.&lt;/p&gt;
        
        &lt;p&gt;실제 서비스 적용 관점에서는 보다 신뢰성있는 검색 결과를 사용자에게 제공하기 위한 AuthGR과 전통적인 정보 검색 과정을 하나로 통합해 제시하는 AI briefing 을 소개한다. 이를 통해 범용 LLM 대비 검색 서비스 특화 모델의 효용성을 확인할 수 있으며, 네이버가 검색 품질 개선을 위해 갖고있는 고민과 앞으로의 방향성을 엿볼 수 있다.
        &lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
        
        &lt;h4 id=&quot;4crmux_naverwebtoonmlplatformhttpsdannavercom25sessions690&quot;&gt;&lt;a href=&quot;https://dan.naver.com/25/sessions/690&quot;&gt;&lt;strong&gt;4. 실시간 추천-CRM 통합 모델로 완성하는 개인화&lt;/strong&gt; UX_NAVER WEBTOON ML Platform 김회인, 이성훈 님&lt;/a&gt;&lt;/h4&gt;
        
        &lt;p&gt;네이버 시리즈는 개인화 UX를 위해 추천부터 CRM까지 다양한 영역에 ML 모델을 활용하고 있습니다. 하지만 여러 모델들이 추가되면서 모델 관리의 복잡성이 커지고, 모델 간 일관성을 유지하기 어려운 한계가 드러났습니다.&lt;/p&gt;
        
        &lt;p&gt;동시에 CRM 모델 중 일부는 실시간으로 처리되지 않는 기능이 있어 개선이 필요한 상황이었습니다. 이러한 문제를 해결하기 위해 모델 개발 관점에서는 추천과 CRM 모델을 하나의 통합 프레임워크로 설계하기로 결정하였고, 모델 서빙 관점에서는 모든 모델의 결과를 실시간으로 받아오기 위해 API 기반 서빙 아키텍처를 구축하기로 결정하였습니다.&lt;/p&gt;
        
        &lt;p&gt;본 발표에서는 네이버 시리즈에 실제 적용된 사례를 중심으로, 추천-CRM 모델 통합 과정과 배치 기반에서 실시간 추론 체계로 전환한 경험을 공유합니다. 대규모 서비스 환경에서 개인화 경험을 고도화하기 위한 모델링/시스템 설계의 실제적인 고민과 해법을 함께 나누고자 합니다.
        &lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
        
        &lt;h4 id=&quot;5_naverhttpsdannavercom25sessions693&quot;&gt;&lt;a href=&quot;https://dan.naver.com/25/sessions/693&quot;&gt;&lt;strong&gt;5. 하루 수백억 건을 처리하는 똑똑한 로그 파이프라인 만들기: 비용·성능·안정성 삼박자&lt;/strong&gt;_NAVER 검색 플랫폼 김완호 님&lt;/a&gt;&lt;/h4&gt;
        
        &lt;p&gt;네이버 전사 로그(최대 초당 수백만건, 하루 수백억건의 로그)를 수집/처리하는 로그 파이프라인 Logiss를 소개하고, Logiss에서 겪은 문제점들과 해결책들을 공유합니다.&lt;/p&gt;
        
        &lt;p&gt;Storm + kafka 환경에서 multi topology를 적용하는 방법과 이를 통해 안정적인 무중단 배포가 가능해진 파이프라인과 지능형 파이프라인의 도입으로 낮시간의 피크 트래픽을 한가한 시간으로 분산시킨 방법, 장애 상황에서 로그의 우선 순위에 따른 차등된 처리 방식, 샘플링 기능으로 저장소를 효율적으로 이용할 수 있게된 방법을 알려드립니다.&lt;/p&gt;
        
        &lt;h4 id=&quot;dan25techhttpsdannavercom25sessionsday2&quot;&gt;&lt;a href=&quot;https://dan.naver.com/25/sessions#DAY2&quot;&gt;[DAN25] Tech 세션 영상 더 보기 &gt;&gt;&lt;/a&gt;&lt;/h4&gt;
      </content:encoded>
    </item>
    <item>
      <title>경험이 쌓일수록 똑똑해지는 네이버 통합검색 LLM Devops Agent</title>
      <link>https://d2.naver.com/helloworld/4199466</link>
      <guid>https://d2.naver.com/helloworld/4199466</guid>
      <pubDate>Sun, 08 Feb 2026 08:02:45 GMT</pubDate>
      <content:encoded>
        &lt;p&gt;네이버 사내 기술 교류 행사인 NAVER ENGINEERING DAY 2025(10월)에서 발표되었던 세션을 공개합니다.&lt;br/&gt; &lt;/p&gt;
        
        &lt;div style=&quot;position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;&quot;&gt;
        
        &lt;iframe width=&quot;800&quot; height=&quot;450&quot; src=&quot;https://tv.naver.com/embed/89197961?autoPlay=true&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot; style=&quot;position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;&quot;&gt;&lt;/iframe&gt;  
        &lt;/div&gt;  
        
        &lt;p&gt;&lt;br/&gt;&lt;/p&gt;
        
        &lt;h4 id=&quot;&quot;&gt;발표 내용&lt;/h4&gt;
        
        &lt;ul&gt;
        &lt;li&gt;네이버 통합 검색에서 더 나은 장애 대응 프로세스를 위해 LLM Agent를 활용하는 방식에 대해 소개합니다.&lt;/li&gt;
        &lt;li&gt;Agent 를 어떤 방식으로 구성하고 구축했는지, 어떻게 평가하고 활용하고 있는지를 자세히 소개합니다.&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;h4 id=&quot;&quot;&gt;발표 대상&lt;/h4&gt;
        
        &lt;ul&gt;
        &lt;li&gt;네이버 검색에서 장애 감지와 분석에 대해 궁금하신 분&lt;/li&gt;
        &lt;li&gt;LLM을 활용한 Agent 구성을 고민하시는 분&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;h4 id=&quot;&quot;&gt;목차&lt;/h4&gt;
        
        &lt;ol&gt;
        &lt;li&gt;기존 장애 대응 프로세스 &lt;br /&gt;
        &lt;ul&gt;&lt;li&gt;네이버 검색 흐름&lt;/li&gt;
        &lt;li&gt;기존 장애대응 프로세스&lt;/li&gt;
        &lt;li&gt;기존 방식의 문제점&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
        &lt;li&gt;Devops Agent v1 &lt;br /&gt;
        &lt;ul&gt;&lt;li&gt;설계&lt;/li&gt;
        &lt;li&gt;v1 구조&lt;/li&gt;
        &lt;li&gt;v1 소개&lt;/li&gt;
        &lt;li&gt;현재 SW stack&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
        &lt;li&gt;Devops Agent v2 &lt;br /&gt;
        &lt;ul&gt;&lt;li&gt;v1의 한계&lt;/li&gt;
        &lt;li&gt;v2 구조&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
        &lt;li&gt;시스템 동작과 특징 &lt;br /&gt;
        &lt;ul&gt;&lt;li&gt;Trigger Queue&lt;/li&gt;
        &lt;li&gt;이상 탐지 방법&lt;/li&gt;
        &lt;li&gt;평가&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
        &lt;li&gt;우리가 풀어가고 있는 문제들 &lt;br /&gt;
        &lt;ul&gt;&lt;li&gt;알람 및 컨텍스트 확대&lt;/li&gt;
        &lt;li&gt;액션 추천&lt;/li&gt;
        &lt;li&gt;지속 가능한 Devops Agent&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
        &lt;/ol&gt;
        
        &lt;blockquote&gt;
        &lt;h5 id=&quot;naverengineeringdaybr&quot;&gt;&lt;strong&gt;◎ NAVER ENGINEERING DAY란?&lt;/strong&gt;&lt;br/&gt;&lt;/h5&gt;
        
        &lt;p&gt;NAVER에서는 사내 개발 경험과 기술 트렌드를 교류를 할 수 있는 프로그램이 많이 있습니다. 그중 매회 평균 70개 이상의 발표가 이루어지는 NAVER ENGINEERING DAY를 빼놓을 수 없는데요. &lt;br /&gt;
        2016년부터 시작된 ENGINEERING DAY는 실무에서의 기술 개발 경험과 새로운 기술과 플랫폼 도입 시 유용하게 활용될 수 있는 팁 등을 공유하며 서로 배우고 성장하는 네이버의 대표적인 사내 개발자 행사입니다. &lt;br /&gt;
        올해 진행된 NAVER ENGINEERING DAY의 일부 세션을 공개합니다.&lt;/p&gt;
        &lt;/blockquote&gt;
      </content:encoded>
    </item>
    <item>
      <title>AI와 함께하는 프로젝트 자동화 : 더 빠르고, 더 스마트하게</title>
      <link>https://d2.naver.com/helloworld/3691494</link>
      <guid>https://d2.naver.com/helloworld/3691494</guid>
      <pubDate>Sun, 08 Feb 2026 08:02:45 GMT</pubDate>
      <content:encoded>
        &lt;p&gt;네이버 사내 기술 교류 행사인 NAVER ENGINEERING DAY 2025(10월)에서 발표되었던 세션을 공개합니다.&lt;br/&gt; &lt;/p&gt;
        
        &lt;div style=&quot;position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;&quot;&gt;
        
        &lt;iframe width=&quot;800&quot; height=&quot;450&quot; src=&quot;https://tv.naver.com/embed/89131408?autoPlay=true&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot; style=&quot;position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;&quot;&gt;&lt;/iframe&gt;  
        &lt;/div&gt;  
        
        &lt;p&gt;&lt;br/&gt;&lt;/p&gt;
        
        &lt;h4 id=&quot;&quot;&gt;발표 내용&lt;/h4&gt;
        
        &lt;ul&gt;
        &lt;li&gt;로컬 환경에서 Ollama LLM과 mcp-agent를 연결해 빌드 실패 분석, 크래시 로그 요약, Slack 자동 리포트까지 구현했습니다.&lt;/li&gt;
        &lt;li&gt;AI가 단순한 도구가 아닌, 프로젝트의 자동화 동료가 되는 과정을 공유합니다.&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;h4 id=&quot;&quot;&gt;발표 대상&lt;/h4&gt;
        
        &lt;ul&gt;
        &lt;li&gt;로컬 LLM(Ollama)과 오픈소스 mcp-agent 를 활용한 AI 자동화 시스템 구축에 관심 있는 개발자&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;h4 id=&quot;&quot;&gt;목차&lt;/h4&gt;
        
        &lt;ul&gt;
        &lt;li&gt;AI와 자동화를 연결하기&lt;/li&gt;
        &lt;li&gt;LLM을 활용한 빌드 실패 알림 자동화&lt;/li&gt;
        &lt;li&gt;LLM을 활용한 크래시 모니터링 자동화&lt;/li&gt;
        &lt;li&gt;Slack with LLM&lt;/li&gt;
        &lt;li&gt;LLM &amp;amp; MCP 면 만능일까? &lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;blockquote&gt;
        &lt;h5 id=&quot;naverengineeringdaybr&quot;&gt;&lt;strong&gt;◎ NAVER ENGINEERING DAY란?&lt;/strong&gt;&lt;br/&gt;&lt;/h5&gt;
        
        &lt;p&gt;NAVER에서는 사내 개발 경험과 기술 트렌드를 교류를 할 수 있는 프로그램이 많이 있습니다. 그중 매회 평균 70개 이상의 발표가 이루어지는 NAVER ENGINEERING DAY를 빼놓을 수 없는데요. &lt;br /&gt;
        2016년부터 시작된 ENGINEERING DAY는 실무에서의 기술 개발 경험과 새로운 기술과 플랫폼 도입 시 유용하게 활용될 수 있는 팁 등을 공유하며 서로 배우고 성장하는 네이버의 대표적인 사내 개발자 행사입니다. &lt;br /&gt;
        올해 진행된 NAVER ENGINEERING DAY의 일부 세션을 공개합니다.&lt;/p&gt;
        &lt;/blockquote&gt;
      </content:encoded>
    </item>
    <item>
      <title>@RequestCache: HTTP 요청 범위 캐싱을 위한 커스텀 애너테이션 개발기</title>
      <link>https://d2.naver.com/helloworld/7610642</link>
      <guid>https://d2.naver.com/helloworld/7610642</guid>
      <pubDate>Sun, 08 Feb 2026 08:02:45 GMT</pubDate>
      <content:encoded>
        &lt;p&gt;웹 애플리케이션을 개발하다 보면 하나의 HTTP 요청 내에서 동일한 외부 API를 여러 번 호출하거나 동일한 연산을 반복하는 경우가 종종 발생합니다. 이러한 중복 호출은 응답 시간을 증가시키고 불필요한 네트워크 오버헤드를 유발합니다.&lt;/p&gt;
        
        &lt;p&gt;이 글에서는 이러한 문제를 해결하기 위해 개발한 &lt;code&gt;@RequestCache&lt;/code&gt;라는 커스텀 애너테이션의 개발 과정과 그 과정에서 겪은 시행착오를 공유하고자 합니다.&lt;/p&gt;
        
        &lt;h2 id=&quot;requestcache&quot;&gt;@RequestCache 소개&lt;/h2&gt;
        
        &lt;p&gt;다음과 같은 서비스 구조를 가정해 보겠습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/11/1-1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;위 구조에서 &lt;code&gt;OrderValidationService&lt;/code&gt;, &lt;code&gt;PaymentService&lt;/code&gt;, &lt;code&gt;NotificationService&lt;/code&gt; 각각에서 사용자의 프로필 정보가 필요하다면, 세 서비스 모두 프로필 조회 API를 호출합니다. 이러한 중복 호출은 &lt;strong&gt;응답 시간 증가&lt;/strong&gt;, &lt;strong&gt;외부 서버의 부하&lt;/strong&gt;, &lt;strong&gt;리소스 낭비&lt;/strong&gt; 등의 문제를 야기합니다.&lt;/p&gt;
        
        &lt;p&gt;이러한 문제를 해결하기 위해 @RequestCache를 개발했습니다. &lt;code&gt;@RequestCache&lt;/code&gt;는 &lt;strong&gt;HTTP 요청 범위(request scope) 내에서 메서드의 호출 결과를 캐싱&lt;/strong&gt;하는 Spring 기반의 커스텀 애너테이션입니다. 하나의 HTTP 요청 내에서 중복된 외부 API 호출이나 반복적인 연산을 방지하여 성능을 개선할 수 있습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;code&gt;@RequestCache&lt;/code&gt;는 다음과 같은 특징이 있습니다.&lt;/p&gt;
        
        &lt;ul&gt;
        &lt;li&gt;&lt;strong&gt;RequestAttribute 기반의 캐시 저장&lt;/strong&gt;: &lt;code&gt;RequestAttribute&lt;/code&gt;를 사용하여 요청별로 독립적인 캐시 인스턴스를 보장합니다. &lt;code&gt;RequestAttribute&lt;/code&gt;는 내부에서 ThreadLocal을 사용하므로 각 스레드의 인스턴스가 독립적이며 스레드 간 격리가 보장됩니다.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;자동 생명주기 관리&lt;/strong&gt;: 캐시와 HTTP 요청의 생명주기가 같으므로 별도로 TTL(time to live)을 관리할 필요가 없습니다. 요청 처리 완료 시 Spring의 &lt;code&gt;FrameworkServlet&lt;/code&gt;이 자동으로 &lt;code&gt;RequestAttribute&lt;/code&gt;를 정리해 메모리 누수를 방지합니다.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;간편한 사용법&lt;/strong&gt;: 애너테이션 하나로 손쉽게 메서드 호출 결과를 캐싱할 수 있습니다.&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;p&gt;다음과 같이 &lt;code&gt;@RequestCache&lt;/code&gt;를 선언하면, 하나의 HTTP 요청 내에서 같은 &lt;code&gt;userId&lt;/code&gt;로 &lt;code&gt;findProfileByUserId()&lt;/code&gt;을 여러 번 호출하는 경우에 실제 외부 API는 한 번만 호출되고 이후에는 캐시된 결과가 반환됩니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;@Service
        @RequiredArgsConstructor
        public class ProfileService {  
        private final ProfileApiClient profileApiClient;
        
        @RequestCache(cacheNames = &quot;findProfileByUserId&quot;)
        public Profile findProfileByUserId(Long userId) {
        // 외부 API 호출
        return profileApiClient.findProfileByUserId(userId);
        }
        }
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;h2 id=&quot;&quot;&gt;대안 검토&lt;/h2&gt;
        
        &lt;p&gt;본격적인 개발에 앞서 &lt;code&gt;@RequestCache&lt;/code&gt;가 정말 필요한지 검증하기 위해 다음 두 가지 대안을 검토했습니다.&lt;/p&gt;
        
        &lt;ul&gt;
        &lt;li&gt;응답 객체를 파라미터로 계속 넘겨주기&lt;/li&gt;
        &lt;li&gt;Redis/Local 캐시를 사용하고 TTL을 적절하게 설정하기&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;h3 id=&quot;&quot;&gt;응답 객체를 파라미터로 넘기는 방식의 한계&lt;/h3&gt;
        
        &lt;p&gt;첫 번째 대안은 응답 객체를 메서드 파라미터로 계속 전달하는 것입니다. 하지만 이 방식은 다음과 같은 문제점이 있습니다.&lt;/p&gt;
        
        &lt;h4 id=&quot;&quot;&gt;호출 깊이가 깊은 경우&lt;/h4&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;@RestController
        @RequiredArgsConstructor
        public class TransactionController {  
        private final OrderValidationService orderValidationService;
        private final PaymentService paymentService;
        private final NotificationService notificationService;
        private final ProfileService profileService;
        
        @PostMapping(&quot;/order&quot;)
        public void processOrder(@RequestParam Long orderId, @RequestParam Long userId) {
        Profile profile = profileService.getProfile(userId);
        
        // ... 주문 검증 Profile 전달
        orderValidationService.validate(orderId, profile);
        
        paymentService.purchase(orderId, profile);
        notificationService.noti(orderId, profile);
        }
        }
        
        @Service
        @RequiredArgsConstructor
        public class OrderValidationService {  
        private final DeliveryValidator deliveryValidator;
        
        public void validate(Long orderId, Profile profile) {
        // ... 주문 검증 로직 (Profile 미사용)
        
        deliveryValidator.validateDeliveryArea(orderId, profile);  // Profile 전달
        }
        }
        
        @Service
        @RequiredArgsConstructor
        public class DeliveryValidator {  
        private final PricingCalculator pricingCalculator;
        
        public void validateDeliveryArea(Long orderId, Profile profile) {
        // ... 배송 지역 검증 로직 (Profile 미사용)
        Money fee = pricingCalculator.calculateFee(orderId, profile);  // Profile 전달
        // ... 배송비 검증
        }
        }
        
        @Service
        @RequiredArgsConstructor
        public class PricingCalculator {
        
        public Money calculateFee(Long orderId, Profile profile) {
        // 실제로 Profile을 사용하는 곳은 여기뿐
        if (profile.isPremiumMember()) {
        return Money.ZERO;
        }
        return Money.of(3000);
        }
        }
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;p&gt;이 코드에서 실제로 &lt;code&gt;Profile&lt;/code&gt;을 사용하는 곳은 &lt;code&gt;PricingCalculator.calculateFee()&lt;/code&gt; 메서드뿐입니다. 하지만 이 데이터를 전달하기 위해 &lt;code&gt;OrderValidationService&lt;/code&gt; → &lt;code&gt;DeliveryValidator&lt;/code&gt; → &lt;code&gt;PricingCalculator&lt;/code&gt;의 모든 메서드가 Profile 파라미터를 선언해야 합니다.&lt;/p&gt;
        
        &lt;p&gt;즉, 응답 객체를 파라미터로 넘기는 방식은 호출 깊이가 깊은 경우에 다음과 같은 문제가 있습니다.&lt;/p&gt;
        
        &lt;ul&gt;
        &lt;li&gt;중간 계층(&lt;code&gt;OrderValidationService&lt;/code&gt;, &lt;code&gt;DeliveryValidator&lt;/code&gt;)은 응답 객체를 사용하지 않지만 파라미터로 받아야 함&lt;/li&gt;
        &lt;li&gt;호출 깊이가 깊어질수록 파라미터 전달이 복잡해짐&lt;/li&gt;
        &lt;li&gt;새로운 데이터가 필요할 때마다 모든 메서드 시그니처를 수정해야 함&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;h4 id=&quot;&quot;&gt;전략 패턴을 사용하는 경우&lt;/h4&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;public interface DiscountPolicy {  
        Money calculate(Long orderId, Profile profile);
        }
        
        @Component
        public class MemberGradeDiscountPolicy implements DiscountPolicy {  
        @Override
        public Money calculate(Long orderId, Profile profile) {
        // Profile의 등급 정보를 사용
        return switch (profile.getGrade()) {
        case GOLD -&amp;gt; Money.of(5000);
        case SILVER -&amp;gt; Money.of(3000);
        default -&amp;gt; Money.ZERO;
        };
        }
        }
        
        @Component
        public class CouponDiscountPolicy implements DiscountPolicy {  
        private final CouponRepository couponRepository;
        
        @Override
        public Money calculate(Long orderId, Profile profile) {
        // Profile을 사용하지 않지만 인터페이스 때문에 선언해야 함
        return couponRepository.findByOrderId(orderId)
        .map(Coupon::getDiscountAmount)
        .orElse(Money.ZERO);
        }
        }
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;p&gt;인터페이스에 Profile을 추가하면, 실제로 Profile이 필요하지 않은 &lt;code&gt;CouponDiscountPolicy&lt;/code&gt;도 Profile을 파라미터로 받아야 합니다. 이는 불필요한 의존성을 만들고 인터페이스의 유연성을 해칩니다.&lt;/p&gt;
        
        &lt;p&gt;즉, 파라미터 전달 방식은 호출 깊이가 깊거나 전략 패턴을 사용하는 경우에 적용하기 어렵습니다.&lt;/p&gt;
        
        &lt;h3 id=&quot;redislocalttl&quot;&gt;Redis/Local 캐시의 TTL 설정 딜레마&lt;/h3&gt;
        
        &lt;p&gt;두 번째 대안은 Redis나 Local 캐시를 사용하고 적절한 TTL을 설정하는 것입니다. 하지만 이 방식도 다음과 같은 문제가 있습니다.&lt;/p&gt;
        
        &lt;h4 id=&quot;ttl&quot;&gt;TTL이 너무 짧은 경우&lt;/h4&gt;
        
        &lt;p&gt;TTL이 너무 짧으면, 하나의 요청 내에서 같은 데이터를 두 번 조회하는 경우에 두 번째 조회 시 첫 번째 캐시가 만료되어 다시 API를 호출해야 합니다. 이는 중복 호출을 방지하려는 원래 목적을 달성하지 못합니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/11/2-1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;예를 들어, 요청 처리 시간이 5초인데 TTL을 3초로 설정한 경우 다음과 같이 동작합니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code&gt;Request A 시작(0초)  
        ├─ Profile 조회(0.1초) - 캐시 미스, 캐시에 저장(3초 후 만료)
        ├─ 비즈니스 로직 처리(0.1~3.5초)
        ├─ Profile 조회(3.5초) - TTL 만료로 캐시 미스(중복 호출 발생)
        └─ Request A 종료(5초)
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;h4 id=&quot;ttl&quot;&gt;TTL이 너무 긴 경우&lt;/h4&gt;
        
        &lt;p&gt;TTL을 길게 설정해도 만료 시점에 따라 캐시 효과가 불안정합니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/11/3-1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;요청 B는 요청 A에서 생성된 캐시를 사용합니다. @RequestCache의 목적은 동일 요청 내 중복 호출 방지이므로, 논리적으로 서로 다른 요청 간에 캐시를 공유하는 것은 의도하지 않은 동작입니다. 요청 C에서는 캐시가 만료되어 다시 캐시 미스가 발생합니다.&lt;/p&gt;
        
        &lt;p&gt;예를 들어, 요청 처리 시간이 3초인데 TTL을 10초로 설정한 경우 다음과 같이 동작합니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code&gt;요청 A 시작(0초)
        ├─ Profile 조회(0.5초) - 캐시 미스, 캐시에 저장(10초 후 만료)
        └─ 요청 A 종료(3초)
        
        요청 B 시작(5초)
        ├─ Profile 조회(5.5초) - 캐시 적중(요청 A의 캐시 사용)
        └─ 요청 B 종료(8초)
        
        요청 C 시작(11초)
        ├─ Profile 조회(11.5초) - 캐시 미스(요청 A의 캐시 만료)
        └─ 요청 C 종료(14초)
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;p&gt;즉, 적절한 TTL을 설정하기 어려우므로 Redis/Local 캐시는 HTTP 요청 범위 캐싱에 적합하지 않으며, 요청 범위와 일치하는 생명주기의 캐시가 필요하다는 결론에 도달했습니다.&lt;/p&gt;
        
        &lt;h2 id=&quot;requestscope&quot;&gt;@RequestScope를 이용한 첫 번째 시도&lt;/h2&gt;
        
        &lt;p&gt;Spring의 &lt;code&gt;@RequestScope&lt;/code&gt;는 Bean의 생명주기를 HTTP 요청 범위로 설정합니다. 이를 CacheManager에 적용하면 간단하게 요청별 캐싱을 구현할 수 있을 것 같았습니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;@Config
        public class CacheConfig {  
        @Bean
        @RequestScope
        public CacheManager requestCacheManager() {
        return new ConcurrentMapCacheManager();
        }
        }
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;h3 id=&quot;requestscope&quot;&gt;@RequestScope의 동작 원리&lt;/h3&gt;
        
        &lt;p&gt;&lt;code&gt;@RequestScope&lt;/code&gt;를 제대로 이해하고 사용하기 위해서는 먼저 다음 두 가지 의문점을 해결해야 했습니다.&lt;/p&gt;
        
        &lt;ul&gt;
        &lt;li&gt;@RequestScope Bean은 어떻게 요청마다 다른 인스턴스를 사용할까?&lt;/li&gt;
        &lt;li&gt;@RequestScope를 붙이면 요청별로 완전히 분리될까?&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;h4 id=&quot;proxy&quot;&gt;Proxy 패턴을 통한 요청별 인스턴스 관리&lt;/h4&gt;
        
        &lt;p&gt;첫 번째 의문의 핵심은 &lt;strong&gt;Proxy&lt;/strong&gt;였습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/11/4-1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;&lt;code&gt;@RequestScope&lt;/code&gt;로 선언된 Bean은 Spring Container에 Proxy 객체로 등록됩니다. 이 Proxy는 싱글턴으로 관리되지만, 실제 메서드 호출 시 현재 요청에 해당하는 실제 인스턴스를 조회하여 메서드 호출을 위임합니다. 각 HTTP 요청마다 새로운 실제 인스턴스가 생성되어 사용됩니다.&lt;/p&gt;
        
        &lt;h4 id=&quot;requestattribute&quot;&gt;RequestAttribute를 통한 요청별 분리와 자동 정리&lt;/h4&gt;
        
        &lt;p&gt;두 번째 의문에 대한 답은 Spring의 &lt;code&gt;AbstractRequestAttributesScope&lt;/code&gt; 클래스를 살펴보면 알 수 있습니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;// AbstractRequestAttributesScope.class
        public abstract class AbstractRequestAttributesScope implements Scope {
        
        @Override
        public Object get(String name, ObjectFactory&amp;lt;?&amp;gt; objectFactory) {
        RequestAttributes attributes = RequestContextHolder.currentRequestAttributes();
        Object scopedObject = attributes.getAttribute(name, this.getScope());
        if (scopedObject == null) {
        scopedObject = objectFactory.getObject();
        attributes.setAttribute(name, scopedObject, this.getScope());
        Object retrievedObject = attributes.getAttribute(name, this.getScope());
        if (retrievedObject != null) {
        scopedObject = retrievedObject;
        }
        }
        
        return scopedObject;
        }
        }
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;p&gt;&lt;code&gt;@RequestScope&lt;/code&gt; Bean의 실제 인스턴스는 &lt;code&gt;RequestAttribute&lt;/code&gt;에 저장됩니다. &lt;code&gt;RequestAttribute&lt;/code&gt;는 &lt;code&gt;FrameworkServlet&lt;/code&gt;에서 생성되므로 요청별로 완전히 분리됩니다. 또한 내부에서 &lt;code&gt;ThreadLocal&lt;/code&gt;을 사용해 thread-safe를 보장합니다.&lt;/p&gt;
        
        &lt;p&gt;RequestAttribute의 자동 정리 메커니즘에 대해서 좀 더 자세히 알아보겠습니다. &lt;code&gt;RequestAttribute&lt;/code&gt;에 저장된 데이터는 요청 종료 시 자동으로 정리되는데, 이는 &lt;code&gt;FrameworkServlet&lt;/code&gt;의 &lt;code&gt;processRequest()&lt;/code&gt; 메서드에서 보장됩니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;// FrameworkServlet.class
        public abstract class FrameworkServlet extends HttpServletBean {
        
        protected final void processRequest(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {
        long startTime = System.currentTimeMillis();
        Throwable failureCause = null;
        LocaleContext previousLocaleContext = LocaleContextHolder.getLocaleContext();
        LocaleContext localeContext = this.buildLocaleContext(request);
        RequestAttributes previousAttributes = RequestContextHolder.getRequestAttributes();
        ServletRequestAttributes requestAttributes = this.buildRequestAttributes(request, response, previousAttributes);
        WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request);
        asyncManager.registerCallableInterceptor(FrameworkServlet.class.getName(), new RequestBindingInterceptor());
        this.initContextHolders(request, localeContext, requestAttributes);
        
        try {
        this.doService(request, response);
        } catch (IOException | ServletException ex) {
        failureCause = ex;
        throw ex;
        } catch (Throwable ex) {
        failureCause = ex;
        throw new ServletException(&quot;Request processing failed: &quot; + ex, ex);
        } finally {
        this.resetContextHolders(request, previousLocaleContext, previousAttributes);
        if (requestAttributes != null) {
        requestAttributes.requestCompleted();
        }
        
        this.logResult(request, response, failureCause, asyncManager);
        this.publishRequestHandledEvent(request, response, startTime, failureCause);
        }
        }
        }
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;p&gt;&lt;code&gt;finally&lt;/code&gt; 블록에서 &lt;code&gt;requestAttributes.requestCompleted()&lt;/code&gt;를 호출하여, 요청이 정상 종료되든 예외가 발생하든 관계없이 RequestAttribute가 반드시 정리됩니다. 그 결과 메모리 누수가 방지됩니다.&lt;/p&gt;
        
        &lt;h3 id=&quot;springactuator&quot;&gt;Spring Actuator와의 충돌&lt;/h3&gt;
        
        &lt;p&gt;&lt;code&gt;@RequestScope&lt;/code&gt;를 적용하고 애플리케이션을 실행하자 예상치 못한 문제가 발생했습니다. &lt;code&gt;ScopeNotActiveException&lt;/code&gt;이 발생해 애플리케이션이 실행되지 않았습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/11/5-1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;pre&gt;&lt;code&gt;Error creating bean with name &apos;cacheManager&apos;: Scope &apos;request&apos; is not active  
        for the current thread; consider defining a scoped proxy for this bean  
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;h4 id=&quot;&quot;&gt;오류 발생 원인&lt;/h4&gt;
        
        &lt;p&gt;원인은 Spring Actuator의 &lt;code&gt;CacheMetricsAutoConfiguration&lt;/code&gt;과의 충돌이었습니다. &lt;code&gt;CacheMetricsAutoConfiguration&lt;/code&gt;은 애플리케이션 시작 시점에 실행되는데, 이때는 HTTP 요청이 없어 &lt;code&gt;RequestScope&lt;/code&gt;가 활성화되지 않습니다.&lt;/p&gt;
        
        &lt;p&gt;오류가 발생하는 전체 흐름은 다음과 같습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;code&gt;@RequestScope&lt;/code&gt; Bean의 Proxy가 실제 타겟 객체를 resolve하기 위해 &lt;code&gt;Scope&lt;/code&gt; 인터페이스의 &lt;code&gt;get()&lt;/code&gt; 메서드를 호출합니다. &lt;code&gt;@RequestScope&lt;/code&gt;의 경우 &lt;code&gt;AbstractRequestAttributesScope.get()&lt;/code&gt;이 호출됩니다. 이때 &lt;code&gt;RequestContextHolder.currentRequestAttributes()&lt;/code&gt;가 호출됩니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;// AbstractRequestAttributesScope.class
        public abstract class AbstractRequestAttributesScope implements Scope {
        
        public Object get(String name, ObjectFactory&amp;lt;?&amp;gt; objectFactory) {
        RequestAttributes attributes = RequestContextHolder.currentRequestAttributes();
        ...
        }
        }
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;p&gt;&lt;code&gt;currentRequestAttributes()&lt;/code&gt; 메서드에서 HTTP 요청이 활성화되지 않은 경우 &lt;code&gt;IllegalStateException&lt;/code&gt;이 발생합니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;// RequestContextHolder.class
        public abstract class RequestContextHolder {
        
        public static RequestAttributes currentRequestAttributes() throws IllegalStateException {
        RequestAttributes attributes = getRequestAttributes();
        if (attributes == null) {
        if (jsfPresent) {
        attributes = RequestContextHolder.FacesRequestAttributesFactory.getFacesRequestAttributes();
        }
        if (attributes == null) {
        // HTTP 요청이 활성화되지 않은 경우
        throw new IllegalStateException(
        &quot;No thread-bound request found:...&quot;);
        }
        }
        return attributes;
        }
        }
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;p&gt;&lt;code&gt;AbstractBeanFactory&lt;/code&gt;에서 이를 catch하여 &lt;code&gt;ScopeNotActiveException&lt;/code&gt;을 던집니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;// AbstractBeanFactory.class
        public abstract class AbstractBeanFactory extends FactoryBeanRegistrySupport  
        implements ConfigurableBeanFactory {
        
        protected &amp;lt;T&amp;gt; T doGetBean(String name, ...) throws BeansException {
        ...
        catch (IllegalStateException ex) {
        throw new ScopeNotActiveException(beanName, scopeName, ex);
        }
        ...
        }
        }
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;h4 id=&quot;&quot;&gt;임시 해결책 및 한계&lt;/h4&gt;
        
        &lt;p&gt;&lt;code&gt;CacheMetricsAutoConfiguration&lt;/code&gt;을 제외하면 기술적으로는 동작하지만 캐시 적중/미스와 같은 중요한 메트릭을 수집할 수 없습니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;@Config
        @EnableAutoConfiguration(exclude = {CacheMetricsAutoConfiguration.class})
        public class CacheConfig {  
        @Bean
        @RequestScope
        public CacheManager requestCacheManager() {
        return new ConcurrentMapCacheManager();
        }
        }
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;p&gt;이는 근본적인 해결책이 아니므로 다른 방식을 고민했습니다.&lt;/p&gt;
        
        &lt;h2 id=&quot;cachemanager&quot;&gt;최종 해결책: 커스텀 CacheManager&lt;/h2&gt;
        
        &lt;p&gt;&lt;code&gt;@RequestScope&lt;/code&gt; 방식은 &lt;code&gt;RequestAttribute&lt;/code&gt;에 &lt;code&gt;CacheManager&lt;/code&gt; 인스턴스를 저장하므로 애플리케이션 시작 시점에 resolve를 시도해 오류가 발생했습니다. 이 과정에서 얻은 인사이트를 바탕으로, 다음과 같은 커스텀 방식을 설계했습니다.&lt;/p&gt;
        
        &lt;ul&gt;
        &lt;li&gt;&lt;code&gt;CacheManager&lt;/code&gt; 자체는 싱글턴으로 유지&lt;/li&gt;
        &lt;li&gt;&lt;code&gt;RequestAttribute&lt;/code&gt;에 &lt;strong&gt;Cache 객체&lt;/strong&gt;를 저장&lt;/li&gt;
        &lt;li&gt;HTTP 요청 활성화 여부를 확인해 적절히 처리&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/11/6-2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;커스텀 방식은 &lt;code&gt;RequestAttribute&lt;/code&gt;에 Cache 객체를 저장하므로, 애플리케이션 시작 시점에는 &lt;code&gt;CacheManager&lt;/code&gt;만 사용해 오류가 발생하지 않습니다.&lt;/p&gt;
        
        &lt;h3 id=&quot;1cachemanager&quot;&gt;1. 커스텀 CacheManager 구현&lt;/h3&gt;
        
        &lt;p&gt;이러한 커스텀 방식을 구현하기 위해서는 Spring의 &lt;code&gt;CacheManager&lt;/code&gt; 인터페이스를 직접 구현해야 합니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/11/7-2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;h4 id=&quot;http&quot;&gt;HTTP 요청 컨텍스트 활성화 확인&lt;/h4&gt;
        
        &lt;p&gt;먼저, HTTP 요청이 활성화되어 있는지 확인하는 유틸리티 메서드를 구현합니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;// RequestScopedCacheManager.class
        
        private boolean isRequestContextActive() {  
        try {
        RequestContextHolder.currentRequestAttributes();
        return true;
        } catch (IllegalStateException e) {
        // HTTP 요청이 활성화되지 않은 경우
        return false;
        }
        }
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;p&gt;앞에서 본 것처럼 &lt;code&gt;IllegalStateException&lt;/code&gt;이 발생하면 요청이 활성화되지 않은 것으로 판단합니다.&lt;/p&gt;
        
        &lt;h4 id=&quot;getcache&quot;&gt;핵심 로직 getCache() 구현&lt;/h4&gt;
        
        &lt;p&gt;&lt;code&gt;RequestScopedCacheManager&lt;/code&gt;의 핵심은 &lt;code&gt;getCache()&lt;/code&gt; 구현입니다. &lt;code&gt;CacheManager&lt;/code&gt;의 &lt;code&gt;getCache()&lt;/code&gt; 메서드는 주어진 이름에 해당하는 캐시를 반환하는 역할을 합니다. &lt;code&gt;@Cacheable&lt;/code&gt; 등의 애너테이션이 동작할 때 캐시를 가져오기 위해 이 메서드를 사용합니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;// RequestScopedCacheManager.class
        
        @Override
        public Cache getCache(String name) {  
        try {
        // 1. 요청 컨텍스트 활성화 확인
        if (!isRequestContextActive()) {
        return new NoOpCache(name);
        }
        
        // 2. RequestAttribute에서 캐시 조회
        RequestAttributes requestAttributes = RequestContextHolder.currentRequestAttributes();
        String cacheKey = CACHE_ATTRIBUTE_PREFIX + name;
        Cache cache = (Cache)requestAttributes.getAttribute(cacheKey, RequestAttributes.SCOPE_REQUEST);
        
        // 3. 캐시가 없으면 생성 후 RequestAttribute에 저장
        if (cache == null) {
        cache = createNewCache(name);
        requestAttributes.setAttribute(cacheKey, cache, RequestAttributes.SCOPE_REQUEST);
        }
        
        return cache;
        } catch (Exception e) {
        log.warn(&quot;요청 캐시 조회 실패 - 캐시 비활성화&quot;, e);
        return new NoOpCache(name);
        }
        }
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;p&gt;동작 흐름은 다음과 같습니다.&lt;/p&gt;
        
        &lt;ol&gt;
        &lt;li&gt;&lt;strong&gt;요청 컨텍스트 활성화 확인&lt;/strong&gt;: HTTP 요청이 활성화되지 않은 경우 &lt;code&gt;NoOpCache&lt;/code&gt; 반환  &lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;RequestAttribute에서 캐시 조회&lt;/strong&gt;: 요청별로 저장된 캐시 조회  &lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;캐시 생성 및 저장&lt;/strong&gt;: 캐시가 없으면 새로 생성해 RequestAttribute에 저장  &lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;예외 처리&lt;/strong&gt;: 예상치 못한 오류 발생 시에도 &lt;code&gt;NoOpCache&lt;/code&gt;를 반환해 안전하게 처리&lt;/li&gt;
        &lt;/ol&gt;
        
        &lt;p&gt;1번 과정에서 &lt;code&gt;null&lt;/code&gt; 대신 &lt;code&gt;NoOpCache&lt;/code&gt;를 반환하는 이유를 알아보겠습니다.&lt;/p&gt;
        
        &lt;p&gt;Spring의 &lt;code&gt;CacheManager&lt;/code&gt; 인터페이스 명세를 보면 &lt;code&gt;getCache()&lt;/code&gt; 메서드는 캐시가 없거나 생성할 수 없을 때 &lt;code&gt;null&lt;/code&gt;을 반환하도록 정의되어 있습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/11/8-2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;p&gt;하지만 실제로 &lt;code&gt;null&lt;/code&gt;을 반환하면 Spring의 &lt;code&gt;AbstractCacheResolver&lt;/code&gt;에서 오류가 발생합니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;// AbstractCacheResolver.class
        public abstract class AbstractCacheResolver implements CacheResolver {
        
        @Override
        public Collection&amp;lt;? extends Cache&amp;gt; resolveCaches(CacheOperationInvocationContext&amp;lt;?&amp;gt; context) {
        Collection&amp;lt;String&amp;gt; cacheNames = getCacheNames(context);
        if (cacheNames == null) {
        return Collections.emptyList();
        }
        Collection&amp;lt;Cache&amp;gt; result = new ArrayList&amp;lt;&amp;gt;(cacheNames.size());
        for (String cacheName : cacheNames) {
        Cache cache = getCacheManager().getCache(cacheName);
        if (cache == null) {
        // null을 반환하면 여기서 예외 발생!
        throw new IllegalArgumentException(&quot;Cannot find cache named &apos;&quot; +
        cacheName + &quot;&apos; for &quot; + context.getOperation());
        }
        result.add(cache);
        }
        return result;
        }
        }
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;p&gt;&lt;code&gt;AbstractCacheResolver&lt;/code&gt;는 &lt;code&gt;@Cacheable&lt;/code&gt;, &lt;code&gt;@CacheEvict&lt;/code&gt; 등의 애너테이션에서 어떤 캐시를 사용할지 결정하는 클래스입니다. 이 클래스는 &lt;code&gt;getCache()&lt;/code&gt;가 &lt;code&gt;null&lt;/code&gt;을 반환하면 &lt;code&gt;IllegalArgumentException&lt;/code&gt;을 던집니다.&lt;/p&gt;
        
        &lt;p&gt;이를 방지하기 위해 Spring의 &lt;code&gt;NoOpCache&lt;/code&gt;를 반환합니다. &lt;code&gt;NoOpCache&lt;/code&gt;는 캐싱을 수행하지 않는 더미 구현체로, 요청 컨텍스트가 비활성화된 환경에서도 오류 없이 정상 동작하도록 합니다. 단, 실제 캐싱은 되지 않으므로 매번 메서드가 실행됩니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;// NoOpCache.class
        public class NoOpCache implements Cache {
        
        private final String name;
        
        @Override
        public ValueWrapper get(Object key) {
        return null; // 항상 캐시 미스
        }
        
        @Override
        public void put(Object key, Object value) {
        // 아무 동작도 하지 않음
        }
        
        // ... 나머지 메서드도 모두 no-op
        }
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;h4 id=&quot;&quot;&gt;전체 구현 코드&lt;/h4&gt;
        
        &lt;p&gt;&lt;code&gt;RequestScopedCacheManager&lt;/code&gt;의 전체 코드는 다음과 같습니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;// RequestScopedCacheManager.class
        public class RequestScopedCacheManager implements CacheManager {
        
        private static final String CACHE_ATTRIBUTE_PREFIX = &quot;requestCache.&quot;;
        
        @Override
        public Cache getCache(String name) {
        try {
        if (!isRequestContextActive()) {
        return new NoOpCache(name);
        }
        
        RequestAttributes requestAttributes = RequestContextHolder.currentRequestAttributes();
        String cacheKey = CACHE_ATTRIBUTE_PREFIX + name;
        Cache cache = (Cache)requestAttributes.getAttribute(cacheKey, RequestAttributes.SCOPE_REQUEST);
        
        if (cache == null) {
        cache = createNewCache(name);
        requestAttributes.setAttribute(cacheKey, cache, RequestAttributes.SCOPE_REQUEST);
        }
        
        return cache;
        } catch (Exception e) {
        log.warn(&quot;요청 캐시 조회 실패 - 캐시 비활성화&quot;, e);
        return new NoOpCache(name);
        }
        }
        
        @Override
        public Collection&amp;lt;String&amp;gt; getCacheNames() {
        if (!isRequestContextActive()) {
        return Collections.emptyList();
        }
        return Collections.singletonList(&quot;requestCache&quot;);
        }
        
        private Cache createNewCache(String name) {
        return new ConcurrentMapCache(name, new ConcurrentHashMap&amp;lt;&amp;gt;(), false);
        }
        
        private boolean isRequestContextActive() {
        try {
        RequestContextHolder.currentRequestAttributes();
        return true;
        } catch (IllegalStateException e) {
        // HTTP 요청이 활성화되지 않은 경우
        return false;
        }
        }
        }
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;h3 id=&quot;2requestcache&quot;&gt;2. @RequestCache 애너테이션 생성&lt;/h3&gt;
        
        &lt;p&gt;이제 사용 편의성을 위해 커스텀 애너테이션을 만들겠습니다. &lt;code&gt;@Cacheable&lt;/code&gt;을 메타 애너테이션으로 사용해 Spring의 기존 캐싱 기능을 그대로 활용하면서, 앞에서 개발한 커스텀 CacheManager를 &lt;code&gt;cacheManager&lt;/code&gt;에 지정합니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;@Target({ElementType.TYPE, ElementType.METHOD})
        @Retention(RetentionPolicy.RUNTIME)
        @Documented
        @Cacheable(cacheManager = &quot;requestScopedCacheManager&quot;)
        public @interface RequestCache {
        
        @AliasFor(annotation = Cacheable.class, attribute = &quot;value&quot;)
        String[] value() default {&quot;requestCache&quot;};
        
        @AliasFor(annotation = Cacheable.class, attribute = &quot;cacheNames&quot;)
        String[] cacheNames() default {&quot;requestCache&quot;};
        
        @AliasFor(annotation = Cacheable.class, attribute = &quot;condition&quot;)
        String condition() default &quot;&quot;;
        
        @AliasFor(annotation = Cacheable.class, attribute = &quot;unless&quot;)
        String unless() default &quot;#result == null&quot;;
        }
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;h3 id=&quot;3bean&quot;&gt;3. Bean 등록&lt;/h3&gt;
        
        &lt;p&gt;일반적인 싱글턴 Bean으로 등록하며, &lt;code&gt;@EnableCaching&lt;/code&gt;으로 Spring의 캐싱 기능을 활성화합니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;@Configuration
        @EnableCaching
        public class CacheConfig {
        
        @Bean
        public CacheManager requestScopedCacheManager() {
        return new RequestScopedCacheManager();
        }
        }
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;h3 id=&quot;4&quot;&gt;4. 사용 예&lt;/h3&gt;
        
        &lt;p&gt;애너테이션까지 만들었으면 다음과 같이 간편하게 사용할 수 있습니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;@Service
        @RequiredArgsConstructor
        public class ProfileService {  
        private final ProfileApiClient profileApiClient;
        
        @RequestCache(cacheNames = &quot;findProfileByUserId&quot;)
        public Profile findProfileByUserId(Long userId) {
        // 외부 API 호출
        return profileApiClient.findProfileByUserId(userId);
        }
        }
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;h2 id=&quot;&quot;&gt;동작 검증&lt;/h2&gt;
        
        &lt;p&gt;실제 동작을 검증하기 위해 동일한 요청 내에서 4번 호출하는 테스트를 수행했습니다.&lt;/p&gt;
        
        &lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;@Override
        public void findByProfileId(ProfileId profileId) {  
        accountReadPort.findByProfileId(profileId);
        accountReadPort.findByProfileId(profileId); // requestCache
        accountReadPort.findByProfileId(profileId); // requestCache
        accountReadPort.findByProfileId(profileId); // requestCache
        }
        &lt;/code&gt;&lt;/pre&gt;
        
        &lt;h3 id=&quot;&quot;&gt;첫 번째 호출 결과&lt;/h3&gt;
        
        &lt;p&gt;&lt;code&gt;cache&lt;/code&gt;가 &lt;code&gt;null&lt;/code&gt;인 것과 캐시 생성 로직이 실행되는 것을 확인했습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/11/9-2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;h3 id=&quot;&quot;&gt;두 번째 이후 호출 결과&lt;/h3&gt;
        
        &lt;p&gt;하나의 요청 내에서 두 번째 호출부터는 &lt;code&gt;RequestAttribute&lt;/code&gt;에 저장된 캐시를 가져와 사용해 실제로 중복 호출이 방지되는 것을 확인했습니다.&lt;/p&gt;
        
        &lt;p&gt;&lt;img src=&quot;/content/images/2025/11/10-1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
        
        &lt;h2 id=&quot;&quot;&gt;한계점&lt;/h2&gt;
        
        &lt;p&gt;&lt;code&gt;@RequestCache&lt;/code&gt;는 요청 컨텍스트 기반으로 동작하기 때문에 다음과 같은 한계가 있습니다.&lt;/p&gt;
        
        &lt;h3 id=&quot;async&quot;&gt;@Async 메서드에서 사용 불가&lt;/h3&gt;
        
        &lt;p&gt;&lt;code&gt;@Async&lt;/code&gt;로 선언된 비동기 메서드는 별도의 스레드에서 실행됩니다. &lt;code&gt;RequestContextHolder&lt;/code&gt;는 전파 모드를 제공하지만, FrameworkServlet에서 &lt;code&gt;inheritable&lt;/code&gt;을 &lt;code&gt;false&lt;/code&gt;로 설정하기 때문에 자식 스레드로 전파되지 않습니다. 따라서 비동기 메서드에서 &lt;code&gt;@RequestCache&lt;/code&gt;를 사용하면 캐싱이 동작하지 않으며, 오류가 발생하지는 않지만 매번 실제 메서드가 실행됩니다.&lt;/p&gt;
        
        &lt;h3 id=&quot;kafkaconsumer&quot;&gt;Kafka Consumer에서 사용 불가&lt;/h3&gt;
        
        &lt;p&gt;Kafka Consumer는 HTTP 요청 컨텍스트가 아닌 메시지 처리 컨텍스트에서 실행됩니다. 따라서 &lt;code&gt;@RequestCache&lt;/code&gt;를 적용해도 캐싱이 동작하지 않으며, 매번 실제 로직이 수행됩니다.&lt;/p&gt;
        
        &lt;h3 id=&quot;threadlocal&quot;&gt;고려했던 대안: ThreadLocal&lt;/h3&gt;
        
        &lt;p&gt;요청 컨텍스트의 한계를 극복하기 위해 ThreadLocal 방식도 고려해 보았습니다. ThreadLocal을 사용하면 각 스레드의 캐시가 독립적이므로 @Async나 Kafka Consumer 환경에서도 동작할 수 있습니다.&lt;/p&gt;
        
        &lt;p&gt;하지만 ThreadLocal 방식은 다음과 같은 문제점이 있어 채택하지 않았습니다.&lt;/p&gt;
        
        &lt;h4 id=&quot;&quot;&gt;복잡한 생명주기 관리&lt;/h4&gt;
        
        &lt;p&gt;ThreadLocal에 저장된 캐시는 자동으로 정리되지 않기 때문에, HTTP 요청, Kafka 메시지 처리 등 각 생명주기마다 수동으로 &lt;code&gt;clear()&lt;/code&gt;를 호출해야 합니다. AOP나 Interceptor를 통한 자동 정리가 필요하지만, 모든 케이스를 커버하기 어렵습니다. 각 실행 컨텍스트(HTTP 요청, Kafka Consumer, @Async 등)마다 정리 로직을 구현해야 하며, 테스트 환경에서도 별도의 정리 로직이 필요합니다. 이는 코드의 복잡도를 크게 증가시킵니다.&lt;/p&gt;
        
        &lt;h4 id=&quot;&quot;&gt;메모리 누수 위험&lt;/h4&gt;
        
        &lt;p&gt;실수로 캐시를 정리하지 않으면 ThreadLocal에 캐시가 계속 남아 메모리 누수가 발생합니다. 특히 스레드 풀을 사용하는 환경에서는 스레드가 재사용되면서 이전 작업의 캐시가 남아있어 더욱 심각한 문제가 될 수 있습니다.&lt;/p&gt;
        
        &lt;p&gt;따라서 &lt;code&gt;@Async&lt;/code&gt;와 Kafka Consumer에서는 캐싱이 되지 않더라도, 비교적 간단하고 안전한 요청 컨텍스트 방식을 채택했습니다.&lt;/p&gt;
        
        &lt;h2 id=&quot;&quot;&gt;마치며&lt;/h2&gt;
        
        &lt;p&gt;&lt;code&gt;@RequestCache&lt;/code&gt;는 HTTP 요청 범위 캐싱이라는 특정 문제를 해결하기 위해 만들어졌습니다. 완벽하지는 않지만, 실용적이고 안전한 해결책이 되었다고 생각합니다.&lt;/p&gt;
        
        &lt;p&gt;혹시 이 글을 읽으신 분 중에 &lt;code&gt;@Async&lt;/code&gt;나 Kafka Consumer 환경에서도 안전하게 동작하는 더 나은 아이디어가 있는 분이 계시다면, 언제든지 의견을 주시면 감사하겠습니다!&lt;/p&gt;
      </content:encoded>
    </item>
    <item>
      <title>이건 첫 번째 클릭! 히트맵 같이 보기</title>
      <link>https://d2.naver.com/helloworld/0957098</link>
      <guid>https://d2.naver.com/helloworld/0957098</guid>
      <pubDate>Sun, 08 Feb 2026 08:02:45 GMT</pubDate>
      <content:encoded>
        &lt;p&gt;네이버 사내 기술 교류 행사인 NAVER ENGINEERING DAY 2025(10월)에서 발표되었던 세션을 공개합니다.&lt;br/&gt; &lt;/p&gt;
        
        &lt;div style=&quot;position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;&quot;&gt;
        
        &lt;iframe width=&quot;800&quot; height=&quot;450&quot; src=&quot;https://tv.naver.com/embed/89068823?autoPlay=true&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot; style=&quot;position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;&quot;&gt;&lt;/iframe&gt;  
        &lt;/div&gt;  
        
        &lt;p&gt;&lt;br/&gt;&lt;/p&gt;
        
        &lt;h4 id=&quot;&quot;&gt;발표 내용&lt;/h4&gt;
        
        &lt;ul&gt;
        &lt;li&gt;네이버 통합검색의 클릭 로그를 히트맵과 히스토그램으로 시각화하여 직관적으로 사용자 행동을 파악할 수 있는 기술을 소개합니다.&lt;/li&gt;
        &lt;li&gt;실시간으로 진화하는 네이버 검색 서비스를 대응하기 위해 겪은 시행착오와 노하우를 공유합니다.&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;h4 id=&quot;&quot;&gt;발표 대상&lt;/h4&gt;
        
        &lt;ul&gt;
        &lt;li&gt;웹 페이지 사용자 소비를 시각적 요소로 확인하고 싶은 분&lt;/li&gt;
        &lt;li&gt;정량적 데이터를 이해하는 데 어려움을 겪는 분&lt;/li&gt;
        &lt;li&gt;데이터 시각화를 기반으로 서비스 개선의 직관적 근거를 찾고자 하는 분&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;blockquote&gt;
        &lt;h5 id=&quot;naverengineeringdaybr&quot;&gt;&lt;strong&gt;◎ NAVER ENGINEERING DAY란?&lt;/strong&gt;&lt;br/&gt;&lt;/h5&gt;
        
        &lt;p&gt;NAVER에서는 사내 개발 경험과 기술 트렌드를 교류를 할 수 있는 프로그램이 많이 있습니다. 그중 매회 평균 70개 이상의 발표가 이루어지는 NAVER ENGINEERING DAY를 빼놓을 수 없는데요. &lt;br /&gt;
        2016년부터 시작된 ENGINEERING DAY는 실무에서의 기술 개발 경험과 새로운 기술과 플랫폼 도입 시 유용하게 활용될 수 있는 팁 등을 공유하며 서로 배우고 성장하는 네이버의 대표적인 사내 개발자 행사입니다. &lt;br /&gt;
        올해 진행된 NAVER ENGINEERING DAY의 일부 세션을 공개합니다.&lt;/p&gt;
        &lt;/blockquote&gt;
      </content:encoded>
    </item>
    <item>
      <title>DBT, Airflow를 활용한 데이터 계보 중심 파이프라인 만들기</title>
      <link>https://d2.naver.com/helloworld/8992409</link>
      <guid>https://d2.naver.com/helloworld/8992409</guid>
      <pubDate>Sun, 08 Feb 2026 08:02:45 GMT</pubDate>
      <content:encoded>
        &lt;p&gt;네이버 사내 기술 교류 행사인 NAVER ENGINEERING DAY 2025(10월)에서 발표되었던 세션을 공개합니다.&lt;br/&gt; &lt;/p&gt;
        
        &lt;div style=&quot;position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;&quot;&gt;
        
        &lt;iframe width=&quot;800&quot; height=&quot;450&quot; src=&quot;https://tv.naver.com/embed/88994525?autoPlay=true&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot; style=&quot;position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;&quot;&gt;&lt;/iframe&gt;  
        &lt;/div&gt;  
        
        &lt;p&gt;&lt;br/&gt;&lt;/p&gt;
        
        &lt;h4 id=&quot;&quot;&gt;발표 내용&lt;/h4&gt;
        
        &lt;ul&gt;
        &lt;li&gt;과거 데이터 파이프라인의 문제를 해결하고 사용자 중심의 on-demand data lineage pipeline 서비스인 Flow.er를 개발하고 발전시킨 내용에 대해 소개합니다&lt;/li&gt;
        &lt;li&gt;DBT, Airflow를 활용하여 어떻게 데이터 계보 중심 파이프라인을 구축했는지 공유 합니다&lt;/li&gt;
        &lt;li&gt;데이터 파이프라인 플랫폼으로써 여러 데이터 조직으로 확장하기 위한 개발 컴포넌트들을 소개합니다&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;h4 id=&quot;&quot;&gt;발표 대상&lt;/h4&gt;
        
        &lt;ul&gt;
        &lt;li&gt;DBT, Airflow를 활용하여 품질 높은 Data Product 운영이 필요한 분들&lt;/li&gt;
        &lt;li&gt;DBT 운영 도입을 고려중인 Data Engineer&lt;/li&gt;
        &lt;li&gt;Airflow를 활용하고 있으나 과거 데이터 적재(Backfill) 및 파이프라인 복구 작업으로 인해 운영 비용이 높은 분들&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;h4 id=&quot;&quot;&gt;목차&lt;/h4&gt;
        
        &lt;ul&gt;
        &lt;li&gt;Episode 1: Introduction
        &lt;ul&gt;&lt;li&gt;1-1: Data FLOW&lt;/li&gt;
        &lt;li&gt;1-2: 과거 파이프라인의 문제&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
        &lt;li&gt;Episode 2: Flow.er. On-demand data lineage pipeline
        &lt;ul&gt;&lt;li&gt;2-1: Proof of Concept&lt;/li&gt;
        &lt;li&gt;2-2: Flow.er&lt;/li&gt;
        &lt;li&gt;2-3: Flow-er 구성 요소&lt;/li&gt;
        &lt;li&gt;2-4: DBT의 역할&lt;/li&gt;
        &lt;li&gt;2-5: Airflow의 역할&lt;/li&gt;
        &lt;li&gt;2-6: 개인 인스턴스&lt;/li&gt;
        &lt;li&gt;2-7: 모델 관리 페이지&lt;/li&gt;
        &lt;li&gt;2-8: CI/CD 파이프라인&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
        &lt;li&gt;Episode 3: Flow.er의 확장 – 추가 프로덕트 개발과 개선
        &lt;ul&gt;&lt;li&gt;3-1: Playground&lt;/li&gt;
        &lt;li&gt;3-2: Tower&lt;/li&gt;
        &lt;li&gt;3-3: Manager DAG System 개선&lt;/li&gt;
        &lt;li&gt;3-4: 정합성 향상을 위한 Partition Checker&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
        &lt;li&gt;Episode 4: Flow.er의 미래 - 하고 싶은 것들
        &lt;ul&gt;&lt;li&gt;4-1: MCP 서버 운영하기&lt;/li&gt;
        &lt;li&gt;4-2: 또 다른 미래&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
        &lt;li&gt;Episode 5: Conclusion
        &lt;ul&gt;&lt;li&gt;5-1: 무엇이 바뀌었는가&lt;/li&gt;
        &lt;li&gt;5-2: Conclusion&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;blockquote&gt;
        &lt;h5 id=&quot;naverengineeringdaybr&quot;&gt;&lt;strong&gt;◎ NAVER ENGINEERING DAY란?&lt;/strong&gt;&lt;br/&gt;&lt;/h5&gt;
        
        &lt;p&gt;NAVER에서는 사내 개발 경험과 기술 트렌드를 교류를 할 수 있는 프로그램이 많이 있습니다. 그중 매회 평균 70개 이상의 발표가 이루어지는 NAVER ENGINEERING DAY를 빼놓을 수 없는데요. &lt;br /&gt;
        2016년부터 시작된 ENGINEERING DAY는 실무에서의 기술 개발 경험과 새로운 기술과 플랫폼 도입 시 유용하게 활용될 수 있는 팁 등을 공유하며 서로 배우고 성장하는 네이버의 대표적인 사내 개발자 행사입니다. &lt;br /&gt;
        올해 진행된 NAVER ENGINEERING DAY의 일부 세션을 공개합니다.&lt;/p&gt;
        &lt;/blockquote&gt;
      </content:encoded>
    </item>
    <item>
      <title>서비스 조직에서 Kafka를 사용할 때 알아 두어야 할 것들 (5)</title>
      <link>https://d2.naver.com/helloworld/3974242</link>
      <guid>https://d2.naver.com/helloworld/3974242</guid>
      <pubDate>Sun, 08 Feb 2026 08:02:45 GMT</pubDate>
      <content:encoded>
        &lt;p&gt;네이버 사내 기술 교류 행사인 NAVER ENGINEERING DAY 2025(10월)에서 발표되었던 세션을 공개합니다.&lt;br/&gt; &lt;/p&gt;
        
        &lt;div style=&quot;position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;&quot;&gt;
        
        &lt;iframe width=&quot;800&quot; height=&quot;450&quot; src=&quot;https://tv.naver.com/embed/88720186?autoPlay=true&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot; style=&quot;position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;&quot;&gt;&lt;/iframe&gt;  
        &lt;/div&gt;  
        
        &lt;p&gt;&lt;br/&gt;&lt;/p&gt;
        
        &lt;h4 id=&quot;&quot;&gt;발표 내용&lt;/h4&gt;
        
        &lt;p&gt;Consumer Group Protocol v2를 소개합니다.&lt;/p&gt;
        
        &lt;h4 id=&quot;&quot;&gt;발표 대상&lt;/h4&gt;
        
        &lt;ul&gt;
        &lt;li&gt;조직에서 Kafka를 사용하거나 관심 있는 분들&lt;/li&gt;
        &lt;li&gt;Consumer Group Protocol 에 대해 관심 있는 분들&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;h4 id=&quot;&quot;&gt;목차&lt;/h4&gt;
        
        &lt;ul&gt;
        &lt;li&gt;Consumer Group Protocol (v1) 특징과 문제점&lt;/li&gt;
        &lt;li&gt;Consumer Group Protocol (v2) 특징
        &lt;ul&gt;&lt;li&gt;장점&lt;/li&gt;
        &lt;li&gt;성능&lt;/li&gt;
        &lt;li&gt;사용법&lt;/li&gt;
        &lt;li&gt;설정&lt;/li&gt;
        &lt;li&gt;툴&lt;/li&gt;
        &lt;li&gt;마이그레이션&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;blockquote&gt;
        &lt;h5 id=&quot;naverengineeringdaybr&quot;&gt;&lt;strong&gt;◎ NAVER ENGINEERING DAY란?&lt;/strong&gt;&lt;br/&gt;&lt;/h5&gt;
        
        &lt;p&gt;NAVER에서는 사내 개발 경험과 기술 트렌드를 교류를 할 수 있는 프로그램이 많이 있습니다. 그중 매회 평균 70개 이상의 발표가 이루어지는 NAVER ENGINEERING DAY를 빼놓을 수 없는데요. &lt;br /&gt;
        2016년부터 시작된 ENGINEERING DAY는 실무에서의 기술 개발 경험과 새로운 기술과 플랫폼 도입 시 유용하게 활용될 수 있는 팁 등을 공유하며 서로 배우고 성장하는 네이버의 대표적인 사내 개발자 행사입니다. &lt;br /&gt;
        올해 진행된 NAVER ENGINEERING DAY의 일부 세션을 공개합니다.&lt;/p&gt;
        &lt;/blockquote&gt;
      </content:encoded>
    </item>
    <item>
      <title>API 호출식 웜업의 부작용을 넘어서 : 라이브러리만 데우는 JVM 웜업</title>
      <link>https://d2.naver.com/helloworld/1580651</link>
      <guid>https://d2.naver.com/helloworld/1580651</guid>
      <pubDate>Sun, 08 Feb 2026 08:02:45 GMT</pubDate>
      <content:encoded>
        &lt;p&gt;네이버 사내 기술 교류 행사인 NAVER ENGINEERING DAY 2025(10월)에서 발표되었던 세션을 공개합니다.&lt;br/&gt; &lt;/p&gt;
        
        &lt;div style=&quot;position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;&quot;&gt;
        
        &lt;iframe width=&quot;800&quot; height=&quot;450&quot; src=&quot;https://tv.naver.com/embed/88624312?autoPlay=true&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot; style=&quot;position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;&quot;&gt;&lt;/iframe&gt;  
        &lt;/div&gt;  
        
        &lt;p&gt;&lt;br/&gt;&lt;/p&gt;
        
        &lt;h4 id=&quot;&quot;&gt;발표 내용&lt;/h4&gt;
        
        &lt;p&gt;API 호출식 웜업의 부작용을 개선한 라이브러리 웜업을 소개합니다.&lt;/p&gt;
        
        &lt;h4 id=&quot;&quot;&gt;발표 대상&lt;/h4&gt;
        
        &lt;p&gt;JVM JIT Compiler의 웜업 방식 기본을 알고 있는 분 또는 관심있는 분 &lt;br /&gt;
        JVM 기반 웹 어플리케이션의 웜업에 관심있는 분&lt;/p&gt;
        
        &lt;h4 id=&quot;&quot;&gt;목차&lt;/h4&gt;
        
        &lt;ul&gt;
        &lt;li&gt;JVM WARM-UP?&lt;/li&gt;
        &lt;li&gt;기존 웜업 방식과 문제&lt;/li&gt;
        &lt;li&gt;아이디어&lt;/li&gt;
        &lt;li&gt;라이브러리 웜업 구현&lt;/li&gt;
        &lt;li&gt;검증&lt;/li&gt;
        &lt;li&gt;이점 및 한계&lt;/li&gt;
        &lt;/ul&gt;
        
        &lt;blockquote&gt;
        &lt;h5 id=&quot;naverengineeringdaybr&quot;&gt;&lt;strong&gt;◎ NAVER ENGINEERING DAY란?&lt;/strong&gt;&lt;br/&gt;&lt;/h5&gt;
        
        &lt;p&gt;NAVER에서는 사내 개발 경험과 기술 트렌드를 교류를 할 수 있는 프로그램이 많이 있습니다. 그중 매회 평균 70개 이상의 발표가 이루어지는 NAVER ENGINEERING DAY를 빼놓을 수 없는데요. &lt;br /&gt;
        2016년부터 시작된 ENGINEERING DAY는 실무에서의 기술 개발 경험과 새로운 기술과 플랫폼 도입 시 유용하게 활용될 수 있는 팁 등을 공유하며 서로 배우고 성장하는 네이버의 대표적인 사내 개발자 행사입니다. &lt;br /&gt;
        올해 진행된 NAVER ENGINEERING DAY의 일부 세션을 공개합니다.&lt;/p&gt;
        &lt;/blockquote&gt;
      </content:encoded>
    </item>
  </channel>
</rss>