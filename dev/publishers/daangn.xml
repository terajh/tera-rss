<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>dev RSS - 당근마켓 테크</title>
    <link>https://medium.com/daangn</link>
    <description>당근마켓 테크 RSS 피드</description>
    <lastBuildDate>Sat, 28 Feb 2026 16:30:33 GMT</lastBuildDate>
    <item>
      <title>2조 토큰을 카테고리 분류에 쓰면서 알게된 것들</title>
      <link>https://medium.com/daangn/2%EC%A1%B0-%ED%86%A0%ED%81%B0%EC%9D%84-%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC-%EB%B6%84%EB%A5%98%EC%97%90-%EC%93%B0%EB%A9%B4%EC%84%9C-%EC%95%8C%EA%B2%8C%EB%90%9C-%EA%B2%83%EB%93%A4-f619f1db6b7b?source=rss----4505f82a2dbd---4</link>
      <guid>https://medium.com/daangn/2%EC%A1%B0-%ED%86%A0%ED%81%B0%EC%9D%84-%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC-%EB%B6%84%EB%A5%98%EC%97%90-%EC%93%B0%EB%A9%B4%EC%84%9C-%EC%95%8C%EA%B2%8C%EB%90%9C-%EA%B2%83%EB%93%A4-f619f1db6b7b?source=rss----4505f82a2dbd---4</guid>
      <pubDate>Fri, 27 Feb 2026 11:36:44 GMT</pubDate>
      <content:encoded>&lt;h3&gt;카테고리 분류에 2조 토큰을 쓰면서 알게된 것들&lt;/h3&gt;&lt;p&gt;안녕하세요. 당근 Taxonomy 팀 &lt;a href=&quot;mailto:me@winterjung.dev&quot;&gt;윈터(winter.jung)&lt;/a&gt;, &lt;a href=&quot;mailto:jiwon.lee959@gmail.com&quot;&gt;지원(jiwon)&lt;/a&gt;이에요. 저희 팀은 택소노미(Taxonomy)라고 부르는 카테고리 체계를 만들고, 그 체계를 기반으로 중고거래, 모임 게시글 등 당근에 올라오는 게시글을 자동으로 분류해 실제 서비스가 사용하도록 적재하는 파이프라인을 운영하고 있어요.&lt;/p&gt;&lt;p&gt;이번 글에서는 프로덕션 파이프라인에서 카테고리 분류를 위해 LLM을 어떻게 쓰고 있는지, 그리고 성능, 비용, 운영 측면에서 잘 사용하기 위해 어떤 고민과 시도를 했는지 이야기해보려고 해요.&lt;/p&gt;&lt;h3&gt;택소노미가 뭔가요?&lt;/h3&gt;&lt;p&gt;택소노미라는 단어가 좀 생소하실 수 있는데, 사실 온라인 마트나 서점, 쇼핑몰의 카테고리를 생각해보시면 바로 이해가 되실 거예요. 택소노미는 트리 구조로 된 카테고리 체계를 뜻해요. 어떤 데이터가 어떤 종류인지를 일관된 규칙으로 표현하기 위한 분류 체계이고, 상황에 따라 카탈로그라고도 불러요. 이 글에서는 용어를 택소노미로 통일할게요.&lt;/p&gt;&lt;p&gt;예를 들어 “아우터 &amp;gt; 패딩/다운 &amp;gt; 롱패딩”처럼 위에서 아래로 내려가며 더 구체적인 의미를 담을 수 있고, 같은 아이템이라도 서비스의 필요에 따라 “겨울 아우터 &amp;gt; 출퇴근용”처럼 다른 위계를 담아볼 수 있어요.&lt;/p&gt;&lt;p&gt;택소노미에는 카테고리뿐만 아니라 속성도 담을 수 있어요. 카테고리가 이 상품이 무슨 종류인지를 표현하는 명사라면, 속성은 이 상품이 어떤 특징을 갖는지를 표현하는 형용사에 가까워요. 예를 들어 같은 “롱패딩”이라도 브랜드=나이키, 색상=블랙, 재질=폴리에스터 같은 속성으로 더 구체적으로 설명할 수 있어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*vAKy7BgEpBkx5AtNAIE2cg.png&quot; /&gt;&lt;figcaption&gt;당근 내부 중고거래 카테고리 예시&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;택소노미가 왜 중요한가요?&lt;/h3&gt;&lt;p&gt;택소노미가 있으면 같은 종류의 아이템을 통일된 방식으로 다룰 수 있어요. 예를 들어 “스마트폰”을 서비스마다 “휴대폰”, “모바일기기”, “핸드폰” 제각각 취급하는게 아니라 {&amp;quot;id&amp;quot;: &amp;quot;electronic_smartphone&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;전자기기 &amp;gt; 스마트폰&amp;quot;}처럼 일관된 방식으로 사용할 수 있어요. 이게 생각보다 서비스 전반에 큰 영향을 줘요.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;검색은 카테고리를 기준으로 결과를 좁히거나 확장할 수 있어요. 예를 들어 스마트폰을 검색했다면 아이폰, 갤럭시 같은 하위 카테고리를 포함한 검색이 가능해져요.&lt;/li&gt;&lt;li&gt;추천은 비슷한 카테고리의 아이템을 묶어서 학습하거나, 반대로 같은 카테고리만 연속으로 나오지 않게 다양성을 설계할 수 있어요.&lt;/li&gt;&lt;li&gt;광고나 타겟팅은 아이템, 콘텐츠의 카테고리를 기반으로 더 정교한 세그먼트를 만들 수 있어요.&lt;/li&gt;&lt;li&gt;데이터 분석이나 피처 엔지니어링에서도 카테고리와 속성은 매우 재사용성이 높은 공통 피처가 돼요.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;이렇게 택소노미는 검색, 추천, 광고, 분석, ML 모델까지 여러 팀이 함께 쓰는 공통 언어 역할을 해요.&lt;/p&gt;&lt;h3&gt;당근은 어디서 카테고리를 쓰고있나요?&lt;/h3&gt;&lt;p&gt;당근에서 카테고리는 생각보다 다양한 곳에서 쓰여요. 대표적으로는 중고거래 게시글이 있고, 모임을 만들 때 어떤 타입의 모임인지를 표현하는 체계도 있고, 동네지도에 노출되는 업체에도 카테고리가 필요해요.&lt;/p&gt;&lt;p&gt;특히 당근의 핵심인 중고거래 영역에서는 내부적으로 최대 3 depth로 나뉜 약 1,400개 수준의 카테고리를 관리하고 있어요. 다만 실제로 당근 앱을 사용하는 사용자 입장에서는 보통 앱 화면에서 표면적으로 보이는 카테고리나, 추천 칩 같은 형태로만 카테고리를 만나보셨을 거예요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*pezBSWlwnggMRMoGVNtDSA.png&quot; /&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*25am3gjWBLR9maDUQlFyRQ.png&quot; /&gt;&lt;figcaption&gt;(좌) 앱에서 보이는 중고거래 카테고리 (우) 홈 피드 상단에서 볼 수 있는 추천 칩&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;택소노미 관리는 그동안 주로 사람이 해왔어요&lt;/h3&gt;&lt;p&gt;전통적으로 택소노미 관리는 휴먼 리소스가 많이 필요한 영역이었어요.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;정의 자체가 도메인 전문가의 영역이에요. 어떤 카테고리를 만들지, 서로 어떻게 구분할지, 어디에 속하게 할지 같은 문제는 정답이 있는 문제라기보다 도메인과 제품의 맥락을 아는 사람이 결정하는 경우가 많아요.&lt;/li&gt;&lt;li&gt;ML로 분류하려면 라벨 데이터가 필요해요. 모델을 학습시키려면 결국 사람이 라벨링한 데이터가 필요하고, 라벨링을 하려면 기준이 필요하고, 이 기준을 유지보수하려면 또 관리 비용이 들어요.&lt;/li&gt;&lt;li&gt;거버넌스와 모니터링이 필요해요. 택소노미 자체의 품질도 모니터링해야 하고, 분류 결과가 이상해졌을 때 대응하는 프로세스도 필요해요. 택소노미가 바뀌면 번역, 영향 범위 확인, 관계부서 합의, 모델 재학습 같은 연쇄 작업이 생기기도 해요.&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;당근은 그동안 어떻게 분류해왔나요?&lt;/h3&gt;&lt;p&gt;하지만 이 글을 읽으시는 당근 사용자 분들은 “나는 중고거래 게시글 올릴 때 카테고리를 그렇게 많이 고르지 않았는데?”라는 생각이 드실 거예요. 실제로 사용자가 직접 3-depth까지 세밀하게 선택하도록 UI/UX를 구성하기엔 게시글 작성에 허들로 작용하기도 하고, 사용자 입력만으로 신뢰도 높은 분류를 얻기도 어려워요.&lt;/p&gt;&lt;p&gt;그래서 지금까지 당근에서는 게시글 작성 시 발생하는 Kafka 이벤트를 받아 LLM으로 카테고리를 추출해 그 결과를 적재하는 Golang 기반 컨슈머 애플리케이션을 운영하며, 사용자 입력에 전적으로 의존하기보다는 시스템이 추가로 분류해 데이터를 증강하는 방향을 시도해왔어요.&lt;/p&gt;&lt;p&gt;다만 기존 방식엔 제품적, 기술적 아쉬움이 존재했어요.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;카테고리 정의를 한 곳에서 관리하는게 아닌 필요에 따라 각자 팀에서 정의하고 추출하는 방식이라 어느 한 곳의 노하우와 개선이 전파되기 어려웠어요.&lt;/li&gt;&lt;li&gt;카테고리만으로 표현력이 부족했어요. 봄 시즌 옷, 따뜻한 재질 같은 속성을 정의하고 활용하고 싶었어요.&lt;/li&gt;&lt;li&gt;이벤트 스트림만 지원하느라 대용량 배치 처리를 제대로 지원하지 못했고, 장애 복구 시 백필도 어려운 구조였어요. 또 앞으로 택소노미 적용 범위를 넓히기엔 그 데이터 소스들이 늘 Kafka 이벤트로 존재하는 건 아니었어요.&lt;/li&gt;&lt;li&gt;품질 관리가 부족했어요. 중요한 피처인데도 현재 뽑은 카테고리가 정말 잘 뽑힌 건지 검증하는 체계가 부족했고, 파이프라인의 불안정성이나 장애 전파 구조도 고민거리였어요.&lt;/li&gt;&lt;li&gt;프롬프트, 모델 변경의 효과와 부작용을 빠르게 검증하기 어려웠어요. 별도 검증 체계가 없었기에 그 변화를 알기 위해서는 오프라인, 온라인 실험까지 가야만 했는데, 그 속도가 더 빨라질 필요가 있었어요.&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;그래서 Taxonomy Management System을 만들었어요&lt;/h3&gt;&lt;p&gt;Taxonomy Management System은 택소노미를 관리하고, 다양한 데이터 소스에 대해 LLM 기반 분류를 안정적으로 실행하고, 카테고리와 속성을 신뢰성 있게 제공하며, 그 품질을 지속적으로 모니터링하는 파이프라인이에요. 구현과 운영의 중심에는 LLM이 있고, 실행 인프라는 Dataflow(Beam)를 선택했어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*CypG5n_f5ed5Z-Gd0AIiUw.png&quot; /&gt;&lt;/figure&gt;&lt;h3&gt;왜 Dataflow(Beam)을 사용했나요?&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;대용량 데이터를 병렬로 추론할 수 있어야 했어요. LLM 호출 자체가 초 단위의 응답 시간이 걸리기에 높은 throughput이 필요했어요.&lt;/li&gt;&lt;li&gt;하나의 로직으로 스트림 처리와 대규모 배치 처리를 모두 지원하고 싶었어요.&lt;/li&gt;&lt;li&gt;Spark나 Flink 같은 다른 선택지도 있었지만, 이미 다른 동일 조합의 파이프라인을 팀 내에서 운영하며 경험치가 있었기에 Dataflow + Beam 구조가 현실적인 선택이었어요.&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;추론된 결과의 Source of Truth는 BigQuery로 잡았어요&lt;/h3&gt;&lt;p&gt;별도의 서빙 서버를 두기보다는 분류 결과를 BigQuery에 쌓아서 누구나 쿼리 가능한 원천 데이터로 제공했어요. 오프라인 활용(분석, 실험, 학습)은 BigQuery로 충분히 커버할 수 있고, 온라인에서 필요한 경우에는 Kafka sink를 통해 사내 피쳐플랫폼에 적재하는 방식으로 연결했어요.&lt;/p&gt;&lt;h3&gt;다양한 택소노미, 파이프라인을 대응하기 위한 구조&lt;/h3&gt;&lt;p&gt;택소노미는 하나만 있는 게 아니고, 중고거래나 모임 등 서비스마다 형태가 달라질 수 있어요. 그래서 시스템은 특정 케이스에 고정되지 않게 설계했어요.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;택소노미 정의는 YAML로 관리해요.&lt;/li&gt;&lt;/ul&gt;&lt;pre&gt;- id: elap&lt;br&gt;  name: Electronics &amp;amp; Appliances&lt;br&gt;  children:&lt;br&gt;  - id: elap-1&lt;br&gt;    name: Laptops&lt;br&gt;    children:&lt;br&gt;    - id: elap-1-1&lt;br&gt;      name: LG Gram&lt;br&gt;    - id: elap-1-2&lt;br&gt;      name: Apple MacBook&lt;br&gt;      attributes:&lt;br&gt;      - color&lt;br&gt;      - brand&lt;br&gt;  - id: elap-2&lt;br&gt;    name: Mobile Phones&lt;br&gt;    children:&lt;br&gt;    - id: elap-2-1&lt;br&gt;      name: iPhones&lt;br&gt;    - id: elap-2-2&lt;br&gt;      name: Galaxy Phones&lt;/pre&gt;&lt;ul&gt;&lt;li&gt;YAML config로 파이프라인 설정을 관리해요.&lt;/li&gt;&lt;/ul&gt;&lt;pre&gt;taxonomy:&lt;br&gt;  content_type: fleamarket&lt;br&gt;  taxonomy_name: karrot_category&lt;br&gt;&lt;br&gt;dataflow_worker:&lt;br&gt;  min_num_workers: 1&lt;br&gt;  max_num_workers: 10&lt;br&gt;  machine_type: n1-highmem-8&lt;br&gt;&lt;br&gt;kafka_source:&lt;br&gt;  topic: entities.fleamarket_article&lt;br&gt;&lt;br&gt;kafka_sink:&lt;br&gt;  topic: entities.taxonomy_result&lt;br&gt;&lt;br&gt;bigquery_sink:&lt;br&gt;  destination: production-data.taxonomy_management_system.results&lt;/pre&gt;&lt;ul&gt;&lt;li&gt;여러 LLM 옵션을 YAML 설정으로 표현할 수 있게 해요.&lt;/li&gt;&lt;/ul&gt;&lt;pre&gt;llm:&lt;br&gt;  primary_model: gemini-2.5-flash&lt;br&gt;  eval_models:&lt;br&gt;    - gpt-5-mini&lt;br&gt;    - gemini-3-flash&lt;br&gt;    - claude-sonnet-4-5&lt;br&gt;  categorization: SINGLE_SHOT&lt;br&gt;  attribute_assignment: ALL_AT_ONCE&lt;br&gt;  evaluation: TWO_STAGE&lt;br&gt;  eval_sample_ratio: 0.01&lt;/pre&gt;&lt;ul&gt;&lt;li&gt;글로벌 다국어 지원이 가능한 구조로 택소노미 체계를 구성했어요. 특히 번역 과정은 규모가 커지면 바로 병목이 돼요. 1만 개가 넘는 카테고리의 다국어 데이터를 마련하기 위해 여기서도 LLM을 사용했는데, 데이터를 청크별로 잘게 쪼개 LLM에게 번역시킨 뒤, 그 번역 결과를 다시 새로운 컨텍스트의 LLM에게 일관성있고 자연스러운 표현인지 검증하는 방식을 사용했어요. 택소노미는 트리 구조라는 특성이 있기에 상위 depth에서 사용한 표현을 하위 depth에서도 그 일관성을 맞추기 위해 DFS 방식으로 진행하며 상위 카테고리의 번역 데이터를 컨텍스트로 첨부해주었어요.&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;택소노미를 어떻게 새로 만들고 확장했는지&lt;/h3&gt;&lt;p&gt;택소노미를 처음부터 사람 손으로 만들기엔 도메인 지식도 필요하고 그 규모가 100개, 1,000개를 넘으면 정의도 어렵고 확장도 어렵기에 여기에도 LLM을 적극적으로 이용했어요.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;신규 택소노미를 생성할 땐 기존에 well-known 택소노미가 존재하는지 딥 리서치를 이용해 참고 자료를 마련하고, 이를 참고해 실제 데이터를 기반으로 가상의 카테고리를 생성해가며 택소노미 트리를 구성해나가요.&lt;/li&gt;&lt;li&gt;기존 택소노미를 확장시킬 땐 샘플링된 데이터를 기존 택소노미로 분류를 시도해보고, 부적합 한 경우 신규 카테고리를 제안시켜요. LLM과 유사도로 비슷한 카테고리는 병합시킨 뒤 일정 기준 이상의 카테고리들은 신규 카테고리 후보로 승격시켜요.&lt;/li&gt;&lt;li&gt;승격된 신규 카테고리 후보는 1. 아까 신규 카테고리를 제안한 샘플 데이터들이 실제로 신규 카테고리에 할당되는지 2. regression 평가로 예전 택소노미와 신규 택소노미로 분류가 갈린 데이터를 LLM에게 주고 예전께 더 낫다고 하는 경우가 적은지 두 단계에 걸쳐 심사한 뒤 정식 택소노미로 편입시켜요.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;이런 방식으로 기존에 사용하던 3-depth의 1,400개 택소노미 외에도 6-depth 이상의 10,000개 규모의 택소노미도 새롭게 정의할 수 있었어요.&lt;/p&gt;&lt;h3&gt;카테고리와 속성은 LLM이 어떻게 추론하나요?&lt;/h3&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*ovRpKlkGi_epCS8GyPy8bA.png&quot; /&gt;&lt;figcaption&gt;파이프라인 추론 Flow&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;카테고리는 그 개수가 10,000개 이상 많아질 수 있기에 추론 정확도가 중요하고 그만큼 다양한 프롬프트 시도를 통해 높은 정확도를 이뤄내야 해요. 택소노미 파이프라인을 처음 구축할 땐 직관적으로 떠올릴 수 있는 아래 방식으로 먼저 시도했어요.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;단일 단계 방식 Single Shot: 모든 카테고리를 주고 고르게 하기&lt;/li&gt;&lt;li&gt;계층적 방식 Hierarchical: 택소노미는 트리구조로 카테고리마다 계층이 있기에, 그 계층(depth)마다 가장 그럴듯한 답을 고르게 하고, 선택된 카테고리의 하위 계층에 대해 다시 고르게 하기.&lt;/li&gt;&lt;li&gt;토너먼트 방식 Two-stage: 전체 카테고리 리스트를 N개의 청크로 나눠 각 청크마다 후보를 고르게 하고, 선택된 후보군을 다시 토너먼트 형식으로 고르게 해서 최종 1개 고르기&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;LLM 모델 마다, 택소노미 규모마다 적절한 방식이 따로 있기에 다양한 프롬프트 엔지니어링 옵션을 마련해두고, 손쉽게 다양한 옵션을 시도해볼 수 있도록 아래처럼 파이프라인의 DoFn 컴포넌트 형태로 잘 모듈화 해 Article → Category 추론 → Attribute 추론의 흐름으로 사용하도록 구성했어요. 새로운 방식이 필요한 경우 새로운 Strategy를 구현하여 파이프라인에 갈아 끼워요. 예를 들어 two stage 방식의 카테고리 추출 방식이 필요하다면 이 로직을 담은 새로운 DoFn을 구현하여 (e.g. TwoStageStrategy) categorization stage의 SingleShotStrategy를 대체할 수 있어요.&lt;/p&gt;&lt;pre&gt;# Categorization stage&lt;br&gt;class SingleShotStrategy(DoFn):&lt;br&gt;    def process(self, element: Article) -&amp;gt; Iterator[Tuple[Article, Category]]&lt;br&gt;&lt;br&gt;# Attribute assignment stage&lt;br&gt;class AllAtOnceStrategy(DoFn):&lt;br&gt;    def process(&lt;br&gt;        self, element: Tuple[Article, Category]&lt;br&gt;    ) -&amp;gt; Iterator[Tuple[Article, Category, List[AttributeValue]]]:&lt;/pre&gt;&lt;h3&gt;평가는 어떻게 했나요? → LLM as a Judge&lt;/h3&gt;&lt;p&gt;분류를 아무리 많이 해도, 결국 그 분류가 적절했는지 정확도를 알 수 있어야 해요. 특히 프로덕션에서 운영하며 모델, 프롬프트, LLM 옵션을 계속해서 튜닝하다 보면 이 변경이 부작용은 없는지, 성능을 더 낫게 만들었는지를 빠르게, 반복적으로 판단할 수 있어야 해요. 그래서 저희는 똑똑한 모델들끼리 합의해 정답을 정하는 LLM as a Judge 방식의 평가를 적극적으로 사용했어요.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;일정 비율의 샘플을 서로 다른 N개의 모델로 돌려서 N개의 label을 얻어요.&lt;/li&gt;&lt;li&gt;그 N개의 label로 Ground-Truth label을 형성해요.&lt;/li&gt;&lt;li&gt;이 Ground-Truth를 기준으로 각 모델의 정확도를 계산하고 모니터링해요.&lt;/li&gt;&lt;li&gt;LLM 모델, 프롬프트, 파이프라인 구조 등을 변경할 때 마다 이 정확도의 변화를 비교하고 더 나빠지진 않는지, 더 좋아지는지를 판단해요.&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Ground Truth는 어떻게 만드나요?&lt;/h3&gt;&lt;p&gt;Ground truth를 만드는 방식은 majority voting을 사용했어요. 상황에 따라 plurality voting이나 weighted voting 같은 선택지도 가능하지만, 저희는 직관적이고 가장 구현이 간단한 방식을 선택했어요.&lt;/p&gt;&lt;p&gt;다만 평가 대상이 카테고리인지, 속성인지, 카테고리를 여러 개 뽑는 상황인지에 따라 ground truth를 만드는 방식과 형태가 달라져요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*y56AdAOB5vsjPvAvcZFWKw.png&quot; /&gt;&lt;/figure&gt;&lt;h3&gt;품질 지표는 어떻게 계산하나요?&lt;/h3&gt;&lt;p&gt;Ground truth를 만들었다면 이를 활용해 여러 카테고리, 속성 품질 지표를 계산할 수 있어요.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Category Accuracy&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;카테고리 정확도는 일종의 precision@1 지표로 Primary model이 추론한 카테고리와 ground truth 카테고리가 일치하는 비율이에요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/922/1*YitHurCvOx0JgVQM80rYBA.png&quot; /&gt;&lt;figcaption&gt;Category Accuracy = 1/3 = 33.3%&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Attribute Precision / Recall&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;속성은 한 게시글에 대해 여러 쌍이 정답이 될 수 있는 multi-label 문제예요. 그래서 전체가 맞았는지만 보는 accuracy 대신 precision과 recall을 사용해요.&lt;/p&gt;&lt;p&gt;Precision은 primary model이 추론한 (attribute, value) pair 중 실제로 맞은 비율이에요.&lt;/p&gt;&lt;pre&gt;Precision(article) = |Pred ∩ GT| / |Pred|&lt;/pre&gt;&lt;p&gt;Recall은 반대로, ground truth pair 중 primary model이 찾아낸 비율이에요.&lt;/p&gt;&lt;pre&gt;Recall(article) = |Pred ∩ GT| / |GT|&lt;/pre&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*_YJ66YO9iGt0ByGN7B0GQA.png&quot; /&gt;&lt;figcaption&gt;Attribute Precision Avg = (50 + 0 + 100) / 3 = 50%, Recall Avg = (33.3 + 0 + 50) / 3 = 27.7%&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;이렇게 개별 게시글마다 precision과 recall을 구한 뒤, 전체 게시글의 평균을 내서 최종 지표로 사용해요. Primary model이 정답 set을 얼마나 정확하게 맞추는지, 얼마나 빠짐없이 포괄하는지를 나눠서 볼 수 있어요.&lt;/p&gt;&lt;h3&gt;평가 체계의 검증&lt;/h3&gt;&lt;p&gt;LLM as a Judge 방식으로 만든 평가 체계가 진짜로 유효한지에 대한 검증도 중요해요. 모델들끼리의 합의가 곧 정답이라고 확신할 수는 없으니까요. 예를 들어 소규모로 human-labeled goldset 샘플을 만들고, LLM judge와의 상관관계를 확인하는 방식으로 평가 체계를 점검할 수 있어요. 또 top-1 정확도뿐 아니라 depth별, 카테고리별 정확도나 일관성 지표를 같이 보면 어떤 방향으로 틀리는지 더 잘 파악할 수 있어요.&lt;/p&gt;&lt;h3&gt;만들고 나면 끝이 아닌 시작, 운영은 어떻게 했나요?&lt;/h3&gt;&lt;p&gt;이렇게 Taxonomy Management System을 만들었지만 사실 만들었다 자체보단 그 이후 프로덕션 환경에서 운영해오며 얻은 교훈이 더 많았어요.&lt;/p&gt;&lt;p&gt;카테고리를 얼마나 잘 맞추는지도 중요하지만, 하루 수십만 건씩 올라오는 게시글을 꾸준히 분류해야 하다 보니 합리적인 비용으로 운영하는 것도 그만큼 중요했어요. 결국 합리적인 정확도 안에서 비용을 최소화하는 지점을 찾아야 했고, 그 지점을 찾기 위해 프롬프트, 모델, 분류 전략 조합을 반복해서 실험하면서 비용과 정확도의 sweet spot을 찾아갔어요.&lt;/p&gt;&lt;h3&gt;정확도를 올리기 위한 프롬프트 엔지니어링&lt;/h3&gt;&lt;p&gt;초기에는 텍스트만으로 분류하던 프롬프트에 이미지를 추가했어요. 중고거래 게시글은 텍스트만으로는 상품 특성이 잘 드러나지 않는 경우가 많아요. 사진을 같이 넣어주면 LLM이 실제로 무엇을 파는지 더 잘 파악할 수 있고, 그게 정확도로 이어졌어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*7pNFvUC28Bti1DdjB-23wA.png&quot; /&gt;&lt;/figure&gt;&lt;p&gt;다만 프롬프트를 손보면 항상 정확도가 오르는 건 아니었어요. 예를 들어 기존에는 카테고리명만 LLM에게 넘기고 있었는데, 카테고리 경로 정보인 breadcrumb까지 같이 넣어 정확도를 올려보려 했던 적이 있어요. 직관적으로는 상위 문맥이 붙으면 좋아질 것 같았는데, 실제로는 성능 변화가 미미했어요. 그 외에도 Few-shot 프롬프트나, 세부적인 Insturction 튜닝은 그 수고와 비용에 비해 결과 변화가 없거나 오히려 낮아지는 경우도 빈번했어요.&lt;/p&gt;&lt;h3&gt;비용을 줄이기 위한 프롬프트 개선도 했어요&lt;/h3&gt;&lt;p&gt;정확도를 올리는 시도만큼이나 비용을 줄이기 위한 프롬프트 개선도 중요했어요. LLM API의 프롬프트 캐싱을 활용하려면 프롬프트 구조 자체를 캐시 친화적으로 바꿔야 하거든요.&lt;/p&gt;&lt;p&gt;그래서 게시글 내용처럼 매 요청마다 바뀌는 정보는 프롬프트 뒤쪽에 두고, instruction과 카테고리 목록처럼 상대적으로 고정된 정보는 앞쪽에 배치했어요. 이렇게 하면 정적인 부분의 캐시 히트율이 올라가고 전체 비용을 줄일 수 있었어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*dna5sod-TkDbyc8lLpt5GA.png&quot; /&gt;&lt;/figure&gt;&lt;h3&gt;모델 변경 실험도 병행했어요&lt;/h3&gt;&lt;p&gt;프롬프트 개선과 함께 모델 자체를 바꿔보는 실험도 했어요. 더 좋은 모델을 쓸수록 정확도가 올라가는 경향은 항상은 아니어도 어느정도 존재했어요. 하지만 분류량이 많다보니 장기적인 운영 관점에서는 모델 단가를 무시할 수 없었어요. 정확도는 조금 올라가는 반면 비용이 크게 뛰어버리면 그 모델을 프로덕션의 주 모델로 사용할 순 없었어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*d9fUoyAFXONLpvr1UKJjzg.png&quot; /&gt;&lt;figcaption&gt;우측 하단일수록 Sweet Spot&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;여기까지의 결론은 분명했어요&lt;/h3&gt;&lt;p&gt;단순 프롬프트 개선과 모델 변경만으로는 정확도를 향상과 낮은 비용 유지 두 목적 모두 달성하기는 점점 어려워졌어요. 어느 순간부터는 프롬프트를 다듬더라도 정확도 향상이 미미해지는 시점이 오고, 더 좋은 모델로 정확도를 올리면 비용이 따라서 오르는 형태였어요.&lt;/p&gt;&lt;p&gt;그래서 시선을 바꿨어요. 지금까지는 어떻게 LLM이 주어진 카테고리 중 최적을 뽑게 할지를 고민했다면, 이제는 애초에 어떤 카테고리를 LLM에게 쥐어줄지를 설계하는 방향으로 접근했어요.&lt;/p&gt;&lt;h3&gt;분류 전략 개선&lt;/h3&gt;&lt;h3&gt;초기 전략들: Single Shot, Hierarchical, Two-Stage&lt;/h3&gt;&lt;p&gt;앞서 소개한 세 가지 전략을 다시 운영 관점에서 짚어볼게요.&lt;/p&gt;&lt;p&gt;Single shot은 가장 먼저 시도한 방식이에요. 전체 카테고리를 LLM에게 한 번에 보여주고 고르게 해요. 구현이 단순하고 LLM 호출이 1회로 끝나요. 카테고리 목록이 매번 동일하기 때문에 프롬프트 캐싱에도 유리해요. 하지만 카테고리가 수백 개를 넘어가면 긴 목록 속에서 정확도가 떨어졌어요.&lt;/p&gt;&lt;p&gt;Hierarchical은 택소노미가 트리 구조라는 점을 활용한 방식이에요. 최상위 카테고리부터 시작해 한 레벨씩 내려가며 하나를 골라요. 매 단계에서 해당 레벨의 카테고리만 보여주기 때문에 토큰 사용량은 크게 줄어들어요. 하지만 처음에 잘못된 경로를 선택하면 하위에서 복구할 수 없다는 구조적 한계가 있었어요.&lt;/p&gt;&lt;p&gt;Two-stage는 한 번에 보내면 정확도가 떨어지니 N개로 나누어 보내자는 토너먼트 방식이에요. 예를 들어 1,500개 카테고리를 300개씩 나누면 5개의 청크가 되고, 각각 LLM을 호출해 후보를 선별한 뒤 최종 라운드에서 하나를 고르는 거예요. Single shot에 비해 정확도가 올라갔지만, 전체 카테고리를 다 커버하고 최종 선택까지 해야 하므로 토큰 사용량이 많았어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*ibGWmcR6O53r9OcXrF4Mww.png&quot; /&gt;&lt;figcaption&gt;Single Shot, Hierarchical, Two-stage 방식의 추론 Flow&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;이 초기 전략들의 공통적인 한계는, 결국 전체 카테고리를 LLM이 한 번은 봐야 하거나 매 레벨마다 봐야 한다는 점이었어요. 카테고리 규모가 100개를 넘어 1,000개 이상으로 커질수록 비용과 정확도 문제가 심화되었어요.&lt;/p&gt;&lt;h3&gt;1,000개 규모에서 동작하는 전략&lt;/h3&gt;&lt;p&gt;그래서 애초에 LLM에게 카테고리를 보여주기 전에 그 후보를 미리 줄이는 방법으로 임베딩을 활용한 전략을 만들었어요.&lt;/p&gt;&lt;p&gt;Embedding Two-stage는 LLM을 호출하기 전에 게시글과 카테고리의 임베딩 유사도를 계산해서 상위 n%의 카테고리만 남긴 뒤 토너먼트를 진행하는 방식이에요. 임베딩 연산은 LLM 호출에 비해 저렴하기 때문에, 카테고리 대부분을 사전에 걸러낸다는 것만으로도 전체 비용을 크게 줄일 수 있었어요.&lt;/p&gt;&lt;p&gt;여기서 한 걸음 더 나아간 게 Embedding Summary 방식이에요. 중고거래 게시글에는 분류와 무관한 표현들이 많이 섞여 있어 raw 게시글을 그대로 임베딩하면 그 성능이 떨어질 수 있어요. 그래서 LLM으로 게시글을 한 줄로 요약한 뒤, 그 요약문으로 임베딩 유사도를 비교하도록 했어요. 예를 들어 {&amp;quot;title&amp;quot;: “노스페이스 화이트라벨 미니백&amp;quot;, “content&amp;quot;: &amp;quot;노스페이스 화이트라벨 심플미니백 블랙 색상입니다. 핸드폰 넣고 가볍고 휴대하기 좋은 사이즈예요. 간단한 소지품 보관에 용이합니다. 거의 새것 상태입니다&amp;quot;} 같은 게시글이 있다면, 이를 &amp;quot;unisex_northface_mini_bag_black&amp;quot; 같은 핵심 표현으로 요약한 뒤 임베딩을 만드는 거예요. LLM 호출이 1회 추가되지만, 노이즈가 제거된 요약문이 더 정확한 후보 필터링을 만들어냈어요. 기존보다 카테고리 후보군을 더 적게 남기더라도 좋은 성능을 보여줬기 때문에, Embedding Two-stage보다도 적은 비용으로 운영할 수 있었어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*tNOs2ZN2pRAfgYGDBKtKIg.png&quot; /&gt;&lt;/figure&gt;&lt;h3&gt;10,000개 카테고리에서의 개선&lt;/h3&gt;&lt;p&gt;하지만 이것도 만 개 규모의 택소노미로 확장되니 문제의 성격이 달라졌어요. Hierarchical로는 정확도가 안 나오고, Two-stage로도 카테고리가 너무 많아 비용이 과하게 비쌌어요. Embedding 방식을 적용해 10%만 남겨도 필터링 후에 남는 카테고리 후보군 자체의 절대적인 크기가 크기 때문에 더 적합한 전략이 필요했어요.&lt;/p&gt;&lt;p&gt;이 규모에 맞게 설계한 첫 번째 전략이 DFS Two-stage 전략이에요. 각 레벨에서 하나만 고르는 Hierarchical 방식과 달리, 각 레벨마다 여러개의 그럴듯한 카테고리를 선택하며 Leaf depth까지 탐색해요. 탐색이 끝나면 방문한 후보 중에서 최종 선택을 해요. Two-stage 대비 비용이 절감되고, Hierarchical 대비 정확도가 개선되었어요. 하지만 depth가 깊어질수록 레벨마다 LLM 호출이 발생하고 토큰이 누적되는 문제가 있었어요.&lt;/p&gt;&lt;p&gt;그래서 1,000개 규모에서와 같은 접근으로, 어떻게 하면 LLM에게 전달하는 카테고리 후보를 줄일 지 고민했고 &lt;a href=&quot;https://softwaredoug.com/blog/2026/01/08/semantic-search-without-embeddings.html&quot;&gt;Semantic Search Without Embeddings 블로그 글&lt;/a&gt;에서 힌트를 얻어 검색할 때 처럼 BM25 키워드 매칭을 활용해 카테고리를 사전 필터링할 수 있지 않을까 가설을 세웠어요.&lt;/p&gt;&lt;p&gt;게시글에서 키워드와 동의어를 한 번에 추출하고, 이를 검색어로 사용해 카테고리 목록의 BM25 스코어를 구한 뒤 높은 점수의 카테고리 N개를 LLM에게 최종 선택하라고 하는 방식이에요. 예를 들어 “크리스마스 트리 풀세트”라는 게시글이라면 [christmas, tree, decorations, holiday] 같은 키워드와 [xmas, ornaments, baubles, seasonal] 같은 동의어를 추출해서 검색하는 거예요.&lt;/p&gt;&lt;p&gt;하지만 BM25만으로는 Recall 성능이 좋게 나오지 않았어요. 키워드가 정확히 일치하지 않는 경우를 놓치기 쉬웠거든요. 이를 보완하기 위해 앞서 소개한 요약문 기반 임베딩 유사도 검색을 결합한 하이브리드 방식을 도입했어요. BM25는 키워드 매칭에 강하고, 임베딩은 의미적 유사성에 강해요. 둘을 결합하면 서로를 보완할 수 있어요. 구체적으로는 LLM이 게시글에서 요약문과 키워드, 동의어를 한 번에 추출하고, 키워드와 동의어로는 BM25 스코어를, 요약문으로는 임베딩 유사도를 각각 계산한 뒤 Reciprocal Rank Fusion으로 두 랭킹을 융합해 최종 후보를 선정해요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/780/1*Ui4VMyPZahcEKMLFnOntzw.png&quot; /&gt;&lt;/figure&gt;&lt;p&gt;이렇게 DFS 수준의 성능을 유지하면서 LLM 호출 횟수 자체를 줄이고, 사전 필터링을 통해 토큰 사용량도 줄일 수 있었어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*hGiTiQCmfk7Z335_qOSFCg.png&quot; /&gt;&lt;/figure&gt;&lt;h3&gt;시도했으나 채택하지 않은 전략&lt;/h3&gt;&lt;p&gt;여기서는 효과적이었던 전략만 소개했지만 사실 그 과정에서 여러 시행착오가 많았어요.&lt;/p&gt;&lt;p&gt;키워드 룰셋 기반 방식은 과거 정답 데이터를 기반으로 키워드와 카테고리 매핑을 만들어서, 명확한 케이스는 LLM 없이 처리하려는 시도였어요. 하지만 실제 데이터는 롱테일 분포를 따르기 때문에 규칙으로 커버할 수 있는 범위가 좁아 들이는 노력 대비 이득이 크지 않았어요. 또 “아이패드 케이스”가 “iPad”가 아니라 “태블릿 케이스”로 분류되어야 하는 것처럼, 그 룰셋이 쉽게 복잡해지고 사람 혹은 LLM을 이용한 고도화가 필요했기에 이 방향으로는 더 투자하지 않았어요.&lt;/p&gt;&lt;p&gt;Agentic grep은 기존 전략들과는 꽤 다른 접근이었어요. 기존 전략들이 시스템이 카테고리를 보여주고 LLM이 고르는 방식이라면, 이 전략은 LLM에게 전체 카테고리를 보여주는 대신 grep 도구를 쥐어주고 스스로 탐색하게 하는 방식이에요. 예를 들어 “아이폰 15 프로”라는 게시글이 들어오면, LLM이 “iPhone”, “Smartphone”, “Electronic device” 등의 키워드로 직접 grep하고, 결과를 확인한 뒤, 후보군을 점점 좁혀가 최종 카테고리를 제출하는 식으로 자율적으로 탐색해요. 하지만 실제로 Evaluation을 수행해봤을 땐 생각보다 정확도가 높지 않았고 비용이 매우 높아서 실제로 도입되진 않았어요.&lt;/p&gt;&lt;h3&gt;그 외 운영 개선 작업들&lt;/h3&gt;&lt;p&gt;전략만큼 큰 변화는 아니더라도, 꾸준히 효과를 만들어낸 개선들도 많았어요.&lt;/p&gt;&lt;p&gt;먼저 임베딩 품질을 높이는 작업을 병행했어요. Ground-truth 샘플을 이용해 오프라인 실험으로 여러 임베딩 모델을 비교해보며 Recall과 Similarity, Rank 성능이 좋은 모델로 변경하기도 했고, Gemini 임베딩 모델의 task type을 적용해서 게시글과 카테고리 각각에 더 적합한 임베딩을 만들도록 튜닝하기도 했어요.&lt;/p&gt;&lt;p&gt;이미지 최적화도 큰 효과가 있었어요. 기존에는 해상도를 512x512로 맞췄는데, Gemini Flash 2.0 모델 기준으로 이 해상도는 이미지 1장당 4개의 타일이 필요해서 약 1,032 토큰이 소비됐어요. 해상도를 384x384로 낮추면 1개의 타일만 사용하게 되어 이미지당 토큰을 1/4로 줄일 수 있었어요. 그리고 사용자가 올린 이미지를 전부 보내던 방식에서, 이미지 개수를 줄이더라도 정확도 손실이 크지 않다는 걸 확인해서 이미지 개수 자체도 줄였어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*fwTPPL_BpORUQCfRbzbFvw.png&quot; /&gt;&lt;/figure&gt;&lt;p&gt;속성 precision을 올리기 위한 프롬프트 개선도 있었어요. 상품 상태나 거래 방식처럼 주관적인 판단이 필요한 속성을 추가한 이후, 속성 precision이 떨어지는 문제가 있었어요. 경계가 불분명한 값이나 기준이 모호한 값이 있었기 때문이에요. 그래서 각 속성 description에 분류 기준을 더 구체적으로 추가했고, 그 기준을 프롬프트에서 사용할 수 있게 해서 precision을 끌어올렸어요.&lt;/p&gt;&lt;pre&gt;name: Item condition&lt;br&gt;description: |&lt;br&gt;  Indicates the physical condition and functional state of an item.&lt;br&gt;&lt;br&gt;  Classification criteria (Korean keywords):&lt;br&gt;  - new: 새상품, 미개봉, 택달린, 새것, BNIB&lt;br&gt;  - open_box: 단순개봉, 개봉만 함, 박스개봉&lt;br&gt;  - used_like_new: 거의 새것, 1-2회 사용, 착용만 해봄, 시착만&lt;br&gt;  - used_excellent: 상태 좋음, 깨끗함, 하자 없음, A급&lt;br&gt;  - used_good: 사용감 있음, 약간의 사용감, 보통, B급&lt;br&gt;  - used_fair: 하자, 기스, 얼룩, 변색, 수선 필요&lt;br&gt;&lt;br&gt;  Default: used_good (when condition is not explicitly mentioned)&lt;/pre&gt;&lt;h3&gt;지표 트래킹&lt;/h3&gt;&lt;p&gt;위에서 이야기한 변경들의 효과와 리스크를 확인하고, 이상치를 감지하기 위해서는 지속적인 지표 트래킹이 필수예요. 전략이나 프롬프트, 모델 변경이 아니더라도 데이터 트렌드가 바뀌거나 의존하는 LLM 서비스의 상태에 따라 지표가 움직일 수 있기 때문이에요.&lt;/p&gt;&lt;p&gt;저희는 품질 대시보드를 만들어 비용, 정확도, 카테고리 레벨별 정확도를 한눈에 볼 수 있게 했어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*cB6WhBfmMczG9Z-wgV_wvw.png&quot; /&gt;&lt;/figure&gt;&lt;p&gt;이 외에도 속성도 그 분포를 추적하고, 특정 카테고리로 분류가 쏠리진 않는지, Primary 모델과 Eval 모델의 판단이 갈렸을 때 어떻게 갈린건지 알 수 있는 오분류 샘플 등도 확인하며 지속적으로 전략이나 프롬프트 개선의 단서를 얻고있어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*BKZCegNaI6fgg6n_2zGvOQ.png&quot; /&gt;&lt;/figure&gt;&lt;h3&gt;이렇게 만든 데이터, 어디에 쓰이나요?&lt;/h3&gt;&lt;p&gt;이런 과정을 거쳐 분류된 카테고리와 속성은 실제로 당근 내 여러 서비스에서 쓰이고 있어요.&lt;/p&gt;&lt;p&gt;앞서 말씀드렸듯 분류 결과는 BigQuery에 쌓아서 다른 팀에서 자유롭게 활용할 수 있도록 했어요. 이 곳에 쌓인 데이터는 분석, 실험, 추천 모델 학습 등 필요한 팀이 가져다 쓸 수 있는 원천 데이터 역할을 해요.&lt;/p&gt;&lt;p&gt;택소노미 체계 자체를 다른 서비스에서 코드로 활용해야 하는 경우도 있어요. 상위 카테고리를 조회해야 한다거나, 검색에서 하위 카테고리를 모두 포함해 검색해야 하는 경우 등이 그래요. 이를 위해 각 팀에서 택소노미 YAML 파일을 직접 파싱하고 트리를 구성하는걸 피하기 위해 택소노미에선 Golang과 Python SDK를 만들어 제공해드리고있어요. 카테고리 조회, 트리 탐색, 속성 조회를 할 수 있고, 택소노미의 정의와 구조를 한 곳에서 관리할 수 있어요.&lt;/p&gt;&lt;pre&gt;from taxonomy_manager import TaxonomyManager, Category, Attribute&lt;br&gt;&lt;br&gt;tm = TaxonomyManager.create_taxonomy_manager(&lt;br&gt;    content_type=&amp;quot;fleamarket&amp;quot;,&lt;br&gt;    config_name=&amp;quot;karrot_category&amp;quot;,&lt;br&gt;)&lt;br&gt;&lt;br&gt;cat: Category = tm.get_category(&amp;quot;aa-1-1&amp;quot;)&lt;br&gt;print(cat.name)           # 카테고리 이름&lt;br&gt;print(cat.breadcrumb)     # &amp;quot;Electronics &amp;gt; Phones&amp;quot; 형태&lt;br&gt;print(cat.child_ids)      # 하위 카테고리 ID 목록&lt;br&gt;&lt;br&gt;if tm.category_id_exists(&amp;quot;aa-1-1&amp;quot;):&lt;br&gt;    print(&amp;quot;exists&amp;quot;)&lt;/pre&gt;&lt;h3&gt;서비스 사용 케이스&lt;/h3&gt;&lt;p&gt;또 추천엔진이나 검색엔진에서 각 게시글의 카테고리와 속성 분류 결과를 모델 피쳐로 활용할 수 있도록 카테고리 분류 결과를 Kafka를 거쳐 피쳐플랫폼에도 적재하고 있어요.&lt;/p&gt;&lt;p&gt;이렇게 쌓인 카테고리 피쳐는 주로 홈피드 중고거래 게시글 추천에서 활용하고 있어요. 비슷한 카테고리의 게시글이 연달아 나오지 않도록 다양성을 확보하는 휴리스틱에 사용되기도 하고, 추천 모델의 피쳐로도 활용되고 있어요. 게시글의 카테고리 피쳐나 카테고리 기반 통계 피쳐 등이 모델에 들어가요.&lt;/p&gt;&lt;p&gt;크로스 도메인 추천도 흥미로운 케이스예요. 중고거래뿐만 아니라 모임의 카테고리 체계도 택소노미 시스템에서 관리하고 있기 때문에, 중고거래와 모임 카테고리 간의 관련성을 파악할 수 있어요. 이를 활용해서 테니스 라켓 중고거래 게시글을 보고 있는 사용자에게 테니스 모임을 추천하는 식의 크로스 도메인 추천을 제공하고 있어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*EH4gWjMj7j4DetFhQIRcsg.png&quot; /&gt;&lt;figcaption&gt;테니스 라켓 물품에 보이는 테니스 모임 추천&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;앞으로 더 뭘 할 건가요?&lt;/h3&gt;&lt;p&gt;2025년 하반기에 Taxonomy Management System을 구축한 후 지금까지 운영해오며 많은 확장과 개선이 있었지만 아직도 많은 개선점들이 존재해요.&lt;/p&gt;&lt;p&gt;첫 번째는 LLM에서 자체 모델로의 전환, 혹은 파인튜닝 시도예요. 지금까지 모든 분류는 적어도 1번 이상의 LLM API 호출이 발생하고 이로인해 택소노미 파이프라인 비용의 대부분이 LLM 비용인 상황이에요. 어느정도 체계가 안정되어 변화가 자주 발생하지 않는 택소노미는 6개월 이상 쌓인 분류 결과를 활용해 ML 모델을 학습시키는 시도를 해보려고 해요. 일정 비율은 모델로 처리하고, 나머지는 LLM을 유지해서 새로운 카테고리에도 대응하고 품질을 계속 검토하는 식으로요. 이렇게 하면 품질은 유지하면서 전체 비용이 절감되리라 기대해요. 상황에 따라 LLM 파인튜닝도 옵션이 될 수 있고요.&lt;/p&gt;&lt;p&gt;두 번째는 추론 품질 지표 고도화예요. 지금은 전략, 프롬프트, 모델을 바꿀 때 정확도와 비용을 중심으로 판단하고 있는데, 이것만으로는 그 비교가 충분히 날카롭지 않을 때가 있어요. 어떤 카테고리를 더 잘 맞추고, 어떤 카테고리를 더 못 맞추는지, 그리고 얼마나 심각하게 틀렸는지까지 근거로 삼을 수 있도록 지표를 개선하고 있어요.&lt;/p&gt;&lt;p&gt;세 번째는 택소노미 Evolution을 더 잘하는 거예요. 분류 정확도와는 별개로 택소노미 체계 자체의 품질을 높이는 방향이에요. 택소노미 체계 품질을 높이려면, 이 체계를 평가하는 지표도 있어야 해요. 어떤 것이 좋은 택소노미인지 정량적으로 정의할 수 있는 지표를 설계하고, 카테고리와 속성을 추가하거나 체계 변경이 생길 때 어떤 영향을 미치는지 실험하면서 발전시켜 나가려고 해요.&lt;/p&gt;&lt;p&gt;네 번째는 적은 인력으로도 LLM과 Code Agent를 레버리지 삼아 더 큰 아웃풋을 내는 거예요. 택소노미 정의, 번역, 전략 실험까지 Agent를 적극 활용하면서 운영 부담을 줄이고 있는데, 앞으로는 이런 방식으로 더 잘 레버리지해서 더 많은 개선을 만들어내려 해요.&lt;/p&gt;&lt;h3&gt;끝으로&lt;/h3&gt;&lt;p&gt;여기까지 작년 하반기부터 지금까지 Taxonomy 팀이 어떻게 택소노미를 정의하고, 추론을 더 잘하기 위한 시스템을 구축해왔고, 어떻게 운영해왔는지 읽어주셔서 감사해요. 당근에서는 현재 AI와 ML을 활용한 다양한 시도를 하고 있어요. 마침 &lt;a href=&quot;https://2026ml.daangn.com/&quot;&gt;당근에서 ML 엔지니어를 절찬리 채용 중&lt;/a&gt;이니 많은 관심 부탁드려요.&lt;/p&gt;&lt;h3&gt;같이 읽으면 좋은 글&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://medium.com/daangn/%EB%8B%B9%EA%B7%BC%EC%9D%98-genai-%ED%94%8C%EB%9E%AB%ED%8F%BC-ee2ac8953046&quot;&gt;당근의 GenAI 플랫폼&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/2309.13063&quot;&gt;Using Large Language Models to Generate, Validate, and Apply User Intent Taxonomies&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://shopify.engineering/product-taxonomy-at-scale&quot;&gt;Beyond classification: How AI agents are evolving Shopify’s product taxonomy at scale&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://public.walmart.com/content/walmart-global-tech/en_us/blog/post/using-llms-to-manage-product-catalogs.html&quot;&gt;How Walmart uses LLMs to manage its massive product catalogs&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=f619f1db6b7b&quot; width=&quot;1&quot; height=&quot;1&quot; alt=&quot;&quot;&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&quot;https://medium.com/daangn/2%EC%A1%B0-%ED%86%A0%ED%81%B0%EC%9D%84-%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC-%EB%B6%84%EB%A5%98%EC%97%90-%EC%93%B0%EB%A9%B4%EC%84%9C-%EC%95%8C%EA%B2%8C%EB%90%9C-%EA%B2%83%EB%93%A4-f619f1db6b7b&quot;&gt;2조 토큰을 카테고리 분류에 쓰면서 알게된 것들&lt;/a&gt; was originally published in &lt;a href=&quot;https://medium.com/daangn&quot;&gt;당근 테크 블로그&lt;/a&gt; on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</content:encoded>
    </item>
    <item>
      <title>‘로컬’ 슈퍼 앱에서 장기 유저 모델링은 어떻게 달라질까?</title>
      <link>https://medium.com/daangn/%EB%A1%9C%EC%BB%AC-%EC%8A%88%ED%8D%BC-%EC%95%B1%EC%97%90%EC%84%9C-%EC%9E%A5%EA%B8%B0-%EC%9C%A0%EC%A0%80-%EB%AA%A8%EB%8D%B8%EB%A7%81%EC%9D%80-%EC%96%B4%EB%96%BB%EA%B2%8C-%EB%8B%AC%EB%9D%BC%EC%A7%88%EA%B9%8C-d10cf75845bd?source=rss----4505f82a2dbd---4</link>
      <guid>https://medium.com/daangn/%EB%A1%9C%EC%BB%AC-%EC%8A%88%ED%8D%BC-%EC%95%B1%EC%97%90%EC%84%9C-%EC%9E%A5%EA%B8%B0-%EC%9C%A0%EC%A0%80-%EB%AA%A8%EB%8D%B8%EB%A7%81%EC%9D%80-%EC%96%B4%EB%96%BB%EA%B2%8C-%EB%8B%AC%EB%9D%BC%EC%A7%88%EA%B9%8C-d10cf75845bd?source=rss----4505f82a2dbd---4</guid>
      <pubDate>Fri, 27 Feb 2026 10:26:07 GMT</pubDate>
      <content:encoded>&lt;p&gt;안녕하세요! 당근 ML Foundation 팀에서 ML Engineer로 일하고 있는 Hawke와 Ben.Kim이에요. 저희 팀은 개인화 추천 개선을 위한 “기반 기술”을 만드는 역할을 하고 있어요. 이 글에서는 유저의 장기 행동 로그를 Transformer로 학습해 유저 임베딩을 만들고, 홈피드·광고 등 다양한 추천 모델에 적용해 큰 폭의 온라인 지표 개선을 달성한 여정을 공유하려고 해요.&lt;/p&gt;&lt;h3&gt;왜 장기 유저 모델링이 필요할까?&lt;/h3&gt;&lt;p&gt;추천 시스템에서 “유저가 지금 무엇을 원하는지”는 최근 행동에서 잘 드러나요. 하지만 서비스를 운영하다 보면 최근 행동만으로는 답하기 어려운 질문들을 계속 마주치게 돼요.&lt;/p&gt;&lt;h4&gt;&lt;strong&gt;1. 단기 히스토리에 담기지 않는 지속 취향과 반복 관심사는 어떻게 반영할까요?&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;매 겨울 패딩이나 방한용품을 반복해서 검색하는 유저, 이사철마다 부동산 매물을 탐색하는 유저가 있어요. 최근 로그만으로는 이런 패턴이 드러나지 않아요.&lt;/p&gt;&lt;h4&gt;&lt;strong&gt;2. 여러 버티컬을 넘나드는 유저의 관심사는 어떻게 파악할까요?&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;부동산에서 매물을 탐색하는 유저가 중고거래에서 가구·가전을 검색하고, 동네생활에서 이사 후기를 찾는 경우가 있어요. 하나의 관심사가 장기간에 걸쳐 여러 버티컬에 나타나는데, 일부 지면의 최근 데이터만 사용하면 이런 연결을 잡기 어려워요.&lt;/p&gt;&lt;h4&gt;&lt;strong&gt;3. 추천이 만든 노출 로그만 학습하면 생기는 selection bias를 장기 관점에서 완화할 수 있을까요?&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;짧은 기간의 로그만 학습하면 “모델이 보여준 것만 다시 학습하는” 순환에 빠질 수 있어요. 장기 로그를 활용하면 여러 세대의 모델과 다양한 맥락에서 발생한 액션을 함께 보게 되어 이 순환을 완화할 여지가 있어요.&lt;/p&gt;&lt;p&gt;하지만 추천 모델에 히스토리를 더 길게 넣으면 단순히 해결되는 문제가 아니에요. 예를 들어, 랭킹 모델은 지연(latency)에 민감해 실시간 입력을 무한정 늘리기 어렵고, 히스토리를 길게 가져갈수록 계산량과 인프라 복잡도가 급격히 커져요. 결국 &lt;strong&gt;긴 기간의 데이터를 넣는 것 + 잘 배울 수 있도록 설계하는 것 + 서빙할 수 있게 만드는 것&lt;/strong&gt;, 이 세 가지를 함께 풀어야 하는 문제예요.&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2205.04507&quot;&gt;Pinterest&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/abs/2311.09544&quot;&gt;Meta&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/abs/2505.04421&quot;&gt;ByteDance&lt;/a&gt; 등에서도 장기 히스토리 활용이 추천 성능에 큰 개선을 준 사례가 이미 보고되고 있었어요. 저희도 이 방향으로 가보기로 했어요.&lt;/p&gt;&lt;h3&gt;우리가 택한 방향: 장기 유저 임베딩을 ‘공통 피처’로 만들자&lt;/h3&gt;&lt;p&gt;저희가 선택한 접근 방식은 이래요. 장기 히스토리는 &lt;strong&gt;별도의 user encoder가 오프라인에서 학습하고 추론&lt;/strong&gt;하고, 다운스트림 모델(홈피드 랭킹, 후보 모델, 광고 랭킹)은 이를 “공통 유저 피처”로 받아 쓰는 구조예요.&lt;/p&gt;&lt;p&gt;이 방식의 장점은 세 가지예요.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;다운스트림 모델은 장기 히스토리를 직접 들고 있지 않아도 돼요.&lt;/strong&gt; 지연과 복잡도를 관리하기 쉬워요.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;User encoder는 데이터와 컴퓨팅 스케일을 독립적으로 키울 수 있어요.&lt;/strong&gt; 다운스트림 모델을 건드리지 않고 user encoder만 스케일업하거나 실험할 수 있어서 실험 속도가 빨라지고, 모델 크기와 학습 데이터를 자유롭게 확장할 수 있어요.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;한 번 만든 임베딩을 여러 지면에서 재사용할 수 있어요.&lt;/strong&gt; 홈피드, 후보 모델, 광고 등 다양한 곳에서 동일한 유저 임베딩을 사용해요.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;물론 이 구조에도 한계가 있어요.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;user encoder는 수백억 건의 로그와 큰 Transformer로 학습되어 다운스트림 모델보다 훨씬 풍부한 표현력을 가지고 있지만, 다운스트림 모델은 이를 고정된 하나의 피처 벡터로만 받아쓰기 때문에 그 표현력이 충분히 전달되지 못해요.&lt;/li&gt;&lt;li&gt;오프라인 배치 추론 방식이기 때문에 유저의 최신 행동이 즉시 임베딩에 반영되지 않는 신선도(freshness) 문제가 있어요.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;유저 임베딩 추론 주기를 줄여 실시간에 가까운 갱신을 하거나, 다운스트림 태스크에 대한 fine-tuning과 distillation으로 user encoder의 표현력을 더 끌어다 쓰는 것 등 이런 한계를 극복하기 위한 시도들은 앞으로의 과제로 남겨두고 있어요.&lt;/p&gt;&lt;h3&gt;User Modeling with Contrastive Learning&lt;/h3&gt;&lt;p&gt;이제 유저 임베딩을 만들기 위해 저희가 사용한 user encoder 구조를 소개할게요. 모델 구조는 잘 알려진 two-tower 구조를 사용했어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*5Xi8xKr7i4RrnGsk4aktqw.png&quot; /&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;User Tower&lt;/strong&gt;: 유저의 액션 시퀀스를 Causal Transformer에 통과시켜 유저 임베딩을 생성해요.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Item Tower&lt;/strong&gt;: 아이템 피처들을 MLP에 통과시켜 아이템 임베딩을 생성해요.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;학습&lt;/strong&gt;: 유저 임베딩과 다음 액션 아이템 임베딩 사이의 InfoNCE loss (contrastive learning)로 학습해요.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;LLM이 다음 토큰을 예측하며 언어를 배우듯, 이 모델은 유저의 다음 액션을 예측하며 유저의 취향을 배워요. 유저 시퀀스의 매 시점에서 “이 유저가 다음에 어떤 아이템과 상호 작용을 할까?”를 예측하도록 하고, 배치 내 다른 아이템들은 negative로 사용하는 in-batch negative 방식이에요.&lt;/p&gt;&lt;p&gt;학습 데이터로는 중고거래·알바·부동산·중고차 등 여러 버티컬에서 발생한 클릭, 전환(관심, 채팅 지원 등) 액션을 모두 사용했어요. 기존 추천 모델들이 일부 지면의 짧은 기간 데이터만 사용한 것에 비해, 저희 모델은 모든 버티컬·모든 지면의 장기 데이터를 사용했다는 점이 큰 차이예요. 데이터 양 측면에서는 기존 홈피드 two-tower 후보 모델 대비 약 150배 많은 수백억 개의 유저 행동 로그로 학습했어요.&lt;/p&gt;&lt;h3&gt;아이템을 어떻게 표현할 것인가: ID 임베딩 vs 콘텐츠 임베딩&lt;/h3&gt;&lt;p&gt;장기 유저 모델링에서 아이템 표현 방식의 선택은 스케일과 서빙 전략을 좌우하는 중요한 결정이에요. 저희는 두 가지 접근을 모두 실험했어요.&lt;/p&gt;&lt;h3&gt;Option A: Item ID 임베딩&lt;/h3&gt;&lt;p&gt;Item ID를 주요 피처로 사용하는 방식을 먼저 검토했어요. ID 기반 피처는 추천 도메인에서 보편적으로 강력한 성능을 보여주거든요. 하지만 장기 유저 모델링에 적용하기에는 두 가지 한계가 있어요.&lt;/p&gt;&lt;p&gt;첫째, &lt;strong&gt;Cold item 문제&lt;/strong&gt;예요. 학습이 끝난 후에 새로 생성된 아이템은 ID 임베딩이 없어요. 그래서 유저 임베딩을 학습 시점에 고정(frozen)해서 사용하거나 신규 아이템에 대응하기 위해서는 별도의 테크닉이 필요해요. 특히 아이템의 생애주기가 짧은 편인 중고거래 버티컬에서는 이 문제에 대응하기가 더 까다로워요.&lt;/p&gt;&lt;p&gt;둘째, GPU &lt;strong&gt;메모리 제약&lt;/strong&gt;이에요. 장기 데이터를 학습하면 수억 개 이상의 아이템 ID가 필요한데, 이 임베딩 테이블이 GPU 메모리의 대부분을 차지해요. 그 결과 Transformer 자체의 크기를 키우기 어려웠어요. ID 기반 모델의 경우 전체 파라미터의 99% 이상을 임베딩 테이블이 차지하고, Transformer는 1%도 되지 않았죠. &lt;a href=&quot;https://arxiv.org/abs/1909.02107&quot;&gt;Compositional Embedding&lt;/a&gt;이나 &lt;a href=&quot;https://arxiv.org/abs/2305.12102&quot;&gt;Unified Embedding&lt;/a&gt;과 같은 hash trick을 사용하면 gpu 메모리 사용량을 줄일 수 있었으나, 성능 문제로 채택되지 못하는 경우도 있었어요. 이런 한계를 극복하기 위한 GPU Embedding table sharding 등의 시도를 과제로 남겨두고 있어요.&lt;/p&gt;&lt;h3&gt;Option B: 콘텐츠 임베딩&lt;/h3&gt;&lt;p&gt;이런 한계 때문에 저희는 별도의 LLM 기반 임베딩 모델이 게시글의 메타 데이터로부터 만들어낸 &lt;strong&gt;콘텐츠 임베딩&lt;/strong&gt;을 아이템 피처로 사용하는 방식으로 전환했어요.&lt;/p&gt;&lt;p&gt;콘텐츠 임베딩을 사용하면 두 가지 문제가 한꺼번에 해결돼요.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Cold item 표현 개선&lt;/strong&gt;: 새 아이템도 메타 데이터만 있으면 임베딩을 만들 수 있으므로, LLM 기반 임베딩 모델이 충분히 강력하다면, 유저 임베딩을 정보 손실 없이 주기적으로 갱신할 수 있어요.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;GPU 메모리 확보&lt;/strong&gt;: 임베딩 테이블이 필요 없으므로 GPU 메모리를 Transformer 스케일업에 온전히 사용할 수 있어요. 실제로 Transformer 파라미터를 Item ID 임베딩 사용할 때 대비 1,000배 키울 수 있었어요.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;다만 쉽지만은 않았어요. 콘텐츠 임베딩은 별도의 임베딩 모델로 미리 생성해 파일로 저장해두고, 학습 데이터의 각 example에는 아이템 ID가 들어있어요. 학습 시에 아이템 ID에 해당하는 콘텐츠 임베딩을 파일에서 찾아서 join 해야 하는데, 두 가지 메모리 문제가 있었어요. 수억 개 아이템의 임베딩 파일은 수백 GB에 달해 통째로 메모리에 올리기 어렵고, 아이템 ID로 파일 내 임베딩의 위치를 찾기 위한 매핑 역시 수억 건 규모라 Python dict 같은 자료구조로는 그것만으로도 수십 GB의 메모리를 차지했어요.&lt;/p&gt;&lt;p&gt;그래서 저희는 두 가지 방법을 조합해서 해결했어요.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;memmap (Memory-Mapped File)&lt;/strong&gt;: 임베딩 파일 전체를 메모리에 올리지 않고, 필요한 부분만 디스크에서 읽어오는 방식이에요. 특히, DDP (분산학습) 시에는 여러 프로세스가 OS의 page cache를 공유할 수 있어서 효율적이었어요.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;bbhash (Minimal Perfect Hash)&lt;/strong&gt;: 아이템 ID → 파일 내 위치 매핑에 사용했어요. bbhash는 키 하나당 약 3비트만 사용하는 해시 함수로, Python dict 대비 메모리를 약 97% 절감할 수 있었어요.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;이 두 가지를 조합해 대규모 콘텐츠 임베딩을 머신의 물리 메모리 크기에 무관하게 학습에 활용할 수 있었고, 콘텐츠 임베딩 기반 장기 유저 모델을 현실적인 비용으로 학습할 수 있었어요.&lt;/p&gt;&lt;h3&gt;지역 기반 서비스에서의 in-batch negatives&lt;/h3&gt;&lt;p&gt;여기부터는 저희 프로젝트에서 가장 흥미로운 챌린지였어요. Contrastive learning에서 일반적으로 in-batch negatives를 사용하는데, 이것의 기본 가정은 “배치 내 다른 아이템 = 볼 수 있었는데 선택하지 않은 것”이에요. 하지만 당근은 지역 기반 서비스이기 때문에 이 가정이 깨져요.&lt;/p&gt;&lt;h3&gt;Feasible Negative와 Impossible Negative&lt;/h3&gt;&lt;p&gt;당근에서 거래의 86% 이상은 반경 5km 이내에서 발생해요. 유저는 자기 동네 근처의 게시글만 볼 수 있으니, 서울 강남의 유저가 부산의 중고 물품을 보는 건 불가능해요. 하지만 랜덤으로 배치를 구성하면, 배치에는 전국 각지의 유저와 아이템이 섞여 들어와요. 이때 배치 내 negative로 사용되는 아이템은 두 종류로 나뉘어요.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Feasible negatives&lt;/strong&gt;: 유저가 “볼 수 있었는데” 선택하지 않은 아이템. 이것이 의미 있는 학습 신호예요.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Impossible negatives&lt;/strong&gt;: 유저가 애초에 “볼 수 없는” 아이템. 플랫폼 정책에 의해 노출이 불가능한 것이지, 유저 취향과는 관련이 없어요.&lt;/li&gt;&lt;/ul&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*WfqO2-QhAU2D83fpEyIU0w.png&quot; /&gt;&lt;figcaption&gt;당근에서의 노출 가능성을 나타낸 그림이에요. 유저 𝑢는 자신의 노출 범위(viewable cells) 안에 있는 아이템(𝑖₁, 𝑖₂, 𝑖₃)만 홈피드에서 볼 수 있어요. 노출 범위 밖의 아이템(빨간 점)은 유저에게 노출되지 않아요.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;당근에서의 노출 가능성을 나타낸 그림이에요. 유저 𝑢는 자신의 노출 범위(viewable cells) 안에 있는 아이템(𝑖₁, 𝑖₂, 𝑖₃)만 홈피드에서 볼 수 있어요. 노출 범위 밖의 아이템(빨간 점)은 유저에게 노출되지 않아요.&lt;/p&gt;&lt;p&gt;문제는 랜덤 배치에서 &lt;strong&gt;약 98%가 impossible negatives&lt;/strong&gt;였다는 점이에요. 모델이 학습하는 비교의 상당 부분이 “취향”이 아니라 “노출 불가능”을 구분하는 데 쓰이고 있었고, 그 결과 contrastive learning의 학습 신호가 크게 희석됐어요.&lt;/p&gt;&lt;h3&gt;해결책: Region-Constrained Batch Sampling (RCBS)&lt;/h3&gt;&lt;p&gt;해결 방법은 의외로 간단했어요. &lt;strong&gt;모델이나 loss를 그대로 두고, 배치 구성 방식만 바꿨어요.&lt;/strong&gt; 같은 지역의 유저끼리 배치를 묶으면 배치 내 아이템들이 서로 볼 수 있는 범위 안에 있게 되거든요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*uGWjUTE5Y3EUGYfRGZxUMA.png&quot; /&gt;&lt;figcaption&gt;기존 random batching과 Region-Constrained Batch Sampling(RCBS)을 비교한 그림이에요. 유저 𝑢에 대해 RCBS는 같은 지역의 유저들(파란 셀)로 미니배치를 구성해서, random batching 대비 impossible negatives(빨간 셀)를 크게 줄여줘요.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;기존 random batching과 Region-Constrained Batch Sampling(RCBS)을 비교한 그림이에요. 유저 𝑢에 대해 RCBS는 같은 지역의 유저들(파란 셀)로 미니배치를 구성해서, random batching 대비 impossible negatives(빨간 셀)를 크게 줄여줘요.&lt;/p&gt;&lt;p&gt;유저의 지역 정보로 배치를 묶어주니, impossible negatives 비율이 98%에서 30%으로 줄었어요. 나머지 30%는 유저마다 노출 반경이 다르거나, 이사 등으로 과거에 다른 지역에서 활동한 기록이 있는 경우 등등에 해당해요.&lt;/p&gt;&lt;p&gt;단순히 impossible negatives를 줄인 것 외에 부가 효과도 있었어요. Feasible negatives는 “유저가 볼 수 있었는데 선택하지 않은” 아이템이기 때문에 impossible negatives보다 더 어려운(harder) negative 역할을 해요. 같은 동네의 비슷한 아이템들 사이에서 유저의 진짜 취향을 구분해야 하니까요. 실제로 RCBS 방식으로 평가했을 때 Random 평가보다 점수가 낮게 나왔는데, 이는 feasible negatives가 더 어려운 negative임을 보여줘요.&lt;/p&gt;&lt;h3&gt;다른 방법이 아닌 batch sampling으로 해결한 이유?&lt;/h3&gt;&lt;p&gt;가장 먼저 떠오르는 방법은 impossible negatives를 배치 내에서 mask out하는 거예요. 유저가 물리적으로 접근할 수 없는 아이템을 loss 계산에서 제외하는 방식이죠. 하지만 배치의 98%가 impossible negatives인 상황에서 이들을 모두 mask out하면 effective batch size가 극단적으로 작아져요. Contrastive learning에서 배치 사이즈는 성능에 직결되는 핵심 요소인데, 대부분의 negative를 날려버리면 학습 자체가 매우 비효율적이에요. 그래서 negative를 걸러내는 대신, 배치 구성 자체를 바꿔서 처음부터 feasible negatives가 많아지도록 하는 RCBS가 더 효율적인 해결책이었어요.&lt;/p&gt;&lt;p&gt;Hard negative mining도 생각해 봤지만, 한 유저의 hard negative가 다른 유저에게는 impossible negative가 될 수 있어요. 즉, 유저마다 feasibility를 고려해서 negative를 따로 mining해야 하는데, 이는 구현이 복잡하고 비용이 많이 들어요. 반면 RCBS는 같은 지역의 유저들로 배치를 구성하는 것만으로도 in-batch에서 harder negative가 자연스럽게 등장할 수 있기 때문에, 별도의 mining 없어도 비슷한 효과를 얻을 수 있는 더 간단한 방법이었어요.&lt;/p&gt;&lt;h3&gt;랭킹·후보·광고에 적용하기&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;홈피드/광고 랭킹 모델에서&lt;/strong&gt; 유저 임베딩의 효과를 실험하기 위해 단순히 유저 피처로 추가했어요. 유저 임베딩에 projection layer를 통과시킨 후 기존 피처들과 concat 하는 방식이에요. 장기 유저 모델링이 유저의 장기적인 취향 시그널을, 기존 랭킹 모델이 단기적인 실시간 시그널을 각각 담당하는 식으로 역할이 분리되기를 기대했어요.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;홈피드/광고 후보(retrieval) 모델에는&lt;/strong&gt; 여러 가지 방법을 시도했어요. 그중 성능이 가장 좋았던 건 랭킹 모델에서처럼 기존 모델에 유저 임베딩을 피처로 추가하는 것이 아닌, 유저 임베딩만으로 후보군을 제공하는 방법이었어요. 서로 다른 성질의 후보군이 추천의 다양성을 높여준 것으로 보여요.&lt;/p&gt;&lt;h3&gt;유저 임베딩 갱신&lt;/h3&gt;&lt;p&gt;콘텐츠 임베딩 기반 모델에서는 새 아이템에 대해서도 좋은 임베딩을 얻을 수 있으므로, 최적의 유저 임베딩 갱신 주기를 찾기 위한 실험을 했어요. 오프라인에서는 고정, 24시간 갱신, 12시간 갱신 간에 유의미한 차이가 보이지 않았지만, 온라인 A/B 테스트에서는 고정보다는 주기적 추론이, 주기적 추론에서는 추론 주기가 짧을수록 더 좋은 성능을 보였어요. 비용과 성능의 trade-off를 고려해 &lt;strong&gt;24시간 주기&lt;/strong&gt;로 결정했어요.&lt;/p&gt;&lt;p&gt;또 갱신 주기 이내에 계산을 마치기 위해 추론 파이프라인은 beam pipeline으로 구현하여 GCP dataflow 위에서 GPU로 추론했어요. 또한, 전체 유저의 임베딩을 추론하는 대신, 갱신 주기 안에 액션을 해서 갱신이 필요한 유저의 임베딩만 추론하여 추론 비용과 시간을 최적화했어요.&lt;/p&gt;&lt;p&gt;유저 임베딩의 성능을 최대로 활용하려면 실시간 추론에 가까워져야 하기에, 이를 지원하는건 앞으로 풀어야 할 큰 엔지니어링 챌린지 중 하나예요.&lt;/p&gt;&lt;h3&gt;실험 결과&lt;/h3&gt;&lt;h3&gt;오프라인 결과&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;유저 모델링 pretraining&lt;/strong&gt; 단계에서 RCBS의 효과를 보기 위해서, random batch로 학습 시킨 모델 (Random-Train), 같은 coarse 지역 셀에 속한 유저들로 구성한 batch로 학습시킨 모델 (RCBS-Train(coarse)), 그리고 같은 fine 지역 셀에 속한 유저들로 구성한 batch로 학습시킨 모델 (RCBS-Train(fine)), 이렇게 세 가지 버전의 성능을 비교했어요.&lt;/p&gt;&lt;p&gt;그리고 feasible negatives가 실제로 harder negative인지를 확인하기 위해 평가도 두 가지 배치로 나눠서 진행했어요. 하나는 feasible negative의 비율이 낮은 random batch 에서의 Random-Eval Recall이고, 다른 하나는 feasible negative 비율이 높은 같은 fine 지역 셀에 속한 유저들로 구성한 batch 에서의 RCBS-Eval (fine) Recall이에요. 각 batch 에서의 impossible negative 비율도 함께 측정했어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*YMvdzrgHBNz4hIYryPj8Ug.png&quot; /&gt;&lt;figcaption&gt;유저 모델링 pretraining 오프라인 평가&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;실험 결과 RCBS를 설계할 때의 직관인, impossible negatives를 줄이면 contrastive learning 학습 신호의 질이 올라갈 것이다는 것을 확인할 수 있었어요. Impossible negative 비율이 낮을수록 Recall이 일관되게 높아졌고, RCSB-Train (fine)은 Random-Train 대비 Recall@10이 Random-Eval에서 +49%, RCBS-Eval (fine)에서 +70% 개선됐어요.&lt;/p&gt;&lt;p&gt;또한 같은 모델이라도 RCBS-Eval에서의 점수가 Random-Eval보다 항상 낮게 나왔는데, 이는 feasible negatives가 impossible negatives보다 harder negative라는 것을 실험적으로 보여줘요.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;다운스트림 태스크&lt;/strong&gt;에서도 RCBS-Train (fine) 유저 임베딩이 일관되게 더 좋은 성능을 보였어요. 홈피드 랭킹에서 Random-Train 유저 임베딩의 개선폭이 미미한 반면, RCBS-Train (fine) 유저 임베딩은 유의미한 개선을 가져왔다는 점이 인상적이에요. 똑같이 장기 유저 로그를 활용하더라도 어떻게 학습시켰냐에 따라 성능이 크게 차이 났어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/850/1*mkPoXKleqRejjUNj_REM5A.png&quot; /&gt;&lt;figcaption&gt;다운스트림 태스크 오프라인 평가&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;온라인 A/B 테스트&lt;/h3&gt;&lt;p&gt;오프라인 실험에서 가장 성능이 좋았던 RCBS-Train (fine) 유저 임베딩을 홈피드 및 광고 후보/랭킹에 적용한 온라인 실험을 했어요. 실험 결과 trade-off 없이 여러 지표가 함께 개선된 걸 관측했고, 그 결과 여러 차례의 배포까지 이어졌어요.&lt;/p&gt;&lt;p&gt;아래 표는 여러 차례의 A/B 테스트의 누적 지표 변화예요. 클릭과 노출뿐 아니라 DAV(Daily Active Viewers), 앱 체류시간, 광고 매출까지 전방위적으로 개선됐어요. 특히 중고거래 채팅, 체류시간, DAV는 깊은 연결이 늘었다는 의미여서 고무적인 결과였어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/510/1*WFxPg9SXvqWbCbqidY8Sdg.png&quot; /&gt;&lt;figcaption&gt;온라인 A/B 테스트 누적 지표 변화&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;마치며&lt;/h3&gt;&lt;p&gt;이 프로젝트를 통해, 잘 알려진 방법을 그대로 가져다 쓰는 것이 아니라 서비스 도메인을 이해하고 그에 맞게 설계하는 것이 중요하다는 걸 다시 한번 느꼈어요. 유저 모델링 뿐만 아니라, 당근 각 팀의 ML 엔지니어들이 서비스 곳곳에서 이러한 설계에 많은 노력을 기울이고 있어요.&lt;/p&gt;&lt;p&gt;앞으로는 더 많은 지면과 버티컬로 확장하며 모델과 데이터 스케일을 키워나갈 예정이에요. 엔지니어링 측면에서는 유저 임베딩 추론 주기를 단축하고 추론 효율을 개선하는 것이 다음 과제예요.&lt;/p&gt;&lt;p&gt;&lt;em&gt;이 글의 일러스트는 Irene 이 도와주셨어요. 감사해요!&lt;/em&gt;&lt;/p&gt;&lt;p&gt;당근에서는 추천, 검색, 광고 등 다양한 도메인에서 서비스 특성을 반영한 ML 설계, 대규모 데이터·학습·추론 파이프라인, large-scale 모델링 등 흥미로운 문제를 풀고 있어요. 이런 문제를 함께 풀어갈 ML Engineer를 찾고 있으니, 관심이 있다면 아래 채용 공고를 확인해 보세요!&lt;/p&gt;&lt;p&gt;👉️ &lt;a href=&quot;https://2026ml.daangn.com/&quot;&gt;2026 당근 ML 직군 채용 바로가기&lt;/a&gt;&lt;/p&gt;&lt;img src=&quot;https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=d10cf75845bd&quot; width=&quot;1&quot; height=&quot;1&quot; alt=&quot;&quot;&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&quot;https://medium.com/daangn/%EB%A1%9C%EC%BB%AC-%EC%8A%88%ED%8D%BC-%EC%95%B1%EC%97%90%EC%84%9C-%EC%9E%A5%EA%B8%B0-%EC%9C%A0%EC%A0%80-%EB%AA%A8%EB%8D%B8%EB%A7%81%EC%9D%80-%EC%96%B4%EB%96%BB%EA%B2%8C-%EB%8B%AC%EB%9D%BC%EC%A7%88%EA%B9%8C-d10cf75845bd&quot;&gt;‘로컬’ 슈퍼 앱에서 장기 유저 모델링은 어떻게 달라질까?&lt;/a&gt; was originally published in &lt;a href=&quot;https://medium.com/daangn&quot;&gt;당근 테크 블로그&lt;/a&gt; on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</content:encoded>
    </item>
    <item>
      <title>200MB 모듈을 팀 단위로 해결하기: 당근 숏폼팀의 On-demand Dynamic Feature Module 도입</title>
      <link>https://medium.com/daangn/200mb-%EB%AA%A8%EB%93%88%EC%9D%84-%ED%8C%80-%EB%8B%A8%EC%9C%84%EB%A1%9C-%ED%95%B4%EA%B2%B0%ED%95%98%EA%B8%B0-%EB%8B%B9%EA%B7%BC-%EC%88%8F%ED%8F%BC%ED%8C%80%EC%9D%98-on-demand-dynamic-feature-module-%EB%8F%84%EC%9E%85-adb6794f2a9b?source=rss----4505f82a2dbd---4</link>
      <guid>https://medium.com/daangn/200mb-%EB%AA%A8%EB%93%88%EC%9D%84-%ED%8C%80-%EB%8B%A8%EC%9C%84%EB%A1%9C-%ED%95%B4%EA%B2%B0%ED%95%98%EA%B8%B0-%EB%8B%B9%EA%B7%BC-%EC%88%8F%ED%8F%BC%ED%8C%80%EC%9D%98-on-demand-dynamic-feature-module-%EB%8F%84%EC%9E%85-adb6794f2a9b?source=rss----4505f82a2dbd---4</guid>
      <pubDate>Fri, 27 Feb 2026 10:12:24 GMT</pubDate>
      <content:encoded>&lt;p&gt;안녕하세요. 당근 숏폼팀 안드로이드 엔지니어 Bob이에요.&lt;/p&gt;&lt;p&gt;당근 스토리는 동네 가게와 일상을 1분 이내 영상으로 공유하는 지역 기반 숏폼 서비스예요. 동네 맛집, 운동, 미용실 같은 가게 이야기부터 일상적인 동네 소식까지, 우리 동네 사람들에게 자연스럽게 노출되는 게 특징이에요. 비즈니스, 부동산, 모임 등 당근의 여러 서비스에서도 숏폼을 활용하고 있고요.&lt;/p&gt;&lt;p&gt;현재 당근 스토리는 국내에서만 운영되고 있어요. 글로벌 앱에는 아직 숏폼 기능이 포함되어 있지 않죠.&lt;/p&gt;&lt;h3&gt;편집 기능이 만든 고민&lt;/h3&gt;&lt;p&gt;당근 앱은 &lt;strong&gt;MAU 2000만&lt;/strong&gt;이 넘는 대규모 서비스로, 멀티모듈 구조로 되어 있어요. 숏폼팀도 shortform 모듈 안에서 독립적으로 개발하고 있죠.&lt;/p&gt;&lt;p&gt;당근 스토리에 비디오 편집 기능을 추가했을 때, 이 모듈의 용량이 &lt;strong&gt;200MB&lt;/strong&gt;가 됐어요. 필터, 이펙트, 스티커 같은 리소스가 전부 SDK에 번들로 들어 있었거든요.&lt;/p&gt;&lt;p&gt;용량을 줄여야겠다는 게 첫 생각이었어요. 우선 &lt;strong&gt;리소스를 전부 CDN으로 전환&lt;/strong&gt;하는 작업부터 시작했어요. 필요할 때만 다운로드하는 구조로 바꿨더니, 새 필터나 이펙트를 앱 배포 없이 반영할 수 있게 됐고 A/B 테스트도 유연해졌어요. 이 과정에서 용량이 &lt;strong&gt;200MB → 40MB&lt;/strong&gt;로 줄었죠. 하지만 40MB도 여전히 가벼운 수치는 아니었어요.&lt;/p&gt;&lt;p&gt;영상 편집은 소수만 사용하는 기능인데, 글로벌 전체 사용자에게 40MB가 함께 설치되는 건 고민이었어요.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;우리 팀의 실험이 전체 사용자 경험에 영향을 주지 않았으면 좋겠다&lt;/strong&gt; — 이게 팀의 결론이었고, DFM 도입으로 이어졌어요.&lt;/p&gt;&lt;h3&gt;Dynamic Feature Module이란?&lt;/h3&gt;&lt;p&gt;DFM(Dynamic Feature Module)은 앱의 특정 기능을 별도 모듈로 분리해서 필요할 때만 다운로드할 수 있게 해주는 &lt;a href=&quot;https://developer.android.com/guide/playcore/feature-delivery?hl=ko&quot;&gt;Android App Bundle&lt;/a&gt;의 기능이에요. 배포(Delivery) 방식은 세 가지가 있어요:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Install-time Delivery&lt;/strong&gt;: 앱 설치 시 함께 설치&lt;/li&gt;&lt;li&gt;&lt;strong&gt;On-demand Delivery&lt;/strong&gt;: 사용자 요청 시 다운로드&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Conditional Delivery&lt;/strong&gt;: 조건(국가, API 레벨 등)에 따라 자동 설치&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;당근은 이미 Conditional Delivery로 국가별 모듈을 제공한 경험이 있어요. 설치 시점에 국가별 코드를 자동으로 내려보내는 방식이었죠. (&lt;a href=&quot;https://medium.com/daangn/app-bundle%EC%9D%98-dynamic-delivery%EB%A1%9C-%EA%B5%AD%EA%B0%80%EB%B3%84-%EB%AA%A8%EB%93%88-%EC%A0%9C%EA%B3%B5%ED%95%98%EA%B8%B0-ee699c561707&quot;&gt;App Bundle의 Dynamic Delivery로 국가별 모듈 제공하기&lt;/a&gt;)&lt;/p&gt;&lt;p&gt;이번에는 설치 시점이 아니라 &lt;strong&gt;사용자가 필요할 때만 다운로드&lt;/strong&gt;해야 하는 상황이었기 때문에, &lt;strong&gt;On-demand Delivery&lt;/strong&gt;를 선택했어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*FQjRDKhpLtdSePfx5K8NCA.png&quot; /&gt;&lt;/figure&gt;&lt;p&gt;On-demand Delivery로 전환하면, 편집 기능을 쓰지 않는 대다수 사용자와 글로벌 사용자는 설치 시 40MB를 받지 않아도 앱을 사용할 수 있어요.&lt;/p&gt;&lt;p&gt;동시에 &lt;strong&gt;사용자가 편집 기능을 처음 쓰는 순간&lt;/strong&gt;의 경험도 함께 설계해야 했어요. DFM 다운로드를 어떻게 자연스럽게 보여줄지, 네트워크 이슈가 있을 때 어떻게 안내할지 같은 운영 과제도 함께 고민했죠.&lt;/p&gt;&lt;h3&gt;실제 사용자 플로우&lt;/h3&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*ppr7mBp5D9FQByMyEbzpew.png&quot; /&gt;&lt;/figure&gt;&lt;p&gt;&lt;em&gt;편집 버튼을 누르면 편집 모듈이 다운로드되고, 이후에는 로컬에 설치되어 바로 사용 가능해요.&lt;/em&gt;&lt;/p&gt;&lt;h3&gt;개발 과정에서 마주한 이슈들&lt;/h3&gt;&lt;p&gt;처음에는 “DFM에서 코드영역을 완전히 분리하자”고 생각했어요. 네이티브 라이브러리(SO 파일)뿐 아니라 기능 코드, DI까지 모두 DFM으로 옮기려 했죠. 하지만 막상 해보니, “기술적으로 가능한 것”과 “운영에서 효율적인 것” 사이에는 간극이 있었어요.&lt;/p&gt;&lt;blockquote&gt;DFM을 사용하게 되면 모듈구조가 &lt;strong&gt;base 모듈&lt;/strong&gt;과 &lt;strong&gt;feature(DFM) 모듈&lt;/strong&gt; 두 가지로 나뉘어요. base 모듈은 앱 설치 시 항상 포함되는 기본 모듈이고, feature 모듈은 필요할 때 추가로 다운로드되는 모듈이에요. 아래 이슈들은 이 구조에서 발생한 것들이에요.&lt;/blockquote&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*tYj3lcsbjbMHttXgpbg-HQ.png&quot; /&gt;&lt;/figure&gt;&lt;h3&gt;1. Hilt/DI 제약&lt;/h3&gt;&lt;p&gt;Hilt는 컴파일 타임에 모든 모듈의 의존성 그래프를 합쳐서 코드를 생성해요. 그런데 DFM은 base와 별도로 빌드되기 때문에, Hilt의 어노테이션 프로세서가 DFM 안의 @Inject나 @Module을 base 빌드 시점에 알 수 없어요. 그래서 DFM에서는 Hilt를 그대로 쓸 수 없어요. 대신 EntryPoint 패턴으로 base에서 의존성을 노출하고, DFM 쪽에서 Dagger 컴포넌트를 직접 구성해야 해요.&lt;/p&gt;&lt;pre&gt;// base: EntryPoint로 의존성 노출&lt;br&gt;@InstallIn(SingletonComponent::class)&lt;br&gt;@EntryPoint&lt;br&gt;interface VideoEditorDependencies {&lt;br&gt;    fun provideVideoProcessor(): VideoProcessor&lt;br&gt;}&lt;br&gt;&lt;br&gt;// DFM: Dagger 컴포넌트 수동 구성&lt;br&gt;@Component(dependencies = [VideoEditorDependencies::class])&lt;br&gt;interface VideoEditorComponent {&lt;br&gt;    fun inject(activity: VideoEditorActivity)&lt;br&gt;    @Component.Factory&lt;br&gt;    interface Factory {&lt;br&gt;        fun create(deps: VideoEditorDependencies): VideoEditorComponent&lt;br&gt;    }&lt;br&gt;}&lt;br&gt;&lt;br&gt;// 런타임 초기화&lt;br&gt;class VideoEditorActivity : AppCompatActivity() {&lt;br&gt;    override fun onCreate(savedInstanceState: Bundle?) {&lt;br&gt;        super.onCreate(savedInstanceState)&lt;br&gt;        val deps = EntryPointAccessors.fromApplication(&lt;br&gt;            applicationContext, VideoEditorDependencies::class.java&lt;br&gt;        )&lt;br&gt;        DaggerVideoEditorComponent.factory().create(deps).inject(this)&lt;br&gt;    }&lt;br&gt;}&lt;/pre&gt;&lt;h3&gt;2. SplitCompat 설정&lt;/h3&gt;&lt;p&gt;Android에서 DFM은 split APK 형태로 별도 설치돼요. 문제는 기본 ClassLoader가 나중에 설치된 split APK의 클래스나 리소스를 인식하지 못한다는 거예요. SplitCompat은 이 ClassLoader를 패치해서, On-demand로 설치된 DFM의 코드와 리소스에 접근할 수 있게 해줘요. 설정하지 않으면 DFM 설치 후에도 ClassNotFoundException이나 리소스 로딩 실패가 발생할 수 있어요.&lt;/p&gt;&lt;pre&gt;// 방법 1&lt;br&gt;@HiltAndroidApp&lt;br&gt;class MyApplication : SplitCompatApplication()&lt;br&gt;&lt;br&gt;// 방법 2&lt;br&gt;@HiltAndroidApp&lt;br&gt;class MyApplication : Application() {&lt;br&gt;  override fun attachBaseContext(base: Context) {&lt;br&gt;    super.attachBaseContext(base)&lt;br&gt;    SplitCompat.install(this)&lt;br&gt;  }&lt;br&gt;}&lt;/pre&gt;&lt;h3&gt;3. SO 파일 관리&lt;/h3&gt;&lt;p&gt;DFM 환경에서는 일반적인 앱과 SO 파일의 로딩·패키징 방식이 달라서, 확인해야 할 케이스가 여럿 있었어요:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;라이브러리 로딩 경로&lt;/strong&gt;: On-demand DFM의 SO 파일은 일반적인 nativeLibraryDir이 아니라 SplitCompat이 관리하는 별도 경로에 설치돼요. &lt;strong&gt;System.loadLibrary()&lt;/strong&gt;로는 찾지 못하고 UnsatisfiedLinkError가 발생하기 때문에, &lt;strong&gt;SplitInstallHelper.loadLibrary()&lt;/strong&gt;를 사용해야 해요. 서드파티 SDK처럼 코드를 수정할 수 없는 경우에는 해당 의존성을 base 모듈로 옮겨야 해요.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;ABI 필터 불일치&lt;/strong&gt;: base 모듈과 DFM이 지원하는 ABI 세트가 다르면 bundletool 빌드 자체가 실패해요. 모든 모듈의 &lt;strong&gt;ndk.abiFilters&lt;/strong&gt;를 동일하게 맞춰야 해요.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;특히 까다로웠던 게 &lt;strong&gt;STL 문제&lt;/strong&gt;예요.&lt;/p&gt;&lt;blockquote&gt;STL(C++ Standard Template Library)은 C++의 표준 라이브러리로, 문자열 처리·메모리 관리·자료구조 등 C++ 프로그램의 핵심 기능을 제공해요. Android에서는 libc++_shared.so라는 하나의 SO 파일로 앱에 포함되는데, 여러 네이티브 라이브러리가 이 파일을 공유하기 때문에 DFM처럼 모듈이 분리된 환경에서는 버전 관리가 특히 중요해요.&lt;/blockquote&gt;&lt;p&gt;C++ 네이티브 라이브러리들이 사용하는 STL은 Android에서 libc++_shared.so 형태로 앱에 포함돼요. DFM 환경에서는 각 모듈이 독립적으로 빌드된 뒤 런타임에 결합되기 때문에, 버전 불일치가 발생할 수 있어요.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;심볼 충돌&lt;/strong&gt;: Android 동적 링커는 먼저 로드된 심볼을 우선 사용해요(First-Loaded-Wins). base 모듈의 libc++가 먼저 로드되면, DFM 라이브러리도 그 버전의 심볼을 쓰게 돼요.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;런타임 크래시&lt;/strong&gt;: NDK 버전마다 STL 객체의 내부 구조가 미세하게 다르기 때문에, ABI 불일치로 앱이 비정상 종료될 수 있어요.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;메모리 오염&lt;/strong&gt;: A 버전 STL에서 할당한 메모리를 B 버전 STL이 해제하려고 하면 힙 영역에서 잘못된 메모리 해제가 발생해요. 가장 주의가 필요한 부분이에요.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;이러한 이슈들을 해결하기 위해서 &lt;strong&gt;base 모듈의 Gradle 스크립트&lt;/strong&gt;에서 특정 SO 파일을 의도적으로 제외해서 On-demand DFM에서만 내려받게 만들었어요. 중복 충돌을 피하기 위해 일부 SO 파일은 pick-first로 하나만 패키징하도록 조정했고요.&lt;/p&gt;&lt;pre&gt;android {&lt;br&gt;    packaging {&lt;br&gt;        jniLibs {&lt;br&gt;            excludes += &amp;quot;lib/*/libvideoeditor.so&amp;quot;      // DFM에서만 제공&lt;br&gt;            pickFirsts += &amp;quot;lib/*/libc++_shared.so&amp;quot;     // STL 중복 방지&lt;br&gt;        }&lt;br&gt;    }&lt;br&gt;}&lt;/pre&gt;&lt;h3&gt;4. R8 규칙 관리&lt;/h3&gt;&lt;p&gt;Release 직전에 발견한 이슈도 있었어요. DFM에만 둔 keep 규칙 때문에 base의 타입이 난독화되면서 런타임에 타입을 찾지 못하는 현상이 생긴 거예요. 이 경험 덕에 “규칙은 한 곳에서 관리한다”는 원칙이 굳어졌어요. &lt;strong&gt;keep 규칙은 base에 집중&lt;/strong&gt;하고, DFM의 consumerProguard는 최소한으로 유지하는 방향으로 정리했어요.&lt;/p&gt;&lt;h3&gt;그래서 우리는, SO 파일만 분리했어요&lt;/h3&gt;&lt;p&gt;이런 이슈들을 하나씩 겪으면서 깨달은 건, 모든 코드를 DFM으로 옮길 필요가 없다는 거였어요. 결국 &lt;strong&gt;DFM에는 SO 파일만 넣고&lt;/strong&gt; 기능 코드는 base에 유지하는 방향으로 수렴했어요.&lt;/p&gt;&lt;p&gt;남은 40MB를 뜯어보니 &lt;strong&gt;대부분이 SO 파일&lt;/strong&gt;이었거든요. 비디오 편집 SDK 자체가 네이티브 라이브러리로 구현되어 있어서, 비디오 처리·이미지 필터링·이펙트 렌더링 엔진이 전부 SO 파일 형태였어요. 반면 기능 코드 자체는 몇백 KB 수준이었고요. 그래서 기능 코드는 base 모듈에 두고, 용량의 핵심인 SO 파일만 On-demand로 다운로드하는 구조를 택했어요.&lt;/p&gt;&lt;h4&gt;&lt;strong&gt;장점:&lt;/strong&gt;&lt;/h4&gt;&lt;ul&gt;&lt;li&gt;기능 코드가 base에 있으니 DFM 로딩에 실패해도 앱이 죽지 않아요. SO 파일만 없는 상태니까 안내만 보여주면 되죠.&lt;/li&gt;&lt;li&gt;로컬 개발할 때 DFM을 신경 쓸 필요가 없고, 디버깅도 훨씬 수월해요.&lt;/li&gt;&lt;li&gt;SO 파일만 분리해도 &lt;strong&gt;90% 이상의 용량 절감&lt;/strong&gt; 효과를 얻을 수 있었어요.&lt;/li&gt;&lt;/ul&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*3bFOmzazPghLwI9NLhvxHQ.png&quot; /&gt;&lt;/figure&gt;&lt;h4&gt;&lt;strong&gt;단점:&lt;/strong&gt;&lt;/h4&gt;&lt;ul&gt;&lt;li&gt;코드는 base에 있고 SO 파일은 DFM에 있는 구조라, 처음 접하는 엔지니어에게 낯설 수 있어요.&lt;/li&gt;&lt;li&gt;DFM 다운로드 → SO 파일 로딩 → 기능 사용까지의 흐름을 명시적으로 관리해야 해요.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;이 흐름을 코드로 표현하면 다음과 같아요. 모듈 설치 여부를 확인하고, 설치되어 있으면 SO 파일을 로딩한 뒤 기능을 실행하는 구조예요:&lt;/p&gt;&lt;pre&gt;class VideoEditorLauncher(private val context: Context) {&lt;br&gt;  private val splitInstallManager = SplitInstallManagerFactory.create(context)&lt;br&gt;  fun launchEditor() {&lt;br&gt;    if (isModuleInstalled()) {&lt;br&gt;      try {&lt;br&gt;        System.loadLibrary(&amp;quot;videoeditor&amp;quot;)&lt;br&gt;        startEditorActivity()&lt;br&gt;      } catch (e: UnsatisfiedLinkError) {&lt;br&gt;        showError(&amp;quot;편집 기능을 사용할 수 없습니다&amp;quot;)&lt;br&gt;      }&lt;br&gt;    } else {&lt;br&gt;      requestModuleInstall()&lt;br&gt;    }&lt;br&gt;  }&lt;br&gt;  private fun isModuleInstalled(): Boolean {&lt;br&gt;    return splitInstallManager.installedModules.contains(&amp;quot;videoeditor&amp;quot;)&lt;br&gt;  }&lt;br&gt;}&lt;/pre&gt;&lt;blockquote&gt;✅&lt;strong&gt;핵심은 글로벌 사용자에게 불필요한 40MB 부담을 주지 않으면서도, 다른 팀 서비스에 영향을 주지 않는 구조를 만든 거예요.&lt;/strong&gt;&lt;/blockquote&gt;&lt;h3&gt;마무리&lt;/h3&gt;&lt;p&gt;&lt;em&gt;💡아래는 이번 경험을 통해 느낀 &lt;/em&gt;&lt;strong&gt;&lt;em&gt;개인적인 견해&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;예요.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;처음엔 모든걸 깔끔하게 분리하는 아키텍처를 목표로 했어요. 그 과정에서 의존성 관리, SO 파일 버전 정합성, R8 규칙 분산 같은 고려할 점들을 하나씩 풀어나갔죠.&lt;/p&gt;&lt;p&gt;최종적으로 선택한 건 “SO 파일만 분리하는 DFM”으로 &lt;strong&gt;국내 전용 기능의 용량을 글로벌 사용자와 분리하면서도 안정적으로 운영할 수 있는 실용적인 방법&lt;/strong&gt;이었어요.&lt;/p&gt;&lt;p&gt;대규모 앱에서 팀 단위로 실험할 때 중요하다고 느낀 점은:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;안정성&lt;/strong&gt;: 다른 팀과 글로벌 서비스에 영향을 주지 않을 것&lt;/li&gt;&lt;li&gt;&lt;strong&gt;독립성&lt;/strong&gt;: 팀이 자율적으로 개발하고 실험할 수 있을 것&lt;/li&gt;&lt;li&gt;&lt;strong&gt;운영 효율성&lt;/strong&gt;: 팀원 누구나 이해하고 고칠 수 있을 것&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;“한 번 써보자”로 시작한 프로젝트였는데, 결국 &lt;strong&gt;“멋있게 만들기”보다 “안정적으로 굴리기”가 더 중요하다&lt;/strong&gt;는 걸 배웠어요.&lt;/p&gt;&lt;h3&gt;Appendix&lt;/h3&gt;&lt;blockquote&gt;📎On-demand DFM을 직접 적용해보신다면 참고해보세요.&lt;/blockquote&gt;&lt;p&gt;DFM은 &lt;strong&gt;설치된 상태와 설치되지 않은 상태&lt;/strong&gt; 모두를 확인해야 해요.&lt;/p&gt;&lt;h3&gt;테스트 방식&lt;/h3&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;실제 환경&lt;/strong&gt;: Play Console 내부 테스트나 Internal App Sharing으로 실제 다운로드 플로우 검증&lt;/li&gt;&lt;li&gt;&lt;strong&gt;로컬 반복&lt;/strong&gt;: bundletool로 DFM 설치/미설치 상태를 전환하면서 빠르게 반복 테스트&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Universal APK&lt;/strong&gt;: 모든 모듈이 합쳐진 상태라 일반 APK처럼 빠르게 설치·검증 가능&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;bundletool 명령어&lt;/h3&gt;&lt;p&gt;DFM은 Play Store를 통해 제공되는 기능이라, 로컬 환경에서 테스트하려면 bundletool을 사용해야 해요.&lt;/p&gt;&lt;pre&gt;# 디바이스 스펙 추출&lt;br&gt;bundletool get-device-spec --output=device-spec.json&lt;br&gt;&lt;br&gt;# 기본 APKs 빌드&lt;br&gt;bundletool build-apks \\&lt;br&gt;  --bundle=app-release.aab --output=app.apks \\&lt;br&gt;  --ks=keystore.jks --ks-pass=pass:password \\&lt;br&gt;  --ks-key-alias=alias --key-pass=pass:password&lt;br&gt;&lt;br&gt;# DFM 미설치 테스트 (base만)&lt;br&gt;bundletool build-apks \\&lt;br&gt;  --bundle=app-release.aab --output=base-only.apks \\&lt;br&gt;  --device-spec=device-spec.json --modules=base&lt;br&gt;bundletool install-apks --apks=base-only.apks&lt;br&gt;&lt;br&gt;# DFM 설치 테스트 (base + DFM)&lt;br&gt;bundletool build-apks \\&lt;br&gt;  --bundle=app-release.aab --output=with-dfm.apks \\&lt;br&gt;  --device-spec=device-spec.json --modules=base,videoeditor&lt;br&gt;bundletool install-apks --apks=with-dfm.apks&lt;br&gt;&lt;br&gt;# Universal APK&lt;br&gt;bundletool build-apks \\&lt;br&gt;  --bundle=app-release.aab --output=universal.apks --mode=universal&lt;br&gt;bundletool install-apks --apks=universal.apks&lt;br&gt;&lt;br&gt;# 모듈별 사이즈 확인&lt;br&gt;bundletool get-size total --apks=app.apks --modules=base&lt;br&gt;bundletool get-size total --apks=app.apks --modules=base,videoeditor&lt;/pre&gt;&lt;h3&gt;체크리스트&lt;/h3&gt;&lt;h4&gt;&lt;strong&gt;적용 전&lt;/strong&gt;&lt;/h4&gt;&lt;ul&gt;&lt;li&gt;모듈 사이즈 확인 (AAB Build 후 실제 용량 측정)&lt;/li&gt;&lt;li&gt;다운로드 타이밍 예측 (네트워크 속도별 시뮬레이션)&lt;/li&gt;&lt;li&gt;SplitCompat 적용 위치 결정&lt;/li&gt;&lt;li&gt;base/DFM 미설치/설치 케이스 전부 테스트&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;&lt;strong&gt;운영 중 모니터링&lt;/strong&gt;&lt;/h4&gt;&lt;ul&gt;&lt;li&gt;DFM 다운로드 성공률&lt;/li&gt;&lt;li&gt;SO 파일 로딩 실패율&lt;/li&gt;&lt;li&gt;편집 기능 진입 성공률&lt;/li&gt;&lt;li&gt;네트워크 실패 시 재시도 성공률&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;참고 링크&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://developer.android.com/guide/playcore/feature-delivery&quot;&gt;Play Feature Delivery 개요&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://developer.android.com/guide/playcore/feature-delivery#dynamic-feature-module&quot;&gt;DFM 모듈 구조 가이드&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://developer.android.com/training/dependency-injection/hilt-multi-module&quot;&gt;DFM에서의 Dagger/Hilt&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://developer.android.com/studio/build/shrink-code&quot;&gt;R8/ProGuard 개요&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://developer.android.com/ndk/guides&quot;&gt;NDK 및 SO 로딩&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;당근 모바일 엔지니어 채용 공고&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://about.daangn.com/jobs/?q=mobile#_filter&quot;&gt;https://about.daangn.com/jobs/?q=mobile#_filter&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=adb6794f2a9b&quot; width=&quot;1&quot; height=&quot;1&quot; alt=&quot;&quot;&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&quot;https://medium.com/daangn/200mb-%EB%AA%A8%EB%93%88%EC%9D%84-%ED%8C%80-%EB%8B%A8%EC%9C%84%EB%A1%9C-%ED%95%B4%EA%B2%B0%ED%95%98%EA%B8%B0-%EB%8B%B9%EA%B7%BC-%EC%88%8F%ED%8F%BC%ED%8C%80%EC%9D%98-on-demand-dynamic-feature-module-%EB%8F%84%EC%9E%85-adb6794f2a9b&quot;&gt;200MB 모듈을 팀 단위로 해결하기: 당근 숏폼팀의 On-demand Dynamic Feature Module 도입&lt;/a&gt; was originally published in &lt;a href=&quot;https://medium.com/daangn&quot;&gt;당근 테크 블로그&lt;/a&gt; on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</content:encoded>
    </item>
    <item>
      <title>웹뷰 엔지니어를 위한 iOS Webview Input 경험 개선기</title>
      <link>https://medium.com/daangn/%EC%9B%B9%EB%B7%B0-%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A5%BC-%EC%9C%84%ED%95%9C-ios-webview-input-%EA%B2%BD%ED%97%98-%EA%B0%9C%EC%84%A0%EA%B8%B0-94a5c2882118?source=rss----4505f82a2dbd---4</link>
      <guid>https://medium.com/daangn/%EC%9B%B9%EB%B7%B0-%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A5%BC-%EC%9C%84%ED%95%9C-ios-webview-input-%EA%B2%BD%ED%97%98-%EA%B0%9C%EC%84%A0%EA%B8%B0-94a5c2882118?source=rss----4505f82a2dbd---4</guid>
      <pubDate>Mon, 23 Feb 2026 04:43:26 GMT</pubDate>
      <content:encoded>&lt;p&gt;안녕하세요. 당근 커뮤니티실에서 Software Engineer로 일하고 있는 &lt;strong&gt;Dave&lt;/strong&gt;예요. 저는 지난 4년간 &lt;strong&gt;웹뷰 기반의 커뮤니티 당근모임을&lt;/strong&gt; 만들어 왔어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*UQJATj8l6BS6kFoKIRvr3w.png&quot; /&gt;&lt;figcaption&gt;당근모임&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;당근의 커뮤니티 서비스인 동네생활에서 이웃들과 일상을 공유하고, 모임에서 같은 관심사를 가진 사람들과 대화하며, 카페에서 특정 주제로 정보를 나누고 이야기하는 등 유저 간 게시글, 댓글, 채팅을 통해 소통하는 순간이 많은데요.&lt;/p&gt;&lt;p&gt;그렇다 보니 커뮤니티 프로덕트에서의 Input은 단순한 폼 요소가 아니라 유저 경험을 좌우하는 핵심 인터랙션이었어요. 문제는 이 입력 경험이 &lt;strong&gt;웹뷰 환경&lt;/strong&gt;에서 이루어진다는 점이었는데요. 웹뷰에서는 가상 키보드, Focus, Viewport 같은 OS 레벨 동작을 완전히 제어하기 어렵고, 특히 iOS에서는 &lt;strong&gt;키보드가 올라올 때 화면이 밀리는 문제&lt;/strong&gt;가 유저의 흐름을 쉽게 끊어버렸어요.&lt;/p&gt;&lt;p&gt;그래서 이번 글에서는 이 문제를 해결하기 위해 겪었던 시행착오들을 기록해 보려고 해요.&lt;/p&gt;&lt;h3&gt;문제의 발견&lt;/h3&gt;&lt;p&gt;iOS 웹뷰에서 input에 focus가 되면, 화면 하단의 input을 키보드 위로 보이게 하기 위해 페이지 전체가 위로 밀려 올라가요. 이때 상단 콘텐츠가 화면 밖으로 사라지게 되는데, 이 동작은 웹 개발자가 제어할 수 없었어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/320/1*xNGNEhOzYnxTtLQcVQWrvw.gif&quot; /&gt;&lt;figcaption&gt;iOS input focus 기본 동작&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;우선 이 현상을 이해하려면 두 가지 Viewport 개념을 알아야 하는데요.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Layout Viewport&lt;/strong&gt;: CSS 레이아웃 기준 영역이에요. 키보드가 올라와도 크기가 변하지 않아요.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Visual Viewport&lt;/strong&gt;: 실제로 사용자 눈에 보이는 영역이에요. 키보드가 올라오면 그만큼 줄어들어요.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;키보드가 올라오면 Visual Viewport만 줄어들고, Layout Viewport는 그대로 유지돼요. 이 차이 때문에 iOS는 focus된 input을 보이게 하려고 페이지 전체를 밀어올리는 것이죠.&lt;/p&gt;&lt;h3&gt;첫번째 시도 — resize&lt;/h3&gt;&lt;p&gt;가장 먼저 떠올린 방법은 단순했어요. &lt;strong&gt;iOS가 밀어 올리면, 그냥 다시 내리자.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;visualViewport의 resize 이벤트를 감지해서 키보드 높이만큼 wrapper를 축소하고, window.scrollTo(0, 0)로 밀린 스크롤을 되돌리는 방식이에요.&lt;/p&gt;&lt;pre&gt;function Approach1() {&lt;br&gt;  const { keyboardHeight, isKeyboardOn } = useVisualViewport();&lt;br&gt;&lt;br&gt;  // visualViewport 변경될 때마다 스크롤을 원점으로 되돌림&lt;br&gt;  useEffect(() =&amp;gt; {&lt;br&gt;    const handler = () =&amp;gt; window.scrollTo(0, 0);&lt;br&gt;    window.visualViewport?.addEventListener(&amp;quot;resize&amp;quot;, handler);&lt;br&gt;    window.visualViewport?.addEventListener(&amp;quot;scroll&amp;quot;, handler);&lt;br&gt;    return () =&amp;gt; { /* cleanup */ };&lt;br&gt;  }, []);&lt;br&gt;  return (&lt;br&gt;    &amp;lt;div style={{&lt;br&gt;      position: &amp;quot;fixed&amp;quot;, top: 0, left: 0, right: 0,&lt;br&gt;      bottom: isKeyboardOn ? keyboardHeight : 0, // 키보드 높이만큼 축소&lt;br&gt;    }}&amp;gt;&lt;br&gt;      &amp;lt;div style={{ flex: 1, overflowY: &amp;quot;auto&amp;quot; }}&amp;gt;{/* 컨텐츠 */}&amp;lt;/div&amp;gt;&lt;br&gt;      &amp;lt;footer&amp;gt;&lt;br&gt;        &amp;lt;input placeholder=&amp;quot;댓글을 입력해주세요.&amp;quot; /&amp;gt;&lt;br&gt;      &amp;lt;/footer&amp;gt;&lt;br&gt;    &amp;lt;/div&amp;gt;&lt;br&gt;  );&lt;br&gt;}&lt;/pre&gt;&lt;h3&gt;한계&lt;/h3&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/320/1*2OMWSOUiOPriTNqDSwFDnw.gif&quot; /&gt;&lt;figcaption&gt;첫번째 시도의 결과물&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;문제는 &lt;strong&gt;scrollTo가 호출되기 전에 이미 화면이 밀려 올라간다&lt;/strong&gt;는 거예요.&lt;/p&gt;&lt;p&gt;iOS가 페이지를 밀고 → resize 이벤트가 발생하고 → 그제서야 scrollTo로 복구하니까, 사용자 눈에는 &lt;strong&gt;화면이 위로 밀렸다가 다시 내려오는 깜빡임&lt;/strong&gt;이 보였어요. 키보드가 올라오는 동안 resize 이벤트가 여러 번 발생하면서 화면이 덜덜 떨리기도 했고요.&lt;/p&gt;&lt;h3&gt;두번째 시도 — offsetTop&lt;/h3&gt;&lt;p&gt;첫 번째 시도의 문제는 “밀린 후에 복구한다”는 접근 자체였어요. 아무리 빠르게 복구해도 그 사이의 갭은 보이니까요.&lt;/p&gt;&lt;p&gt;그래서 방향을 바꿨어요. &lt;strong&gt;되돌리지 말고, 밀린 만큼 따라가자고.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;visualViewport.offsetTop은 화면이 얼마나 밀렸는지를 알려주는 값이에요. 이 값만큼 wrapper의 top을 같이 내려주면, 시각적으로는 콘텐츠가 제자리에 있는 것처럼 보여요.&lt;/p&gt;&lt;pre&gt;function useFixedLayoutSize(containerRef) {&lt;br&gt;  useEffect(() =&amp;gt; {&lt;br&gt;    const appScreenEl = containerRef.current?.closest(&amp;quot;.app-screen&amp;quot;);&lt;br&gt;    if (!appScreenEl) return;&lt;br&gt;    &lt;br&gt;    // AppScreen 루트를 fixed로 전환&lt;br&gt;    Object.assign(appScreenEl.style, {&lt;br&gt;      position: &amp;quot;fixed&amp;quot;, top: &amp;quot;0&amp;quot;, bottom: &amp;quot;0&amp;quot;, left: &amp;quot;0&amp;quot;, right: &amp;quot;0&amp;quot;,&lt;br&gt;    });&lt;br&gt;    const handler = () =&amp;gt; {&lt;br&gt;      const vv = window.visualViewport;&lt;br&gt;      if (!vv) return;&lt;br&gt;      const keyboardHeight = Math.max(0, window.innerHeight - vv.height);&lt;br&gt;      // iOS가 offsetTop을 비동기로 반영하므로 약간의 딜레이가 필요&lt;br&gt;      setTimeout(() =&amp;gt; {&lt;br&gt;        const offsetTop = window.visualViewport?.offsetTop ?? 0;&lt;br&gt;        appScreenEl.style.top = `${offsetTop}px`;  // 밀린 만큼 따라감&lt;br&gt;        appScreenEl.style.bottom = keyboardHeight &amp;gt; 0&lt;br&gt;          ? `${keyboardHeight - offsetTop}px` : &amp;quot;0px&amp;quot;;&lt;br&gt;      }, 150);&lt;br&gt;    };&lt;br&gt;    window.visualViewport?.addEventListener(&amp;quot;resize&amp;quot;, handler);&lt;br&gt;    window.visualViewport?.addEventListener(&amp;quot;scroll&amp;quot;, handler);&lt;br&gt;    return () =&amp;gt; { /* cleanup */ };&lt;br&gt;  }, [containerRef]);&lt;br&gt;}&lt;/pre&gt;&lt;p&gt;첫 번째보다 확실히 나았어요. 하지만 완벽하진 않았어요.&lt;/p&gt;&lt;h3&gt;한계&lt;/h3&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/320/1*tW_k1JDIQ4UqBklkeHlgAg.gif&quot; /&gt;&lt;figcaption&gt;두번째 시도의 결과물&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;offsetTop을 실시간으로 따라가다 보니, 키보드가 올라오는 동안 wrapper가 계속 위치를 조정하면서 &lt;strong&gt;미세한 떨림&lt;/strong&gt;이 있었어요. 유저가 여러 input을 빠르게 탭하거나 키보드를 접었다 폈다 하면 화면이 계속 흔들려서 어지럽다는 피드백도 있었고요.&lt;/p&gt;&lt;p&gt;결국 “iOS의 동작에 반응해서 보정하는” 방식 자체가 한계였어요. 아무리 빠르게 따라가도, iOS의 동작과 저희의 대응 사이에는 시간 차가 존재하니까요.&lt;/p&gt;&lt;h3&gt;세번째 시도 — Fake Input Swap&lt;/h3&gt;&lt;p&gt;이번에는 발상을 바꿔봤어요. 따라가지 말고, &lt;strong&gt;iOS가 밀 필요 자체를 없애자.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;iOS가 화면을 밀어올리는 이유는 focus된 input을 키보드 위로 보이게 하기 위해서예요. 그렇다면 focus를 받는 input이 아예 화면 바깥에 있다면? iOS는 의미 있는 스크롤을 할 수 없어요.&lt;/p&gt;&lt;p&gt;input을 두 개 준비했어요. 사용자에게 보이는 Fake Input(readOnly)과, 화면 밖에 숨겨둔 Real Input.&lt;/p&gt;&lt;pre&gt;function FooterWithInputSwap() {&lt;br&gt;  const [isKeyboardActive, setIsKeyboardActive] = useState(false);&lt;br&gt;  const realInputRef = useRef(null);&lt;br&gt;  const [text, setText] = useState(&amp;quot;&amp;quot;);&lt;br&gt;&lt;br&gt;  const hiddenStyle = { position: &amp;quot;absolute&amp;quot;, top: -9999, left: -9999, opacity: 0 };&lt;br&gt;  const visibleStyle = { flex: 1, padding: &amp;quot;10px 16px&amp;quot;, background: &amp;quot;#f5f5f5&amp;quot; };&lt;br&gt;  return (&lt;br&gt;    &amp;lt;footer&amp;gt;&lt;br&gt;      {/* Fake: 보이지만 readOnly. 터치하면 Real에 focus */}&lt;br&gt;      &amp;lt;input readOnly value={text} placeholder=&amp;quot;댓글을 입력해주세요.&amp;quot;&lt;br&gt;        onClick={() =&amp;gt; realInputRef.current?.focus()}&lt;br&gt;        style={isKeyboardActive ? hiddenStyle : visibleStyle} /&amp;gt;&lt;br&gt;      {/* Real: 평소엔 화면 밖. 키보드 올라오면 swap */}&lt;br&gt;      &amp;lt;input ref={realInputRef} value={text}&lt;br&gt;        onChange={(e) =&amp;gt; setText(e.target.value)}&lt;br&gt;        placeholder=&amp;quot;댓글을 입력해주세요.&amp;quot;&lt;br&gt;        onFocus={() =&amp;gt; requestAnimationFrame(() =&amp;gt; setIsKeyboardActive(true))}&lt;br&gt;        onBlur={() =&amp;gt; setIsKeyboardActive(false)}&lt;br&gt;        style={isKeyboardActive ? visibleStyle : hiddenStyle} /&amp;gt;&lt;br&gt;    &amp;lt;/footer&amp;gt;&lt;br&gt;  );&lt;br&gt;}&lt;/pre&gt;&lt;p&gt;사용자가 Fake Input을 터치하면 화면 밖의 Real Input에 focus가 가고, iOS는 화면 밖 요소를 위해 스크롤할 수 없으니 밀림이 발생하지 않아요. 키보드가 올라온 후 두 input을 swap하면 자연스럽게 입력이 가능해져요.&lt;/p&gt;&lt;h3&gt;한계&lt;/h3&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/320/1*ItcPpptf5AQjdKaWNr6kUg.gif&quot; /&gt;&lt;figcaption&gt;세번째 시도의 결과물&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;input focus시에 가상 키보드의 height보다 더 위에 input이 보였다가 움직이는 작은 이슈는 있었지만, 이제 어지러운 화면 밀림은 해결됐어요.&lt;/p&gt;&lt;p&gt;그렇지만 코드의 복잡도가 문제였어요.&lt;/p&gt;&lt;p&gt;input이 두 개다 보니 value, selection, placeholder 같은 &lt;strong&gt;상태를 계속 동기화&lt;/strong&gt;해야 했어요. 단순한 텍스트면 괜찮은데, textarea 자동 높이 조절이나 멘션, 이모지가 들어가면 유지보수 부담이 상당했어요. swap 시점의 미세한 깜빡임도 있었고, 키보드가 올라왔는지 정확히 감지하기 어려워서 네이티브 브릿지에 의존하는 등 로직이 점점 복잡해졌죠.&lt;/p&gt;&lt;p&gt;더 단순한 방법이 필요했어요.&lt;/p&gt;&lt;h3&gt;네번째 시도 — Opacity&lt;/h3&gt;&lt;p&gt;세번째 시도의 아이디어는 원하는대로 동작했어요. 하지만 문제는 input을 두 개 관리해야 한다는 점이었죠.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;input이 하나인 채로, focus 시점에만 iOS를 속일 수 있다면?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;iOS는 opacity: 0인 요소에 대해서는 scroll-into-view를 수행하지 않는 것으로 보여요. 이걸 활용해서, &lt;strong&gt;터치하는 순간 opacity를 0으로 만들고, 키보드가 올라온 뒤에 1로 복원하는 방식&lt;/strong&gt;을 적용했어요.&lt;/p&gt;&lt;pre&gt;function FooterWithOpacityTrick() {&lt;br&gt;  const [text, setText] = useState(&amp;quot;&amp;quot;);&lt;br&gt;  const inputRef = useRef(null);&lt;br&gt;  const isHiddenRef = useRef(false);&lt;br&gt;&lt;br&gt;  // 키보드가 완전히 올라오면 opacity 복원&lt;br&gt;  useEffect(() =&amp;gt; {&lt;br&gt;    const handler = () =&amp;gt; {&lt;br&gt;      if (!isHiddenRef.current) return;&lt;br&gt;      const keyboardHeight = window.innerHeight - (window.visualViewport?.height ?? 0);&lt;br&gt;      if (keyboardHeight &amp;gt; 80) {&lt;br&gt;        isHiddenRef.current = false;&lt;br&gt;        inputRef.current.style.opacity = &amp;quot;1&amp;quot;;&lt;br&gt;      }&lt;br&gt;    };&lt;br&gt;    window.visualViewport?.addEventListener(&amp;quot;resize&amp;quot;, handler);&lt;br&gt;    return () =&amp;gt; { /* cleanup */ };&lt;br&gt;  }, []);&lt;br&gt;  const handleTouchStart = () =&amp;gt; {&lt;br&gt;    if (!isHiddenRef.current &amp;amp;&amp;amp; inputRef.current) {&lt;br&gt;      isHiddenRef.current = true;&lt;br&gt;      inputRef.current.style.opacity = &amp;quot;0&amp;quot;;  // iOS의 자동 스크롤 차단&lt;br&gt;      inputRef.current.focus();&lt;br&gt;    }&lt;br&gt;  };&lt;br&gt;  return (&lt;br&gt;    &amp;lt;footer&amp;gt;&lt;br&gt;      &amp;lt;input ref={inputRef} value={text}&lt;br&gt;        onChange={(e) =&amp;gt; setText(e.target.value)}&lt;br&gt;        placeholder=&amp;quot;댓글을 입력해주세요.&amp;quot;&lt;br&gt;        onTouchStart={handleTouchStart}&lt;br&gt;        onBlur={() =&amp;gt; { isHiddenRef.current = false; inputRef.current.style.opacity = &amp;quot;1&amp;quot;; }}&lt;br&gt;      /&amp;gt;&lt;br&gt;    &amp;lt;/footer&amp;gt;&lt;br&gt;  );&lt;br&gt;}&lt;/pre&gt;&lt;p&gt;input 하나로, 상태 동기화 없이, 동일한 효과를 얻을 수 있었어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/320/1*ba-PTpKNfBBRo9QsrZq5YA.gif&quot; /&gt;&lt;figcaption&gt;마지막 시도의 결과물&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;앞선 시도들이 &lt;strong&gt;“iOS의 행동에 반응하는”&lt;/strong&gt; 방식이었다면, 이번에는 &lt;strong&gt;“iOS가 행동하기 전에 선제적으로 차단하는”&lt;/strong&gt; 방식이에요.&lt;/p&gt;&lt;h3&gt;마치며&lt;/h3&gt;&lt;p&gt;솔직히 opacity로 브라우저를 속이는 이 해결책은 매우 hacky해요. 공식적인 API도, 표준적인 방법도 없었고, iOS 버전이 업데이트되면서 동작이 달라져 다시 해결책을 찾아야 할 때도 있었어요. 그래서 모든 페이지에 적용하진 않고, 글쓰기가 핵심인 페이지에만 선택적으로 적용하고 있어요.&lt;/p&gt;&lt;p&gt;그럼에도 이렇게까지 한 이유는, &lt;strong&gt;커뮤니티에서의 글쓰기는 핵심 경험이기 때문&lt;/strong&gt;이에요. 키보드가 올라올 때마다 화면이 밀리는 건 유저 경험에 치명적이었고, 정석적인 방법이 없다고 그냥 둘 수는 없었어요.&lt;/p&gt;&lt;p&gt;결국 저희가 만드는 기술은 유저를 위한 거라고 생각해요. 완벽한 코드보다 중요한 건 유저가 불편함 없이 서비스를 사용할 수 있는 것이니까요. 더 나은 해결책을 찾으면 다시 개선할 거고, 새로운 문제가 생기면 또 고민할 거예요. 그게 저희가 커뮤니티 서비스를 만들면서 배운 가장 중요한 교훈이에요.&lt;/p&gt;&lt;p&gt;비슷한 문제를 겪고 계신 분들께 조금이라도 도움이 되었으면 좋겠어요! 🥕&lt;/p&gt;&lt;img src=&quot;https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=94a5c2882118&quot; width=&quot;1&quot; height=&quot;1&quot; alt=&quot;&quot;&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&quot;https://medium.com/daangn/%EC%9B%B9%EB%B7%B0-%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A5%BC-%EC%9C%84%ED%95%9C-ios-webview-input-%EA%B2%BD%ED%97%98-%EA%B0%9C%EC%84%A0%EA%B8%B0-94a5c2882118&quot;&gt;웹뷰 엔지니어를 위한 iOS Webview Input 경험 개선기&lt;/a&gt; was originally published in &lt;a href=&quot;https://medium.com/daangn&quot;&gt;당근 테크 블로그&lt;/a&gt; on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</content:encoded>
    </item>
    <item>
      <title>서버를 위한 Redux: Node.js 이벤트 소싱 라이브러리 개발기</title>
      <link>https://medium.com/daangn/%EC%84%9C%EB%B2%84%EB%A5%BC-%EC%9C%84%ED%95%9C-redux-node-js-%EC%9D%B4%EB%B2%A4%ED%8A%B8-%EC%86%8C%EC%8B%B1-%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC-%EA%B0%9C%EB%B0%9C%EA%B8%B0-0b2cd4f4a569?source=rss----4505f82a2dbd---4</link>
      <guid>https://medium.com/daangn/%EC%84%9C%EB%B2%84%EB%A5%BC-%EC%9C%84%ED%95%9C-redux-node-js-%EC%9D%B4%EB%B2%A4%ED%8A%B8-%EC%86%8C%EC%8B%B1-%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC-%EA%B0%9C%EB%B0%9C%EA%B8%B0-0b2cd4f4a569?source=rss----4505f82a2dbd---4</guid>
      <pubDate>Fri, 23 Jan 2026 05:34:40 GMT</pubDate>
      <content:encoded>&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*gIudw1xt0amPdg4bzieFGQ.png&quot; /&gt;&lt;/figure&gt;&lt;p&gt;안녕하세요. 당근 프론트엔드코어 리더를 맡고 있는 Tony예요. 저희 팀은 70명이 넘는 당근의 프론트엔드 엔지니어분들이 더 편하고 즐겁게 개발할 수 있도록 개발 환경을 다듬는 일을 하고 있어요.&lt;/p&gt;&lt;p&gt;내부 도구를 만들다보면 감사 처리, 롤백, 알림처럼 요구사항이 점점 더 복잡해지게 되는데요. 최근 이처럼 복잡한 요구사항들을 잘 관리하고자 ‘이벤트 소싱 패턴’을 도입했어요.&lt;/p&gt;&lt;p&gt;이 글에서는 이 패턴이 만들어진 배경과 함께 더 쉽게 쓰실 수 있도록저희가 직접 만들고 오픈소싱한 라이브러리를 소개하려고해요. 이벤트 소싱이 어쩌면 복잡하고 어려운 개념일 수 있지만, 프론트엔드 엔지니어링을 해보셨다면 쉽게 접할 수 있는 ‘Redux’를 서버로 옮겨놓았다고 생각하면 좀 더 쉽게 몰입하실 수 있을 거예요.&lt;/p&gt;&lt;p&gt;프론트엔드와 백엔드 엔지니어는 각각 다른 문제를 해결하고 있기에 어쩌면 서로 다른 세상에 살고 있다고 볼 수도 있는데요. 오늘 이 글을 통해 비즈니스 로직에 대하여 프론트엔드와 백엔드 엔지니어가 서로 이야기를 나눌 수 있는 공통점이 생기면 좋겠어요. 그럼 시작하겠습니다.&lt;/p&gt;&lt;h3&gt;배경&lt;/h3&gt;&lt;p&gt;먼저 API 서버 엔지니어링에 대해서 이야기 해보도록 할게요. 흔히 API 서버는 DB에 데이터를 저장하고, 동시에 그데이터를 읽고 처리해서 클라이언트에 응답을 주는 역할을 해요.그리고 DB에 데이터를 만들고, 읽고, 수정하고, 지우는 일련의 행위를 CRUD(Create, Read, Update, Delete)라고 부르죠.&lt;/p&gt;&lt;p&gt;우리가 만들어야하는 기능은 대부분 DB에 대한 CRUD를 통해 간단하게 설계할 수 있을 거예요. 게시판을 예로 들자면, 글을 작성하고, 수정하고, 삭제하고, 불러오는 기능만 있다면DB CRUD 기능으로도 충분히 간단한 구현이 가능할 거예요.&lt;/p&gt;&lt;p&gt;하지만 만약 CRUD로 표현하기 어려운 개념이 등장하면 어떻게 될까요?예를 들어 같은 게시판이라도 글에 승인이라는 개념이 들어간다면요. 글이 올라온 뒤운영자가 이를 승인하거나 거절할 수 있어야 한다면 이를 어떻게 구현하면 좋을까요? 혹은 수정 기록을 남겨야 한다면어떻게 구현할 수 있을까요?&lt;/p&gt;&lt;p&gt;전통적인 CRUD 방식에서는 이런 요구사항을 만족하기 위해 추가적인 테이블과 복잡한 로직이 필요해요. 예를 들어:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;승인 기능&lt;/strong&gt;: status 컬럼을 추가하고, 승인/거절 시간을 기록하는 컬럼들을 만들고...&lt;/li&gt;&lt;li&gt;&lt;strong&gt;수정 기록&lt;/strong&gt;: 별도의 히스토리 테이블을 만들고, 매번 수정할 때마다 이전 데이터를 복사해서 저장하고…&lt;/li&gt;&lt;li&gt;&lt;strong&gt;롤백 기능&lt;/strong&gt;: 어떤 상태로 되돌릴지 추적하고, 복잡한 로직으로 데이터를 복원하고…&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;이런 기능들을 하나씩 추가하다 보면 코드가 점점 복잡해지고, 유지보수가 어려워지게 됩니다. 더 큰 문제는 이런 방식으로는 “왜 이렇게 되었는가”를 추적하기가 어렵다는 점이에요. 현재 상태만 저장되어 있을 뿐, 그 과정에서 무슨 일이 있었는지는 알 수 없거든요.&lt;/p&gt;&lt;h3&gt;이벤트 소싱: 모든 변경을 기록하다&lt;/h3&gt;&lt;p&gt;이벤트 소싱(Event Sourcing)은 이런 문제들을 해결하는 패턴이에요. 핵심 아이디어는 아주 간단해요:&lt;/p&gt;&lt;blockquote&gt;&lt;em&gt;“현재 상태”만 저장하는 대신, “상태를 변경시킨 모든 이벤트”를 저장하자&lt;/em&gt;&lt;/blockquote&gt;&lt;p&gt;예를 들어, 게시글의 현재 상태가 “승인됨”이라면, CRUD 방식에서는 status: &amp;quot;approved&amp;quot; 이렇게 저장하겠죠. 하지만 이벤트 소싱에서는 이렇게 저장해요:&lt;/p&gt;&lt;pre&gt;1. 게시글이 작성됨 (content: &amp;quot;안녕하세요&amp;quot;, author: &amp;quot;Tony&amp;quot;)&lt;br&gt;2. 게시글이 수정됨 (content: &amp;quot;안녕하세요 수정했어요&amp;quot;)&lt;br&gt;3. 게시글이 승인됨 (approver: &amp;quot;관리자&amp;quot;, reason: &amp;quot;적절한 내용&amp;quot;)&lt;/pre&gt;&lt;p&gt;이렇게 하면 어떤 좋은 점이 있을까요?&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;완벽한 감사 로그&lt;/strong&gt;: 누가, 언제, 무엇을, 왜 했는지 모두 기록돼요.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;타임머신 기능&lt;/strong&gt;: 과거 어느 시점의 상태든 재구성할 수 있어요.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;롤백이 쉬워요&lt;/strong&gt;: 특정 시점 이후의 이벤트를 무시하면 되니까요.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;비즈니스 인사이트&lt;/strong&gt;: 데이터가 어떻게 변했는지 분석할 수 있어요.&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Redux를 아시나요?&lt;/h3&gt;&lt;p&gt;프론트엔드 엔지니어라면 Redux를 들어보셨을 거에요. Redux는 React 애플리케이션의 상태를 관리하는 라이브러리인데요, 사실 Redux가 사용하는 패턴이 바로 이벤트 소싱과 매우 유사해요.&lt;/p&gt;&lt;p&gt;Redux에서는 이렇게 작동하죠:&lt;/p&gt;&lt;pre&gt;// 1. Action (이벤트와 유사)&lt;br&gt;dispatch({&lt;br&gt;  type: &amp;#39;user/profileUpdated&amp;#39;,&lt;br&gt;  payload: { bio: &amp;#39;Hello&amp;#39; },&lt;br&gt;});&lt;br&gt;&lt;br&gt;// 2. Reducer (상태를 계산)&lt;br&gt;function userReducer(state, action) {&lt;br&gt;  switch (action.type) {&lt;br&gt;    case &amp;#39;user/profileUpdated&amp;#39;:&lt;br&gt;      return { ...state, bio: action.payload.bio };&lt;br&gt;    default:&lt;br&gt;      return state;&lt;br&gt;  }&lt;br&gt;}&lt;/pre&gt;&lt;p&gt;이벤트 소싱도 같아요:&lt;/p&gt;&lt;pre&gt;// 1. Event (Action과 유사)&lt;br&gt;dispatch(&amp;#39;user:profile_updated&amp;#39;, { bio: &amp;#39;Hello&amp;#39; });&lt;br&gt;&lt;br&gt;// 2. Reducer (상태를 계산)&lt;br&gt;function userReducer(prevState, event) {&lt;br&gt;  switch (event.eventName) {&lt;br&gt;    case &amp;#39;user:profile_updated&amp;#39;:&lt;br&gt;      return { ...prevState, bio: event.body.bio };&lt;br&gt;    default:&lt;br&gt;      return prevState;&lt;br&gt;  }&lt;br&gt;}&lt;/pre&gt;&lt;p&gt;차이점이 있다면:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Redux&lt;/strong&gt;: 브라우저 메모리에서 상태를 관리&lt;/li&gt;&lt;li&gt;&lt;strong&gt;이벤트 소싱&lt;/strong&gt;: 데이터베이스에 영구적으로 이벤트를 저장&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;결국 “이벤트를 통해 상태를 관리한다”는 핵심 아이디어는 동일합니다. Redux를 써본 적이 있다면, 이벤트 소싱은 이미 반쯤 이해하신 셈이에요.&lt;/p&gt;&lt;h3&gt;Ventyd: TypeScript를 위한 이벤트 소싱 라이브러리&lt;/h3&gt;&lt;p&gt;내부 도구를 개발하면서 이벤트 소싱을 도입하려고 했지만 TypeScript 환경에서 쉽게 사용할 수 있는 라이브러리를 찾기 어려웠어요. 그래서 직접 만들기로 했습니다. 목표는 명확했어요:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Redux 처럼 친숙하게&lt;/strong&gt;: 프론트엔드 엔지니어와 일반적인 Node.js 엔지니어도 쉽게 이해할 수 있도록&lt;/li&gt;&lt;li&gt;&lt;strong&gt;TypeScript 퍼스트&lt;/strong&gt;: 타입 안정성을 최우선으로&lt;/li&gt;&lt;li&gt;&lt;strong&gt;유연하게&lt;/strong&gt;: 어떤 DB든, 어떤 검증 라이브러리든 사용할 수 있게&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;이렇게 해서 만들어진 라이브러리가 &lt;strong&gt;Ventyd예요.&lt;/strong&gt;&lt;/p&gt;&lt;h3&gt;간단한 사용 예시&lt;/h3&gt;&lt;p&gt;User 엔티티를 만드는 과정을 보여드릴게요:&lt;/p&gt;&lt;h3&gt;1. 스키마 정의&lt;/h3&gt;&lt;p&gt;먼저 어떤 이벤트가 있고, 어떤 상태를 가질지 정의해요:&lt;/p&gt;&lt;pre&gt;import { defineSchema } from &amp;#39;ventyd&amp;#39;;&lt;br&gt;import { valibot, v } from &amp;#39;ventyd/valibot&amp;#39;;&lt;br&gt;&lt;br&gt;const userSchema = defineSchema(&amp;#39;user&amp;#39;, {&lt;br&gt;  schema: valibot({&lt;br&gt;    event: {&lt;br&gt;      // 사용자가 생성될 때&lt;br&gt;      created: v.object({&lt;br&gt;        nickname: v.string(),&lt;br&gt;        email: v.pipe(v.string(), v.email()),&lt;br&gt;      }),&lt;br&gt;&lt;br&gt;      // 프로필이 수정될 때&lt;br&gt;      profile_updated: v.object({&lt;br&gt;        nickname: v.optional(v.string()),&lt;br&gt;        bio: v.optional(v.string()),&lt;br&gt;      }),&lt;br&gt;&lt;br&gt;      // 사용자가 삭제될 때&lt;br&gt;      deleted: v.object({&lt;br&gt;        reason: v.optional(v.string()),&lt;br&gt;      }),&lt;br&gt;&lt;br&gt;      // 사용자가 복구될 때&lt;br&gt;      restored: v.object({}),&lt;br&gt;    },&lt;br&gt;&lt;br&gt;    // 최종 상태의 형태&lt;br&gt;    state: v.object({&lt;br&gt;      nickname: v.string(),&lt;br&gt;      email: v.pipe(v.string(), v.email()),&lt;br&gt;      bio: v.optional(v.string()),&lt;br&gt;      deletedAt: v.nullable(v.optional(v.string())),&lt;br&gt;    }),&lt;br&gt;  }),&lt;br&gt;  initialEventName: &amp;#39;user:created&amp;#39;,&lt;br&gt;});&lt;/pre&gt;&lt;blockquote&gt;Valibot 대신 Zod, TypeBox, ArkType 등 원하는 검증 라이브러리를 사용할 수 있어요. (&lt;a href=&quot;https://ventyd.com/docs/schema&quot;&gt;https://ventyd.com/docs/schema&lt;/a&gt;)&lt;/blockquote&gt;&lt;h3&gt;2. Reducer 정의&lt;/h3&gt;&lt;p&gt;이벤트가 발생했을 때 상태를 어떻게 변경할지 정의해요:&lt;/p&gt;&lt;pre&gt;import { defineReducer } from &amp;#39;ventyd&amp;#39;;&lt;br&gt;&lt;br&gt;const userReducer = defineReducer(userSchema, (prevState, event) =&amp;gt; {&lt;br&gt;  switch (event.eventName) {&lt;br&gt;    case &amp;#39;user:created&amp;#39;:&lt;br&gt;      return {&lt;br&gt;        nickname: event.body.nickname,&lt;br&gt;        email: event.body.email,&lt;br&gt;        bio: undefined,&lt;br&gt;        deletedAt: null,&lt;br&gt;      };&lt;br&gt;    case &amp;#39;user:profile_updated&amp;#39;:&lt;br&gt;      return {&lt;br&gt;        ...prevState,&lt;br&gt;        ...(event.body.nickname &amp;amp;&amp;amp; { nickname: event.body.nickname }),&lt;br&gt;        ...(event.body.bio !== undefined &amp;amp;&amp;amp; { bio: event.body.bio }),&lt;br&gt;      };&lt;br&gt;    case &amp;#39;user:deleted&amp;#39;:&lt;br&gt;      return {&lt;br&gt;        ...prevState,&lt;br&gt;        deletedAt: event.eventCreatedAt,&lt;br&gt;      };&lt;br&gt;    case &amp;#39;user:restored&amp;#39;:&lt;br&gt;      return {&lt;br&gt;        ...prevState,&lt;br&gt;        deletedAt: null,&lt;br&gt;      };&lt;br&gt;    default:&lt;br&gt;      return prevState;&lt;br&gt;  }&lt;br&gt;});&lt;/pre&gt;&lt;p&gt;Redux의 reducer와 같이 이전 상태와 이벤트를 받아 다음 상태를 계산하는 순수함수를 작성하면 돼요.&lt;/p&gt;&lt;h3&gt;3. Entity 클래스 정의&lt;/h3&gt;&lt;p&gt;비즈니스 로직을 담은 클래스를 만들어요:&lt;/p&gt;&lt;pre&gt;import { Entity, mutation } from &amp;#39;ventyd&amp;#39;;&lt;br&gt;&lt;br&gt;class User extends Entity(userSchema, userReducer) {&lt;br&gt;  // 편리한 getter들&lt;br&gt;  get nickname() {&lt;br&gt;    return this.state.nickname;&lt;br&gt;  }&lt;br&gt;  get isDeleted() {&lt;br&gt;    return this.state.deletedAt !== null;&lt;br&gt;  }&lt;br&gt;&lt;br&gt;  // 비즈니스 메서드: 프로필 수정&lt;br&gt;  updateProfile = mutation(this, (dispatch, updates: { nickname?: string; bio?: string }) =&amp;gt; {&lt;br&gt;    // 비즈니스 규칙 검증&lt;br&gt;    if (this.isDeleted) {&lt;br&gt;      throw new Error(&amp;#39;삭제된 사용자는 수정할 수 없습니다&amp;#39;);&lt;br&gt;    }&lt;br&gt;    // 이벤트 발행&lt;br&gt;    dispatch(&amp;#39;user:profile_updated&amp;#39;, updates);&lt;br&gt;  })&lt;br&gt;&lt;br&gt;  // 비즈니스 메서드: 삭제&lt;br&gt;  delete = mutation(this, (dispatch, reason?: string) =&amp;gt; {&lt;br&gt;    if (this.isDeleted) {&lt;br&gt;      throw new Error(&amp;#39;이미 삭제된 사용자입니다&amp;#39;);&lt;br&gt;    }&lt;br&gt;    dispatch(&amp;#39;user:deleted&amp;#39;, { reason });&lt;br&gt;  })&lt;br&gt;&lt;br&gt;  // 비즈니스 메서드: 복구&lt;br&gt;  restore = mutation(this, (dispatch) =&amp;gt; {&lt;br&gt;    if (!this.isDeleted) {&lt;br&gt;      throw new Error(&amp;#39;삭제되지 않은 사용자입니다&amp;#39;);&lt;br&gt;    }&lt;br&gt;    dispatch(&amp;#39;user:restored&amp;#39;, {});&lt;br&gt;  })&lt;br&gt;}&lt;/pre&gt;&lt;h3&gt;4. Repository 생성&lt;/h3&gt;&lt;p&gt;코어 비즈니스 로직이 끝났어요. 이제 작성한 비즈니스 로직을 DB와 연동할 수 있는 Repository를 만들어요:&lt;/p&gt;&lt;pre&gt;import { createRepository, Adapter } from &amp;#39;ventyd&amp;#39;;&lt;br&gt;&lt;br&gt;const myAdapter: Adapter = {&lt;br&gt;  // 직접 DB 연결을 구현해요&lt;br&gt;};&lt;br&gt;&lt;br&gt;const userRepository = createRepository(User, {&lt;br&gt;  adapter: myAdapter,&lt;br&gt;  plugins: [&lt;br&gt;    // 감사 로그 플러그인&lt;br&gt;    auditLogPlugin,&lt;br&gt;    // 알림 플러그인&lt;br&gt;    notificationPlugin,&lt;br&gt;  ],&lt;br&gt;});&lt;/pre&gt;&lt;blockquote&gt;Ventyd는 따로 미리 만들어진 어댑터를 제공하지 않아요. 각자가 서버 환경에서 사용하고 계신 DB, ORM으로 직접 구현해서 주입할 수 있도록 일부러 설계되었어요. (&lt;a href=&quot;https://ventyd.vercel.app/docs/database&quot;&gt;https://ventyd.vercel.app/docs/database&lt;/a&gt;)&lt;/blockquote&gt;&lt;h3&gt;5. 사용하기&lt;/h3&gt;&lt;pre&gt;// 새 사용자 생성&lt;br&gt;const user = User.create({&lt;br&gt;  body: {&lt;br&gt;    nickname: &amp;#39;Tony&amp;#39;,&lt;br&gt;    email: &amp;#39;tony@example.com&amp;#39;,&lt;br&gt;  },&lt;br&gt;});&lt;br&gt;&lt;br&gt;// 프로필 수정&lt;br&gt;user.updateProfile({&lt;br&gt;  bio: &amp;#39;당근 Software Engineer&amp;#39;,&lt;br&gt;});&lt;br&gt;&lt;br&gt;// DB에 저장&lt;br&gt;await userRepository.commit(user);&lt;br&gt;&lt;br&gt;// 나중에 불러오기&lt;br&gt;const loadedUser = await userRepository.findOne({&lt;br&gt;  entityId: user.entityId,&lt;br&gt;});&lt;br&gt;&lt;br&gt;console.log(loadedUser?.nickname); // &amp;#39;Tony&amp;#39;&lt;br&gt;console.log(loadedUser?.bio); // &amp;#39;당근 Software Engineer&amp;#39;&lt;/pre&gt;&lt;blockquote&gt;💡 만약 &lt;em&gt;entityId&lt;/em&gt;가 아닌 다른 필드들로 쿼리가 필요하다면, DB에 인덱싱하는 로직을 어댑터 또는 플러그인으로 직접 구현하시면 돼요. 관련한 내용은 아래 문서를 확인하세요. (&lt;a href=&quot;https://ventyd.com/docs/querying&quot;&gt;https://ventyd.com/docs/querying&lt;/a&gt;)&lt;/blockquote&gt;&lt;h3&gt;실제로 어떻게 쓰고 있나요?&lt;/h3&gt;&lt;p&gt;당근에서는 내부 도구들에 Ventyd를 적용하고 있어요. 특히 아래 같은 상황에서 매우 유용하게 사용하고 있는데요. 더 구체적인 상황을 하나씩 설명해 볼게요.&lt;/p&gt;&lt;h3&gt;예시 1: 프론트엔드 배포 플랫폼&lt;/h3&gt;&lt;p&gt;당근에서 만드는 프론트엔드 배포 플랫폼에서는 배포 프로세스의 모든 단계를 추적하고 있어요.&lt;/p&gt;&lt;pre&gt;// 아래 코드는 실제 코드가 아닌 예시입니다&lt;br&gt;&lt;br&gt;// 배포가 시작되고&lt;br&gt;deployment.create({&lt;br&gt;  projectId: &amp;#39;my-app&amp;#39;,&lt;br&gt;  branch: &amp;#39;main&amp;#39;,&lt;br&gt;  commit: &amp;#39;a1b2c3d&amp;#39;,&lt;br&gt;});&lt;br&gt;&lt;br&gt;// 빌드가 진행되고&lt;br&gt;deployment.startBuild();&lt;br&gt;deployment.completeBuild({ artifactUrl: &amp;#39;s3://...&amp;#39; });&lt;br&gt;&lt;br&gt;// 검증을 거치고&lt;br&gt;deployment.runTests();&lt;br&gt;deployment.completeTests({ success: true });&lt;br&gt;&lt;br&gt;// 배포되고&lt;br&gt;deployment.deploy({ environment: &amp;#39;production&amp;#39; });&lt;br&gt;&lt;br&gt;// 문제가 생기면 롤백&lt;br&gt;deployment.rollback({ reason: &amp;#39;high error rate&amp;#39; });&lt;br&gt;&lt;br&gt;// -&amp;gt; 모든 과정이 이벤트로 기록됩니다&lt;/pre&gt;&lt;p&gt;이렇게 하면 이 배포는 누가, 언제, 어떤 커밋으로 배포했고, 왜 롤백했는지 같은 질문에 바로 답할 수 있어요. 특히 특정 기능이 배포되었을 때슬랙으로 알림을 받는 등 변경사항을 추적하는 코드가 필요할 경우 기존에는 여러 지점에 패치를 해야했지만, 이벤트 소싱 패턴을 사용하면 모든 변경을 한 곳에서 다루기 때문에, 변경 사항을 추적하는 로직도 한곳에 모을 수 있습니다.&lt;/p&gt;&lt;pre&gt;const myRepository = createRepository(Deployment, {&lt;br&gt;  // ...&lt;br&gt;  plugins: [&lt;br&gt;    // 변경사항이 commit 될때 슬랙 알림을 받아요.&lt;br&gt;    slackPlugin(),&lt;br&gt;  ],&lt;br&gt;});&lt;/pre&gt;&lt;h3&gt;예시 2: 게임 상태 관리&lt;/h3&gt;&lt;p&gt;게임 상태를 다루면서도 흥미로운 활용 사례를 발견했어요. 얼마 전 미니 게임을 개발하면서 게임에서 발생하는 이벤트와 그로 인해 계산되는 상태를 Ventyd Entity로 정의했어요. 그리고 이 코어 로직을 클라이언트와 서버 양쪽에서 동시에 활용했습니다:&lt;/p&gt;&lt;pre&gt;// 아래 코드는 실제 코드가 아닌 예시입니다&lt;br&gt;&lt;br&gt;// 게임 상태 Entity 정의&lt;br&gt;class GameState extends Entity(gameSchema, gameReducer) {&lt;br&gt;  movePlayer(direction: &amp;#39;up&amp;#39; | &amp;#39;down&amp;#39; | &amp;#39;left&amp;#39; | &amp;#39;right&amp;#39;) {&lt;br&gt;    dispatch(&amp;#39;game:player_moved&amp;#39;, { direction });&lt;br&gt;  }&lt;br&gt;  collectItem(itemId: string) {&lt;br&gt;    dispatch(&amp;#39;game:item_collected&amp;#39;, { itemId });&lt;br&gt;  }&lt;br&gt;}&lt;br&gt;&lt;br&gt;// 클라이언트에서: 서버 없이 즉시 게임 상태 계산&lt;br&gt;function handlePlayerAction(action: GameAction) {&lt;br&gt;&lt;br&gt;  // 로컬에서 즉시 상태 업데이트 (낙관적 업데이트)&lt;br&gt;  localGameState.movePlayer(action.direction);&lt;br&gt;&lt;br&gt;  // 백그라운드에서 서버에 이벤트 전송 (동기화)&lt;br&gt;  sendToServer({&lt;br&gt;    events: localGameState.uncommittedEvents,&lt;br&gt;  })&lt;br&gt;}&lt;br&gt;&lt;br&gt;// 서버에서: 같은 Entity로 검증 및 저장&lt;br&gt;async function processGameEvents(events: Event[]) {&lt;br&gt;  const gameState = await gameRepository.findOne({ entityId });&lt;br&gt;&lt;br&gt;  // 이벤트 재생하여 상태 검증&lt;br&gt;  for (const event of events) {&lt;br&gt;    gameState.applyEvent(event); // 부정행위 검증도 가능!&lt;br&gt;  }&lt;br&gt;&lt;br&gt;  await gameRepository.commit(gameState);&lt;br&gt;}&lt;/pre&gt;&lt;p&gt;이를 통해 아래와 같은 이점들을 얻을 수 있었어요.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;즉각적인 반응성&lt;/strong&gt;: 클라이언트에서 서버 응답을 기다리지 않고 즉시 게임 상태를 업데이트할 수 있어요.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;오프라인 지원&lt;/strong&gt;: 네트워크 연결이 끊겨도 게임을 계속하고, 나중에 서버에 동기화할 수 있어요.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;부정행위 방지&lt;/strong&gt;: 서버에서 같은 로직으로 이벤트를 재생하면서 검증할 수 있어요.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;재현 가능&lt;/strong&gt;: 모든 게임 플레이가 이벤트로 기록되어 있어서 버그 재현이나 리플레이 기능 구현이 쉬워요.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;조금 특이한 사례이긴 하지만 프론트엔드와 백엔드가 같은 도메인 로직을 공유할 수 있다는 것이 Ventyd를 사용했을때 큰 장점이 될 수도 있다는 걸 확인한 셈이죠.&lt;/p&gt;&lt;h3&gt;백엔드 엔지니어 관점에서&lt;/h3&gt;&lt;p&gt;백엔드 엔지니어에게는 이런 장점이 있어요:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;도메인 주도 설계(DDD)&lt;/strong&gt;: Entity를 도메인 객체로 자연스럽게 모델링할 수 있어요.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;테스트하기 쉬움&lt;/strong&gt;: 순수 함수인 Reducer는 테스트가 매우 쉬워요.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;버그 추적&lt;/strong&gt;: 프로덕션에서 문제가 생겼을 때, 이벤트 로그를 보면 정확히 무슨 일이 있었는지 알 수 있어요&lt;/li&gt;&lt;li&gt;&lt;strong&gt;성능 최적화&lt;/strong&gt;: 읽기와 쓰기를 분리(CQRS)해서 각각 최적화할 수 있어요.&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;프론트엔드 엔지니어 관점에서&lt;/h3&gt;&lt;p&gt;프론트엔드 엔지니어라면 이렇게 대응해서 생각해볼 수 있어요.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Schema&lt;/strong&gt; = TypeScript interface 정의&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Event&lt;/strong&gt; = Redux action&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Reducer&lt;/strong&gt; = Redux reducer&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Entity&lt;/strong&gt; = 비즈니스 로직을 가진 React Hook (useReducer 같은)&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Repository&lt;/strong&gt; = API 클라이언트&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;익숙한 개념들이죠. Ventyd를 사용하면 프론트엔드와 백엔드가 같은 언어로 비즈니스 로직을 이야기할 수 있어요..&lt;/p&gt;&lt;p&gt;예를 들어:&lt;/p&gt;&lt;pre&gt;// 프론트엔드 (Redux)&lt;br&gt;dispatch({ type: &amp;#39;user/profileUpdated&amp;#39;, payload: { bio: &amp;#39;Hello&amp;#39; } });&lt;br&gt;&lt;br&gt;// 백엔드 (Ventyd)&lt;br&gt;dispatch(&amp;#39;user:profile_updated&amp;#39;, { bio: &amp;#39;Hello&amp;#39; });&lt;/pre&gt;&lt;p&gt;이벤트를 중심으로 한 구조가 비슷해서, 프론트엔드와 백엔드가 서로의 코드를 이해하기가 훨씬 쉬워져요.&lt;/p&gt;&lt;h3&gt;마치며&lt;/h3&gt;&lt;p&gt;Ventyd는 당근에서 이벤트 소싱을 TypeScript 생태계에서 더 쉽게 사용할 수 있도록 만든 라이브러리예요. Redux를 사용해본 프론트엔드 엔지니어라면 빠르게 익숙해질 수 있고, 백엔드 엔지니어에게도 어렵지 않으면서 동시에 강력한 도구가 될 수 있다고 생각해요.&lt;/p&gt;&lt;p&gt;무엇보다 중요한 건, 프론트엔드와 백엔드 엔지니어가 이벤트와 상태라는 공통의 언어로 소통할 수 있게 된다는 점이에요. 이를 통해 더 나은 협업과 더 나은 소프트웨어를 만들 수 있기를 바랍니다.&lt;/p&gt;&lt;p&gt;관심 있으시다면 한번 사용해 보세요!&lt;/p&gt;&lt;h3&gt;링크&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;웹사이트: &lt;a href=&quot;https://ventyd.com&quot;&gt;https://ventyd.com&lt;/a&gt;&lt;/li&gt;&lt;li&gt;GitHub: &lt;a href=&quot;https://github.com/daangn/ventyd&quot;&gt;https://github.com/daangn/ventyd&lt;/a&gt;&lt;/li&gt;&lt;li&gt;NPM: &lt;a href=&quot;https://www.npmjs.com/package/ventyd&quot;&gt;https://www.npmjs.com/package/ventyd&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=0b2cd4f4a569&quot; width=&quot;1&quot; height=&quot;1&quot; alt=&quot;&quot;&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&quot;https://medium.com/daangn/%EC%84%9C%EB%B2%84%EB%A5%BC-%EC%9C%84%ED%95%9C-redux-node-js-%EC%9D%B4%EB%B2%A4%ED%8A%B8-%EC%86%8C%EC%8B%B1-%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC-%EA%B0%9C%EB%B0%9C%EA%B8%B0-0b2cd4f4a569&quot;&gt;서버를 위한 Redux: Node.js 이벤트 소싱 라이브러리 개발기&lt;/a&gt; was originally published in &lt;a href=&quot;https://medium.com/daangn&quot;&gt;당근 테크 블로그&lt;/a&gt; on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</content:encoded>
    </item>
    <item>
      <title>당근페이 백엔드 아키텍처가 걸어온 여정</title>
      <link>https://medium.com/daangn/%EB%8B%B9%EA%B7%BC%ED%8E%98%EC%9D%B4-%EB%B0%B1%EC%97%94%EB%93%9C-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98%EA%B0%80-%EA%B1%B8%EC%96%B4%EC%98%A8-%EC%97%AC%EC%A0%95-98615d5a6b06?source=rss----4505f82a2dbd---4</link>
      <guid>https://medium.com/daangn/%EB%8B%B9%EA%B7%BC%ED%8E%98%EC%9D%B4-%EB%B0%B1%EC%97%94%EB%93%9C-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98%EA%B0%80-%EA%B1%B8%EC%96%B4%EC%98%A8-%EC%97%AC%EC%A0%95-98615d5a6b06?source=rss----4505f82a2dbd---4</guid>
      <pubDate>Thu, 15 Jan 2026 05:40:53 GMT</pubDate>
      <content:encoded>&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*n9g8WhEmaRXe6siBZ3mBrg.png&quot; /&gt;&lt;/figure&gt;&lt;p&gt;안녕하세요, 당근페이팀에서 백엔드 엔지니어로 일하고 있는 제레미예요. 지난 4년 동안 당근머니 시스템을 구축하고 송금 서비스를 성장시켜 왔고, 현재는 오프라인 결제팀에서 당근머니와 포인트 사용 경험을 동네 가게 결제로 넓히고 있어요.&lt;/p&gt;&lt;p&gt;당근페이팀의 백엔드는 Money 라는 하나의 작은 프로젝트에서 출발했어요. 지금은 수십 개의 서비스를 하나의 프로젝트에 운영하고 있고요. 이 과정에서 세 번의 큰 변화가 있었어요. 이 글을 통해 단순했던 계층형 아키텍처(Layered Architecture)에서 헥사고날 아키텍처(Hexagonal Architecture)를 거쳐, 클린 아키텍처(Clean Architecture)와 모노레포(Monorepo)로 확장된 현재까지의 이야기를 들려드리려고 해요.&lt;/p&gt;&lt;blockquote&gt;&lt;em&gt;Any organization that designs a system (defined broadly) will produce a design whose structure is a copy of the organization’s communication structure.&lt;br&gt;&lt;/em&gt;- Melvin Conway&lt;/blockquote&gt;&lt;p&gt;어떤 조직이 시스템을 설계하면, 그 조직의 커뮤니케이션 구조를 본뜬 형태가 된다는 말이 있어요. 어떤 조직 구조를 가지고 있고 어떻게 협업하는지가 프로젝트 구조, 모듈 경계, API 설계 등 코드베이스에 그대로 반영된다는 의미예요. 초기 당근페이팀에는 계정 서비스팀, 송금 서비스팀 그리고 결제 서비스팀이 있었고 백엔드 엔지니어들이 담당하는 프로젝트도 User, Money, Payment로 나뉘어져 있었어요.&lt;/p&gt;&lt;p&gt;저는 송금 서비스팀에서 당근머니와 송금 서비스를 만들었고, 주로 Money 프로젝트에 기여했어요. 저희 팀은 초기에 당근머니 생태계와 송금 서비스만 담당했었는데, 당근페이 전체 서비스가 빠르게 성장하면서 팀의 책임 영역도 자연스럽게 확장되었어요.&lt;/p&gt;&lt;p&gt;특히 혜택과 이벤트를 관리하는 프로모션, 회계를 담당하는 빌링, 당근 포인트까지 서비스 도메인이 늘어날 때마다 코드베이스의 복잡도도 함께 증가했어요. 새로운 기능을 추가할 때마다 기존 코드와의 의존성을 고려해야 했고, 코드 변경 사항의 영향 범위를 예측하기 점점 어려워졌어요.&lt;/p&gt;&lt;p&gt;성장통을 겪으면서 저희 팀은 빠르게 기능을 추가하는 것을 넘어서, 지속 가능한 개발을 위해서는 아키텍처도 함께 진화해야 한다는 것을 깨달았어요. 빠르게 변하는 비즈니스 요구사항에 대응하면서 코드 품질을 유지하고 팀 간 협업을 원활하게 하려면 어떤 아키텍처가 필요할까요? 정답은 없지만 당근페이팀이 서비스 성장과 함께 겪어온 아키텍처 변화 과정을 단계별로 살펴보면서, 각 변화의 배경과 그 과정에서 얻은 인사이트들을 공유드릴게요.&lt;/p&gt;&lt;h3&gt;첫 번째: Layered Architecture&lt;/h3&gt;&lt;p&gt;2021년으로 거슬러 올라갈게요. 당근페이팀은 2021년 봄, “동네 생활 금융을 편하게” 라는 비전을 가지고 만들어졌어요. 당근페이팀의 첫 번째 미션은 동네에서 이웃과 중고거래를 할 때, 누구나 손쉽게 송금할 수 있도록 돕는 서비스를 출시하는 것이었어요.&lt;/p&gt;&lt;p&gt;모두가 전자금융업 라이선스 취득과 송금 서비스 오픈이라는 목표에 집중했고, 엔지니어들도 송금 기능 구현에 전력을 다했어요. 계정, 은행 입출금 그리고 당근머니 관리가 핵심 요소로 정의됐고 각 요소를 담당하는 프로젝트가 만들어졌어요.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;User: 사용자 계정과 인증을 담당해요.&lt;/li&gt;&lt;li&gt;Banking: 출금 계좌를 관리하고 은행 입출금을 담당해요.&lt;/li&gt;&lt;li&gt;Money: 당근머니 지갑을 구현하고 사용자에게 송금 기능을 제공해요. 이 글의 주제가 되는 프로젝트이기도 해요.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;당근의 핵심 성장 동력 중 하나는 ‘빠른 실행력을 바탕으로 기민하게 움직이는 것’ 이에요. 이런 철학에 맞춰서 최초 Money 프로젝트는 Controller — Service — Repository 형태의 계층형 아키텍처로 구성됐어요. 단순하고 직관적인 구조 덕분에 프로젝트를 쉽게 이해할 수 있었고 복잡한 설계 고민 없이 빠르게 기능을 개발하고 실험할 수 있었어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*QmcRPfZL7CYI5wfY5q3JSg.png&quot; /&gt;&lt;figcaption&gt;첫 번째 프로젝트 구조(Layered Architecture)&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;이 구조를 바탕으로 2021년 9월에 전자금융업자 라이선스 취득했고, 같은 해 11월에 중고거래 송금 기능을 빠르게 출시할 수 있었어요. 성공적인 출시 이후 서비스가 예상보다 빠른 속도로 성장했어요. 중고거래 송금 기능에 만족한 사용자들의 피드백을 바탕으로 새로운 기능들이 하나둘 추가됐고, 비즈니스 영역도 점차 확장됐어요. 송금 내역, 계좌송금, 송금 프로모션 이벤트, FDS 연동 등 수많은 기능들이 짧은 시간에 추가되면서 코드베이스의 복잡도가 기하급수적으로 증가했어요.&lt;/p&gt;&lt;p&gt;아키텍처의 Service 계층은 유스케이스 경계 없이 서로의 내부 구현에 직접 의존하게 됐고, 복잡한 호출이 꼬리를 물며 스파게티처럼 얽히기 시작했어요. 당근머니 지갑 등 핵심 비즈니스 로직을 담당하는 Service 클래스는 여러 Service 로부터 입력, 출력 뿐만 아니라 검증, 권한 등 횡단 관심사까지 떠안게 되면서 변경에 취약해졌어요.&lt;/p&gt;&lt;p&gt;복잡한 Service 간 참조는 테스트 작성과 리팩터링도 어렵게 만들었어요. 빠른 출시를 가능하게 했던 계층형 아키텍처는 시간이 지나면서 언젠가 해결해야 할 기술 부채로 자리 잡게 됐죠.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*50HY4rQ4y96ib8POLMVglA.jpeg&quot; /&gt;&lt;figcaption&gt;복잡하게 얽힌 Layered Architecture 구조&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;두 번째: Hexagonal Architecture&lt;/h3&gt;&lt;p&gt;당근페이팀은 매년 12월 마지막 2주 동안 Refactoring Day 시간을 가지고 있어요. Refactoring Day는 잠시 서비스 배포를 멈추고, 리프레시를 위해 휴가를 가거나 쌓여 있던 기술 부채를 해결하는 시간이에요.&lt;/p&gt;&lt;p&gt;저 역시 2022년 12월 마지막 주에 휴가를 계획 중이었는데 갑작스럽게 일정이 취소되면서 2주의 자유 시간이 생겼어요. 2주면 정말 많은 것을 할 수 있는 시간인데 무얼 하며 보내야 할지고민하던 중, 그동안 시간이 충분치 않아서 오랫동안 생각만 하고 있던 Money 프로젝트 아키텍처 고민이 떠올랐고 어떤 문제가 있는지부터 하나씩 정의해 보기로 했어요.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Service 계층 간 의존 관계가 불분명해서, 순환 참조가 발생하고 코드 응집도가 낮다.&lt;/li&gt;&lt;li&gt;Service 클래스 간 강한 결합이 발생해서, 코드 재사용이 어렵고 비슷하지만 서로 다른 중복 코드가 발생한다.&lt;/li&gt;&lt;li&gt;모든 코드베이스에 Spring 기술이 침투해서, 구현 기술과 독립적으로 비즈니스 로직을 작성할 수 없다.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;이 문제들을 해결해야만 내년, 그리고 그 이후의 서비스 성장에 맞춰 팀 전체가 유저 임팩트를 빠르게 만들어낼 수 있다고 판단했어요. 1번과 2번 문제를 해결하기 위해서는 계층 간 응집도는 높이고 결합도는 낮추는 방향의 구조 개선이 필요했고, 3번 문제를 해결하려면 구현 기술과 독립적인 비즈니스 로직을 작성할 수 있는 기반이 요구됐죠.&lt;/p&gt;&lt;p&gt;물론 도메인 계층에서 인프라 의존성을 역전시키고, 파사드나 인터페이스를 잘 설계하면 이런 문제들을 어느 정도 완화할 수는 있었어요. 하지만 팀과 코드베이스가 빠르게 커지는 상황에서는 ‘잘 지키자’ 는 규칙만으로는 한계가 분명했어요. 새로운 기능과 사람이 계속 합류하다 보니, 의도하지 않은 의존성이 다시 스며들고, 구조적인 제약보다 관습에 의존하게 되는 순간들이 반복됐거든요.&lt;/p&gt;&lt;p&gt;헥사고날 아키텍처는 이런 문제를 사람이 아니라 구조로 제어하려는 선택이었어요. 애플리케이션 핵심 로직과 외부 구현을 명확히 분리하고, 포트를 통해서만 의존성이 연결되도록 강제함으로써, 잘못된 의존성이 아예 만들어지기 어려운 형태를 지향했어요. 특히 팀 규모가 커질수록, 각자의 판단에 맡기기보다 구조 자체가 올바른 방향으로 유도해 주는 설계가 필요하다고 느꼈어요.&lt;/p&gt;&lt;p&gt;당시에 헥사고날 아키텍처를 여러 프로젝트에 적용해본 경험을 통해, 이런 강한 제약이 오히려 팀 전체의 생산성과 일관성을 높여준다는 확신을 얻었고, Money 프로젝트에도 이 구조를 도입하기로 결정했어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/626/1*T8Z-mCJ-Eq0Jzrx2SEBVHw.png&quot; /&gt;&lt;figcaption&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Hexagonal_architecture_(software)&quot;&gt;https://en.wikipedia.org/wiki/Hexagonal_architecture_(software)&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;계층형 아키텍처에서 발생한 강결합 문제를 풀기 위해 도메인 규칙을 중심으로 구현부(UI, DB, 외부 API 등)를 명확히 분리하는 방향으로 아키텍처를 재구성했어요. 크게 domain, usecase, adapter 세 가지 모듈로 나누었고 저희 팀은 이 구조를 Money 2.0 이라고 부르고 있어요.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;domain&lt;/strong&gt;: 당근머니를 다루는 지갑의 입금과 출금 같은 도메인 핵심 규칙을 정의하는 모듈이에요. Domain Entity, Domain Event, Domain Policy, Value Object 등이 이 안에 있고, 어떤 프레임워크나 외부 기술에도 의존하지 않는 POJO(Plain Old Java Object) 모듈로 구성되어 있어요.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;usecase&lt;/strong&gt;: 하나의 사용자 시나리오(송금, 충전, 환불 등) 단위로 응집하는 모듈이에요. 트랜잭션 경계, 검증, 도메인 정책 조합, 포트 호출을 책임지고, domain 모듈만 참조해요. 덕분에 동일한 유스케이스를 REST API, 이벤트 컨슈머, 배치 잡 등 여러 애플리케이션에서 재사용할 수 있었어요.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;adapter&lt;/strong&gt;: domain 모듈에서 정의한 인터페이스를 구현하는 모듈이에요. 데이터베이스, 메시지 브로커, 외부 API 호출, 그리고 Web, Batch, Admin 같은 애플리케이션 입출력을 담당해요. usecase와 domain을 참조하고 구현해요.&lt;/li&gt;&lt;/ul&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*VFmm-7Eivnv1xFupwykOdA.png&quot; /&gt;&lt;figcaption&gt;두 번째 프로젝트 구조(Hexagonal Architecture)&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;모듈 간 의존 규칙은 아래처럼 설정했어요.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;money-domain: 어떤 모듈에도 의존하지 않아요.&lt;/li&gt;&lt;li&gt;money-usecase → money-domain 모듈만 의존해요.&lt;/li&gt;&lt;li&gt;money-adapter → money-usecase, money-domain 모듈에 의존해요(외부 기술/프레임워크 포함).&lt;/li&gt;&lt;li&gt;각 애플리케이션(money-api, money-admin-api, money-batch)은 어댑터를 조립해 런타임 구성을 완성해요.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;전환해야 할 기능도 많고 코드 구조 역시 달랐기 때문에, 한 번에 바꾸기보다는 Strangler Fig Pattern과 Feature Toggle을 활용해 점진적으로 전환하기로 했어요.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Strangler Fig Pattern&lt;/strong&gt;: 기존 코드를 한 번에 바꾸지 않고, 새 모듈로 유스케이스 단위의 기능을 옮겨가며 점진적으로 교체하는 전략이에요. 마치 나무에 붙은 덩굴이 점차 원래 줄기를 감싸면서 교체하는 것과 비슷하다고 해서 붙은 이름이에요. &lt;a href=&quot;https://martinfowler.com/bliki/StranglerFigApplication.html&quot;&gt;참고: Martin Fowler — Strangler Fig&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Feature Toggle&lt;/strong&gt;: 새로운 아키텍처로 옮긴 기능을 플래그로 제어해서, 필요할 때는 기존 로직을 사용하고 안정화되면 새 버전을 단계적으로 적용하는 방식이에요. 위험을 최소화하면서도 빠르게 전환을 진행할 수 있었어요. &lt;a href=&quot;https://medium.com/daangn/%EB%A7%A4%EC%9D%BC-%EB%B0%B0%ED%8F%AC%ED%95%98%EB%8A%94-%ED%8C%80%EC%9D%B4-%EB%90%98%EB%8A%94-%EC%97%AC%EC%A0%95-2-feature-toggle-%ED%99%9C%EC%9A%A9%ED%95%98%EA%B8%B0-b52c4a1810cd&quot;&gt;참고: 매일 배포하는 팀이 되는 여정(2) — Feature Toggle 활용하기&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Refactoring Day 기간 동안 계층형 아키텍처에서 헥사고날 아키텍처로 전환하기 위해 컨벤션, 모듈 구조를 포함한 전체 설계와 몇 가지 유스케이스 전환을 마쳤어요. 새로 추가된 기능들은 헥사고날 아키텍처에 맞춰서 작성하고, 계층형 아키텍처의 기존 기능들은 틈틈이 전환을 진행했어요.&lt;/p&gt;&lt;p&gt;헥사고날 아키텍처로의 전환이 가져다 준 가장 큰 변화는 비즈니스 로직이 기술적 세부사항으로부터 명확하게 분리되었다는 점이에요. 이전에는 모든 로직에 Spring 뿐만 아니라 다양한 외부 구현 기술이 뒤섞여 있어서 코드 수정시 연쇄적인 변경이 자주 발생했지만, 이제는 각 모듈이 자신의 역할에만 집중할 수 있게 됐어요.&lt;/p&gt;&lt;p&gt;Domain 모듈은 오직 핵심 도메인 규칙만을, UseCase 모듈은 유저 시나리오 작성만을, Adapter 모듈은 외부 연동만을 담당해요. 덕분에 코드베이스 전체의 모듈 간 결합도를 크게 낮출 수 있었고 구현 기술에 의존하지 않고 비즈니스 로직 작성에만 집중할 수 있는 환경이 만들어졌어요. 서비스가 더 확장되더라도 유지보수성과 테스트 용이성을 확보할 수 있었어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*pzWkX-_p5tmoQY5j2XTvKg.png&quot; /&gt;&lt;figcaption&gt;Hexagonal Architecture 적용후 변화&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Money 2.0 구조는 당근머니를 하나은행 계좌와 통합해서 사용할 수 있는 당근머니 하나통장, 당근페이 송금 기능을 당근마켓의 모든 서비스에서 사용할 수 있게 도와주는 송금 티켓 플랫폼 등 2023년 한 해 동안 기술적으로 도전적이었던 문제들을 해결할 수 있게 도와준 기반이 되기도 했어요.&lt;/p&gt;&lt;h3&gt;Hexagonal Architecture 적용 이후&lt;/h3&gt;&lt;p&gt;팀에서 새로운 제품을 만든다면, 엔지니어는 어떤 일을 먼저 하게 될까요? 비즈니스 요구사항을 분석하거나 구현에 필요한 기술적 요구사항을 검토할 거예요. 이와 동시에 코드 작성을 위한 프로젝트를 세팅하고, 보일러플레이트를 만들거예요.&lt;/p&gt;&lt;p&gt;제로부터 하나씩 쌓아 올리는 과정은 모두에게 색다른 경험을 주고 높은 자유도를 보장하기 때문에 많은 엔지니어가 새로운 프로젝트에 코드를 작성하는걸 선호해요. 그러다보면 이 과정에 들어가는 비용을 줄이고 더 빠르고 쉽게 프로젝트를 세팅할 수 있도록 우리 팀만의 프로젝트 템플릿(Scaffolding)을 만들거예요. 이제 누구나 스크립트 한 번이면 프로젝트를 초기화할 수 있는 환경이 만들어졌어요.&lt;/p&gt;&lt;p&gt;하지만 이렇게 쉽게 프로젝트를 늘려가다 보면 서비스 성장과 함께 팀에서 관리하는 프로젝트는 한 개, 두 개를 넘어 금세 수십 개로 불어나요. 팀의 엔지니어가 3명인데 관리해야 할 프로젝트가 20개를 넘는다고 상상해보세요.&lt;/p&gt;&lt;p&gt;처음엔 같은 프로젝트 템플릿으로 시작했더라도 각 프로젝트의 코드 컨벤션과 라이브러리 버전은 날이 갈수록 달라질 거예요. 결국 같은 팀에서 관리하지만 서로 다른 방식으로 개발되고 유지보수는 점점 더 어려워져요. 새로 합류한 엔지니어는 일관되지 않은 모습을 보고 혼란을 느낄 수도 있어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/980/1*9djt1UPUJHNi6cN_6Koljg.png&quot; /&gt;&lt;figcaption&gt;&lt;a href=&quot;https://monorepo.tools/&quot;&gt;https://monorepo.tools/&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;저희 팀은 새로운 제품을 만들때 별도 프로젝트를 생성할 때도 있었고, 팀의 메인 프로젝트인 Money 안에 추가하기도 했어요. 새로운 프로젝트를 빠르게 생성할 수 있게 도와주는 템플릿 프로젝트가 있었지만, Money 프로젝트 안에는 서비스를 빠르게 확장할 수 있게 도와주는 플랫폼성 기능들을 제공하고 있어서 대부분 이곳에 추가되었어요.&lt;/p&gt;&lt;p&gt;사용자에게 혜택이나 광고를 서빙하는 배너 서비스와 당근포인트를 관리하는 포인트 서비스가 Money 프로젝트 안에 생성됐어요. 편의 기능들을 재사용할 수 있고 정형화되어 있는 구조에 맞춰 빠른 개발이 가능하다는 장점이 있었죠. 하지만 비즈니스 로직과 외부 구현체의 경계만 존재하고, 도메인 간 경계가 없는 헥사고날 아키텍처 안에 서로 다른 도메인 서비스가 공존하다 보니 여러 문제점이 드러나기 시작했어요.&lt;/p&gt;&lt;h4&gt;문제 1. 기준 없이 Adapter 모듈에 수많은 구현 클래스가 추가되었어요&lt;/h4&gt;&lt;p&gt;특정 라이브러리를 사용한 구현 세부 사항이나 외부 시스템 연동은 헥사고날 아키텍처의 Adapter 모듈에 위치해요. 역할과 책임이 명확해서 큰 고민 없이 인터페이스 구현체들은 Adapter 모듈에 추가됐어요. 하지만 이런 장점은 Adapter 모듈을 참조하는 여러 부트스트랩 애플리케이션 입장에서 불필요한 의존성을 참조하게 되는 역효과를 가져왔어요.&lt;/p&gt;&lt;p&gt;배너 서비스의 구현체, 포인트 서비스의 구현체 모두 Adapter 모듈에 작성되어서 머니 서비스 애플리케이션에는 필요하지 않은 배너와 포인트 의존성이 포함된 채 구동되었어요. Adapter 모듈은 아키텍처 의도와 다르게 언젠간 정리되어야 할 부채가 쌓여가는 공간이 되어버렸어요.&lt;/p&gt;&lt;p&gt;Domain Repository 구현체도 Adapter 모듈의 out 패키지 하위에 위치해 있었어요. 고민 없이 빠르게 구현할 수 있다는 장점이 있지만, 머니·포인트·배너 등 특정 Domain Repository의 구현체를 찾기 어렵고 어떤 의존성을 가지고 있는지 코드를 보지 않으면 파악하기 힘들어졌어요. Domain Repository 구현체들이 한곳에 모여 있으면서 얻을 수 있는 장점은 생각 없이 코드를 추가할 수 있다는 점 정도뿐이었어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*siPFBOPqR-isdPJ47f2KWQ.png&quot; /&gt;&lt;figcaption&gt;기준 없이 추가된 Adapter Layer의 수많은 구현 클래스&lt;/figcaption&gt;&lt;/figure&gt;&lt;h4&gt;문제 2. 배포할 서비스와 관계 없는 서비스들이 배포되었어요&lt;/h4&gt;&lt;p&gt;저희 팀은 trunk-based development 방법론에 맞춰 개발하고 있어서 Main Branch에 변경 사항이 발생하면 애플리케이션이 자동으로 배포돼요. 배포 트리거에 특정 도메인이나 서비스별 구분을 두고 있지 않다 보니, 머니 서비스의 코드가 변경되면 전혀 관계 없는 배너와 포인트 서비스도 함께 배포 됐어요. 서비스별로 패키지 이름을 구분해서 일괄 배포되는 문제를 일부 해결할 수는 있었지만, 패키지를 넘나드는 코드 참조가 생기면 문제는 여전히 발생했어요. 결국 근본적인 문제 해결 방법은 아니었죠.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*rrV_SDL2ylVJJIZNjW7r1Q.png&quot; /&gt;&lt;figcaption&gt;money-internal-api를 배포하는데 banner, point 등 모든 서비스가 배포되는 현상&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;이 외에도 초기에 누릴 수 있었던 재사용 가능한 편의 기능, 외부 구현체와의 관심사 분리 등의 장점은 시간이 갈수록 오히려 개발 생산성이 저하되는 문제로 이어졌어요.수십 번의 배포를 반복하며 빠른 속도로 일하는 저희 팀의 비즈니스 전개를 방해하는 요소가 되었고 해결해야 할 문제로 다가왔어요.&lt;/p&gt;&lt;h3&gt;세 번째: Clean Architecture &amp;amp; Monorepo&lt;/h3&gt;&lt;p&gt;Money 2.0 설계는 계층형 아키텍처의 문제를 풀기 위해 핵심 로직과 외부 구현을 분리하는 헥사고날 아키텍처를 기반으로 했지만, 도메인 간 관심사 분리는 충분히 고려하지 못했어요. 그래서 여러 도메인이 한 지붕 아래에서 잘 지낼 수 있게 도와주는 새로운 구조가 필요해졌어요.&lt;/p&gt;&lt;p&gt;소프트웨어 아키텍처는 개념이나 추상적인 이론만 놓고 보면 장점이 분명해 보여요. 하지만 중요한 건, 이런 아키텍처나 패턴을 우리 팀의 상황에 맞는 구체적인 규칙과 구조로 어떻게 풀어내느냐예요. 헥사고날 아키텍처를 애플리케이션(Application), 포트(Port), 어댑터(Adapter) 모듈로 나눈다고 했을 때, 각 모듈을 코드베이스에 어떻게 배치할지, 네이밍은 어떤 기준으로 맞출지, 그리고 구체 클래스들을 런타임에 어떤 방식으로 조합할지 등 아주 구체적인 고민이 필요해요. 결국 이 아키텍처를 우리 팀의 일하는 방식과 프로젝트 특성에 맞게 적용하기 위해서는, 개념을 넘어 실제로 동작하는 규칙과 형태를 정의해야 했어요.&lt;/p&gt;&lt;p&gt;머니, 포인트, 쿠폰, 기프팅 등 여러 도메인 서비스들을 하나의 프로젝트에 관리하면서 발생하는 문제를 해결하기 위해, 새로운 구조가 달성해야 할 목표와 고려해야 할 내용들을 논의하였고 Robert C. Martin의 클린 아키텍처(Clean Architecture)를 베이스로 한 모노레포(Monorepo) 모듈 구조를 만들었어요.&lt;/p&gt;&lt;h4&gt;목표&lt;/h4&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;도메인 모듈화&lt;/strong&gt;: 단일 프로젝트 내에서 도메인별 모듈을 명확히 분리하고, 도메인 간 의존 관계를 명시적으로 관리해요.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;의존성 역전&lt;/strong&gt;: 고수준 모듈(도메인, 비즈니스 로직)은 저수준 모듈(외부 시스템, 인프라 구현)에 직접 의존하지 않고, 모든 의존성은 추상화된 인터페이스를 기준으로 설계하여 구현 교체와 테스트가 용이한 구조를 만들어요.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;확장성과 유지보수성&lt;/strong&gt;: 애플리케이션 비즈니스 로직이 특정 구현에 의존하지 않는 헥사고날 아키텍처의 장점을 유지하면서, 새로운 도메인과 기능이 추가되더라도 기존 코드에 미치는 영향을 최소화해요.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;배포 독립성&lt;/strong&gt;: 특정 도메인의 변경이 다른 도메인 서비스의 배포로 이어지지 않도록 해요. 서비스 단위의 독립적인 배포가 가능하도록 구조를 설계해요.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;테스트 용이성&lt;/strong&gt;: 모듈별 독립적인 테스트 환경을 제공하고, Fixture 및 Stubbing 모듈을 통해 외부 의존성 없이 테스트할 수 있도록 해요.&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;기본 아키텍처&lt;/h4&gt;&lt;p&gt;베이스로 삼은 클린 아키텍처(Clean Architecture)의 핵심은 한 단어 The Dependency Rule 로 표현할 수 있어요. ‘의존성은 항상 안쪽(비즈니스 규칙)으로만 향해야 한다’ 는 말이에요. 이 규칙을 바탕으로 모듈의 의존 관계를 고수준 정책이 저수준 구현을 의존하지 않도록 설계했어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/772/1*PVgABZDP57QZJJrJLjb1aQ.png&quot; /&gt;&lt;figcaption&gt;&lt;a href=&quot;https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html&quot;&gt;https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h4&gt;프로젝트 모듈 구조&lt;/h4&gt;&lt;p&gt;크게 bootstrap, core, infrastructure, library, platform, usecase 여섯 개의 모듈로 구성되어 있어요. 모듈 사이의 모든 상호작용은 구체 클래스가 아닌 인터페이스를 통해 이루어지고, 각 모듈은 독립적으로 개발, 테스트 그리고 교체될 수 있어요.&lt;/p&gt;&lt;p&gt;bootstrap:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;모든 레이어의 의존성을 조립해서 애플리케이션을 실행하는 최상위 모듈이에요.&lt;/li&gt;&lt;li&gt;머니, 포인트, 프로모션, 선물하기 등 각 서비스의 애플리케이션들이 디렉터리 단위로 구분되어 있어요.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;core:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;각 도메인의 핵심 비즈니스 규칙을 정의하는 모듈이에요.&lt;/li&gt;&lt;li&gt;core:{domain}:domain: 외부 기술에 의존하지 않고 비즈니스 규칙을 정의해요.&lt;/li&gt;&lt;li&gt;core:{domain}:data: core:domain 모듈에서 정의한 인터페이스를 구현해요.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;infrastructure:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;애플리케이션 실행에 필요한 기술적인 세부사항을 모아놓은 모듈이에요.&lt;/li&gt;&lt;li&gt;상위 레이어의 어댑터들이 이 모듈의 기술들을 사용해서 구현체를 완성해요.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;library:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Async, Logging, Retry 등 모든 모듈에서 공통으로 사용하는 횡단 관심사를 제공하는 모듈이에요.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;platform:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;인증, FDS, 당근채팅 등 도메인과 관련된 외부 플랫폼을 연동한 모듈이에요.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;usecase:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;계좌등록, 송금, 더치페이 등 하나의 사용자 시나리오 단위의 비즈니스 로직을 작성하는 모듈이에요.&lt;/li&gt;&lt;/ul&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*fjgSHiqusYt857MZG_64kQ.png&quot; /&gt;&lt;figcaption&gt;세 번째 프로젝트 구조(Clean Architecture &amp;amp; Monorepo)&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Clean Architecture &amp;amp; Monorepo 적용 이후&lt;/h3&gt;&lt;h4&gt;1. Hexagonal Architecture 구조에서 발생하던 문제가 해결 되었어요&lt;/h4&gt;&lt;p&gt;모든 서비스에서 공통으로 사용하던 도메인과 어댑터 모듈이 사라지고 도메인마다 별도 모듈을 구성함으로써 각 도메인을 독립적으로 관리할 수 있게 됐어요. money-domain 모듈에 있던 머니, 포인트, 배너 등 다양한 서비스의 도메인 규칙들은 core:{domain}:domain 모듈 하위로 분리되었고, money-adapter 모듈에 존재했던 구현체들이 각 도메인의 관심사에 맞게 core:{domain}:data 모듈 하위로 분리되었어요.&lt;/p&gt;&lt;p&gt;bootstrap 모듈에서 각 애플리케이션 구동에 필요한 모듈만 조합할 수 있게 되면서 헥사고날 아키텍처에서 발생하던 서비스 배포 문제도 함께 해결됐어요. 머니 송금 유스케이스의 변경 사항은 머니 부트스트랩 하위의 애플리케이션에만 영향을 주고 관계 없는 다른 애플리케이션에는 영향을 주지 않는 구조가 된 거예요.&lt;/p&gt;&lt;h4&gt;2. 비즈니스 임팩트를 빠르게 만들 수 있는 환경을 만들었어요&lt;/h4&gt;&lt;p&gt;수십 개의 서비스를 하나의 프로젝트에서 운영하다 보니 자연스럽게 조직 전반에 걸친 다양한 툴이 만들어졌어요. 그중 하나가 디렉터리 구조, 공통 설정, 의존성, Test Scaffolding 등 애플리케이션 구성에 필요한 모든 보일러플레이트를 만들어주는 도구예요. 새로운 애플리케이션 구성이 필요하면 엔지니어는 버튼 한 번만으로 빠르게 초기 코드베이스를 완성할 수 있었어요.&lt;/p&gt;&lt;p&gt;프로젝트 통합 이후 코드 라인 수는 빠르게 늘었지만, 이때마다 저희 팀이 집요하게 지킨 건 피드백 루프의 속도였어요. 전체 코드 라인 수는 전년 대비 2배 가까이 늘었는데도 팀원 모두 빌드 속도를 틈틈이 개선해서 엔지니어가 체감하는 빌드 소요 시간은 늘지 않았어요. 빌드·테스트·배포가 늦어지지 않으니 작은 변경도 부담 없이 자주 릴리즈하고, 작은 실험 → 빠른 릴리즈 → 빠른 피드백 → 다음 개선의 사이클을 유지할 수 있었어요. 그 결과 사용자의 피드백을 빠르게 반영해서 비즈니스 임팩트를 더 짧은 주기로 만들어낼 수 있게 되었어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*2pjR7gmjfTtuBh1GM2KKNw.png&quot; /&gt;&lt;figcaption&gt;코드 라인수 증가(192%↑)에 따른 평균 빌드 소요 시간과 배포 횟수 비교&lt;/figcaption&gt;&lt;/figure&gt;&lt;h4&gt;3. 일관된 시스템을 만들고 기술적 성숙도를 공유할 수 있게 되었어요&lt;/h4&gt;&lt;p&gt;복잡한 마이크로서비스 환경에서 일관된 기준이 없으면 시스템에 문제가 발생했을 때 문제 원인(Root Cause)를 찾기 어렵고 문제 해결이 특정 개인에 의존해야 하는 현상이 생길 수도 있어요. A 서비스와 B 서비스 간에 타임아웃 설정은 어떻게 되어 있는지, A 서비스가 어떤 의존성을 가지고 빌드 되는지 등 모노레포에 적용된 가시성 높은 규칙들 덕분에 개인이 아닌 코드 기여자 누구라도 문제 해결에 뛰어들 수 있게 되었고 해결에 소요되는 시간도 단축시킬 수 있었어요.&lt;/p&gt;&lt;p&gt;수십 개의 프로젝트를 관리해 본 경험이 있으시다면 공통으로 개선해야 할 부분이나 린트, 테스트, 빌드, 배포 기준 등이 서비스마다 모두 달라서 유지보수가 어려웠던 경험이 떠오를 거예요. 모노레포 도입 이후에는 한 번의 개선이 모든 곳에 원자적으로 반영이 되어서 의존성 관리, 변경과 탐색이 훨씬 쉬워졌어요. 트러블 슈팅을 통한 레슨런이 모노레포의 모든 서비스에 반영될 수 있었고, 안정성과 일관성이 중요한 금융 서비스에 신뢰를 더할 수 있었어요.&lt;/p&gt;&lt;p&gt;이제는 어떤 서비스가 언제 배포되었고 배포로 인한 에러는 없었는지 릴리즈 리포팅을 자동화하면서 배포 과정이 이전보다 더 투명해졌어요. 또 런북(Runbook)을 바탕으로 사람이 모니터링하던 운영 방식을 시스템으로 자동화하면서 장애 대응 역시 개인이 아닌 팀 전체의 역량으로 축적되고 있어요.&lt;/p&gt;&lt;h4&gt;4. 엔지니어링 역량이 함께 성장할 수 있는 환경을 만들었어요&lt;/h4&gt;&lt;p&gt;효과적인 성장을 위해서는 문제 인식과 개선 그리고 피드백 사이클을 만드는 게 중요해요. 모노레포는 이 사이클을 반강제적으로 만들어 주었어요😅 서로 다른 목적 조직이 하나의 프로젝트에 코드를 기여하게 되면서, 개선해야 할 부분이 보이면 이전보다 더 적극적으로 공유했고, 모두가 공감할 만한 문제가 수면 위로 올라오면 관심 있는 누구든, 혹은 주간 온콜 담당자가 문제를 해결했어요.&lt;/p&gt;&lt;p&gt;특히 코드 리뷰는 피드백 사이클의 중요한 축이 되었어요. 변경 사항이 한 곳에 모이면서 코드가 더 잘 보이게 되었고, 그만큼 리뷰 참여와 코멘트도 자연스럽게 늘어났어요. 코드 리뷰는 단순한 승인 절차를 넘어, 설계 의도를 공유하고 서로 배우는 주요한 협업 수단이자 함께 성장할 수 있는 기반이 되었어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*xka98JRckNT8jN-jP12wKQ.png&quot; /&gt;&lt;figcaption&gt;PR 생성과 코드 리뷰 수&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;라이브러리 버전 업그레이드, Generational ZGC 적용, Gradle Build Cache 적용, TestContainer 도입, Stream Application 활용, 온콜 시스템 자동화 등 시스템 안정성과 개발 생산성을 높이기 위한 엔지니어링 작업은 한 번에 여러 서비스에 임팩트를 줄 수 있어서, 특정 팀만의 일이 아니라 모두의 관심사가 되었어요. 이런 작업을 함께 논의하고 설계하고 실제로 적용해보는 과정에서 각자의 전문 영역을 넘어 서로의 관점을 배우게 되었고 자연스럽게 공통의 엔지니어링 기준이 생겼어요. 결과적으로 ‘내 서비스만 잘 만들기’ 를 넘어, 조직 전체의 기술 수준을 한 단계 끌어올리는 데 기여하고 있다는 감각이 팀원들의 중요한 성장 동력이 되었던 것 같아요.&lt;/p&gt;&lt;h4&gt;회고&lt;/h4&gt;&lt;p&gt;이번 회고에서는 좋았던 점(Keep)보다는 어렵거나 힘들었던 것(Problem), 그리고 더 잘해보고 싶은 점(Try)에 대해 이야기를 많이 나누었어요. 덕분에 지금의 방식이 어느 정도 자리를 잡았고, 다음 단계를 고민할 시점이라는 공감대가 생겼죠. 모노레포는 저희가 그 방향성 덕분에 하나의 팀(One Team)으로 일할 수 있는 환경을 만들어 주었어요. 다른 컴포넌트의 구조를 자연스럽게 이해하게 되었고, 코드 리뷰와 논의를 통해 개인의 경험이 팀 전체의 지식으로 확산되는 흐름이 만들어졌거든요. 무엇보다 ‘내가 맡은 영역’을 넘어 서로의 고민을 함께 나눌 수 있다는 점이 동료들에게 긍정적으로 받아들여졌던 것 같아요.&lt;/p&gt;&lt;p&gt;물론 장점만 있었던 건 아니에요. 코드베이스가 커질수록 빌드 속도 문제나 인지 부하에 대한 부담이 점점 더 또렷해졌고, 모듈과 레이어의 경계를 사람마다 조금씩 다르게 해석할 수 있다는 점도 알게 되었어요. 지금은 감당 가능한 수준이지만, 팀과 코드가 더 커진다면 이 방식이 계속 유효할지에 대한 고민도 자연스럽게 나왔고요.&lt;/p&gt;&lt;p&gt;이번 회고를 통해 다시 느낀 건, 모노레포가 어떤 팀에게나 항상 정답은 아니라는 점이었어요. 지금의 팀 규모와 문제 상황에서는 ‘함께 보고, 함께 고치고, 함께 책임지는’ 구조가 큰 힘을 발휘했지만, 이 선택이 언제까지나 최선일 수는 없으니까요. 그래서 중요한 건 모노레포 자체가 아니라, 현재 팀의 문제를 가장 잘 해결해줄 수 있는 도구를 찾는 것이라고 생각해요. 저희도 물론 언젠가 팀의 상황이 달라진다면, 다른 선택을 하게 될 수도 있을 거예요. 그리고 이 여정은 Lorde, William, Winter, Leo, Clover, Robin 동료들과 함께였기에 가능했어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*FEzrF0yVSdl3xjgpkgW3Ow.png&quot; /&gt;&lt;figcaption&gt;머니 서비스팀 백엔드 엔지니어 KPT(Keep, Problem, Try) 회고&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;마치며&lt;/h3&gt;&lt;p&gt;세계적으로 유명한 리더십 코치 Marshall Goldsmith는 그의 저서 What Got You Here Won’t Get You There 에서 “과거의 성공 방식이 미래의 성공을 보장하지 않는다”고 말해요. 즉 지금까지의 성공 방식이 항상 미래의 성공을 보장하지 않기 때문에, 문제를 인식하고 개선하며 변화에 맞춰 나가야만 한계를 뚫고 성장할 수 있다는 뜻이에요.&lt;/p&gt;&lt;p&gt;당근페이 백엔드 프로젝트도 그랬어요. 위에서 설명했듯 단순한 Layered Architecture에서 출발해 Hexagonal Architecture를 거쳐, 지금의 Clean Architecture와 Monorepo로 확장되기까지, 이 글에 담지 못한 수백 가지의 작은 변화들도 있었어요. 물론 지금 구조가 당장 내일의 환경에 맞지 않을 수도 있기 때문에 그 때에 맞춰서 또 변화를 준비해야 할 수도 있어요. 그렇기에 지금도 저희는 변화를 준비하고 있고요.&lt;/p&gt;&lt;p&gt;모노레포는 개발의 불편함을 단번에 없애주는 마법은 아니었어요. 하지만 그 불편함을 혼자가 아닌 팀원 전체가 공유하게 만들어주었어요. 덕분에 반복적인 개선이 쌓여 모두의 성장으로 이어지는 문화가 자리잡을 수 있었어요. 더 나은 코드 리뷰 환경, 고민을 덜어주는 코딩 컨벤션, 빌드 속도 개선과 자동화가 자연스러운 일상이 된 것처럼요.&lt;/p&gt;&lt;p&gt;물론 이런 변화로 동시에 새로운 과제들도 나타났어요. 코드베이스가 더 커질수록 구조를 어떻게 유지할지, 개발자 경험(Developer Experience)을 어떻게 지켜낼지, 그리고 이런 문화를 어떻게 다음 단계까지 확장해 나갈지는 여전히 고민해야 할 문제예요. 저희는 지금이 완성이 아니라, 과정이라고 생각하고 있어요. 계속해서 더 나은 방향을 실험하고 개선해 나가려고 해요.&lt;/p&gt;&lt;p&gt;금융 서비스에서 더 빠르고 안정적으로 비즈니스와 유저 임팩트를 만들어가기 위해, 아직 함께 풀어야 할 과제가 많아요. 이 여정에 함께 고민하고 만들어갈 백엔드 엔지니어 동료를 기다리고 있어요. Mission Critical 환경에서 당근페이 비즈니스를 성장시키는 도전에 관심이 있다면, 아래 채용 공고도 한 번 읽어보세요.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://team.daangn.com/jobs/4511184003/&quot;&gt;Software Engineer, Backend — 당근페이 (Kotlin)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;당근페이팀에 더 궁금한 게 있으시다면 댓글을 달아주시거나 &lt;a href=&quot;mailto:jeremy.kim@daangnpay.com&quot;&gt;jeremy.kim@daangn.com&lt;/a&gt; 으로 연락해주셔도 좋아요.&lt;/p&gt;&lt;p&gt;긴 글 읽어주셔서 감사합니다.&lt;/p&gt;&lt;img src=&quot;https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=98615d5a6b06&quot; width=&quot;1&quot; height=&quot;1&quot; alt=&quot;&quot;&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&quot;https://medium.com/daangn/%EB%8B%B9%EA%B7%BC%ED%8E%98%EC%9D%B4-%EB%B0%B1%EC%97%94%EB%93%9C-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98%EA%B0%80-%EA%B1%B8%EC%96%B4%EC%98%A8-%EC%97%AC%EC%A0%95-98615d5a6b06&quot;&gt;당근페이 백엔드 아키텍처가 걸어온 여정&lt;/a&gt; was originally published in &lt;a href=&quot;https://medium.com/daangn&quot;&gt;당근 테크 블로그&lt;/a&gt; on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</content:encoded>
    </item>
    <item>
      <title>Building Event Center: Karrot’s User Event Management Platform</title>
      <link>https://medium.com/daangn/building-event-center-karrots-user-event-management-platform-387c58b10530?source=rss----4505f82a2dbd---4</link>
      <guid>https://medium.com/daangn/building-event-center-karrots-user-event-management-platform-387c58b10530?source=rss----4505f82a2dbd---4</guid>
      <pubDate>Mon, 12 Jan 2026 01:50:33 GMT</pubDate>
      <content:encoded>&lt;h4&gt;The Journey from Restructuring User Event &lt;strong&gt;Conventions&lt;/strong&gt; to Building an Admin Platform&lt;/h4&gt;&lt;p&gt;Hi there! I’m Mika, a frontend engineer on &lt;a href=&quot;https://www.karrotmarket.com/?in=manhattan-7426&quot;&gt;Karrot’s&lt;/a&gt; Data team.&lt;/p&gt;&lt;p&gt;At Karrot, massive amounts of user events are collected every day. These events are essential for designing experiments, improving our products, and making data-driven decisions. But as the logs scaled, managing them effectively became increasingly important.&lt;/p&gt;&lt;p&gt;That’s why we restructured our company-wide logging convention and built a platform called &lt;em&gt;Event Center&lt;/em&gt; — an admin platform for managing user events across the company. We shifted from a Git-based, code-centric workflow to a UI-driven approach, automating as much manual work as possible. The goal was to handle user events more consistently and safely.&lt;/p&gt;&lt;p&gt;In this post, I’ll share our journey — from why we restructured our logging system to how we designed and implemented Event Center. If you’re dealing with similar challenges, hopefully this gives you some ideas!&lt;/p&gt;&lt;h3&gt;1. User Events: The Starting Point for Data-Driven Decisions&lt;/h3&gt;&lt;p&gt;Millions of users interact with the &lt;em&gt;Karrot&lt;/em&gt; app every day, leaving behind traces of their behavior. Small actions like “viewed a marketplace listing,” “tapped the chat button,” or “added to favorites” accumulate into valuable data.&lt;/p&gt;&lt;p&gt;This data helps us improve user experience and drives product decisions. For example, if we notice that users rarely tap the chat button, we might consider repositioning it to make it more visible. Instead of relying on gut feelings, we can make informed decisions backed by data.&lt;/p&gt;&lt;p&gt;But collecting and analyzing this behavioral data turned out to be more complex than expected. As our log volume grew, we gradually hit the limitations of our operational approach.&lt;/p&gt;&lt;p&gt;Before diving into those challenges, let me briefly explain how we collect user events at Karrot.&lt;/p&gt;&lt;h4&gt;1.1. How We Collect User Events&lt;/h4&gt;&lt;p&gt;As Karrot grew, so did the variety and volume of data we needed to collect. Our existing approach couldn’t scale well or stay user-friendly, so we built our own user event logging system.&lt;/p&gt;&lt;p&gt;Here’s a simplified overview of how user events flow from generation to becoming analyzable data:&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/945/1*GoXNx0DqGP-dnQwuAG5Lrg.png&quot; /&gt;&lt;figcaption&gt;User Event Collection Pipeline (Simplified)&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The process breaks down into three main stages: event collection, validation and processing, and storage.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Event Collection&lt;/strong&gt;: When a user action occurs in the Karrot mobile app, the SDK sends data to our event server (managed by the Data team) based on specific conditions or intervals.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Initial Validation and Routing&lt;/strong&gt;: The event server performs basic validation, then forwards events to GCP Pub/Sub.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Stream Processing and Transformation&lt;/strong&gt;: GCP Dataflow handles real-time validation of key fields, short-window deduplication, and data flattening.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Storage and Error Handling&lt;/strong&gt;: Throughout the pipeline, data is stored in GCS and BigQuery. Invalid events are routed to a &lt;em&gt;Dead Letter Queue (DLQ)&lt;/em&gt; Pub/Sub and stored in a separate BigQuery table for later analysis and debugging.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Batch Deduplication&lt;/strong&gt;: A subsequent batch job performs another round of time-window-based deduplication to improve data accuracy.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Final Data Loading&lt;/strong&gt;: Data is loaded into a format that team members can query directly. Common fields are stored in a flattened structure for immediate access, while event-specific parameters are stored as JSON for flexibility.&lt;/li&gt;&lt;/ol&gt;&lt;h4&gt;1.2. User Event Schema&lt;/h4&gt;&lt;p&gt;Once data reaches BigQuery, proper interpretation becomes essential for meaningful analysis.&lt;/p&gt;&lt;p&gt;That’s where &lt;em&gt;user event schemas&lt;/em&gt; come in. A schema defines what each log means and what fields it contains — the event type, expected parameters, and data formats.&lt;/p&gt;&lt;p&gt;Here’s why schemas matter:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;They identify who owns each event.&lt;br&gt;&lt;/strong&gt;With hundreds of events generated across the company, it can be unclear who’s responsible for each one. Without knowing who created and maintains an event, operations become difficult. So we assign an owner to each event.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;They enable domain-based event classification.&lt;br&gt;&lt;/strong&gt;As our service grew, we needed to organize events systematically. For company-wide analysis, you might want to filter events related to specific domain only. To support this, we define a domain for each event.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;They allow custom parameters per event.&lt;br&gt;&lt;/strong&gt;All events share common fields like event_name, timestamp, and event_id. But each event also has unique information — custom parameters. Without documentation of what these parameters mean and their types, writing queries becomes confusing. You end up constantly checking whether a value is a string or number, or what the exact field name is.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Once you add an event schema, BigQuery automatically creates a table for that event. Custom parameters that were previously stored as JSON are now exposed as regular columns, making SQL queries much simpler:&lt;/p&gt;&lt;pre&gt;SELECT &lt;br&gt;  event_id,     -- common field&lt;br&gt;  event_name,   -- common field&lt;br&gt;  user_id,      -- common field&lt;br&gt;  banner_id,    -- custom parameter&lt;br&gt;  banner_title  -- custom parameter&lt;br&gt;FROM `event_dataset.event_name`&lt;/pre&gt;&lt;p&gt;No more complex queries to extract values from JSON — custom parameters like banner_id are directly queryable, making analysis much easier.&lt;/p&gt;&lt;h3&gt;2. Before: Managing Event Schemas with Git-Based Code&lt;/h3&gt;&lt;p&gt;User event schemas are a critical system for making collected data analyzable. They’re primarily used to define team-specific custom fields and manage ownership, beyond the common logging fields.&lt;/p&gt;&lt;p&gt;These schemas need to be managed easily but consistently by anyone who wants to analyze data. But at the time, Karrot managed schemas through Git-based code. Without standardized event naming conventions, we started experiencing various operational challenges.&lt;/p&gt;&lt;h4&gt;2.1. The Problems&lt;/h4&gt;&lt;p&gt;Managing schemas in code without standardized event names led to multiple challenges. The biggest issue was that adding a single schema required way too much effort.&lt;/p&gt;&lt;blockquote&gt;&lt;strong&gt;Problem 1: Complexity of Code-Based Schema Management&lt;/strong&gt;&lt;/blockquote&gt;&lt;p&gt;Creating a schema required this multi-step process:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Write a JSON schema file in the data pipeline codebase (requires coding knowledge)&lt;/li&gt;&lt;li&gt;Pass validation and formatting CI checks&lt;/li&gt;&lt;li&gt;Create a PR&lt;/li&gt;&lt;li&gt;Go through review cycles with the Data team&lt;/li&gt;&lt;li&gt;Once the PR is merged, a queryable BigQuery schema is auto-generated&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;The schema file in step 1 had to be written manually in Spark’s StructType JSON format:&lt;/p&gt;&lt;pre&gt;// client_{action_type}_{service}_{object}.json&lt;br&gt;{&lt;br&gt;  &amp;quot;type&amp;quot;: &amp;quot;struct&amp;quot;,&lt;br&gt;  &amp;quot;metadata&amp;quot;: {&lt;br&gt;    &amp;quot;description&amp;quot;: &amp;quot;Item click event&amp;quot;,&lt;br&gt;    &amp;quot;owners&amp;quot;: [&amp;quot;data@daangn.com&amp;quot;],&lt;br&gt;    &amp;quot;domains&amp;quot;: [&amp;quot;data&amp;quot;]&lt;br&gt;  },&lt;br&gt;  &amp;quot;fields&amp;quot;: [&lt;br&gt;    {&lt;br&gt;      &amp;quot;name&amp;quot;: &amp;quot;id&amp;quot;,&lt;br&gt;      &amp;quot;type&amp;quot;: &amp;quot;string&amp;quot;,&lt;br&gt;      &amp;quot;nullable&amp;quot;: false,&lt;br&gt;      &amp;quot;metadata&amp;quot;: {&lt;br&gt;        &amp;quot;comment&amp;quot;: &amp;quot;Event ID&amp;quot;&lt;br&gt;      }&lt;br&gt;    }&lt;br&gt;  ]&lt;br&gt;}&lt;/pre&gt;&lt;p&gt;Since schemas supported nested structures, they could get quite complex:&lt;/p&gt;&lt;pre&gt;{&lt;br&gt;  &amp;quot;name&amp;quot;: &amp;quot;extra&amp;quot;,&lt;br&gt;  &amp;quot;type&amp;quot;: {&lt;br&gt;    &amp;quot;type&amp;quot;: &amp;quot;struct&amp;quot;,&lt;br&gt;    &amp;quot;fields&amp;quot;: [&lt;br&gt;      {&lt;br&gt;        &amp;quot;name&amp;quot;: &amp;quot;random&amp;quot;,&lt;br&gt;        &amp;quot;type&amp;quot;: {&lt;br&gt;          &amp;quot;type&amp;quot;: &amp;quot;struct&amp;quot;,&lt;br&gt;          &amp;quot;fields&amp;quot;: [&lt;br&gt;            {&lt;br&gt;              &amp;quot;name&amp;quot;: &amp;quot;parent_item_id&amp;quot;,&lt;br&gt;              &amp;quot;type&amp;quot;: &amp;quot;string&amp;quot;,&lt;br&gt;              &amp;quot;nullable&amp;quot;: true,&lt;br&gt;              &amp;quot;metadata&amp;quot;: {&lt;br&gt;                &amp;quot;comment&amp;quot;: &amp;quot;Parent item ID&amp;quot;&lt;br&gt;              }&lt;br&gt;            }&lt;br&gt;          ]&lt;br&gt;        }&lt;br&gt;      }&lt;br&gt;    ]&lt;br&gt;  }&lt;br&gt;}&lt;/pre&gt;&lt;p&gt;Step 1 was overly complicated. Even adding a simple field meant filling out metadata, nullable, type, and other attributes. Typos and formatting mistakes were common.&lt;/p&gt;&lt;p&gt;With deeply nested struct structures, missing a single bracket or comma would fail CI.&lt;/p&gt;&lt;blockquote&gt;&lt;strong&gt;Problem 2: Long Review Cycles&lt;/strong&gt;&lt;/blockquote&gt;&lt;p&gt;Other teams had to write JSON and submit PRs, which required Data team review. Convention violations, type errors, insufficient descriptions — various issues would trigger revision requests, leading to back-and-forth cycles that ate up significant time.&lt;/p&gt;&lt;blockquote&gt;&lt;strong&gt;Problem 3: Inconsistent Event Naming&lt;/strong&gt;&lt;/blockquote&gt;&lt;p&gt;Without enforced naming conventions, event names ended up in various formats:&lt;/p&gt;&lt;p&gt;Example 1: Same service, different casing&lt;/p&gt;&lt;ul&gt;&lt;li&gt;home_feed vs homeFeed (snake_case vs camelCase)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Example 2: Same action, different words&lt;/p&gt;&lt;ul&gt;&lt;li&gt;show_article vs shown_article&lt;/li&gt;&lt;li&gt;view vs shown&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;strong&gt;Problem 4: Screen Name Confusion and Management Difficulties&lt;/strong&gt;&lt;/blockquote&gt;&lt;p&gt;Different teams called the same screen by different names. Some named screens based on functionality, others based on product specs. Without a unified standard, consistency gradually broke down. Screen information was scattered across team-specific Notion pages and separate documents.&lt;/p&gt;&lt;p&gt;This structure affected not just engineers working directly with event schemas, but also various roles that relied on logs. Here’s a summary of the difficulties each role experienced:&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/936/1*0S5UGgmSa2yLdpKXzJmJIw.png&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Schemas managed in code without a unified event system slowed down the entire workflow beyond just one team’s inconvenience.&lt;/p&gt;&lt;h4&gt;2.2. The Solutions&lt;/h4&gt;&lt;p&gt;To address these challenges, the Data team set a few key directions:&lt;/p&gt;&lt;blockquote&gt;&lt;strong&gt;1. Establish a standardized user event system company-wide.&lt;/strong&gt;&lt;/blockquote&gt;&lt;p&gt;We decided to unify the different event naming conventions across teams into a common language — not team-specific jargon, but a common language everyone could use. We believed a consistent standard was necessary before logs could become company-wide assets.&lt;/p&gt;&lt;p&gt;So we standardized all event names. Now when someone mentions &lt;em&gt;“chat button click on the fleamarket listing detail screen,” &lt;/em&gt;there’s no ambiguity — everyone knows exactly what event that is. This reduces communication overhead and makes data discovery much faster.&lt;/p&gt;&lt;blockquote&gt;&lt;strong&gt;2. Build an admin platform for defining user event schemas via UI instead of code.&lt;/strong&gt;&lt;/blockquote&gt;&lt;p&gt;We determined that code-based schema management, limited to certain teams and roles, had inherent limitations. So we decided to build an admin platform where anyone could define schemas directly through a UI. The system would automatically generate event names and formats according to conventions, maintaining consistency automatically.&lt;/p&gt;&lt;p&gt;Once you register a screen in the admin, you can see all events occurring on that screen in one place. Wondering &lt;em&gt;“what events exist on the fleamarket listing detail screen?”&lt;/em&gt; Now anyone — regardless of team or role — can look it up instantly.&lt;/p&gt;&lt;blockquote&gt;&lt;strong&gt;3. Create a CLI that safely converts user event schemas to typed code for each programming language.&lt;/strong&gt;&lt;/blockquote&gt;&lt;p&gt;Define schemas in one place — Event Center, and the CLI automatically generates platform-specific code for IOS, Android, and Webview. This catches common errors like missing fields or type mismatches at compile time.&lt;/p&gt;&lt;h3&gt;3. Step One: Company-Wide Event System Overhaul&lt;/h3&gt;&lt;p&gt;To solve these problems, we first established a company-wide consistent event system. We decided that just changing tools while leaving different team rules in place wouldn’t be a fundamental fix. To create consistency across teams, we built the following event naming convention:&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/903/1*gjKed2ID3b3BkIW9CZMkqg.png&quot; /&gt;&lt;figcaption&gt;Event Naming Convention&lt;/figcaption&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;strong&gt;1. User event must follow a three-level hierarchy: Service → Screen → Action (Event).&lt;/strong&gt;&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Service&lt;/strong&gt;: The top-level unit representing the business domain.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Screen&lt;/strong&gt;: Belongs to a service. Represents each screen the user sees.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Event&lt;/strong&gt;: Belongs to a screen. Represents user actions on that screen.&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;strong&gt;2. User event name must follow the format: client_{action}_{service}_{screen}_{object}&lt;/strong&gt;&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;Actions are defined in past tense.&lt;/li&gt;&lt;li&gt;Elements are separated by snake_case, and individual elements use camelCase.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In practice, we also defined separate conventions for UI elements like bottomsheets and dialogs, but I’ll keep this overview focused on the core concepts.&lt;/p&gt;&lt;p&gt;With this naming convention, you can now tell which service and screen an event belongs to just by looking at its name.&lt;/p&gt;&lt;h3&gt;4. Step Two: Event Center — User Events Management Platform&lt;/h3&gt;&lt;p&gt;After establishing a company-wide user event system, we needed a tool that would make it easy to define events following these rules. Having standards is pointless if defining and managing events remains difficult.&lt;/p&gt;&lt;p&gt;So we developed a log management system for systematically managing user events. Let me walk you through each step.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*YOQRb6ZIhkXSE895pdOQcA.png&quot; /&gt;&lt;/figure&gt;&lt;h4&gt;4.1. Service Management&lt;/h4&gt;&lt;p&gt;You can view and manage all company services — each service represents a product domain within Karrot, like Payment or Jobs. Events are organized by service.&lt;/p&gt;&lt;h4&gt;4.2. Screen Management&lt;/h4&gt;&lt;p&gt;As mentioned earlier, different teams called the same screen by different names, and documentation was scattered, making it hard to understand what events belong to each screen. To solve this, we built functionality to register and manage screens.&lt;/p&gt;&lt;p&gt;Once you register a screen, you can add the events that occur on it. Now all events for that screen are visible in one place.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*5S3_0mLzvNCKrIx0piSbkw.png&quot; /&gt;&lt;figcaption&gt;Register a screen&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*KuIHkElhvxtY6o2oPr804w.png&quot; /&gt;&lt;figcaption&gt;Screen Detail&lt;/figcaption&gt;&lt;/figure&gt;&lt;h4&gt;4.3. Defining User Events&lt;/h4&gt;&lt;p&gt;Select the screen where you want to add logging, then register and manage event schemas using a consistent log structure.&lt;/p&gt;&lt;p&gt;Throughout this process, you don’t need to know anything about Spark StructType or JSON schemas. The system automatically handles:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Applying naming conventions&lt;/li&gt;&lt;li&gt;Generating Spark StructType JSON-based schemas&lt;/li&gt;&lt;li&gt;All validation checks that used to require reviews and CI&lt;/li&gt;&lt;li&gt;BigQuery View Table creation&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Now anyone can register user event schemas with just a few clicks. Automated review processes have significantly improved time efficiency.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1022/1*grqeU1OwFzCh-ap1rHzfYA.png&quot; /&gt;&lt;figcaption&gt;Add User Event to Screen&lt;/figcaption&gt;&lt;/figure&gt;&lt;h4&gt;4.4. QA for User Events&lt;/h4&gt;&lt;p&gt;After implementing logging, developers often wonder &lt;em&gt;“is this actually being collected properly?”&lt;/em&gt; In Event Center, internal team members can query logs they generated using their own user ID.&lt;/p&gt;&lt;p&gt;Here’s how the QA process works:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Developer implements logging code and performs the action on their device.&lt;/li&gt;&lt;li&gt;In Event Center, search by your ID to view events you just triggered in near real-time, or check events from a specific time period.&lt;/li&gt;&lt;li&gt;Immediately verify whether the event was collected correctly and parameters contain expected values.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;No need to run BigQuery queries directly or check the app manually. Questions like &lt;em&gt;“is &lt;/em&gt;&lt;em&gt;item_id being captured correctly?&amp;quot;&lt;/em&gt; get instant answers.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1005/1*rKWCzy6mjQfgLIOarRCQgg.png&quot; /&gt;&lt;figcaption&gt;Event Tracking&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;5. Type-Safe Code Generation via CLI&lt;/h3&gt;&lt;p&gt;Once you define an event in Event Center, developers can auto-generate type-safe code using the CLI. With help from the Mobile team, we developed CLIs for each platform:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;iOS&lt;/strong&gt;: Generates Swift types&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Android&lt;/strong&gt;: Generates Kotlin types&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Webview&lt;/strong&gt;: Generates TypeScript interfaces&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;Webview TypeScript Code Generation Example&lt;/h4&gt;&lt;p&gt;The CLI transforms Spark StructType JSON schemas into TypeScript:&lt;/p&gt;&lt;pre&gt;// package.json&lt;br&gt;{&lt;br&gt;  &amp;quot;scripts&amp;quot;: {&lt;br&gt;    &amp;quot;codegen&amp;quot;: &amp;quot;event-center-codegen generate&amp;quot;&lt;br&gt;  }&lt;br&gt;}&lt;br&gt;&lt;br&gt;// Usage&lt;br&gt;pnpm codegen&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;Auto-generated code&lt;/strong&gt;&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/754/1*U1YmEBbtngpkqqipDR4r4A.png&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Developers simply use the generated types. If a field name is misspelled, it triggers a compile error. Logging is now safer with IDE autocomplete and type checking.&lt;/p&gt;&lt;h4&gt;Wrapping Up&lt;/h4&gt;&lt;p&gt;I’ve introduced you to Event Center, the log management system our team built to systematically manage user events. Event Center isn’t a tool born from one team’s idea —it’s the result of collaboration across multiple teams and roles. We shared our pain points and aligned our perspectives throughout the design process.&lt;/p&gt;&lt;p&gt;Data analysts defined the consistent event system and helped establish standards for key screens and user events. Data engineers built reliable pipelines and ensured data quality. As a frontend engineer, I created the user-friendly admin interface and the CLI to improve developer experience.&lt;/p&gt;&lt;p&gt;When rolling out Event Center, we worked closely with the Mobile team and developers across teams. Together, we unified previously scattered event definitions into a single system and reorganized everything by screen. This migration brought our company-wide event system to production.”&lt;/p&gt;&lt;p&gt;Event Center isn’t just one team’s tool — it’s an attempt to collectively change how we handle user events at Karrot.&lt;/p&gt;&lt;p&gt;That said, challenges remain. While Event Center solved many problems, it’s not a perfect solution. As people started using it, we discovered new areas to improve.&lt;/p&gt;&lt;h4&gt;User Experience Improvements&lt;/h4&gt;&lt;ul&gt;&lt;li&gt;Adding an event still requires multiple clicks and inputs. We need faster, simpler methods.&lt;/li&gt;&lt;li&gt;Currently, only single screens can be registered, so when UI varies based on success/failure states, each state needs its own screen. This needs improvement too.&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;Taking Automation Further&lt;/h4&gt;&lt;ul&gt;&lt;li&gt;We still have limitations in pinpointing exactly which UI element triggered an event on a given screen.&lt;/li&gt;&lt;li&gt;What if we could integrate with &lt;em&gt;Figma&lt;/em&gt; to define events at the design stage and auto-generate code? We want to create an environment where designers, PMs, and engineers can discuss events while looking at the same screen.&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;&lt;strong&gt;Analytics Tool Extensions&lt;/strong&gt;&lt;/h4&gt;&lt;ul&gt;&lt;li&gt;We’re considering automatic calculation of basic metrics like CTR, PV, and AU from logged data, and UI-based experiment metric configuration. The goal is to move beyond just collecting logs to enabling immediate decision-making.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;We plan to tackle these challenges one by one as Event Center continues to evolve.&lt;/p&gt;&lt;p&gt;This year, the Data team is taking another step toward our vision — &lt;em&gt;making data-driven decisions for users every day.&lt;/em&gt; Event Center was one effort along that journey.&lt;/p&gt;&lt;p&gt;Our team is working to improve everything from how we collect logs to how we interpret and leverage data. Interested in this work? If you want to be part of building systems that turn data into better products and decisions, we’d love to chat. Check out our open positions below:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://about.daangn.com/jobs/7507320003/&quot;&gt;Data Analytics Engineer&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://about.daangn.com/jobs/4300801003/&quot;&gt;Software Engineer&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=387c58b10530&quot; width=&quot;1&quot; height=&quot;1&quot; alt=&quot;&quot;&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&quot;https://medium.com/daangn/building-event-center-karrots-user-event-management-platform-387c58b10530&quot;&gt;Building Event Center: Karrot’s User Event Management Platform&lt;/a&gt; was originally published in &lt;a href=&quot;https://medium.com/daangn&quot;&gt;당근 테크 블로그&lt;/a&gt; on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</content:encoded>
    </item>
    <item>
      <title>당근의 사용자 행동 로그 관리 플랫폼: 이벤트센터 개발기</title>
      <link>https://medium.com/daangn/%EB%8B%B9%EA%B7%BC%EC%9D%98-%EC%82%AC%EC%9A%A9%EC%9E%90-%ED%96%89%EB%8F%99-%EB%A1%9C%EA%B7%B8-%EA%B4%80%EB%A6%AC-%ED%94%8C%EB%9E%AB%ED%8F%BC-%EC%9D%B4%EB%B2%A4%ED%8A%B8%EC%84%BC%ED%84%B0-%EA%B0%9C%EB%B0%9C%EA%B8%B0-e3c240945882?source=rss----4505f82a2dbd---4</link>
      <guid>https://medium.com/daangn/%EB%8B%B9%EA%B7%BC%EC%9D%98-%EC%82%AC%EC%9A%A9%EC%9E%90-%ED%96%89%EB%8F%99-%EB%A1%9C%EA%B7%B8-%EA%B4%80%EB%A6%AC-%ED%94%8C%EB%9E%AB%ED%8F%BC-%EC%9D%B4%EB%B2%A4%ED%8A%B8%EC%84%BC%ED%84%B0-%EA%B0%9C%EB%B0%9C%EA%B8%B0-e3c240945882?source=rss----4505f82a2dbd---4</guid>
      <pubDate>Thu, 08 Jan 2026 09:36:40 GMT</pubDate>
      <content:encoded>&lt;h4&gt;코드로 관리하던 사용자 행동 로그를 플랫폼으로 만든 이유&lt;/h4&gt;&lt;p&gt;안녕하세요. 당근 데이터가치화팀에서 프론트엔드 엔지니어로 일하고 있는 &lt;em&gt;미카(Mika.kang)&lt;/em&gt;예요.&lt;/p&gt;&lt;p&gt;당근에서는 수많은 사용자 행동 로그가 매일 쌓이고 있어요. 이 로그들은 실험을 설계하고, 제품을 개선하고, 의사결정을 내리는 데 중요한 역할을 해요. 하지만 로그가 많아질수록 관리 방식의 중요성도 함께 커졌어요.&lt;/p&gt;&lt;p&gt;그래서 전사 로그 체계를 다시 정리했고, 사용자 행동 로그를 관리하는 시스템, &lt;em&gt;이벤트센터&lt;/em&gt;를 새로 만들었어요. Git과 코드로 관리하던 방식을 UI 중심으로 바꾸고, 사람이 직접 처리하던 작업은 최대한 자동화했어요. 사용자 행동 로그를 더 일관되고 안전하게 다루기 위해서요.&lt;/p&gt;&lt;p&gt;이 글에서는 전사 로그 체계를 개편하게 된 배경부터, 이벤트센터를 어떻게 설계하고 구현했는지까지 과정을 이야기해보려고 해요. 로그가 점점 늘어나면서 관리가 부담이 되기 시작한 분들께 이 글이 작은 힌트가 되기를 바라요!&lt;/p&gt;&lt;h3&gt;1. 사용자 행동 로그 — 데이터 기반 의사결정의 시작점&lt;/h3&gt;&lt;p&gt;매일 수백만 명의 사용자가 당근 앱을 사용하며 각자 다양한 행동 데이터를 남겨요. &lt;em&gt;“중고거래 게시글을 봤다”, “채팅 버튼을 눌렀다”, “관심 목록에 추가했다”&lt;/em&gt; 같은 작은 행동 하나하나가 모여 데이터가 되죠.&lt;/p&gt;&lt;p&gt;이 데이터는 사용자 경험을 개선하고, 제품 의사결정의 근거가 돼요. 예를 들어 &lt;em&gt;“게시글 상세 화면에서 채팅 버튼을 누르는 비율이 낮다면, 버튼 위치를 바꿔볼까?”&lt;/em&gt; 같은 결정을 내릴 수 있게 되어요. 감이 아니라 데이터를 기반으로 판단할 수 있게 되는 거죠.&lt;/p&gt;&lt;p&gt;하지만 이러한 사용자 행동 데이터를 수집하고 분석하는 과정은 생각보다 단순하지 않았어요. 여러 가지 어려움이 많았죠. 로그의 양이 늘어날수록 점차 운영 방식의 한계를 마주하게 되었어요.&lt;/p&gt;&lt;p&gt;이 어려움을 더 자세히 설명하기 전에, 먼저 당근에서 사용자 행동 로그가 어떤 방식으로 수집되는지부터 간단하게 짚어보려고 해요.&lt;/p&gt;&lt;h4&gt;1.1. 사용자 행동 로그 수집 방식&lt;/h4&gt;&lt;p&gt;당근이 성장하면서 수집하는 데이터의 종류와 양도 빠르게 늘어났어요. 기존 방식으로는 확장성과 사용성을 함께 챙기기 어려웠고, 그래서 자체 사용자 행동 로그 시스템을 구축해서 사용하고 있어요.&lt;/p&gt;&lt;p&gt;아래는 사용자 행동 로그가 발생한 뒤, 분석 가능한 데이터로 저장되기까지의 흐름을 간단히 정리한 그림이에요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*ocL8AWQ8skqvoPD6Fhbfjg.png&quot; /&gt;&lt;figcaption&gt;사용자 행동 로그 수집 파이프라인 (간소화 버전)&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;전체 과정은 크게 이벤트 수집, 검증과 처리, 저장 단계로 나뉘어요.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;이벤트 수집&lt;/strong&gt; : 당근 모바일 앱에서 특정 사용자 행동이 발생하면, SDK로 특정 조건이나 주기에 따라 데이터가치화팀이 관리하는 이벤트 서버로 전송돼요.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;1차 검증 및 전달&lt;/strong&gt; : 이벤트 서버는 기본적인 유효성 검사를 수행한 후, GCP Pub/Sub으로 이벤트를 전달해요.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;스트리밍 처리 및 정제&lt;/strong&gt; : GCP Dataflow에서 실시간 스트리밍으로 주요 필드의 유효성을 검증하고, 짧은 시간 내 중복 제거(short window deduplication) 및 데이터 변환(flatten)을 진행해요.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;저장 및 에러 처리: &lt;/strong&gt;처리 과정 전반에서 데이터는 GCS와 BigQuery에 저장돼요. 유효하지 않은 이벤트는 DLQ(Dead Letter Queue) Pub/Sub으로 보내지고, 별도의 BigQuery 테이블에 저장돼요. 이후 원인 분석이나 개선에 활용할 수 있어요.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;배치 중복 제거&lt;/strong&gt; : 이후 배치 작업으로 한 번 더 &lt;em&gt;시간 윈도우 기반 중복 제거&lt;/em&gt;를 진행해요. 데이터 정확도를 높이기 위한 단계예요.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;최종 데이터 적재&lt;/strong&gt; : 구성원들이 바로 사용할 수 있는 형태로 데이터 적재가 완료돼요. 공통 필드는 flatten된 형태로 저장돼 바로 조회할 수 있고, 이벤트별로 다른 파라미터는 JSON 형태로 저장해 유연성을 확보했어요.&lt;/li&gt;&lt;/ol&gt;&lt;h4&gt;1.2. 사용자 행동 이벤트 스키마&lt;/h4&gt;&lt;p&gt;이벤트 파이프라인을 통해 데이터가 BigQuery에 적재되면, 이제 이 데이터를 어떻게 해석할지가 중요해지는데요. 단순히 로그가 쌓이는 것만으로는 분석이 어렵기 때문이에요.&lt;/p&gt;&lt;p&gt;그래서 이때 추가로 필요한 게 &lt;em&gt;사용자 행동 이벤트 스키마&lt;/em&gt;예요. 이벤트 스키마는 각 로그가 어떤 의미를 가지는지, 어떤 필드로 구성되어 있는지를 정의해요. 어떤 이벤트인지, 어떤 파라미터가 들어오는지, 값은 어떤 형태인지까지 함께 정리돼 있어요.&lt;/p&gt;&lt;p&gt;이벤트 스키마가 필요한 이유를 아래에서 더 자세히 알려드릴게요.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;이벤트의 관리 주체를 알 수 있어요.&lt;br&gt;&lt;/strong&gt;전사에서 수백 개의 이벤트가 발생하다 보니, 문제가 생겼을 때 누구에게 물어봐야 하는지 모르는 경우가 생겨요. 이 이벤트를 누가 만들었고, 누가 책임지고 관리하는지 알 수 없으면 운영이 어려워져요. 그래서 각 이벤트마다 오너를 지정해요.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;도메인별로 이벤트를 분류할 수 있어요.&lt;br&gt;&lt;/strong&gt;서비스가 커지면서 이벤트를 체계적으로 분류할 필요도 생겼어요. 전사 단위 분석을 하다 보면 중고거래와 관련된 이벤트만 모아서 보고 싶은 경우도 있어요. 이런 요구를 충족하기 위해 각 이벤트마다 도메인을 함께 정의해요.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;이벤트별로 커스텀한 파라미터를 정의할 수 있어요.&lt;br&gt;&lt;/strong&gt;모든 이벤트에는 event_name, timestamp, event_id 같은 공통 필드가 있어요. 동시에각 이벤트마다 고유한 정보(커스텀 파라미터)도 존재하죠. 이런 커스텀 파라미터가 어떤 의미를 가지는지, 타입은 무엇인지 정의돼 있지 않으면 쿼리할 때 혼란이 생겨요. 이 값이 문자열인지 숫자인지, 필드 이름이 정확히 무엇인지 매번 다시 확인해야 하거든요.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;이벤트 스키마를 추가하면 BigQuery에 이벤트별 테이블이 자동으로 생성돼요. 기존의 JSON 형태로 저장되던 커스텀 파라미터도 일반 컬럼처럼 펼쳐져서, SQL 쿼리로 바로 접근할 수 있어요.&lt;/p&gt;&lt;pre&gt;SELECT &lt;br&gt;  event_id,     -- 공통 필드&lt;br&gt;  event_name,   -- 공통 필드&lt;br&gt;  user_id,      -- 공통 필드&lt;br&gt;  banner_id     -- 커스텀 파라미터&lt;br&gt;  banner_title  -- 커스텀 파라미터&lt;br&gt;FROM `이벤트 데이터셋.이벤트명`&lt;/pre&gt;&lt;p&gt;JSON에서 값을 꺼내는 복잡한 쿼리 없이, 커스텀 파라미터도 banner_id처럼 바로 조회할 수 있어서 분석이 훨씬 간편해져요.&lt;/p&gt;&lt;h3&gt;2. 이전의 사용자 행동 이벤트 스키마 정의 방식 — Git 기반 코드로 관리&lt;/h3&gt;&lt;p&gt;사용자 행동 로그 스키마는 수집된 사용자 행동 데이터를 분석할 수 있도록 도와주는 중요한 시스템이에요. 주로 공통으로 로깅되는 필드외에 팀에서 사용하는 커스텀한 필드 및 오너십 관리를 위해서 정의되고 있어요.&lt;/p&gt;&lt;p&gt;이러한 스키마는 데이터 분석을 원하는 누구나 일관된 방식으로 쉽고 빠르게 관리할 수 있어야해요. 하지만 당시 당근에서는 &lt;strong&gt;이 스키마가 Git 기반 코드로 관리되고 있었어요. 이벤트 이름에 대한 컨벤션이 통일되어 있지 않다 보니, 운영하면서 여러 가지 불편함이 생기기 시작했어요.&lt;/strong&gt;&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*rRLWGfae-s6JZirMdKzYRQ.png&quot; /&gt;&lt;/figure&gt;&lt;h4&gt;2.1 문제인식&lt;/h4&gt;&lt;p&gt;스키마가 코드로 관리되고, 이벤트 이름도 통일돼 있지 않다 보니 운영 과정에서 여러 가지 어려움이 생겼어요. 그중 가장 크게 느낀 건 스키마를 한 번 더 추가하는 데 드는 비용이 너무 컸다는 점이었어요.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;문제 1: 코드 기반 스키마 관리의 복잡함&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;스키마를 생성하기 위해서는 아래와 같은 복잡한 과정을 거쳐야 했어요.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;데이터 파이프라인 코드에 json 스키마 파일 작성 (코드 지식 필요)&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;유효성 검사 및 포매팅 CI 통과&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;PR 생성&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;데이터가치화팀의 리뷰 ↔ 수정 반복&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;PR 머지하면 BigQuery 조회 가능한 스키마 자동 생성&lt;/strong&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;1번에서 작성하는 스키마 파일은 Spark의 StructType JSON 형태로 직접 작성해야했어요.&lt;/p&gt;&lt;pre&gt;// client_{action_type}_{service}_{object}.json&lt;br&gt;{&lt;br&gt;  &amp;quot;type&amp;quot;: &amp;quot;struct&amp;quot;,&lt;br&gt;  &amp;quot;metadata&amp;quot;: {&lt;br&gt;    &amp;quot;description&amp;quot;: &amp;quot;아이템 클릭 이벤트&amp;quot;,&lt;br&gt;    &amp;quot;owners&amp;quot;: [&lt;br&gt;      &amp;quot;data@daangn.com&amp;quot;&lt;br&gt;    ],&lt;br&gt;    &amp;quot;domains&amp;quot;: [&lt;br&gt;      &amp;quot;sample&amp;quot;&lt;br&gt;    ]&lt;br&gt;  },&lt;br&gt;  &amp;quot;fields&amp;quot;: [&lt;br&gt;    {&lt;br&gt;      &amp;quot;name&amp;quot;: &amp;quot;id&amp;quot;,&lt;br&gt;      &amp;quot;type&amp;quot;: &amp;quot;string&amp;quot;,&lt;br&gt;      &amp;quot;nullable&amp;quot;: false,&lt;br&gt;      &amp;quot;metadata&amp;quot;: {&lt;br&gt;        &amp;quot;comment&amp;quot;: &amp;quot;이벤트 id&amp;quot;&lt;br&gt;      }&lt;br&gt;    },&lt;br&gt;    ...&lt;br&gt;  ]&lt;br&gt;}&lt;/pre&gt;&lt;p&gt;스키마는 중첩 구조를 지원하기때문에, 아래와 같이 복잡한 구조로 중첩될 수도 있어요.&lt;/p&gt;&lt;pre&gt;{&lt;br&gt;  &amp;quot;name&amp;quot;: &amp;quot;extra&amp;quot;,&lt;br&gt;  &amp;quot;type&amp;quot;: {&lt;br&gt;    &amp;quot;type&amp;quot;: &amp;quot;struct&amp;quot;,&lt;br&gt;    &amp;quot;fields&amp;quot;: [&lt;br&gt;      {&lt;br&gt;        &amp;quot;name&amp;quot;: &amp;quot;random&amp;quot;,&lt;br&gt;        &amp;quot;type&amp;quot;: {&lt;br&gt;          &amp;quot;type&amp;quot;: &amp;quot;struct&amp;quot;,&lt;br&gt;          &amp;quot;fields&amp;quot;: [&lt;br&gt;            {&lt;br&gt;              &amp;quot;name&amp;quot;: &amp;quot;parent_item_id&amp;quot;,&lt;br&gt;              &amp;quot;type&amp;quot;: &amp;quot;string&amp;quot;,&lt;br&gt;              &amp;quot;nullable&amp;quot;: true,&lt;br&gt;              &amp;quot;metadata&amp;quot;: {&lt;br&gt;                &amp;quot;comment&amp;quot;: &amp;quot;부모 item  id&amp;quot;&lt;br&gt;              }&lt;br&gt;            }&lt;br&gt;            ...&lt;br&gt;          ]&lt;br&gt;        }&lt;br&gt;      }&lt;br&gt;    ]&lt;br&gt;  }&lt;br&gt;}&lt;/pre&gt;&lt;p&gt;이 중 문제는 1번 단계의 진입장벽이 높았다는 거예요. 단순한 필드 하나를 추가하려고 해도 metadata, nullable, type 같은 속성을 전부 채워야 했고, 오타나 형식 실수도 자주 발생했어요.&lt;/p&gt;&lt;p&gt;게다가 스키마는 중첩 구조를 지원하다 보니, 실제로는 더 복잡한 형태를 자주 다뤄야 했어요. 예를 들어아래처럼 struct 안에 struct가 여러 번 중첩되기도 해요.&lt;/p&gt;&lt;p&gt;예를 들어, struct 안에 struct, 그 안에 또 fields … 하나라도 괄호나 쉼표를 빠뜨리면 CI가 실패했어요.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;문제 2: 긴 리뷰 사이클&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;기존에는 다른 팀 구성원들이 JSON을 작성하고 PR을 올리려면, 저희 데이터가치화팀의 리뷰를 받아야 했어요. 컨벤션 위반이나 타입 실수, 설명이 부족한 경우 등 여러 이유로 수정 요청이 오곤 했고, 그때마다 다시 코드를 고치고, 다시 리뷰를 기다리고… 시간이 많이 소요됐죠.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;문제 3: 일관성 없는 이벤트 네이밍 체계&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;이벤트 이름에 대한 컨벤션이 강제되지 않았다 보니, 다양한 형식으로 이벤트 이름이 만들어졌어요.&lt;/p&gt;&lt;p&gt;예시 1) 같은 서비스, 다른 표기&lt;/p&gt;&lt;ul&gt;&lt;li&gt;home_feed vs homeFeed (snake_case vs camelCase)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;예시 2) 같은 액션, 다른 표현&lt;/p&gt;&lt;ul&gt;&lt;li&gt;show_article vs shown_article&lt;/li&gt;&lt;li&gt;view vs shown&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;문제 4: 화면 이름의 혼란 및 관리의 어려움&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;같은 화면을 두고도 팀마다 부르는 이름도 달랐어요. 어떤 팀은 기능을 기준으로, 어떤 팀은 기획 문서 기준으로 화면을 부르다 보니, 기준이 자연스럽게 흐려진 거예요. 화면 정보도 팀별 노션이나 별도 문서에 나뉘어 관리되고 있었고요.&lt;/p&gt;&lt;p&gt;이런 구조는 이벤트 스키마를 직접 다루는 엔지니어뿐 아니라, 로그를 활용하는 여러 직군에도 영향을 주고 있었어요. 실제로 각 직군에서 느끼는 어려움을 아래에 간단히 정리해봤어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/878/1*cRo2x9D9hdGNfyteYnUPUA.png&quot; /&gt;&lt;/figure&gt;&lt;p&gt;이처럼 스키마가 코드로 관리되고, 이벤트 체계가 통일되지 않은 구조는 특정 팀의 불편을 넘어, 로그를 활용하는 전체 흐름을 느리게 만들고 있었어요.&lt;/p&gt;&lt;h4&gt;2.2 해결방안 도출&lt;/h4&gt;&lt;p&gt;사내 구성원들이 이벤트를 다루며 겪는 어려움을 해결하기 위해, 데이터가치화팀은 몇 가지 방향을 먼저 설정했어요.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 전사 공통의 일관된 사용자 행동 로그 체계를 만들어요.&lt;br&gt;&lt;/strong&gt;팀마다 다르게 쓰던 이벤트 이름을 각 팀의 개별 언어가 아니라 전사 공통의 언어로 통일하기로 했어요. 로그를 전사 자산으로 활용하려면 먼저 같은 기준으로 이해할 수 있는 체계가 필요했다고 판단했기 때문이에요. 그래서 팀마다 다르게 쓰이던 이벤트 이름을 하나의 기준으로 정리했어요. 예를 들면&lt;em&gt; “중고거래 게시글 상세 화면의 채팅 버튼 클릭”&lt;/em&gt;이라고 말하면, 이벤트 이름만 보고도 모두가 특정 이벤트를 떠올리는 거죠. 커뮤니케이션 비용이 줄어들고, 데이터를 찾는 시간도 단축돼요.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 코드대신 UI로 사용자 행동 스키마를 정의할 수 있는 어드민 플랫폼을 만들어요.&lt;br&gt;&lt;/strong&gt;스키마로 코드를 관리하는 방식은 일부 팀, 직군에만 맡기는 방식이라 한계가 있다고 판단했어요. 그래서 사용자 스키마를 UI에서 모두 직접 정의할 수 있는 어드민 플랫폼을 만들기로 했어요. 시스템이 이벤트 이름 및 형식을 자동으로 컨벤션에 맞게 생성하는 방식이에요.. 체계가 자동으로 적용되어서 일관성이 유지돼요.&lt;/p&gt;&lt;p&gt;어드민에 화면을 등록하면, 해당 화면에서 발생하는 모든 이벤트를 한곳에서 확인할 수 있어요. &lt;em&gt;“중고거래 게시글 상세 화면에 어떤 이벤트가 있지?”&lt;/em&gt; 궁금할 때 팀과 직군에 관계 없이 누구나 바로 조회할 수 있어요.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 사용자 행동 스키마를 각 프로그래밍 언어의 타입으로 안전하게 변환하는 CLI를 만들어요.&lt;br&gt;&lt;/strong&gt;한 곳(이벤트센터)에서 스키마를 정의하면, CLI가 각 플랫폼에 맞는 코드를 자동으로 생성해줘요. 덕분에 컴파일 타임에 자주 생기는 필드 누락이나 타입 실수 같은 오류를 사전에방지할 수 있어요.&lt;/p&gt;&lt;h3&gt;3. 해결의 시작: 전사 이벤트 체계 개편 — 모두가 같은 규칙으로!&lt;/h3&gt;&lt;p&gt;문제를 해결하기 위해 먼저 전사 공통의 일관된 이벤트 체계를 정립했어요. 팀마다 다른 규칙을 그대로 둔 채 도구만 바꾸는 건 근본적인 해결이 아니라고 판단했거든요. 모두가 같은 규칙으로 말할 수 있도록 아래와 같이 이벤트 네이밍 컨벤션을 구축하기로 했죠.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*qzOluscoMhCWP7UGoMtxTw.png&quot; /&gt;&lt;figcaption&gt;이벤트 네이밍 컨벤션&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;1. 사용자 행동 로그는 서비스 — 스크린 — 액션(이벤트) 3단계의 계층 구조를 따라야 해요.&lt;/strong&gt;&lt;br&gt;- &lt;strong&gt;서비스(Service)&lt;/strong&gt;: 최상위 단위예요. 비즈니스 도메인을 의미해요.&lt;br&gt;- &lt;strong&gt;스크린(Screen)&lt;/strong&gt;: 서비스에 종속돼요. 사용자가 보는 각각의 화면을 의미해요.&lt;br&gt;- &lt;strong&gt;이벤트(Event)&lt;/strong&gt;: 스크린에 종속돼요. 해당 화면에서 발생하는 사용자 행동을 의미해요.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 사용자 행동 로그 이름은 client_{action}_{service}_{screen}_{object} 형태를 따라야해요.&lt;br&gt;- &lt;/strong&gt;action은 과거형으로 정의해요.&lt;br&gt;- 각각의 요소는 snake_case로 구분하고, 하나의 요소는 camelCase로 정의해요.&lt;/p&gt;&lt;p&gt;실제로는 bottomsheet, dialog 같은 UI 요소에 대한 컨벤션도 별도로 정의되어 있었어요. 다만 이 글에서는 전사 이벤트 체계의 핵심 개념만 간략하게 소개할게요.&lt;/p&gt;&lt;p&gt;이 기준을 적용한 뒤로는 이벤트 이름만 봐도 어느 서비스의 어떤 화면에서 발생한 이벤트인지 바로 파악할 수 있게 되었어요.&lt;/p&gt;&lt;h3&gt;4. 해결책: 사용자 행동 로그 관리 플랫폼 ‘이벤트센터’ — 코드 대신 UI로, 간단하게&lt;/h3&gt;&lt;p&gt;전사 공통의 사용자 행동 로그를 체계한 정리한 다음에는 이 체계를 쉽게 사용하면서 이벤트를 정의할 수 있는 도구가 필요하다고 판단했어요. 규칙은 존재하는데, 정의하고 관리하는 과정이 여전히 어렵다면 문제는 근본적으로 해결되지 않으니까요.&lt;/p&gt;&lt;p&gt;그래서 아래와 같은 플로우로 사용자 행동 로그를 체계적으로 관리할 수 있는 로그 관리 시스템을 개발했어요. 지금부터 각 단계를 더 자세히 하나씩 차근차근 설명해 볼게요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*dGoP7sjMhhLw1LLTUulHbA.png&quot; /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;4.1 서비스 관리&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;전사의 모든 서비스를 조회하고 관리할 수 있어요. 중고거래, 동네생활, 당근페이 등 서비스별로 분류해서 이벤트를 볼 수 있어요.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4.2 스크린 관리&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;앞서 언급한 것처럼, 같은 화면을 팀마다 다르게 부르거나 문서가 흩어져 있어서 특정 화면의 이벤트를 파악하기 어려웠어요. 이를 해결하기 위해 스크린을 등록하고 관리하는 기능을 만들었어요.&lt;/p&gt;&lt;p&gt;스크린을 등록하면, 해당 스크린에서 발생하는 이벤트를 추가할 수 있어요. 한 화면에 어떤 이벤트들이 있는지 한곳에서 확인할 수 있게 되었어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*BPEr0CyHbchg9hju9PopBw.png&quot; /&gt;&lt;figcaption&gt;스크린 등록&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*vgmmhuAN5FU-1vqEIeyeSg.png&quot; /&gt;&lt;figcaption&gt;스크린 상세 조회&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;4.3 사용자 행동 로그 정의&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;사용자 행동 로그를 심을 화면을 선택하고, 일관된 로그 체계로 이벤트 스키마를 등록하고 관리할 수 있어요.&lt;/p&gt;&lt;p&gt;이 과정에서 Spark StructType이나 JSON 스키마를 알 필요가 전혀 없어요. 시스템이 자동으로 아래 항목을 처리해요.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;네이밍 컨벤션 적용&lt;/li&gt;&lt;li&gt;Spark StructType JSON 기반의 스키마 생성&lt;/li&gt;&lt;li&gt;리뷰 및 CI로 확인하던 유효성 검사가 모두 내재화&lt;/li&gt;&lt;li&gt;BigQuery View Table 생성&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;누구나 손쉽게 몇 번의 클릭으로 사용자 행동 로그 스키마를 등록할 수 있게 되었어요. 또한 리뷰 프로세스가 자동화되어서 시간 효율을 높였어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*d64wk3I8fQMjrWj3BbAvbA.png&quot; /&gt;&lt;figcaption&gt;스크린에 이벤트 추가하기&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;4.4 사용자 행동 로그 QA&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;개발자가 로깅을 심고 나서 &lt;em&gt;“이게 잘 쌓이고 있나?”&lt;/em&gt; 궁금할 때가 있잖아요. 이벤트센터에서는 내부 구성원이 본인의 ID로 직접 발생시킨 로그를 조회할 수 있어요.&lt;/p&gt;&lt;p&gt;QA 과정은 이렇게 진행돼요.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;개발자가 로깅 코드를 심고, 본인 기기에서 해당 행동을 수행해요.&lt;/li&gt;&lt;li&gt;이벤트센터에서 본인 ID로 검색하면, 방금 발생한 이벤트를 준실시간으로 조회하거나, 특정 기간에 발생한 이벤트를 확인할 수 있어요.&lt;/li&gt;&lt;li&gt;이벤트가 제대로 수집되었는지, 파라미터 값이 의도한 대로 들어갔는지 바로 확인할 수 있어요.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;BigQuery에서 직접 쿼리를 돌리거나 앱에 직접 접속하지않아도, “item_id” 가 제대로 들어가는가?” 같은 질문에 즉시 답할 수 있어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*uQjOcfi3_R6btOyOhqoHxg.png&quot; /&gt;&lt;figcaption&gt;이벤트 트래킹&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;5. CLI로 타입 안전한 코드 생성&lt;/h3&gt;&lt;p&gt;사용자 행동 로그 관리 플랫폼인 이벤트센터에서 이벤트를 정의하면, 개발자는 CLI로 타입 안전한 코드를 자동 생성할 수 있어요. 모바일실의 도움으로 네이티브, 웹뷰 각 플랫폼에 맞는 CLI가 개발되었어요.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;iOS: Swift 타입 생성&lt;/li&gt;&lt;li&gt;Android: Kotlin 타입 생성&lt;/li&gt;&lt;li&gt;Webview: TypeScript 인터페이스 생성&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Webview의 Typescript 코드 생성 예시&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;CLI는 Spark StructType JSON 스키마를 TypeScript로 변환해서 코드를 생성해요.&lt;/p&gt;&lt;pre&gt;# package.json에 명령어 정의&lt;br&gt;&amp;quot;scripts&amp;quot;: {&lt;br&gt;  &amp;quot;codegen&amp;quot;: &amp;quot;event-center-codegen generate&amp;quot;,&lt;br&gt;}&lt;br&gt;&lt;br&gt;# 명령어 사용&lt;br&gt;pnpm codegen&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;자동 생성된 코드&lt;/strong&gt;&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*mbJle36Do042mFyD0dUKnA.png&quot; /&gt;&lt;/figure&gt;&lt;p&gt;개발자는 생성된 타입을 그대로 사용하기만 하면 돼요. 필드명을 잘못 쓰면 컴파일 에러가 나요. IDE의 자동완성과 타입 체크를 받으며 안전하게 로깅할 수 있게 되었어요.&lt;/p&gt;&lt;h4&gt;마무리&lt;/h4&gt;&lt;p&gt;지금까지 사용자 행동 로그를 체계적으로 관리하기 위해 저희 팀에서 직접 구축한 로그 관리 시스템 이벤트센터를 소개해봤어요. 이벤트센터는 한 팀의 아이디어로 만들어진 도구라기보다, 여러 팀과 직군의 고민이 모여 완성된 결과물이에요. 각자가 겪고 있던 페인 포인트를 공유하고, 서로의 관점을 맞춰가며 설계했어요.&lt;/p&gt;&lt;p&gt;데이터 분석가는 일관된 이벤트 체계를 정의하고, 주요 화면과 사용자 행동 로그의 기준을 함께 정리했어요. 데이터 엔지니어는 안정적인 파이프라인을 구축하고 데이터 품질을 책임졌어요. 프론트엔드 엔지니어인 저는 사용하기 쉬운 어드민과 개발자 경험을 개선하는 CLI를 만들었고요.&lt;/p&gt;&lt;p&gt;이벤트센터를 실제로 전사에 적용하는 과정에서는 모바일실과 각 팀의 웹뷰 담당자들과 긴밀하게 협업했어요. 기존에 각기 다른 기준으로 정의돼 있던 이벤트를 하나의 체계로 맞추고, 화면 단위로 이벤트를 다시 정리하는 작업을 함께 진행했어요. 이 마이그레이션 과정 덕분에 전사 이벤트 체계를 실제 서비스에 안정적으로 안착시킬 수 있었어요.&lt;/p&gt;&lt;p&gt;이벤트센터는 특정 팀의 도구라기보다, 당근 안에서 사용자 행동 로그를 다루는 방식을 함께 바꿔보려는 시도의 결과라고 생각해요.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;한편으로 앞으로의 도전도 여전히 남아있어요.&lt;/strong&gt; 이벤트센터가 많은 문제를 해결해주긴 했지만, 완벽한 솔루션은 아니에요. 실제로 사용해보면서 새로운 과제들도 분명히 보이기 시작했어요.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;사용성 개선&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;이벤트를 추가하기 위해 여러 번의 클릭과 입력이 필요해요. 더 빠르고 간편한 방법이 필요해요.&lt;/li&gt;&lt;li&gt;또 현재는 단일 스크린만 등록할 수 있어서, 같은 화면이라도 성공과 실패에 따라 UI가 달라지는 경우에는 모든 상태를 개별 스크린으로 관리해야 해요. 이 부분도 개선이 필요한 지점이에요.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;자동화 확대&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;특정 화면에서 이벤트가 발생했을 때, 화면의 어떤 요소에서 발생했는지를 정확히 특정하는 데에는 아직 한계가 있어요.&lt;/li&gt;&lt;li&gt;Figma와 연동해 디자인 단계에서부터 이벤트를 정의하고, 코드까지 자동으로 생성할 수 있다면 어떨까요. 디자이너, PM, 엔지니어가 같은 화면을 보며 이벤트를 논의할 수 있는 환경을 만들고 싶어요.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;분석 도구 확장&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;로깅된 데이터를 기반으로 CTR, PV, AU 같은 기본 지표를 자동으로 계산하거나, UI 기반으로 실험 지표를 설정하는 기능도 고민하고 있어요. 로그를 쌓는 데서 그치지 않고, 바로 의사결정으로 이어질 수 있도록요.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;이런 과제들을 하나씩 해결해 나가면서, 이벤트센터도 계속해서 발전시켜 나갈 예정이에요.&lt;/p&gt;&lt;p&gt;올해 데이터가치화팀은 이런 목표를 향해 한 걸음 더 나아가고 있어요. 매일 데이터를 통해 사용자를 위한 의사결정을 한다는 비전을 실제로 만들어가기 위해서예요. 이벤트센터도 그 과정에서 나온 하나의 시도였고요.&lt;/p&gt;&lt;p&gt;지금 저희 팀에서는 로그를 쌓는 방식부터, 데이터를 해석하고 활용하는 구조까지 함께 고민하고 있어요. 이 방향에 공감하고, 데이터로 제품과 조직의 의사결정을 바꾸는 일을 직접 만들어보고 싶은 분을 기다리고 있어요. 관심이 생기셨다면 아래 채용 공고를 확인해 보세요.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://about.daangn.com/jobs/7507320003/&quot;&gt;Data Analytics Engineer 채용 공고&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://about.daangn.com/jobs/4300801003/&quot;&gt;Software Engineer, Data 채용 공고&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=e3c240945882&quot; width=&quot;1&quot; height=&quot;1&quot; alt=&quot;&quot;&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&quot;https://medium.com/daangn/%EB%8B%B9%EA%B7%BC%EC%9D%98-%EC%82%AC%EC%9A%A9%EC%9E%90-%ED%96%89%EB%8F%99-%EB%A1%9C%EA%B7%B8-%EA%B4%80%EB%A6%AC-%ED%94%8C%EB%9E%AB%ED%8F%BC-%EC%9D%B4%EB%B2%A4%ED%8A%B8%EC%84%BC%ED%84%B0-%EA%B0%9C%EB%B0%9C%EA%B8%B0-e3c240945882&quot;&gt;당근의 사용자 행동 로그 관리 플랫폼: 이벤트센터 개발기&lt;/a&gt; was originally published in &lt;a href=&quot;https://medium.com/daangn&quot;&gt;당근 테크 블로그&lt;/a&gt; on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</content:encoded>
    </item>
    <item>
      <title>Standardizing User Activation: How We Built a Shared Data Layer at Karrot</title>
      <link>https://medium.com/daangn/standardizing-user-activation-how-we-built-a-shared-data-layer-at-karrot-342ed895508f?source=rss----4505f82a2dbd---4</link>
      <guid>https://medium.com/daangn/standardizing-user-activation-how-we-built-a-shared-data-layer-at-karrot-342ed895508f?source=rss----4505f82a2dbd---4</guid>
      <pubDate>Fri, 02 Jan 2026 09:42:38 GMT</pubDate>
      <content:encoded>&lt;p&gt;Hello, I’m Pepper, a Data Analytics Engineer on the Data Team at Karrot.&lt;/p&gt;&lt;p&gt;Our team&amp;#39;s vision is to &amp;quot;make user-focused decisions through data every day.&amp;quot; So we don&amp;#39;t just focus on reliably collecting massive amounts of data — we also work on transforming it into trustworthy, easy-to-use formats.&lt;/p&gt;&lt;p&gt;In this post, I&amp;#39;d like to share how we moved away from manually calculating Activation analysis with ad hoc queries and elevated it to a shared data layer used across the organization.&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;Background&lt;/strong&gt;&lt;/h3&gt;&lt;h4&gt;The Limits of Active User Metrics&lt;/h4&gt;&lt;p&gt;Like many services, Active Users (DAU, WAU, MAU) are essential metrics at Karrot. But the number of Active Users only shows &amp;quot;what happened&amp;quot; — it doesn&amp;#39;t directly explain &amp;quot;why it happened.&amp;quot; For example, you can see that &amp;quot;MAU increased by 10% this month,&amp;quot; but it&amp;#39;s hard to answer questions such as why Active Users changed or what we should do to increase them further.&lt;/p&gt;&lt;p&gt;To answer these questions, we need a &lt;strong&gt;perspective that doesn&amp;#39;t treat Active Users as a single number but breaks them down into components with distinct characteristics&lt;/strong&gt;. That&amp;#39;s precisely what User Activation does.&lt;/p&gt;&lt;h4&gt;&lt;strong&gt;User Activation: Activity States and State Transitions&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;User Activation is a framework that goes beyond simply classifying users as active or inactive. It examines users’ current &lt;strong&gt;activity state &lt;/strong&gt;and how they transition between &lt;strong&gt;states &lt;/strong&gt;over time.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Activity states&lt;/strong&gt; indicate a user&amp;#39;s state at a specific point in time. For example, states like New, Retained, Reactivated, and Inactive.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;State transitions &lt;/strong&gt;represent how users move between activity states over time. For example, transitions like New → Retained, Retained → Inactive, or Reactivated → Inactive.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Activity states&lt;/strong&gt; alone can tell you &amp;quot;how many users are in each state right now,&amp;quot; but they can&amp;#39;t reveal &amp;quot;where they came from&amp;quot; or &amp;quot;what paths lead to churn.&amp;quot; By looking at &lt;strong&gt;state transitions&lt;/strong&gt; together, you can understand the paths users take. Segmenting users by these transition patterns enables tailored interpretations and actions across activity levels.&lt;/p&gt;&lt;p&gt;For example, when the number of Active Users increases, you can use activity states to decompose and explain whether the growth came from new user acquisition or returning existing users. If retention rate drops, you can use state transitions to pinpoint which specific segment is churning more, rather than just concluding &amp;quot;retention rate got worse.&amp;quot;&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;Goals&lt;/strong&gt;&lt;/h3&gt;&lt;h4&gt;&lt;strong&gt;Why We Needed a Common Layer&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;To analyze user behavior through the lens of User Activation, you need data that already includes each user&amp;#39;s activity state and how that state changes over time. The challenge was that when each team defined and maintained this logic independently, it was difficult to maintain reliable data and a stable pipeline. Team-created data often lacked context about who created it, when, and with what criteria — making it hard to understand or verify results over time. Operational issues, such as failed scheduled queries or reprocessing, sometimes broke idempotency or left data without freshness guarantees. Ultimately, the data existed, but it was often difficult to use with confidence.&lt;/p&gt;&lt;p&gt;We decided to build an &lt;strong&gt;Activation Layer—a common layer that applies Activation in accordance with unified, organization-level standards&lt;/strong&gt;. Our goal was to ensure the reliability and operational stability of results while enabling multiple teams to reuse the same standards.&lt;/p&gt;&lt;blockquote&gt;&lt;strong&gt;User Activation is a framework&lt;/strong&gt; for interpreting Active User metrics through states and transitions. The &lt;strong&gt;Activation Layer is a common data layer&lt;/strong&gt; that provides per-user state and transition information needed for interpretation, following consistent standards.&lt;/blockquote&gt;&lt;h4&gt;&lt;strong&gt;What We Wanted the Activation Layer to Do&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;After deciding to build the Activation Layer as a shared common layer, our first task was defining &amp;quot;what this layer should provide.&amp;quot; By organizing the recurring questions within our company, we identified the following specific information needs:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Whether the current activity is New, Retained, or Reactivated (&lt;strong&gt;activity state&lt;/strong&gt;)&lt;/li&gt;&lt;li&gt;How the state changed from the previous period to the current period (&lt;strong&gt;state transition&lt;/strong&gt;)&lt;/li&gt;&lt;li&gt;Whether recent activity has been continuous (&lt;strong&gt;continuity&lt;/strong&gt;)&lt;/li&gt;&lt;li&gt;How long since the last activity before returning (&lt;strong&gt;return interval&lt;/strong&gt;)&lt;/li&gt;&lt;li&gt;How long since the previous active state (&lt;strong&gt;inactivity duration&lt;/strong&gt;)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;For example, if a user visited on December 10, December 11, and December 20, we should provide the above information at the daily level, as shown.&lt;/p&gt;&lt;pre&gt;user_A (daily)&lt;br&gt;- 2025–12–10 NEW&lt;br&gt;- 2025–12–11 RETAINED (prev=2025–12–10, interval=1d)&lt;br&gt;- 2025–12–20 REACTIVATED (prev=2025–12–111,11interval=9d)&lt;/pre&gt;&lt;p&gt;While we used visits as an example here, User Activation applies not only to app visits but also to core actions such as selling used items, writing community posts, or opening push notifications.&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;Three Challenges We Solved While Designing the Activation Layer&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;Now, let me walk you through how we implemented the Activation Layer. First, here&amp;#39;s an overview of the overall structure.&lt;/p&gt;&lt;h4&gt;&lt;strong&gt;Overall Structure at a Glance&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;We designed the Activation Layer to sit on top of Karrot&amp;#39;s existing DBT project data hierarchy. Instead of using raw event logs directly, we built it in the order of Base (refined) → Fact (action unit) → Activation (state/flow analysis).&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*0w14QIwG2lT219KsuSqiMw.png&quot; /&gt;&lt;figcaption&gt;&lt;em&gt;Activation Layer placed on top of DBT project hierarchy (Base/Dimension/Fact)&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;blockquote&gt;For more details about Karrot&amp;#39;s data hierarchy structure, please refer to our post &amp;quot;&lt;a href=&quot;https://medium.com/daangn/dbt%EC%99%80-airflow-%EB%8F%84%EC%9E%85%ED%95%98%EB%A9%B0-%EB%A7%88%EC%A3%BC%ED%95%9C-7%EA%B0%80%EC%A7%80-%EB%AC%B8%EC%A0%9C%EB%93%A4-61250a9904ab&quot;&gt;7 Problems We Faced While Adopting DBT and Airflow.&lt;/a&gt;&amp;quot;&lt;/blockquote&gt;&lt;p&gt;We built the Activation Layer so that three models — FirstLast, Activation, and Activation Status — work together as a set on top of a single Fact model. I&amp;#39;ll explain what each model contains, what role it plays, and how they connect later.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*vocvyTM-tK1ZT74P5dUBbQ.png&quot; /&gt;&lt;figcaption&gt;&lt;em&gt;Activation Layer structure where 3 models are sequentially connected based on a Fact model&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;While building this structure, we faced three main challenges: &lt;strong&gt;reliability, cost, and productivity&lt;/strong&gt;. Let me explain how we solved each one.&lt;/p&gt;&lt;h4&gt;&lt;strong&gt;1. Reliability: Clearly Fixing the Reference Action&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;First, if we want to run Activation as a shared layer, we need an explicit reference action. If teams interpret the criteria differently, no one can reuse the data without revalidating it each time. We prioritized &lt;strong&gt;making the reference action obvious at a glance—just by looking at the model name and definition&lt;/strong&gt;.&lt;/p&gt;&lt;p&gt;At first, we tried to map event logs 1:1 to Activation reference actions. But product teams usually log events at the UI level — button clicks, screen views — so a single event can represent different actions depending on its parameters. For example, one &amp;quot;interest button click&amp;quot; event can cover both adding and removing interest. If we used &amp;quot;interest added&amp;quot; as the reference action, we would have to keep filtering for the &amp;quot;add&amp;quot; case every time we queried it.&lt;/p&gt;&lt;p&gt;Instead of using event logs directly as reference actions, &lt;strong&gt;we should fix the reference actions themselves to be precise units.&lt;/strong&gt; Karrot uses DBT for data modeling and manages models with a conceptual distinction called Layers.&lt;/p&gt;&lt;p&gt;Among them, the Fact Layer defines user actions. It expresses meaningful action units, ranging from simple actions (e.g., &amp;quot;user sent a message&amp;quot;) to actions that require conditions and business logic (e.g., &amp;quot;user actively used the feed&amp;quot;).&lt;/p&gt;&lt;p&gt;We decided to &lt;strong&gt;define reference actions as Fact models and implement the Activation Layer to use them as inputs&lt;/strong&gt;. To make reference actions even more visible at a glance, we established a naming convention where Activation model names include the Fact model name.&lt;/p&gt;&lt;pre&gt;# Naming convention&lt;br&gt;&amp;lt;fact_name&amp;gt;_activation_&amp;lt;time_grain&amp;gt;&lt;br&gt;# fact_name: Same as Fact Layer model name (action meaning defined in Fact)&lt;br&gt;# time_grain: daily | weekly | monthly&lt;br&gt;# Examples&lt;br&gt;users_visited_app_activation_daily&lt;br&gt;users_opened_push_activation_daily&lt;br&gt;users_created_article_activation_daily&lt;/pre&gt;&lt;p&gt;As a result, Activation models now clearly indicate the reference action from the model name alone, reducing the room for interpretation to vary based on event parameters or filter conditions.&lt;/p&gt;&lt;h4&gt;&lt;strong&gt;2. Cost: Making It Sustainable&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;To calculate Activation, we need to track two timestamps per user: &lt;strong&gt;the first occurrence and the previous occurrence&lt;/strong&gt;. Even if users are active on the same day, their Activation state can differ depending on when they last acted. For example, someone who visits on December 20 may be classified as Retained or Reactivated, depending on whether they last visited on December 19 or December 11.&lt;/p&gt;&lt;p&gt;The problem is that if there&amp;#39;s no pre-calculated table for these values, you have to scan the entire Fact model to find the previous occurrence. In a service environment with large data volumes, such as Karrot, &lt;strong&gt;scan range directly impacts cost and execution time — this was the most significant cost hurdle in operating Activation.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Therefore, we introduced an intermediate table, FirstLast, to reduce compute costs. At the same time, the storage strategy for FirstLast significantly affects both daily run costs and backfill costs, so we compared three approaches.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*C7UBOrIzANz_XilFxs7bPA.png&quot; /&gt;&lt;figcaption&gt;&lt;em&gt;Three candidates considered for FirstLast model implementation&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Candidate 1 — Calculate directly from Fact each time&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;This approach doesn&amp;#39;t use an intermediate table and scans the entire history each time to get User Activation. The structure is simplest, but it requires scanning the whole Fact model history on every execution, resulting in high daily costs and increased execution time. We ruled this out due to the operational burden of repeated runs.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Candidate 2 — Keep only the latest value per user&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;This approach stores the first and last occurrence in a single record per user. The first occurrence rarely changes once it&amp;#39;s set. The most recent occurrence, however, needs daily updates. Since we only merge users who acted today, each daily run scans just one day of the Fact table. However, because it doesn&amp;#39;t store historical last occurrences separately, backfills still require scanning the entire Fact model range.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Candidate 3 — Maintain daily snapshots &lt;/strong&gt;✅&lt;/p&gt;&lt;p&gt;This approach stores each user&amp;#39;s previous occurrences as a daily snapshot. To build today&amp;#39;s snapshot, we start from yesterday&amp;#39;s snapshot, update users who were active today, and carry forward the previous values for users who weren&amp;#39;t. As a result, both the intermediate table update and the Activation calculation only need one day of data. That allows us to keep the scan range fixed to a single day for both daily runs and backfills.&lt;/p&gt;&lt;p&gt;In conclusion, we selected &lt;strong&gt;Candidate 3&lt;/strong&gt; for the FirstLast model because backfills occur periodically at Karrot, and this approach minimizes scan volume even during backfills.&lt;/p&gt;&lt;p&gt;Of course, the snapshot approach has trade-offs too. It increases storage costs as daily snapshots accumulate, and issues on a specific date can cascade to subsequent dates. However, because backfills only need to reload affected partitions, we found this approach more cost-effective and faster than Option 2, which requires full scans. Also, through data quality monitoring, we could detect issues before they spread and respond quickly.&lt;/p&gt;&lt;h4&gt;&lt;strong&gt;3. Productivity: Creating Models for New Actions Without SQL&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;The next challenge we faced was &amp;quot;how can we easily create Activation models for any action?&amp;quot; Activation calculations involve complex logic, such as WINDOW functions, JOINs, and CASE statements. Writing SQL directly each time led to slightly different implementations, resulting in inconsistent schemas.&lt;/p&gt;&lt;p&gt;We encapsulated the calculation logic in DBT macros. New Activation models can now be created by just specifying the reference Fact model name.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;[Before] Implementing Activation logic directly in SQL&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;-- Partial query to get the user&amp;#39;s first action time and previous action for the monthly activity state&lt;br&gt;&lt;br&gt;WITH first_activation AS (&lt;br&gt;    SELECT user_id, MIN(event_date) as first_date&lt;br&gt;    FROM events&lt;br&gt;    WHERE …&lt;br&gt;    GROUP BY user_id&lt;br&gt;),&lt;br&gt;&lt;br&gt;monthly_activity AS (&lt;br&gt;    SELECT&lt;br&gt;    user_id,&lt;br&gt;    DATE_TRUNC(&amp;#39;month&amp;#39;, event_date) as month,&lt;br&gt;    LAG(DATE_TRUNC(&amp;#39;month&amp;#39;, event_date)) OVER (&lt;br&gt;    PARTITION BY user_id ORDER BY event_date&lt;br&gt;    ) as prev_month&lt;br&gt;    FROM events&lt;br&gt;    WHERE …&lt;br&gt;),&lt;br&gt;&lt;br&gt;… (window functions, joins, CASE branches, etc.)&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;[After] Creating models without writing SQL using DBT Macros&lt;/strong&gt;&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*RvO-YWSMQAPsDcSrE4wptw.png&quot; /&gt;&lt;figcaption&gt;&lt;em&gt;Sample of implementation code for FirstLast, Activation, Activation Status models using defined DBT Macros&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;&lt;strong&gt;Final Results&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;To capture the information needed for Activation analysis while meeting the reliability, cost, and productivity as mentioned above, we designed the Activation Layer so that three models operate as a set based on a single Fact model.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/960/1*jA-dOB8dvGIZQIh-8WBB8g.png&quot; /&gt;&lt;figcaption&gt;&lt;em&gt;Data flow diagram of the 3 models within the Activation Layer&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;FirstLast&lt;/strong&gt; aggregates each user&amp;#39;s first/last action timestamps into daily snapshots to improve cost efficiency.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Activation&lt;/strong&gt; takes the Fact model and FirstLast model as inputs, produces New/Retained/Reactivated states and return intervals for dates with activity, and returns the intervals.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Activation Status&lt;/strong&gt; includes inactive users to provide state transitions, continuity, and inactivity duration for all dates.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;These three models are connected sequentially to build the states and flows required for Activation analysis progressively.&lt;/p&gt;&lt;h4&gt;&lt;strong&gt;Three-Model Structure and Data Examples&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;To quickly understand each model&amp;#39;s data composition and how it works, let&amp;#39;s walk through an example: User A visits for the first time on December 10 and then returns on December 11 and December 20.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. FirstLast Model&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;FirstLast is an intermediate model that stores each user&amp;#39;s first/last action timestamps as daily snapshots. Every day, it fetches the previous day&amp;#39;s snapshot, updates the last active date for users with activity today, and carries forward the previous day&amp;#39;s values for users without activity to generate snapshots for all users.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*JSRErBnJmLBXYbgWN3Di9g.png&quot; /&gt;&lt;figcaption&gt;&lt;em&gt;Data example showing how FirstLast model is generated based on User A’s Fact data&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;For User A, on their first visit on December 10, we set both the &lt;strong&gt;first active date&lt;/strong&gt; and &lt;strong&gt;last active date&lt;/strong&gt; to December 10. When they return on December 11, we update only the &lt;strong&gt;last active date&lt;/strong&gt;. From December 12 to 19, the user doesn&amp;#39;t visit, but &lt;strong&gt;we still generate a daily snapshot&lt;/strong&gt;. When they visit again on December 20, we set the &lt;strong&gt;last active date&lt;/strong&gt; to that date.&lt;/p&gt;&lt;p&gt;Thanks to these snapshots, Activation calculations can get the previous timestamp by just referencing the previous day&amp;#39;s snapshot.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. Activation Model&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;This model keeps &lt;strong&gt;only dates with activity based on the Fact model&lt;/strong&gt;. It references the FirstLast model to retrieve the previous activity timestamp, and based on this, calculates &lt;strong&gt;New/Retained/Reactivated states and return intervals&lt;/strong&gt;. It also aggregates information, such as action counts for each date.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*D-PGiCEw96COUoCPdEbrPA.png&quot; /&gt;&lt;figcaption&gt;&lt;em&gt;Data example showing how Activation model is generated based on User A’s Fact and FirstLast data&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;For User A, on December 10, there&amp;#39;s no prior record in FirstLast, so they&amp;#39;re classified as a new user. On December 11, it retrieves the last active date (December 10) from the December 10 snapshot in FirstLast and uses it as the previous active date. Since the &lt;strong&gt;return interval&lt;/strong&gt; between the active date and the previous active date is 1 day, the user is classified as retained. From December 12 to 19, when there&amp;#39;s no activity, no rows are generated in the Activation model.&lt;/p&gt;&lt;p&gt;The Activation model can be used to decompose the number of Active Users into activity-state components (New/Retained/Reactivated) and analyze month-over-month contributions.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. Activation Status Model&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Unlike the Activation model, this model fills in inactive periods to provide states for all dates. It provides not only the &lt;strong&gt;inactivity duration&lt;/strong&gt; and &lt;strong&gt;consecutive active days&lt;/strong&gt; but also &lt;strong&gt;transition segments&lt;/strong&gt; that show how states changed.&lt;/p&gt;&lt;p&gt;Transition segments are values that further segment user flows by combining &amp;quot;previous activity state → current activity state.&amp;quot; For example, users in the same Retained state are distinguished as New User Retained (New → Retained), Core User Retained (Retained → Retained), or Reactivated User Retained (Reactivated → Retained). Similarly, churned users are segmented as Core User Churned (Retained → Inactive), Reactivation Failed (Reactivated → Inactive), etc.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/906/1*u87KeqoQJ_HGAMrJc06RIQ.png&quot; /&gt;&lt;figcaption&gt;&lt;em&gt;Activation Status data example for User A&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;For User A, they start in the New state on December 10, become active on December 11, and transition to the Retained state; therefore, the &lt;strong&gt;transition segment&lt;/strong&gt; is New User Retained. From December 12 to 19, there&amp;#39;s no activity, but we can see the inactivity duration. On December 20, the activity state detail shows they returned after 8 days.&lt;/p&gt;&lt;p&gt;The Activation Status model enables more sophisticated analysis of acquisition-churn-return flows by combining activity states with previous states through transition segments.&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;Use Cases&lt;/strong&gt;&lt;/h3&gt;&lt;h4&gt;&lt;strong&gt;1. AU Dashboard and Analysis Agent&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;As mentioned in the background, the number of Active Users alone doesn&amp;#39;t immediately tell you &amp;quot;why it increased or decreased.&amp;quot; This chart breaks down changes in Active Users relative to the previous period into New/Retained/Reactivated &lt;strong&gt;contributions&lt;/strong&gt;, enabling quick identification of the causes of change.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1) AU Composition — Contribution by Activity State&lt;/strong&gt;&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/933/0*Xc2yanZGVkfQwTdr.png&quot; /&gt;&lt;figcaption&gt;A contribution table by activation state built with mock data (not real data)&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;For example, MAU of November is -1.20%p compared to October, mainly due to decreased Reactivated users (-0.90%p) and Retained users (-0.35%p), partially offset by New users (+0.05%p).&lt;/p&gt;&lt;p&gt;As shown in the example below, we quickly assess the MAU change drivers through user group contributions.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/933/0*zWTW1VBRE4lzQCNa.png&quot; /&gt;&lt;figcaption&gt;&lt;em&gt;Slack message summarizing previous month’s MAU changes (partially blurred)&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;2) Seeing Where Users Flowed — Transition Segment Analysis&lt;/strong&gt;&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/933/0*XjHraG_7F2zbof2T.png&quot; /&gt;&lt;figcaption&gt;&lt;em&gt;Charts for Transition segment analysis created with mock data, not real data&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Looking only at activity states tells us how much each segment grew or shrank this month, but it doesn&amp;#39;t tell us how those changes happened. When Active Users move, knowing the paths they took—where they came from and where they went—helps us decide what to do next.&lt;/p&gt;&lt;p&gt;We use a transition segment in the Activation Status model to break down state transitions and quickly identify which flows changed, even for exact state changes.&lt;/p&gt;&lt;p&gt;For example, both September and November 2025 have 220 retained users (activation_status = retained). Looking only at activity states, the retained users for both months appear the same. But when broken down by transition segment, &amp;quot;Retained New User (New → Retained)&amp;quot; decreased from 100 in September to 50 in November. It means that while overall retained user volume is the same, new user retention is weakening—a signal we can catch. In such cases, there&amp;#39;s a high likelihood we need to examine the onboarding funnel or early experience.&lt;/p&gt;&lt;p&gt;Furthermore, we also provide an analysis Agent that supplies dashboard interpretation guides as prompts. It enables team members to gain a range of insights through conversations with the Agent on our internal LLM platform.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/proxy/0*P5CrvtzTASNg0BmC.png&quot; /&gt;&lt;figcaption&gt;&lt;em&gt;Example of analyzing with Activation analysis bot registered on internal LLM platform&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;2. Marketing Targeting and Performance Analysis&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The Activation model we built is now also being used for the Marketing team&amp;#39;s performance analysis. For example, when executing CRM actions, we define targets based on the Activation Layer. We segment audiences by inactivity duration, like users churned for 3+ months, and can now analyze campaign performance using the same criteria.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. Core Action Tracking by Service&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Each team can now define important core actions as Activation models and track them. Instead of just looking at DAU for that action, they can view activity state composition and day-over-day churn rate together to monitor user flows. It enables teams to identify changes that might be missed when reviewing individual experiment metrics, from the perspective of overall user composition changes within strategic decisions.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/933/0*bBAr0g1Ok8Wry-Nw.png&quot; /&gt;&lt;figcaption&gt;&lt;em&gt;Dashboards built using models created in the Activation Layer, being used for decision-making&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;The biggest realization from building the Activation Layer was that &lt;strong&gt;well-structured data alone can transform team-wide productivity&lt;/strong&gt;. Time spent writing complex SQL queries repeatedly decreased, and teams needing growth analysis can now make decisions based on the data directly.&lt;/p&gt;&lt;p&gt;Also, the Activation Layer wasn&amp;#39;t just about creating a table that calculates AU—it was an attempt to &lt;strong&gt;establish a common language for interpreting user behavior across states and flows&lt;/strong&gt;. Especially in today&amp;#39;s environment, as LLM-powered analysis grows, I believe &lt;strong&gt;providing structured data that LLMs can understand is more important than giving massive raw datasets&lt;/strong&gt;. We plan to continue creating such structured data in the future.&lt;/p&gt;&lt;p&gt;As such, Karrot&amp;#39;s Data Team works on making data trustworthy and easy for anyone to use. Among them, Data Analytics Engineers design structures that enable analysts, engineers, and product teams to consistently leverage data without complex queries, spanning data modeling, pipeline design, and metric definition. If this post sparked your interest in data structuring and modeling, please check out the job postings below!&lt;/p&gt;&lt;p&gt;👉 &lt;a href=&quot;https://about.daangn.com/jobs/7507320003/&quot;&gt;View Data Analytics Engineer Opening&lt;/a&gt;&lt;/p&gt;&lt;p&gt;👉 &lt;a href=&quot;https://about.daangn.com/jobs/4300801003/&quot;&gt;View Software Engineer, Data Opening&lt;/a&gt;&lt;/p&gt;&lt;img src=&quot;https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=342ed895508f&quot; width=&quot;1&quot; height=&quot;1&quot; alt=&quot;&quot;&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&quot;https://medium.com/daangn/standardizing-user-activation-how-we-built-a-shared-data-layer-at-karrot-342ed895508f&quot;&gt;Standardizing User Activation: How We Built a Shared Data Layer at Karrot&lt;/a&gt; was originally published in &lt;a href=&quot;https://medium.com/daangn&quot;&gt;당근 테크 블로그&lt;/a&gt; on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</content:encoded>
    </item>
    <item>
      <title>Activation을 전사 공통 레이어로 만들며 해결한 3가지: 신뢰성, 비용, 생산성</title>
      <link>https://medium.com/daangn/activation%EC%9D%84-%EC%A0%84%EC%82%AC-%EA%B3%B5%ED%86%B5-%EB%A0%88%EC%9D%B4%EC%96%B4%EB%A1%9C-%EB%A7%8C%EB%93%A4%EB%A9%B0-%ED%95%B4%EA%B2%B0%ED%95%9C-3%EA%B0%80%EC%A7%80-%EC%8B%A0%EB%A2%B0%EC%84%B1-%EB%B9%84%EC%9A%A9-%EC%83%9D%EC%82%B0%EC%84%B1-f40d362107ff?source=rss----4505f82a2dbd---4</link>
      <guid>https://medium.com/daangn/activation%EC%9D%84-%EC%A0%84%EC%82%AC-%EA%B3%B5%ED%86%B5-%EB%A0%88%EC%9D%B4%EC%96%B4%EB%A1%9C-%EB%A7%8C%EB%93%A4%EB%A9%B0-%ED%95%B4%EA%B2%B0%ED%95%9C-3%EA%B0%80%EC%A7%80-%EC%8B%A0%EB%A2%B0%EC%84%B1-%EB%B9%84%EC%9A%A9-%EC%83%9D%EC%82%B0%EC%84%B1-f40d362107ff?source=rss----4505f82a2dbd---4</guid>
      <pubDate>Fri, 02 Jan 2026 02:33:17 GMT</pubDate>
      <content:encoded>&lt;h3&gt;당근은 왜 User Activation을 전사 공통 데이터 레이어로 만들었을까?&lt;/h3&gt;&lt;p&gt;안녕하세요. 당근 데이터 가치화팀에서 Data Analytics Engineer로 일하고 있는 Pepper예요.&lt;/p&gt;&lt;p&gt;데이터 가치화팀은 ‘매일 데이터를 통해 사용자를 위한 의사결정을 해요’라는 비전을 위해 수많은 데이터를 안정적으로 수집하고, 더 나아가 신뢰할 수 있는 형태로 제공하는 일을 하고 있어요.&lt;/p&gt;&lt;p&gt;오늘 글에서는 그중 하나로, 당근에서 Activation 분석을 매번 쿼리로 직접 계산하던 방식에서 벗어나 이를 ‘전사 공통 데이터 레이어’로 끌어올린 경험을 소개해 보려고 해요.&lt;/p&gt;&lt;h3&gt;배경&lt;/h3&gt;&lt;h4&gt;Active User 지표의 한계&lt;/h4&gt;&lt;p&gt;많은 서비스가 그렇듯, 당근에서도 Active User 수는 중요한 지표예요. 하지만 Active User 수는 ‘무슨 일이 일어났는지’를 보여줄 뿐, ‘왜 그런 일이 일어났는지’를 직접 설명해 주지는 못해요.&lt;/p&gt;&lt;p&gt;예를 들어, ‘이번 달 Active User가 10% 증가했다’라는 단편적인 사실은 알 수 있지만, 왜 Active User가 늘었는지, 더 나아가 Active User를 늘리려면 무엇을 해야 하는지 같은 질문까지는 답하기 어려워요.&lt;/p&gt;&lt;p&gt;이런 질문에 답하려면, &lt;strong&gt;Active User를 하나의 숫자로 보지 않고, 서로 다른 성격의 구성 요소로 쪼개서 해석할 수 있는 관점&lt;/strong&gt;이 필요해요. 그리고 바로 그 역할을 하는 것이 User Activation이에요.&lt;/p&gt;&lt;h4&gt;User Activation: 활성 상태와 상태 전이&lt;/h4&gt;&lt;p&gt;User Activation은 사용자의 활동을 단순히 활성과 비활성으로 보지 않고 현재 어떤 &lt;strong&gt;활성 상태&lt;/strong&gt;에 있는지, 기간이 바뀌면서 어떤 상태로 이동하는지 &lt;strong&gt;상태 전이&lt;/strong&gt;를 함께 해석하는 관점인데요. 아래에서 좀 더 자세히 설명해 볼게요.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;활성 상태&lt;/strong&gt;는 특정 시점에 사용자가 어떤 상태인지에 대한 분류예요. 예를 들어, 신규(New), 유지(Retained), 복귀(Reactivated), 이탈(Inactived) 같은 상태로 구분해요.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;상태 전이&lt;/strong&gt;는 기간이 지나면서 사용자가 활성 상태 간에 어떻게 이동했는지를 의미해요. 예를 들어, 신규 → 유지, 유지 → 이탈, 복귀 → 이탈처럼 상태 간 이동을 표현해요.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;활성 상태만으로는 ‘지금 몇 명이 어떤 상태인지’는 알 수 있지만, ‘어디서 왔는지’, ‘어떤 경로로 이탈하는지’는 파악하기 어려워요. 상태 전이를 함께 보면 유저가 어떤 경로로 이동하는지 알 수 있고, 이 전이 패턴을 기준으로 유저를 세분화하면 활동성 수준별로 다른 해석과 액션이 가능해져요.&lt;/p&gt;&lt;p&gt;예를 들어, Active User가 늘었을 때 활성 상태를 활용해 Active User 증가가 신규 유입 때문인지, 아니면 기존 사용자의 복귀로 늘어난 것인지를 구성 요소로 분해해서 설명할 수 있어요. 또한 리텐션이 떨어졌다면, 상태 전이를 활용해 단순히 ‘리텐션이 나빠졌다’로 끝나는 게 아니라 어느 세그먼트에서 이탈이 늘었는지를 구체적으로 파악해 의사결정할 수 있어요.&lt;/p&gt;&lt;h3&gt;목표&lt;/h3&gt;&lt;h4&gt;왜 공통 레이어가 필요했나&lt;/h4&gt;&lt;p&gt;User Activation 관점으로 분석하려면 활성 상태와 상태 전이가 계산된 데이터가 필요해요. 그런데 문제는 팀마다 각자 정의하고 운영하는 방식으로는 데이터 신뢰성과 운영 안정성을 확보하기 어렵다는 점이었어요.&lt;/p&gt;&lt;p&gt;팀별로 만들어진 데이터는 누가, 언제, 어떤 기준으로 만들었는지에 대한 맥락이 남지 않아 시간이 지나면 결과를 이해하거나 점검하기 어려웠죠. 또 예약 쿼리 실패나 재처리 같은 운영 이슈가 발생하면 멱등성이 깨지거나 최신성을 보장하지 못한 채로 남은 경우도 있었어요. 결국 데이터는 존재했지만, 마음 놓고 쓰기 어려운 경우가 많았던 거예요.&lt;/p&gt;&lt;p&gt;그래서 Activation을 전사 공통 기준으로 계산하고 운영하는 &lt;strong&gt;공통 레이어인&lt;/strong&gt; &lt;strong&gt;Activation 레이어&lt;/strong&gt;를 만들기로 했어요. 결과의 신뢰도와 운영 안정성을 확보하고, 여러 팀이 같은 기준으로 재사용하는 것을 목표로 삼았죠.&lt;/p&gt;&lt;blockquote&gt;&lt;em&gt;여기서&lt;/em&gt;&lt;strong&gt;&lt;em&gt; User Activation&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;은 Active User를 상태와 전이로 해석하는 관점이고, &lt;/em&gt;&lt;strong&gt;&lt;em&gt;Activation 레이어&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;는 그 해석에 필요한 사용자별 상태/전이 정보를 일관된 기준으로 제공하는 공통 데이터 레이어를 의미해요.&lt;/em&gt;&lt;/blockquote&gt;&lt;h4&gt;Activation 레이어로 무엇을 하려 했나&lt;/h4&gt;&lt;p&gt;Activation 레이어는 전사 공통 레이어로 만들기로 결정한 뒤, 가장 먼저 한 일은 ‘이 레이어가 무엇을 제공해야 하는지’를 정의하는 것이었어요. 사내에서 반복되던 질문을 정리하다 보니, 구체적으로는 아래와 같은 정보들이에요.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;이번 활동이 신규/유지/복귀 중 무엇인지(&lt;strong&gt;활성 상태&lt;/strong&gt;)&lt;/li&gt;&lt;li&gt;직전 기간의 상태에서 이번 기간의 상태로 어떻게 바뀌었는지(&lt;strong&gt;상태 전이&lt;/strong&gt;)&lt;/li&gt;&lt;li&gt;최근 활동이 연속적으로 이어지고 있는지(&lt;strong&gt;연속성&lt;/strong&gt;)&lt;/li&gt;&lt;li&gt;직전 활동 이후 얼마 만에 돌아왔는지(&lt;strong&gt;복귀 간격&lt;/strong&gt;)&lt;/li&gt;&lt;li&gt;마지막 활성 이후 얼마나 쉬고 있는지(&lt;strong&gt;이탈 기간)&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;예를 들어 어떤 유저가 12월 10일, 12월 11일, 12월 20일에 방문했다면, 위 정보들이 일 기준으로 아래처럼 제공되어야 해요.&lt;/p&gt;&lt;pre&gt;user_A (daily)&lt;br&gt;- 2025-12-10 NEW&lt;br&gt;- 2025-12-11 RETAINED (prev=2025-12-10, interval=1d)&lt;br&gt;- 2025-12-20 REACTIVATED (prev=2025-12-11, interval=9d)&lt;/pre&gt;&lt;p&gt;여기서는 방문을 예시로 들었지만, User Activation은 앱 방문뿐 아니라 중고물품 판매나 커뮤니티 글 작성, 알림 오픈처럼 코어 행동에도 적용할 수 있어요.&lt;/p&gt;&lt;h3&gt;Activation 레이어를 설계하며 해결한 3가지 고민&lt;/h3&gt;&lt;p&gt;이제부터 Activation 레이어를 어떻게 구현했는지 이야기해 볼게요. 먼저 전체 구조를 보면 다음과 같아요.&lt;/p&gt;&lt;h4&gt;전체 구조 한눈에 보기&lt;/h4&gt;&lt;p&gt;Activation 레이어는 기존 당근 DBT 프로젝트의 데이터 계층 위에 한 단계를 더 얹는 형태로 설계했어요. 원천 이벤트 로그(Raw Data)를 그대로 사용하는 대신, Base (정제) → Fact (행동 단위) → Activation (상태/흐름 분석) 순서로 쌓아 올린 구조예요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*0w14QIwG2lT219KsuSqiMw.png&quot; /&gt;&lt;figcaption&gt;DBT 프로젝트 계층 구조(Base/Dimension/Fact)에 Activation 레이어를 올려놓은 구조&lt;/figcaption&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;em&gt;당근의 데이터 계층 구조를 더 자세히 알고 싶다면, &lt;/em&gt;&lt;a href=&quot;https://medium.com/daangn/dbt%EC%99%80-airflow-%EB%8F%84%EC%9E%85%ED%95%98%EB%A9%B0-%EB%A7%88%EC%A3%BC%ED%95%9C-7%EA%B0%80%EC%A7%80-%EB%AC%B8%EC%A0%9C%EB%93%A4-61250a9904ab&quot;&gt;&lt;em&gt;DBT와 Airflow 도입하며 마주한 7가지 문제들&lt;/em&gt;&lt;/a&gt;&lt;em&gt; 글을 참고해 주세요.&lt;/em&gt;&lt;/blockquote&gt;&lt;p&gt;Activation 레이어는 하나의 Fact 모델을 기준으로, 3개 모델(FirstLast, Activation, Activation Status)이 한 세트로 동작하도록 구성했어요. 각 모델이 어떤 데이터를 담고, 어떤 역할을 맡는지, 그리고 어떤 구조로 서로 연결되어 있는지는 뒤에서 풀어볼게요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*Rp8t7kOXRAQq6oDZEArocg.png&quot; /&gt;&lt;figcaption&gt;Fact 모델을 기준으로 3개 모델이 순차적으로 연결되는 Activation 레이어 구조&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;이 구조를 만들면서 실제로 마주한 고민은 크게 세 가지였어요. 바로 &lt;strong&gt;신뢰성, 비용, 생산성&lt;/strong&gt;에 대한 문제였어요. 지금부터 어떻게 각 고민을 해결했는지를 설명해 볼게요.&lt;/p&gt;&lt;h4&gt;1. 신뢰성: 기준 행동을 명확하게 고정하기&lt;/h4&gt;&lt;p&gt;먼저 전사 공통 레이어로 운영하려면 Activation의 기준 행동이 명확해야 해요. 기준이 사람마다 다르게 해석되는 순간, 데이터는 재사용될 수 없고 매번 검증을 거쳐야만 쓸 수 있기 때문이에요. 그래서 &lt;strong&gt;모델만 봐도 어떤 행동을 기준으로 Activation을 계산했는지 쉽게 알아차릴 수 있게&lt;/strong&gt; 만드는 것을 우선순위로 뒀어요.&lt;/p&gt;&lt;p&gt;사실 처음에는 이벤트 로그와 Activation 기준 행동을 1:1로 대응시키는 방식을 고려했어요. 하지만 보통 이벤트 로그는 UI 단위(예: 버튼 클릭, 화면 조회)로 로깅되다 보니, 하나의 이벤트 안에서도 파라미터에 따라 행동 의미가 달라지는 경우가 많았어요.&lt;/p&gt;&lt;p&gt;예를 들어, ‘관심 버튼 클릭’ 이벤트 하나에 관심 등록/해제가 함께 로깅 되기도 했어요. 이 경우 관심 등록을 기준 행동으로 쓰려면, 매번 관심 등록에 해당하는 케이스만 필터링한다는 조건을 반복해서 붙여야 했죠.&lt;/p&gt;&lt;p&gt;그래서 &lt;strong&gt;이벤트 로그를 그대로 기준 행동으로 삼는 게 아니라 기준 행동 자체를 명확한 단위로 고정&lt;/strong&gt;해야겠다고 생각했어요. 당근은 dbt로 데이터 모델링을 하고 있고 모델들을 레이어(Layer)라는 개념적 구분으로 관리하고 있는데요.&lt;/p&gt;&lt;p&gt;그중 Fact 레이어는 사용자 행동을 정의해두는 계층이에요. 단순한 행동(예: ‘사용자가 메시지를 보냈다’)부터 조건과 비즈니스 로직이 필요한 행동(예: ‘사용자가 액티브하기 피드를 사용했다’)까지, 의미가 담긴 행동 단위로 표현되도록 운영하고 있어요.&lt;/p&gt;&lt;p&gt;그래서 &lt;strong&gt;기준 행동은 Fact 모델로 정의&lt;/strong&gt;하고, Activation 레이어가 그 Fact 모델을 입력으로 쓰도록 구현하기로 했어요. 또한 기준 행동이 더 한눈에 드러나도록, 아래처럼 Activation 모델명에 Fact 모델 이름이 포함되도록 &lt;strong&gt;네이밍 컨벤션&lt;/strong&gt;을 정했어요.&lt;/p&gt;&lt;pre&gt;# Naming convention&lt;br&gt;&amp;lt;fact_name&amp;gt;_activation_&amp;lt;time_grain&amp;gt;&lt;br&gt;&lt;br&gt;# fact_name: Fact 레이어 모델명과 동일 (행동 의미는 Fact에서 정의)&lt;br&gt;# time_grain: daily | weekly | monthly&lt;br&gt;# Examples&lt;br&gt;users_visited_app_activation_daily&lt;br&gt;users_opened_push_activation_daily&lt;br&gt;users_created_article_activation_daily&lt;/pre&gt;&lt;p&gt;덕분에 Activation 모델은 모델명만 봐도 기준 행동이 명확하게 드러나고, 이벤트 파라미터나 필터 조건에 의해 해석이 흔들릴 여지 크게 줄었어요.&lt;/p&gt;&lt;h4&gt;2. 비용: 지속 가능하게 만들기&lt;/h4&gt;&lt;p&gt;Activation을 계산하려면 같은 날 활동한 유저라도 &lt;strong&gt;직전 활동 시점에 따라 상태가 달라지기 때문에 ‘최초 시점’과 ‘직전 시점’이 각각 필요&lt;/strong&gt;해요. 최초 시점은 해당 행동을 처음 수행한 날짜이고, 직전 시점은 현재 날짜 기준으로 바로 이전에 그 행동을 수행한 날짜예요. 예를 들어 12월 20일에 방문했더라도 직전 방문이 12월 19일인지 12월 11일인지에 따라 유지/복귀처럼 &lt;strong&gt;활성 상태 분류가 달라질 수 있어요.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;문제는 이 값을 미리 정리해 둔 테이블이 없다면, 직전 시점을 찾기 위해 매번 Fact 모델 전체 기간을 스캔해야 한다는 점이에요. 당근처럼 데이터 규모가 큰 서비스 환경에서는 스캔 범위가 곧 비용과 수행 시간으로 이어져, 이 부분이 Activation 운영에서 가장 큰 비용 허들이었어요.&lt;/p&gt;&lt;p&gt;그래서 계산 비용을 줄이기 위해 유저의 첫/마지막 행동 시점을 담은 중간 테이블을 도입하기로 했어요. 그리고 이 중간 테이블은 말 그대로 First(최초)/Last(마지막)을 담고 있어서 &lt;strong&gt;FirstLast 모델&lt;/strong&gt;이라고 부르기로 했어요. 다만 FirstLast 모델을 어떤 방식으로 저장하느냐에 따라 일별 실행 비용뿐 아니라 백필 비용까지 크게 달라지기 때문에, 세 가지 접근 방식을 비교해 봤어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*q9IiVOD4MrZnmh3t33oPlw.png&quot; /&gt;&lt;figcaption&gt;FirstLast 모델 구현을 위해 고민한 세가지 후보&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;후보 1 — Fact에서 매번 직접 계산&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;중간 테이블을 두지 않고 매번 전체 기간을 스캔해서 유저별 최초 시점과 직전 시점을 구하는 방식이에요. 구조는 가장 단순하지만, 실행할 때마다 Fact 모델 전체 기간을 스캔해야 해서 일별 비용과 수행 시간이 크게 발생해요. 운영을 반복하기에 부담이 커서 제외했어요.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;후보 2 — 유저별 최신 값만 유지&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;유저당 최초 시점과 마지막 시점을 한 레코드에 저장하는 방식이에요. 최초 시점은 한 번 정해지면 거의 변하지 않아요. 반면 마지막 시점은 매일 업데이트가 필요하지만, 오늘 행동한 유저만 merge 하면 되니 일별 갱신은 하루치 Fact 모델만 스캔하면 돼요. 다만 과거 날짜의 마지막 시점을 따로 쌓지 않기 때문에, 백필할 때 결국 Fact 모델 전체 범위를 스캔해야 해요.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;후보 3 — 날짜별 스냅샷으로 유지 ✅&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;유저별 직전 시점을 날짜별로 쌓는 방식이에요. 오늘 스냅샷을 만들 때 전날 스냅샷을 가져와서, 오늘 활동한 유저는 업데이트하고 활동이 없는 유저는 전날 값을 그대로 이어가죠. 중간 테이블 갱신도 하루치 데이터만 보면 되고, Activation 계산 시에도 필요한 날짜의 전날 스냅샷을 쓰면 되니 일별 계산과 백필 모두 스캔 범위를 ‘하루치’로 고정할 수 있어요.&lt;/p&gt;&lt;p&gt;이 중 결론적으로 당근에서는 백필이 주기적으로 발생하고, 백필 상황에서도 스캔량을 최소화할 수 있는 방식 3을 선택해서 FirstLast 모델을 정의했어요.&lt;/p&gt;&lt;p&gt;물론 스냅샷 방식에도 trade-off는 있어요. 날짜별로 쌓아서 저장 공간이 점차 늘어나고, 특정 날짜에 문제가 생기면 이후로 영향이 이어질 수 있어요. 하지만 백필 시 영향받은 파티션만 재적재하면 되니 전체 스캔이 필요한 방식 2보다 비용과 수행 시간 측면에서 효율적이라고 판단했어요. 또 데이터 품질 모니터링을 통해 문제가 발생하더라도 영향 범위가 커지기 전에 감지해서 빠르게 대응할 수 있었어요.&lt;/p&gt;&lt;h4&gt;3.생산성: SQL 없이 새 행동을 모델로 만들기&lt;/h4&gt;&lt;p&gt;다음으로 마주한 고민은 ‘어떤 행동이든 쉽게 Activation 모델로 만들려면 어떻게 해야 할까?’였어요. Activation 계산에는 WINDOW 함수나 JOIN, CASE 같은 복잡한 로직이 많이 들어가요. 그래서 매번 SQL을 직접 작성하다 보면 구현 방식이 조금씩 달라지고, 그 과정에서 스키마가 흔들리기 쉽다는 한계가 존재했어요.&lt;/p&gt;&lt;p&gt;그래서 계산 로직을 DBT 매크로로 캡슐화했어요. 새 Activation 모델은 기준이 되는 Fact 모델 이름 (fact_name)만 지정하면 생성되도록 구성했죠.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;[Before]&lt;/strong&gt; Activation 로직을 직접 SQL로 구현하던 방식&lt;/p&gt;&lt;pre&gt;-- 유저의 월별 활성 상태를 구하기 위해 유저의 첫 행동 시점과 직전 행동을 구하는 쿼리 일부&lt;br&gt;WITH first_activation AS (&lt;br&gt;  SELECT user_id, MIN(event_date) as first_date&lt;br&gt;  FROM events&lt;br&gt;  WHERE ...&lt;br&gt;  GROUP BY user_id&lt;br&gt;),&lt;br&gt;monthly_activity AS (&lt;br&gt;  SELECT&lt;br&gt;    user_id,&lt;br&gt;    DATE_TRUNC(&amp;#39;month&amp;#39;, event_date) as month,&lt;br&gt;    LAG(DATE_TRUNC(&amp;#39;month&amp;#39;, event_date)) OVER (&lt;br&gt;      PARTITION BY user_id ORDER BY event_date&lt;br&gt;    ) as prev_month&lt;br&gt;  FROM events&lt;br&gt;  WHERE ...&lt;br&gt;),&lt;br&gt;... (윈도우 함수, 조인, CASE 분기 등)&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;[After]&lt;/strong&gt; DBT Macro를 사용해 SQL 작성 없이 모델 생성&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*RvO-YWSMQAPsDcSrE4wptw.png&quot; /&gt;&lt;figcaption&gt;정의해둔 DBT Macro를 사용해서 FirstLast, Activation, Activation Status 모델 구현 코드 예시&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;최종 결과물&lt;/h3&gt;&lt;p&gt;Activation 분석을 위한 정보를 담으면서도 앞서 이야기한 &lt;strong&gt;신뢰성, 비용, 생산성&lt;/strong&gt;을 모두 만족하기 위해, Activation 레이어는 하나의 Fact 모델을 기준으로 &lt;strong&gt;3개 모델이 한 세트로 동작&lt;/strong&gt;하는 구조로 만들었어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/903/1*dvjoTcFom2zX9fvKcjbM5g.png&quot; /&gt;&lt;figcaption&gt;Activation 레이어 내 3개의 모델의 데이터 흐름도&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;FirstLast&lt;/strong&gt;는 비용을 고려해 유저별 첫/마지막 행동 시점을 &lt;strong&gt;날짜별 스냅샷으로 누적&lt;/strong&gt;하고&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Activation&lt;/strong&gt;은 Fact 모델과 FirstLast 모델을 입력으로 받아 &lt;strong&gt;행동이 있는 시점의 신규/유지/복귀와 복귀 간격&lt;/strong&gt;을 제공하고&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Activation Status&lt;/strong&gt;는 &lt;strong&gt;비활성 유저&lt;/strong&gt;까지 포함해 &lt;strong&gt;상태 전이&lt;/strong&gt;와 &lt;strong&gt;연속성 및 이탈 기간&lt;/strong&gt;을 제공해요.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;이 세 모델이 순서대로 연결되면서 Activation 분석에 필요한 상태와 흐름을 단계적으로 만들어가죠.&lt;/p&gt;&lt;h4&gt;3개 모델 구조와 데이터 예시&lt;/h4&gt;&lt;p&gt;모델별 데이터 구성과 동작 방식을 빠르게 이해하기 위해, 유저 A가 12월 10일에 첫 방문 하고 12월 11일, 12월 20일에 재방문하는 시나리오를 예시로 살펴볼게요.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. FirstLast 모델&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;FirstLast는 &lt;strong&gt;유저별 최초/마지막 행동 시점을 날짜별 스냅샷&lt;/strong&gt;으로 저장하는 중간 모델이에요. 매일 전날 스냅샷을 가져온 뒤, 오늘 행동이 있는 유저는 마지막 활성 일자를 업데이트하고, 행동이 없는 유저는 전날 값을 그대로 유지해서 모든 유저의 스냅샷을 생성해요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*5yQUCebiD5ChC-A7X2v09g.png&quot; /&gt;&lt;figcaption&gt;유저 A의 Fact 데이터를 기반으로 FirstLast 모델이 생성되는 로직을 보여주는 데이터 예시&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;유저 A의 경우, 12월 10일 첫 방문 시 ‘&lt;strong&gt;최초 활성 일자&lt;/strong&gt;’와 ‘&lt;strong&gt;마지막 활성 일자&lt;/strong&gt;’가 모두 12월 10일로 생성되고, 12월 11일 방문 시에는 ‘마지막 활성 일자’만 업데이트돼요. 12월 12일부터 19일까지는 방문이 없지만 매일 스냅샷이 생성되고, 12월 20일에 방문 시 ‘마지막 활성 일자’가 12월 20일로 업데이트돼요.&lt;/p&gt;&lt;p&gt;이 스냅샷 덕분에 Activation 계산 시 전날 스냅샷만 참조하면 직전 시점을 가져올 수 있어요.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. Activation 모델&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Fact 모델을 기준으로 활동이 발생한 날짜만 남기는 모델이에요. FirstLast 모델을 참조해서 &lt;strong&gt;직전 활동 시점&lt;/strong&gt;을 가져오고, 이를 기반으로 &lt;strong&gt;신규/유지/복귀 상태&lt;/strong&gt;와 &lt;strong&gt;복귀 간격&lt;/strong&gt;을 계산해요. 또한 해당 날짜의 행동 횟수 등 &lt;strong&gt;집계 정보&lt;/strong&gt;도 함께 집계해요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*Azgu5482Xux2sZ_gkciPCw.png&quot; /&gt;&lt;figcaption&gt;유저 A의 Fact 데이터와 FirstLast 데이터를 기반으로 Activation 모델이 생성되는 로직을 보여주는 데이터 예시&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;유저 A의 경우, 12월 10일에는 FirstLast에 이전 기록이 없어서 신규 유저로 판정되고, 12월 11일에는 FirstLast의 12월 10일 스냅샷에서 마지막 활성 일자인 12월 10일을 가져와 ‘직전 활성 일자’로 사용해요. 이때 ‘활성 일자’와 ‘직전 활성 일자’ 간의 차이인 ‘복귀 간격’이 1일이기 때문에 복귀 유저로 판정해요. 활동이 없는 12월 12일부터 19일까지는 Activation 모델에 row가 생성되지 않아요.&lt;/p&gt;&lt;p&gt;이처럼 Activation 모델은 Active User를 &lt;strong&gt;활성 상태(신규/유지/복귀) 구성 요소로 분해&lt;/strong&gt;하고, &lt;strong&gt;전월 대비 기여도&lt;/strong&gt;를 분석하는 데 사용될 수 있어요.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. Activation Status 모델&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Activation 모델과 달리 비활성 구간까지 채워서 모든 날짜의 상태&lt;/strong&gt;를 제공하는 모델이에요. ‘이탈 기간’, ‘연속 활동 일수’뿐만 아니라 상태가 어떻게 바뀌었는지를 나타내는 ‘전이 세그먼트’도 함께 제공해요.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;전이 세그먼트&lt;/strong&gt;는 ‘이전 활성 상태 → 현재 활성 상태’ 조합으로 유저의 흐름을 더 세분화한 값이에요. 예를 들어, 같은 유지 유저라도 신규 유저 정착(신규 → 유지), 핵심 유저 유지 (유지 → 유지), 복귀 유저 정착(복귀 → 유지)로 구분돼요. 또한 이탈 유저도 핵심 유저 이탈(유지 → 이탈), 복귀 실패(복귀 → 이탈) 등으로 나뉘어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/877/1*-sc3PywHH92_m6wez1lQ0w.png&quot; /&gt;&lt;figcaption&gt;유저 A의 Activation Status 데이터 예시&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;유저 A의 경우, 12월 10일에는 신규 상태로 시작해 12월 11일에 활성화되어서 유지 상태로 전환되면서 ‘전이 세그먼트’는 신규 유저 정착(New User)가 돼요. 12월 12일부터는 19일까지 활동이 없지만 ‘이탈 기간’을 알 수 있어요. 12월 20일에는 ‘활성 상태 상세’를 통해 8일 만에 복귀했음을 알 수 있어요.&lt;/p&gt;&lt;p&gt;이처럼 Activation Status 모델은 전이 세그먼트로 활성 상태에 직전 상태를 결합해, &lt;strong&gt;유입-이탈-복귀 흐름을 더 정교하게 분석&lt;/strong&gt;할 수 있게 해줘요.&lt;/p&gt;&lt;h3&gt;활용 사례&lt;/h3&gt;&lt;h4&gt;1. AU 대시보드와 분석 Agent&lt;/h4&gt;&lt;p&gt;Activation 레이어를 만들고 이를 기반으로 AU 대시보드를 구성해 Active User를 단순히 ‘몇 명’으로 보지 않고 &lt;strong&gt;왜 변했는지&lt;/strong&gt;를 한 흐름으로 설명할 수 있게 됐어요. AU 대시보드는 &lt;strong&gt;구성, 전이 &lt;/strong&gt;그리고 &lt;strong&gt;지속(리텐션/부활) &lt;/strong&gt;순서로 3단으로 나눠서 보게 구성되어 있어요. 아래는 그중 일부를 mock 데이터로 예시로 보여드릴게요.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1) AU 구성 — 활성 상태별 기여도&lt;/strong&gt;&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*epjc5rj-KW3pIG1_I-VJyg.png&quot; /&gt;&lt;figcaption&gt;실제 데이터가 아니라 mock 데이터로 만든 활성 상태별 기여도 테이블&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;앞서 배경에서 이야기한 것처럼, Active User 수만으로는 ‘왜 늘었는지/줄었는지’를 바로 알기 어려워요. 이 차트는 직전 기간 대비 Active User 변화를 신규/유지/복귀의 &lt;strong&gt;기여도&lt;/strong&gt;로 분해해, 변화 원인을 빠르게 파악할 수 있게 해줘요.&lt;/p&gt;&lt;p&gt;예를 들어 2025년 11월 MAU는 10월 대비 &lt;strong&gt;-1.20%p&lt;/strong&gt;인데, &lt;strong&gt;복귀 유저(-0.90%p)와 유지 유저(-0.35%p) 감소가 주 원인&lt;/strong&gt;이고 신규 유저(+0.05%p)는 일부 상쇄한 것으로 해석할 수 있어요.&lt;/p&gt;&lt;p&gt;아래 사례처럼 월초에 지난달 MAU가 나오면, 유저 그룹별 기여도로 MAU 변화 원인을 빠르게 확인해요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*gg71s6CwdYQaTccP3gBqjA.png&quot; /&gt;&lt;figcaption&gt;전월 MAU 변화 요약 슬랙 메시지(일부 블러 처리)&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;2) 유저가 어디로 흘러갔는지 보기 — Transition segment 분석&lt;/strong&gt;&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*b2J8Owpno0gSovNzwprvVQ.png&quot; /&gt;&lt;figcaption&gt;실제 데이터가 아니라 mock 데이터로 만든 Transition segment 분석용 차트들&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;활성 상태만으로는 ‘이번 달에 각 상태가 얼마나 늘고 줄었는지’는 볼 수 있지만, 그 변화가 &lt;strong&gt;어떤 경로에서 만들어졌는지&lt;/strong&gt;까지는 알기 어려워요. 그런데 Active User 수가 변했을 때는 유저가 어떤 경로로 흘러갔는지 알면 효과적인 액션을 취할 수 있어요.&lt;/p&gt;&lt;p&gt;그래서 이 Activation Status 모델의 transition segment를 이용해 직전 상태 → 이번 상태의 전이로 나눠보고, 같은 상태 변화라도 어떤 흐름이 바뀌었는지 빠르게 파악할 수 있게 했어요.&lt;/p&gt;&lt;p&gt;예를 들어 2025년 9월과 11월 모두 유지 유저(activation_status = retained) 수는 220명으로 동일해요. 활성 상태만 보면 두 달의 유지 상태 유저는 같아보여요. 하지만 transition segment로 쪼개보면, ‘Retained New User (신규 → 유지)’가 9월 100명에서 11월 50명으로 줄었다는 사실을 알 수 있어요.&lt;/p&gt;&lt;p&gt;즉 전체 유지 유저 규모는 유지되었지만, 그 안에서 신규 유저의 정착이 약해지고 있다는 신호를 잡아낼 수 있어요. 이런 경우 온보딩 퍼널이나 초기 경험을 점검해야 할 가능성이 높아요.&lt;/p&gt;&lt;p&gt;더 나아가, 대시보드 해석 가이드를 프롬프트로 제공하는 분석 Agent도 함께 제공하고 있어요. 덕분에 구성원들이 사내 LLM 플랫폼에서 Agent와 대화하며 다양한 인사이트를 얻고 있어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/736/1*vAvcBC_lHZx2jCVphMNOyg.png&quot; /&gt;&lt;figcaption&gt;사내 LLM 플랫폼에 등록된 Activation 분석 봇과 분석하는 예시&lt;/figcaption&gt;&lt;/figure&gt;&lt;h4&gt;2. 마케팅 타겟팅과 성과 분석&lt;/h4&gt;&lt;p&gt;이렇게 만든 Activation 모델은 현재 마케팅팀의 성과 분석에도 활용되고 있어요. 예를 들어 CRM 액션을 집행할 때, Activation 레이어를 기준으로 타겟을 정의해요. 3개월 이상 이탈한 사용자처럼 이탈 기간을 기준으로 대상을 나누고, 같은 기준으로 캠페인 성과도 분석할 수 있게 됐어요.&lt;/p&gt;&lt;h4&gt;3. 서비스별 코어 행동 트래킹&lt;/h4&gt;&lt;p&gt;또 이제 각 팀에서 중요한 코어 행동을 Activation 모델로 정의해 트래킹할 수 있게 됐어요. 단순히 그 행동의 DAU만 보는 게 아니라, &lt;strong&gt;활성 상태 구성&lt;/strong&gt;과 &lt;strong&gt;전일 대비 이탈율&lt;/strong&gt;을 함께 보면서 유저 흐름을 확인해요. 그래서 개별 실험의 지표만으로는 놓치기 쉬운 변화도, 팀의 전략적 판단을 &lt;strong&gt;전체 유저 구성 변화 관점&lt;/strong&gt;에서 점검할 수 있어요.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*1y4ChSw92Uksm1Q7N-fz5Q.png&quot; /&gt;&lt;figcaption&gt;Activation 레이어에 만든 모델을 활용해 대시보드 구현하고 이를 의사결정에 활용하는 모습&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;마치며&lt;/h3&gt;&lt;p&gt;Activation 레이어를 구축하면서 가장 크게 느낀 건, 데이터를 잘 구조화하는 것만으로도 팀 전체의 생산성이 달라진다는 점이었어요. 복잡한 SQL을 매번 작성하던 시간이 줄어들었고, 그로스 분석이 필요한 팀들이 직접 데이터를 보며 의사결정을 내릴 수 있게 됐어요.&lt;/p&gt;&lt;p&gt;또한 Activation 레이어는 ‘AU를 계산하는 테이블’ 하나를 만든 게 아니라, &lt;strong&gt;사용자 행동을 상태와 흐름으로 해석할 수 있는 공통 언어&lt;/strong&gt;를 정리한 시도였어요. 특히 요즘처럼 LLM을 활용한 분석이 늘어나는 환경에서는, 방대한 원천 데이터를 주기보다 LLM이 이해할 수 있는 형태의 구조화된 데이터를 제공하는게 더 중요해지고 있다고 생각해요. 그래서 앞으로도 이런 구조화된 데이터를 만드는 일을 해나가려고 해요.&lt;/p&gt;&lt;p&gt;이렇듯 당근 데이터 가치화팀은 데이터를 신뢰할 수 있고 누구나 활용하기 쉬운 형태로 만드는 일을 하고 있어요. 그중에서도 Data Analytics Engineer는 데이터 모델링과 파이프라인 설계, 지표 정의 등을 넘나들며 분석가와 엔지니어, 제품팀이 복잡한 쿼리 없이도 데이터를 일관되게 활용할 수 있는 구조를 설계하고 있답니다.&lt;/p&gt;&lt;p&gt;만약 이 글을 읽고 데이터 구조화와 모델링에 관심이 생기셨다면, 아래 채용 공고도 함께 확인해 보세요!&lt;/p&gt;&lt;p&gt;👉 &lt;a href=&quot;https://about.daangn.com/jobs/7507320003/&quot;&gt;Data Analytic Engineer 공고 보러 가기&lt;/a&gt;&lt;/p&gt;&lt;p&gt;👉 &lt;a href=&quot;https://about.daangn.com/jobs/4300801003/&quot;&gt;Software Engineer, Data 공고 보러 가기&lt;/a&gt;&lt;/p&gt;&lt;img src=&quot;https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=f40d362107ff&quot; width=&quot;1&quot; height=&quot;1&quot; alt=&quot;&quot;&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&quot;https://medium.com/daangn/activation%EC%9D%84-%EC%A0%84%EC%82%AC-%EA%B3%B5%ED%86%B5-%EB%A0%88%EC%9D%B4%EC%96%B4%EB%A1%9C-%EB%A7%8C%EB%93%A4%EB%A9%B0-%ED%95%B4%EA%B2%B0%ED%95%9C-3%EA%B0%80%EC%A7%80-%EC%8B%A0%EB%A2%B0%EC%84%B1-%EB%B9%84%EC%9A%A9-%EC%83%9D%EC%82%B0%EC%84%B1-f40d362107ff&quot;&gt;Activation을 전사 공통 레이어로 만들며 해결한 3가지: 신뢰성, 비용, 생산성&lt;/a&gt; was originally published in &lt;a href=&quot;https://medium.com/daangn&quot;&gt;당근 테크 블로그&lt;/a&gt; on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</content:encoded>
    </item>
  </channel>
</rss>