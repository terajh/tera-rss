<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>dev RSS - Level Up Coding</title>
    <link>https://levelup.gitconnected.com/</link>
    <description>Level Up Coding RSS ÌîºÎìú</description>
    <lastBuildDate>Wed, 25 Feb 2026 16:35:41 GMT</lastBuildDate>
    <item>
      <title>I replaced my entire QA team with Claude and Agentic Workflow</title>
      <link>https://levelup.gitconnected.com/i-replaced-my-entire-qa-team-with-claude-and-agentic-workflow-aed22dfb2a65?source=rss----5517fd7b58a6---4</link>
      <guid>https://levelup.gitconnected.com/i-replaced-my-entire-qa-team-with-claude-and-agentic-workflow-aed22dfb2a65?source=rss----5517fd7b58a6---4</guid>
      <pubDate>Mon, 23 Feb 2026 17:35:22 GMT</pubDate>
      <content:encoded>&lt;div class=&quot;medium-feed-item&quot;&gt;&lt;p class=&quot;medium-feed-image&quot;&gt;&lt;a href=&quot;https://levelup.gitconnected.com/i-replaced-my-entire-qa-team-with-claude-and-agentic-workflow-aed22dfb2a65?source=rss----5517fd7b58a6---4&quot;&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*yjjotfF4UGz19-TmgO-7lg.png&quot; width=&quot;1200&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;p class=&quot;medium-feed-snippet&quot;&gt;An Open-Source Experiment with Claude, Python, and Playwright&lt;/p&gt;&lt;p class=&quot;medium-feed-link&quot;&gt;&lt;a href=&quot;https://levelup.gitconnected.com/i-replaced-my-entire-qa-team-with-claude-and-agentic-workflow-aed22dfb2a65?source=rss----5517fd7b58a6---4&quot;&gt;Continue reading on Level Up Coding ¬ª&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</content:encoded>
    </item>
    <item>
      <title>Can AI Models Learn From Synthetic Data Without Collapsing?</title>
      <link>https://levelup.gitconnected.com/can-ai-models-learn-from-synthetic-data-without-collapsing-d8ab1e83e962?source=rss----5517fd7b58a6---4</link>
      <guid>https://levelup.gitconnected.com/can-ai-models-learn-from-synthetic-data-without-collapsing-d8ab1e83e962?source=rss----5517fd7b58a6---4</guid>
      <pubDate>Mon, 23 Feb 2026 17:35:14 GMT</pubDate>
      <content:encoded>&lt;div class=&quot;medium-feed-item&quot;&gt;&lt;p class=&quot;medium-feed-image&quot;&gt;&lt;a href=&quot;https://levelup.gitconnected.com/can-ai-models-learn-from-synthetic-data-without-collapsing-d8ab1e83e962?source=rss----5517fd7b58a6---4&quot;&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/2240/1*hd3u-CvmW468jScwm0tcNg.jpeg&quot; width=&quot;2240&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;p class=&quot;medium-feed-snippet&quot;&gt;Model Collapse, Data Scarcity, and the Limits of Recursive Training in Large Language Models&lt;/p&gt;&lt;p class=&quot;medium-feed-link&quot;&gt;&lt;a href=&quot;https://levelup.gitconnected.com/can-ai-models-learn-from-synthetic-data-without-collapsing-d8ab1e83e962?source=rss----5517fd7b58a6---4&quot;&gt;Continue reading on Level Up Coding ¬ª&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</content:encoded>
    </item>
    <item>
      <title>CPU-Driven Circular Buffer</title>
      <link>https://levelup.gitconnected.com/cpu-driven-circular-buffer-7bc0cfe29cc3?source=rss----5517fd7b58a6---4</link>
      <guid>https://levelup.gitconnected.com/cpu-driven-circular-buffer-7bc0cfe29cc3?source=rss----5517fd7b58a6---4</guid>
      <pubDate>Mon, 23 Feb 2026 17:35:05 GMT</pubDate>
      <content:encoded>&lt;div class=&quot;medium-feed-item&quot;&gt;&lt;p class=&quot;medium-feed-image&quot;&gt;&lt;a href=&quot;https://levelup.gitconnected.com/cpu-driven-circular-buffer-7bc0cfe29cc3?source=rss----5517fd7b58a6---4&quot;&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1198/1*PPq4h-QuebBAuSJJxLPJnQ.png&quot; width=&quot;1198&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;p class=&quot;medium-feed-snippet&quot;&gt;Did you know that you can delegate the wrap-around logic of a circular buffer to the hardware?&lt;/p&gt;&lt;p class=&quot;medium-feed-link&quot;&gt;&lt;a href=&quot;https://levelup.gitconnected.com/cpu-driven-circular-buffer-7bc0cfe29cc3?source=rss----5517fd7b58a6---4&quot;&gt;Continue reading on Level Up Coding ¬ª&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</content:encoded>
    </item>
    <item>
      <title>The End of Prompt Engineering as We Know It (and the LLM Feels Fine)</title>
      <link>https://levelup.gitconnected.com/the-end-of-prompt-engineering-as-we-know-it-and-the-llm-feels-fine-e89d35ab996b?source=rss----5517fd7b58a6---4</link>
      <guid>https://levelup.gitconnected.com/the-end-of-prompt-engineering-as-we-know-it-and-the-llm-feels-fine-e89d35ab996b?source=rss----5517fd7b58a6---4</guid>
      <pubDate>Mon, 23 Feb 2026 17:34:58 GMT</pubDate>
      <content:encoded>&lt;div class=&quot;medium-feed-item&quot;&gt;&lt;p class=&quot;medium-feed-image&quot;&gt;&lt;a href=&quot;https://levelup.gitconnected.com/the-end-of-prompt-engineering-as-we-know-it-and-the-llm-feels-fine-e89d35ab996b?source=rss----5517fd7b58a6---4&quot;&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/2183/1*UVudmvTnz8b9swMyIaSkPQ.png&quot; width=&quot;2183&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;p class=&quot;medium-feed-snippet&quot;&gt;How a new paper suggests we&amp;#x2019;ve been overcomplicating LLM prompting&lt;/p&gt;&lt;p class=&quot;medium-feed-link&quot;&gt;&lt;a href=&quot;https://levelup.gitconnected.com/the-end-of-prompt-engineering-as-we-know-it-and-the-llm-feels-fine-e89d35ab996b?source=rss----5517fd7b58a6---4&quot;&gt;Continue reading on Level Up Coding ¬ª&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</content:encoded>
    </item>
    <item>
      <title>How I Cut AI Coding Costs by 80% on a Large Project</title>
      <link>https://levelup.gitconnected.com/how-i-cut-ai-coding-costs-by-80-on-a-large-project-8744016d13a8?source=rss----5517fd7b58a6---4</link>
      <guid>https://levelup.gitconnected.com/how-i-cut-ai-coding-costs-by-80-on-a-large-project-8744016d13a8?source=rss----5517fd7b58a6---4</guid>
      <pubDate>Mon, 23 Feb 2026 17:34:39 GMT</pubDate>
      <content:encoded>&lt;div class=&quot;medium-feed-item&quot;&gt;&lt;p class=&quot;medium-feed-image&quot;&gt;&lt;a href=&quot;https://levelup.gitconnected.com/how-i-cut-ai-coding-costs-by-80-on-a-large-project-8744016d13a8?source=rss----5517fd7b58a6---4&quot;&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*-REYRVMyOx3uOojs0HbIiw.png&quot; width=&quot;1200&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;p class=&quot;medium-feed-snippet&quot;&gt;A detective story about $100/day in AI credits, three guilty culprits, and the investigation that solved the case&lt;/p&gt;&lt;p class=&quot;medium-feed-link&quot;&gt;&lt;a href=&quot;https://levelup.gitconnected.com/how-i-cut-ai-coding-costs-by-80-on-a-large-project-8744016d13a8?source=rss----5517fd7b58a6---4&quot;&gt;Continue reading on Level Up Coding ¬ª&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</content:encoded>
    </item>
    <item>
      <title>Why Your C# AI Agents Will Fail in Production (And How to Fix It)</title>
      <link>https://levelup.gitconnected.com/why-your-c-ai-agents-will-fail-in-production-and-how-to-fix-it-a67dfe0c6341?source=rss----5517fd7b58a6---4</link>
      <guid>https://levelup.gitconnected.com/why-your-c-ai-agents-will-fail-in-production-and-how-to-fix-it-a67dfe0c6341?source=rss----5517fd7b58a6---4</guid>
      <pubDate>Mon, 23 Feb 2026 17:34:31 GMT</pubDate>
      <content:encoded>&lt;p&gt;The transition from a cool AI prototype running in a Jupyter Notebook to a production-grade, scalable microservice is where most projects hit a wall. You have a working model, maybe even a slick UI, but when you try to deploy it into a real cloud environment, it crashes, hangs, or costs a¬†fortune.&lt;/p&gt;&lt;p&gt;Why? Because standard microservice architecture treats AI agents like stateless ‚ÄúCashiers,‚Äù while in reality, they are stateful ‚ÄúProject Managers.‚Äù&lt;/p&gt;&lt;p&gt;To build robust, enterprise-ready AI systems using C# and Kubernetes, you need to rethink your architectural foundation. Let‚Äôs break down the operational shift required to containerize these complex entities effectively.&lt;/p&gt;&lt;h3&gt;The Stateful Nature of AI¬†Agents&lt;/h3&gt;&lt;p&gt;To understand the operational challenge, we must dissect the lifecycle of an AI agent. Unlike a stateless function, an agent is a persistent entity.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;The Cashier (Traditional Microservice):&lt;/strong&gt; Receives an order, processes it, and immediately forgets the customer. The interaction is transactional and ephemeral.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;The Project Manager (AI Agent):&lt;/strong&gt; Retains context. They remember the project‚Äôs history, ongoing tasks, dependencies, and the personalities of team members. If the Project Manager goes home for the night (pod shutdown) and returns the next morning (pod restart), they must resume work without losing the thread of conversation.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In C#, state is typically held in memory within object instances. However, containers are inherently ephemeral. If a Kubernetes node reboots or a pod crashes, the in-memory state of the agent is lost. Therefore, the theoretical foundation of cloud-native AI agents relies on two¬†pillars:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Externalized State:&lt;/strong&gt; Persisting the agent‚Äôs ‚Äúmemory‚Äù (conversation history, tool execution logs, and plan steps) to a durable store (e.g., Redis, PostgreSQL, or Azure Cosmos DB) rather than relying solely on List&amp;lt;T&amp;gt; or Dictionary&amp;lt;TKey, TValue&amp;gt; in¬†memory.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Process Continuity:&lt;/strong&gt; Ensuring the C# process itself can restart and hydrate its state from the external store, effectively ‚Äúwaking up‚Äù with full recollection.&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;The Microservices Boundary for¬†Agents&lt;/h3&gt;&lt;p&gt;We treat an agent not as a single object, but as a &lt;strong&gt;bounded context&lt;/strong&gt;‚Ää‚Äî‚Ääa microservice. This service encapsulates:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;The Orchestrator:&lt;/strong&gt; The C# logic managing the agent‚Äôs decision loop (planning, reflection).&lt;/li&gt;&lt;li&gt;&lt;strong&gt;The Inference Client:&lt;/strong&gt; The interface communicating with LLMs (OpenAI, Azure OpenAI, or local¬†models).&lt;/li&gt;&lt;li&gt;&lt;strong&gt;The Memory Store:&lt;/strong&gt; The vector database interface (e.g., Pinecone, Milvus) for semantic¬†recall.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;The Analogy:&lt;/strong&gt; Think of a &lt;strong&gt;Restaurant Kitchen&lt;/strong&gt;. The agent is the entire kitchen station, not just the chef. The station includes the prep area (memory retrieval), the stove (inference), and the plating area (response formatting). If the stove is overwhelmed (high inference load), we don‚Äôt necessarily need a bigger kitchen; we need more stoves (horizontal scaling) or faster chefs (optimized models).&lt;/p&gt;&lt;h3&gt;Containerizing the Agent¬†Runtime&lt;/h3&gt;&lt;p&gt;Containerization in C# is typically handled via Docker and¬†.NET‚Äôs cross-platform runtime. However, AI agents have specific runtime requirements that differ from standard web¬†APIs.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Dependency Management:&lt;/strong&gt; AI agents rely heavily on external SDKs (e.g., Microsoft.SemanticKernel, OpenAI.SDK, Azure.Identity). These dependencies must be locked down in the container image to ensure reproducibility.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Long-Running Processes:&lt;/strong&gt; Standard web containers are designed to handle requests and return. Agents often run background loops (e.g., ‚ÄúReAct‚Äù loops: Reasoning and Acting). The container entry point (ENTRYPOINT in Docker) must execute a long-running BackgroundService in¬†C#.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Resource Constraints:&lt;/strong&gt; LLM inference is memory-hungry. A container requesting 2GiB of RAM might crash if the agent loads a large local model (like a 4-bit quantized Llama).&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;The Code Concept (Theoretical):&lt;/strong&gt;&lt;br&gt;In a standard web app, the Program.cs might look like¬†this:&lt;/p&gt;&lt;pre&gt;var builder = WebApplication.CreateBuilder(args);&lt;br&gt;var app = builder.Build();&lt;br&gt;app.MapGet(&amp;quot;/&amp;quot;, () =&amp;gt; &amp;quot;Hello World!&amp;quot;);&lt;br&gt;app.Run();&lt;/pre&gt;&lt;p&gt;For an AI Agent, the container entry point is a persistent service:&lt;/p&gt;&lt;pre&gt;using Microsoft.Extensions.Hosting;&lt;br&gt;&lt;br&gt;public class AgentService : BackgroundService&lt;br&gt;{&lt;br&gt;    protected override async Task ExecuteAsync(CancellationToken stoppingToken)&lt;br&gt;    {&lt;br&gt;        while (!stoppingToken.IsCancellationRequested)&lt;br&gt;        {&lt;br&gt;            // The Agent&amp;#39;s Reasoning Loop&lt;br&gt;            await Task.Delay(1000, stoppingToken);&lt;br&gt;        }&lt;br&gt;    }&lt;br&gt;}&lt;/pre&gt;&lt;p&gt;This distinction is vital: the container is not just hosting an API; it is hosting a &lt;strong&gt;living¬†process&lt;/strong&gt;.&lt;/p&gt;&lt;h3&gt;Orchestration: Kubernetes as the Operating System&lt;/h3&gt;&lt;p&gt;Once containerized, the agent needs an environment to run in. Kubernetes (K8s) acts as the operating system for these distributed agents. The theoretical challenge here is managing &lt;strong&gt;StatefulSets&lt;/strong&gt; versus &lt;strong&gt;Deployments&lt;/strong&gt;.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Deployments (Stateless):&lt;/strong&gt; Ideal for the ‚ÄúCashier‚Äù analogy. Pods are interchangeable.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;StatefulSets (Stateful):&lt;/strong&gt; Required if the agent has a unique identity or requires stable¬†storage.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;However, most AI agents are hybrid. They are stateless in compute (the reasoning logic) but stateful in data (the memory). Therefore, we typically use &lt;strong&gt;Deployments&lt;/strong&gt; for the agent pods and rely on external services (Redis, SQL) for¬†state.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The Scaling Challenge:&lt;/strong&gt;&lt;br&gt;Scaling a standard web app is trivial: more requests = more replicas. Scaling an AI agent is complex because inference is expensive.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Vertical Scaling:&lt;/strong&gt; Giving the pod more CPU/GPU (e.g., using GPU nodes in¬†K8s).&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Horizontal Scaling:&lt;/strong&gt; Spinning up more agent replicas.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;This is where &lt;strong&gt;Kubernetes-native patterns&lt;/strong&gt; come in. We use the &lt;strong&gt;Sidecar Pattern&lt;/strong&gt;. The main container runs the agent logic, while a sidecar container handles telemetry, logging, or proxying requests to the¬†LLM.&lt;/p&gt;&lt;h3&gt;Inference Workload Management&lt;/h3&gt;&lt;p&gt;The heaviest load on an AI agent is the inference call to the LLM. This is the ‚Äústove‚Äù in our kitchen analogy. We must manage this workload carefully to avoid bottlenecks and excessive costs.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The Batching Strategy:&lt;/strong&gt;&lt;br&gt;LLMs perform best when processing inputs in batches. A single agent might process one user query, but the underlying infrastructure should ideally batch multiple requests to the GPU to maximize throughput.&lt;br&gt;In C#, we can use System.Threading.Channels or TPL Dataflow to create internal buffers. Instead of sending a request to the LLM immediately, the agent queues the request. A background processor flushes the queue every 100ms or when the batch size reaches¬†32.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The Routing Strategy:&lt;/strong&gt;&lt;br&gt;In a multi-model environment (e.g., using GPT-4 for complex reasoning and a smaller model like GPT-3.5 for simple classification), the agent needs a routing¬†logic.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Concept:&lt;/strong&gt; The &lt;strong&gt;Strategy¬†Pattern&lt;/strong&gt;.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Implementation:&lt;/strong&gt; An IInferenceStrategy interface with implementations Gpt4Strategy and LocalLlamaStrategy.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;K8s Integration:&lt;/strong&gt; We can deploy different model servers as separate Kubernetes services. The agent pod selects the appropriate service URL based on the complexity of the¬†task.&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Event-Driven Communication&lt;/h3&gt;&lt;p&gt;Agents rarely exist in isolation. They collaborate. This requires communication patterns that are resilient and decoupled.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Synchronous vs. Asynchronous:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Synchronous (HTTP/gRPC):&lt;/strong&gt; User asks Agent A. Agent A asks Agent B. Agent A waits. This creates tight coupling and potential deadlocks if Agent B is¬†slow.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Asynchronous (Message Bus):&lt;/strong&gt; User asks Agent A. Agent A publishes an event: ‚ÄúTaskAssigned‚Äù. Agent B subscribes, processes, and publishes ‚ÄúTaskCompleted‚Äù. Agent A reacts to the completion event.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;The Why:&lt;/strong&gt; Asynchronous patterns prevent the ‚Äúthundering herd‚Äù problem where a spike in user traffic cascades through the agent network, overwhelming the inference layer.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;C# and Cloud Events:&lt;/strong&gt;&lt;br&gt;In C#, we utilize libraries like Azure.Messaging.ServiceBus or MassTransit to abstract the message broker. The agent logic becomes event-driven:&lt;/p&gt;&lt;pre&gt;// Theoretical Event Handler&lt;br&gt;public async Task Handle(PlanStepGeneratedEvent evt)&lt;br&gt;{&lt;br&gt;    // The agent decides to use a tool&lt;br&gt;    var result = await _toolExecutor.Execute(evt.ToolName, evt.Arguments);&lt;br&gt;    // Publish result for the next step in the loop&lt;br&gt;    await _eventBus.PublishAsync(new ToolExecutionResultEvent(result));&lt;br&gt;}&lt;/pre&gt;&lt;p&gt;This aligns with the &lt;strong&gt;Actor Model&lt;/strong&gt; concepts from previous books but scales horizontally across pods. If an agent pod crashes, the message remains in the queue (if using a durable broker like Azure Service Bus), ensuring no data¬†loss.&lt;/p&gt;&lt;h3&gt;Resilience and Fault Tolerance&lt;/h3&gt;&lt;p&gt;AI models are non-deterministic. They can hallucinate, fail to format JSON correctly, or time out. The infrastructure must be resilient.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Retry Policies:&lt;/strong&gt;&lt;br&gt;In C#, we use libraries like Polly to define retry strategies. However, retrying an LLM call is different from retrying a database¬†call.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Transient Errors (Network):&lt;/strong&gt; Retry immediately.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Rate Limits (HTTP 429):&lt;/strong&gt; Retry with exponential backoff.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Content Policy Violations:&lt;/strong&gt; Do NOT retry; these are permanent failures.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Circuit Breakers:&lt;/strong&gt;&lt;br&gt;If the LLM API is down or error-prone, the agent should ‚Äúbreak the circuit‚Äù and switch to a fallback mode (e.g., a cached response or a simpler rule-based logic). This prevents the agent from flooding a failing¬†service.&lt;/p&gt;&lt;h3&gt;A Resilient, Message-Driven C# Implementation&lt;/h3&gt;&lt;p&gt;Here is a self-contained C# example demonstrating a resilient, message-driven AI Agent microservice using modern¬†.NET features.&lt;/p&gt;&lt;pre&gt;using System.Text.Json;&lt;br&gt;using System.Threading.Channels;&lt;br&gt;using Microsoft.Extensions.Hosting;&lt;br&gt;using Microsoft.Extensions.Logging;&lt;br&gt;&lt;br&gt;// ==================================================================&lt;br&gt;// 1. Domain Models: Defines the structure of communication.&lt;br&gt;// ==================================================================&lt;br&gt;public record AgentMessage(string AgentId, string Input, DateTime Timestamp);&lt;br&gt;public record AgentResult(string AgentId, string Response, DateTime Timestamp);&lt;br&gt;// ==================================================================&lt;br&gt;// 2. The Agent Logic: Simulates an AI Inference Task.&lt;br&gt;// ==================================================================&lt;br&gt;public class AiInferenceEngine&lt;br&gt;{&lt;br&gt;    private readonly ILogger&amp;lt;AiInferenceEngine&amp;gt; _logger;&lt;br&gt;    public AiInferenceEngine(ILogger&amp;lt;AiInferenceEngine&amp;gt; logger)&lt;br&gt;    {&lt;br&gt;        _logger = logger;&lt;br&gt;    }&lt;br&gt;    // Simulates a CPU/GPU intensive inference call (e.g., LLM prompt processing)&lt;br&gt;    public async Task&amp;lt;AgentResult&amp;gt; ProcessPromptAsync(AgentMessage message, CancellationToken ct)&lt;br&gt;    {&lt;br&gt;        _logger.LogInformation(&amp;quot;Agent {Id}: Received input &amp;#39;{Input}&amp;#39;&amp;quot;, message.AgentId, message.Input);&lt;br&gt;        // Simulate network latency and model processing time&lt;br&gt;        await Task.Delay(new Random().Next(500, 1500), ct);&lt;br&gt;        // Simple mock logic for the &amp;quot;AI&amp;quot; response&lt;br&gt;        var response = $&amp;quot;Processed &amp;#39;{message.Input}&amp;#39; -&amp;gt; Logical Conclusion generated.&amp;quot;;&lt;br&gt;        _logger.LogInformation(&amp;quot;Agent {Id}: Inference complete.&amp;quot;, message.AgentId);&lt;br&gt;        return new AgentResult(message.AgentId, response, DateTime.UtcNow);&lt;br&gt;    }&lt;br&gt;}&lt;br&gt;// ==================================================================&lt;br&gt;// 3. The Microservice Host: Orchestrates the Agent&amp;#39;s lifecycle.&lt;br&gt;// ==================================================================&lt;br&gt;public class AgentWorkerService : BackgroundService&lt;br&gt;{&lt;br&gt;    private readonly ILogger&amp;lt;AgentWorkerService&amp;gt; _logger;&lt;br&gt;    private readonly AiInferenceEngine _engine;&lt;br&gt;    // Channel&amp;lt;T&amp;gt; provides efficient, thread-safe producer/consumer queues.&lt;br&gt;    // This decouples message ingestion from message processing.&lt;br&gt;    private readonly Channel&amp;lt;AgentMessage&amp;gt; _inbox;&lt;br&gt;    public AgentWorkerService(ILogger&amp;lt;AgentWorkerService&amp;gt; logger, AiInferenceEngine engine)&lt;br&gt;    {&lt;br&gt;        _logger = logger;&lt;br&gt;        _engine = engine;&lt;br&gt;        // Bounded channel prevents memory overflow if traffic spikes.&lt;br&gt;        // FullMode.Wait blocks the sender when capacity is reached (backpressure).&lt;br&gt;        _inbox = Channel.CreateBounded&amp;lt;AgentMessage&amp;gt;(new BoundedChannelOptions(capacity: 10)&lt;br&gt;        {&lt;br&gt;            FullMode = BoundedChannelFullMode.Wait&lt;br&gt;        });&lt;br&gt;    }&lt;br&gt;    // ------------------------------------------------------------------&lt;br&gt;    // Ingestion Point: Simulates an external event (e.g., HTTP Request or Queue Message)&lt;br&gt;    // ------------------------------------------------------------------&lt;br&gt;    public async Task EnqueueAsync(AgentMessage message)&lt;br&gt;    {&lt;br&gt;        // WriteAsync respects the cancellation token and handles backpressure automatically&lt;br&gt;        await _inbox.Writer.WriteAsync(message);&lt;br&gt;        _logger.LogDebug(&amp;quot;Message queued for Agent {Id}&amp;quot;, message.AgentId);&lt;br&gt;    }&lt;br&gt;    // ------------------------------------------------------------------&lt;br&gt;    // Processing Loop: The heart of the containerized agent&lt;br&gt;    // ------------------------------------------------------------------&lt;br&gt;    protected override async Task ExecuteAsync(CancellationToken stoppingToken)&lt;br&gt;    {&lt;br&gt;        _logger.LogInformation(&amp;quot;Agent Worker Service started. Waiting for messages...&amp;quot;);&lt;br&gt;        // We consume from the channel using &amp;#39;await foreach&amp;#39;&lt;br&gt;        // This allows the loop to pause efficiently when no messages exist.&lt;br&gt;        await foreach (var message in _inbox.Reader.ReadAllAsync(stoppingToken))&lt;br&gt;        {&lt;br&gt;            try&lt;br&gt;            {&lt;br&gt;                // Process the message using the injected engine&lt;br&gt;                var result = await _engine.ProcessPromptAsync(message, stoppingToken);&lt;br&gt;                // In a real scenario, this would publish to an Event Bus (e.g., RabbitMQ, Azure Service Bus)&lt;br&gt;                // or update a database.&lt;br&gt;                _logger.LogInformation(&amp;quot;Result published: {Response}&amp;quot;, result.Response);&lt;br&gt;            }&lt;br&gt;            catch (OperationCanceledException)&lt;br&gt;            {&lt;br&gt;                // Graceful shutdown requested&lt;br&gt;                _logger.LogWarning(&amp;quot;Processing interrupted due to shutdown signal.&amp;quot;);&lt;br&gt;                break;&lt;br&gt;            }&lt;br&gt;            catch (Exception ex)&lt;br&gt;            {&lt;br&gt;                // CRITICAL: Never let the worker loop die due to a single bad message.&lt;br&gt;                // Log the error and move on (or move to a Dead Letter Queue).&lt;br&gt;                _logger.LogError(ex, &amp;quot;Error processing message from Agent {Id}&amp;quot;, message.AgentId);&lt;br&gt;            }&lt;br&gt;        }&lt;br&gt;    }&lt;br&gt;}&lt;br&gt;// ==================================================================&lt;br&gt;// 4. Main Entry Point: Wiring up Dependency Injection and Execution&lt;br&gt;// ==================================================================&lt;br&gt;public class Program&lt;br&gt;{&lt;br&gt;    public static async Task Main(string[] args)&lt;br&gt;    {&lt;br&gt;        var host = Host.CreateDefaultBuilder(args)&lt;br&gt;            .ConfigureServices(services =&amp;gt;&lt;br&gt;            {&lt;br&gt;                // Register the Engine as a Singleton (stateless logic)&lt;br&gt;                services.AddSingleton&amp;lt;AiInferenceEngine&amp;gt;();&lt;br&gt;                // Register the Worker as a Hosted Service (runs continuously)&lt;br&gt;                services.AddHostedService&amp;lt;AgentWorkerService&amp;gt;();&lt;br&gt;            })&lt;br&gt;            .ConfigureLogging(logging =&amp;gt; &lt;br&gt;            {&lt;br&gt;                logging.ClearProviders();&lt;br&gt;                logging.AddConsole();&lt;br&gt;            })&lt;br&gt;            .Build();&lt;br&gt;        // Start the background service&lt;br&gt;        await host.StartAsync();&lt;br&gt;        // SIMULATION: Inject traffic into the agent to demonstrate the flow&lt;br&gt;        var agentService = host.Services.GetRequiredService&amp;lt;AgentWorkerService&amp;gt;();&lt;br&gt;        Console.WriteLine(&amp;quot;--- Injecting Simulation Traffic ---&amp;quot;);&lt;br&gt;        // Fire and forget 5 messages to simulate concurrent requests&lt;br&gt;        var tasks = new List&amp;lt;Task&amp;gt;();&lt;br&gt;        for (int i = 1; i &amp;lt;= 5; i++)&lt;br&gt;        {&lt;br&gt;            var msg = new AgentMessage($&amp;quot;Agent-{i}&amp;quot;, $&amp;quot;Query #{i}&amp;quot;, DateTime.UtcNow);&lt;br&gt;            tasks.Add(agentService.EnqueueAsync(msg));&lt;br&gt;        }&lt;br&gt;        // Wait for ingestion to complete&lt;br&gt;        await Task.WhenAll(tasks);&lt;br&gt;        // Keep the app running long enough to process the queue&lt;br&gt;        await Task.Delay(5000); &lt;br&gt;        // Graceful shutdown&lt;br&gt;        await host.StopAsync();&lt;br&gt;    }&lt;br&gt;}&lt;/pre&gt;&lt;h3&gt;Key Architectural Concepts in the¬†Code&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Channel&amp;lt;T&amp;gt; for Backpressure:&lt;/strong&gt; We use Channel.CreateBounded to set a capacity. If the agent receives 100 requests per second but can only process 5, the queue fills up. Once full, WriteAsync will pause the caller. This prevents the container from crashing due to Out-Of-Memory (OOM)¬†errors.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;BackgroundService:&lt;/strong&gt; This is the entry point for the container. It runs on a separate thread when the host starts, allowing the agent to process tasks continuously rather than waiting for an HTTP¬†request.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;await foreach:&lt;/strong&gt; This modern C# feature allows the loop to iterate over the channel as data becomes available. If the channel is empty, the loop pauses efficiently (yielding the thread) until a message¬†arrives.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Exception Handling:&lt;/strong&gt; The try/catch block inside the loop is vital. If one message causes a crash, the entire container restarts. By catching exceptions here, we ensure the worker stays alive to process the next¬†message.&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Common Pitfalls to¬†Avoid&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1. Blocking the Ingestion Path&lt;/strong&gt;&lt;br&gt;A common mistake is performing heavy work directly inside the method that receives the request (e.g., the Controller action).&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Bad:&lt;/strong&gt; public IActionResult Post([FromBody] string input) { HeavyInference(input); return Ok();¬†}&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Why it fails:&lt;/strong&gt; The HTTP request holds open a connection (and potentially a thread) until the inference finishes. If you get 50 requests, you might exhaust the thread pool or connection limit, causing the app to¬†hang.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Correct:&lt;/strong&gt; Use the Channel pattern. The EnqueueAsync method returns almost instantly, while the ExecuteAsync loop handles the heavy lifting asynchronously in the background.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2. Unbounded Queues&lt;/strong&gt;&lt;br&gt;Using a standard List or Queue without size limits to buffer incoming requests.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;The Risk:&lt;/strong&gt; If the AI inference engine is slow (e.g., waiting for a GPU), and traffic spikes, the memory usage of that list will grow indefinitely.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;The Result:&lt;/strong&gt; The container hits its memory limit (MemoryLimit in Kubernetes), gets OOMKilled (Out of Memory Killed), and restarts.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;The Fix:&lt;/strong&gt; Always use Channel.CreateBounded to define a hard limit. When the limit is reached, apply backpressure (slow down the clients) rather than crashing.&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;By containerizing AI agents in C#, we gain portability and isolation. By orchestrating them in Kubernetes, we gain scalability and resilience. However, the ‚Äúmagic‚Äù lies in the internal architecture of the C#¬†code:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Interfaces over Implementations:&lt;/strong&gt; Using IChatClient or IMemoryStore allows us to swap infrastructure without changing the agent&amp;#39;s core¬†logic.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Asynchronous Streams:&lt;/strong&gt; Using IAsyncEnumerable&amp;lt;T&amp;gt; allows the agent to stream responses from the LLM to the user in real-time, rather than waiting for the full generation, improving the perceived latency.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Dependency Injection:&lt;/strong&gt;¬†.NET‚Äôs DI container is used to wire up the complex dependencies (Strategies, Buffers, Policies) at startup, ensuring the agent pod initializes correctly every time it scales¬†up.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;This theoretical foundation moves the AI agent from a prototype running in a Jupyter Notebook to a production-grade, scalable microservice capable of handling enterprise workloads.&lt;/p&gt;&lt;h3&gt;Let‚Äôs Discuss&lt;/h3&gt;&lt;ol&gt;&lt;li&gt;In your experience, is the ‚ÄúActor Model‚Äù (like Orleans) overkill for AI agents, or is it the perfect fit for managing their stateful¬†nature?&lt;/li&gt;&lt;li&gt;How do you currently handle the ‚ÄúThundering Herd‚Äù problem when your AI agents trigger expensive API calls? Do you rely on Kubernetes scaling or application-level buffering (like the Channel pattern shown¬†above)?&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;The concepts and code demonstrated here are drawn directly from the comprehensive roadmap laid out in the ebook&lt;br&gt;&lt;strong&gt;Cloud-Native AI &amp;amp; Microservices. Containerizing Agents and Scaling Inference&lt;/strong&gt;.&lt;br&gt;&lt;a href=&quot;http://youtube.com/@csharpmasterclass&quot;&gt;Free lessons on Youtube&lt;/a&gt;.&lt;br&gt;You can find it here: &lt;a href=&quot;https://leanpub.com/CloudNativeAICSharp&quot;&gt;Leanpub.com&lt;/a&gt;.&lt;br&gt;Check all the other programming ebooks on python, typescript, c#: &lt;a href=&quot;https://leanpub.com/u/edgarmilvus&quot;&gt;Leanpub.com&lt;/a&gt;.&lt;br&gt;If you prefer you can find almost all of them on¬†&lt;a href=&quot;https://www.amazon.com/stores/Edgar-Milvus/author/B0G2BS9V5N&quot;&gt;Amazon&lt;/a&gt;.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*pHjrMooIIEWeA-1xmaU4fA.jpeg&quot; /&gt;&lt;/figure&gt;&lt;img src=&quot;https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=a67dfe0c6341&quot; width=&quot;1&quot; height=&quot;1&quot; alt=&quot;&quot;&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&quot;https://levelup.gitconnected.com/why-your-c-ai-agents-will-fail-in-production-and-how-to-fix-it-a67dfe0c6341&quot;&gt;Why Your C# AI Agents Will Fail in Production (And How to Fix It)&lt;/a&gt; was originally published in &lt;a href=&quot;https://levelup.gitconnected.com&quot;&gt;Level Up Coding&lt;/a&gt; on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</content:encoded>
    </item>
    <item>
      <title>10 Tcl Commands Only a Few Bash Programmers Know</title>
      <link>https://levelup.gitconnected.com/10-tcl-commands-for-productive-bashless-shell-scripting-1a10c09c21cc?source=rss----5517fd7b58a6---4</link>
      <guid>https://levelup.gitconnected.com/10-tcl-commands-for-productive-bashless-shell-scripting-1a10c09c21cc?source=rss----5517fd7b58a6---4</guid>
      <pubDate>Mon, 23 Feb 2026 17:34:23 GMT</pubDate>
      <content:encoded>&lt;div class=&quot;medium-feed-item&quot;&gt;&lt;p class=&quot;medium-feed-image&quot;&gt;&lt;a href=&quot;https://levelup.gitconnected.com/10-tcl-commands-for-productive-bashless-shell-scripting-1a10c09c21cc?source=rss----5517fd7b58a6---4&quot;&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1600/1*T5ExJfbVNLD5DxNdQEIxng.png&quot; width=&quot;1600&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;p class=&quot;medium-feed-snippet&quot;&gt;Never deal with confusing Bash syntax or external commands by practicing these Tcl commands&lt;/p&gt;&lt;p class=&quot;medium-feed-link&quot;&gt;&lt;a href=&quot;https://levelup.gitconnected.com/10-tcl-commands-for-productive-bashless-shell-scripting-1a10c09c21cc?source=rss----5517fd7b58a6---4&quot;&gt;Continue reading on Level Up Coding ¬ª&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</content:encoded>
    </item>
    <item>
      <title>The Curse of Dimensionality: A Geometric Horror Story</title>
      <link>https://levelup.gitconnected.com/the-curse-of-dimensionality-a-geometric-horror-story-abe1a6bf0a75?source=rss----5517fd7b58a6---4</link>
      <guid>https://levelup.gitconnected.com/the-curse-of-dimensionality-a-geometric-horror-story-abe1a6bf0a75?source=rss----5517fd7b58a6---4</guid>
      <pubDate>Mon, 23 Feb 2026 17:34:16 GMT</pubDate>
      <content:encoded>&lt;div class=&quot;medium-feed-item&quot;&gt;&lt;p class=&quot;medium-feed-image&quot;&gt;&lt;a href=&quot;https://levelup.gitconnected.com/the-curse-of-dimensionality-a-geometric-horror-story-abe1a6bf0a75?source=rss----5517fd7b58a6---4&quot;&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/822/1*fJHrCnQdTIh0mHzskUAS-w.png&quot; width=&quot;822&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;p class=&quot;medium-feed-snippet&quot;&gt;You think 100 dimensions is &amp;#x201C;10 times more complex&amp;#x201D; than 10. You&amp;#x2019;re wrong. It&amp;#x2019;s a universe more vast and almost completely empty.&lt;/p&gt;&lt;p class=&quot;medium-feed-link&quot;&gt;&lt;a href=&quot;https://levelup.gitconnected.com/the-curse-of-dimensionality-a-geometric-horror-story-abe1a6bf0a75?source=rss----5517fd7b58a6---4&quot;&gt;Continue reading on Level Up Coding ¬ª&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</content:encoded>
    </item>
    <item>
      <title>Building a Ray Tracer from Scratch in C++ Part 1: Mathematical Foundations</title>
      <link>https://levelup.gitconnected.com/building-a-ray-tracer-from-scratch-in-c-part-1-mathematical-foundations-8d778512120c?source=rss----5517fd7b58a6---4</link>
      <guid>https://levelup.gitconnected.com/building-a-ray-tracer-from-scratch-in-c-part-1-mathematical-foundations-8d778512120c?source=rss----5517fd7b58a6---4</guid>
      <pubDate>Mon, 23 Feb 2026 17:34:08 GMT</pubDate>
      <content:encoded>&lt;p&gt;Graphics APIs and game engines make rendering look easy, but they hide most of the interesting details. I wanted to understand what actually happens under the hood, so I decided to build a small 3D renderer from scratch using¬†C++.&lt;/p&gt;&lt;p&gt;By the end of this article, you‚Äôll understand the core ideas behind ray tracing and be able to build a simple renderer yourself.&lt;/p&gt;&lt;p&gt;We‚Äôll finish by rendering the image shown below, without using any graphics libraries or engines but with C++ and¬†Maths.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/800/1*uC-DlpR4SdBkzSbZsfIQ8A.gif&quot; /&gt;&lt;/figure&gt;&lt;h3&gt;Why Ray¬†tracing&lt;/h3&gt;&lt;p&gt;In computer graphics, there are two main rendering techniques: &lt;strong&gt;rasterization&lt;/strong&gt; and &lt;strong&gt;ray¬†tracing&lt;/strong&gt;.&lt;/p&gt;&lt;p&gt;You might ask, what exactly is rendering? In simple terms, rendering is the process of generating a 2D image or video from a 3D model or scene. It‚Äôs considered the final stage of a 3D¬†engine.&lt;/p&gt;&lt;p&gt;While rasterization is fast and used in real-time applications like games, ray tracing simulates how light behaves in the real world to produce highly realistic images, shadows, and reflections. It traces the path of light rays as they interact with objects in a 3D scene, calculating reflections, refractions, and accurate lighting¬†effects.&lt;/p&gt;&lt;p&gt;Ray tracing involves some basic mathematics. Oops, I just mentioned our worst nightmare üòü Don‚Äôt worry though, it‚Äôs not as scary as it sounds. I‚Äôve got you. So without any further ado, let‚Äôs get¬†started.&lt;/p&gt;&lt;blockquote&gt;One drawback of ray tracing is performance. However, there are optimization techniques we can use to improve speed, which we‚Äôll touch on other¬†part.&lt;/blockquote&gt;&lt;p&gt;The below image is generated using ray tracing algorithm&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*kA2OIotuYbnCAGmOqz7VjA.png&quot; /&gt;&lt;figcaption&gt;Ray traced image (source: Wikipedia)&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;How Ray Tracing¬†Works&lt;/h3&gt;&lt;p&gt;Ray tracing simulates how light travels. &lt;strong&gt;Rays&lt;/strong&gt; are cast from a single point in 3D space which is the camera into the scene through an imaginary &lt;strong&gt;viewport&lt;/strong&gt;. Each ray corresponds to a pixel on the screen. When a ray intersects an object (like a sphere or triangle), we compute the closest intersection point to determine the final color of that¬†pixel.&lt;/p&gt;&lt;p&gt;This process is repeated for every pixel, creating a complete, realistic image.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*bWC45w0nku7UpOs_4UbDiQ.png&quot; /&gt;&lt;/figure&gt;&lt;p&gt;we have prepared a pipeline to render a simple shape, we will improve it as we go deeper in the¬†subject.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Camera ‚Üí¬†rays&lt;/li&gt;&lt;li&gt;Ray ‚Üí Object intersection&lt;/li&gt;&lt;li&gt;Drawing a pixel on the¬†screen&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;Let‚Äôs shoot some rays from the¬†camera&lt;/h3&gt;&lt;p&gt;A &lt;strong&gt;ray&lt;/strong&gt; is similar to a line but with an important difference a line extends infinitely in both directions, while a ray starts at a specific point and extends infinitely in one direction.&lt;/p&gt;&lt;p&gt;Mathematically, a ray can be represented using a &lt;strong&gt;parametric equation&lt;/strong&gt;&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/131/1*sgs8pwAmV36Qp6WEWE7GAg.png&quot; /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Where:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;&lt;em&gt;P&lt;/em&gt;&lt;/strong&gt; is any point along the¬†ray&lt;/li&gt;&lt;li&gt;&lt;strong&gt;&lt;em&gt;O&lt;/em&gt;&lt;/strong&gt; is the ray‚Äôs origin (starting point)&lt;/li&gt;&lt;li&gt;&lt;strong&gt;&lt;em&gt;d&lt;/em&gt;&lt;/strong&gt; is the direction vector&lt;/li&gt;&lt;li&gt;&lt;strong&gt;&lt;em&gt;t&lt;/em&gt;&lt;/strong&gt; is a scalar parameter&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;If t = 0, then P = O.&lt;br&gt;If t = 1, then P = O +¬†d.&lt;/p&gt;&lt;p&gt;Increasing t moves the point along the ray indefinitely.&lt;/p&gt;&lt;p&gt;let‚Äôs say we have two points in a space ‚Äúpoint A‚Äù and ‚Äúpoint B‚Äù, let‚Äôs use 2D for now to better understand the above¬†formula.&lt;/p&gt;&lt;p&gt;A = (0, 0) and B = (4,¬†4)&lt;/p&gt;&lt;blockquote&gt;I will use a platform called &lt;strong&gt;desmos &lt;/strong&gt;for plotting points, you can search it¬†online&lt;/blockquote&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1019/1*coq44LwtcEqTU9cvt-WH-A.png&quot; /&gt;&lt;figcaption&gt;Two points in 2D¬†space&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;As we can see in the graph, we have two points, and we want to draw a line segment or a ray between them. A line is defined as an infinite set of points, so how can we represent the line that goes through points A and B? We use the parametric equation of a line. Before writing that equation, however, we need to determine the direction in which the line or ray is pointing. We can find this direction by subtracting point A from point B. The result is a vector, and this vector becomes the direction vector &lt;strong&gt;d&lt;/strong&gt; in the parametric equation&lt;/p&gt;&lt;p&gt;Example:&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/263/1*eCvMyjUmZpNRcSsIz5vgUg.png&quot; /&gt;&lt;/figure&gt;&lt;p&gt;now we have the direction, if you look closely the vector &lt;strong&gt;d&lt;/strong&gt; is the same as the point B, this is when the origin starts from 0, but if it was another point in the space it would be different.&lt;/p&gt;&lt;p&gt;let‚Äôs plug the direction in the equation and draw our line, but there is one missing piece, the ‚Äú&lt;strong&gt;t‚Äù&lt;/strong&gt; right? don‚Äôt worry we don‚Äôt have to do anything for ‚Äòt‚Äô it has to start from 0.0 and increase it infinitly&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/156/1*JFB1J-vaosDe3KYbekW6Nw.png&quot; /&gt;&lt;/figure&gt;&lt;p&gt;we repeat this process and increase the value of ‚Äút‚Äù until we reach B or¬†exceed.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/792/1*fuaTCE-oHMSrzb998gB6MQ.png&quot; /&gt;&lt;figcaption&gt;Line from A to¬†B&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;as you can see here by using the equation we draw a line from A to B, here you can see that when ‚Äú&lt;em&gt;t&lt;/em&gt;‚Äù starts from 0 and reaches 1 it ends at B, this is called a line segment, but we need a ray, and to do that its very simple we set ‚Äút‚Äù to infinity or a large number would work, now we have a ray and next image shows¬†that.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1017/1*sAISfD-O75gbtZ11mKFfJg.png&quot; /&gt;&lt;/figure&gt;&lt;p&gt;here we can see that the line exceeded the point B or the direction, now this is what we call a ray, but we don‚Äôt want to shoot a single ray, we will need to cast/shoot many rays, right? so to do that we need what we call a viewport, let‚Äôs go right into¬†it.&lt;/p&gt;&lt;h3&gt;What is Viewport??&lt;/h3&gt;&lt;p&gt;A viewport is a 2D rectangular virtual window that represents the final image plane through which the camera ‚Äúsees‚Äù the 3D scene. It acts as a canvas or image plane and is usually divided into pixels. Rays are traced from the camera through each pixel on the viewport to determine the final color of the¬†scene.&lt;/p&gt;&lt;p&gt;A viewport is defined by its center point, width and height (aspect ratio), and its distance from the camera. This distance determines the field of view (FOV). If it‚Äôs hard to visualize, you can think of the viewport as a plane placed between the camera and the 3D¬†scene.&lt;/p&gt;&lt;p&gt;Earlier, we drew a line from point A to point B and extended it beyond B. In that example, you can think of point B as representing the viewport or image plane. Of course, a viewport is not a single point, but a rectangular area with width and height. This simplification just helps with visualization.&lt;/p&gt;&lt;p&gt;The viewport‚Äôs main purpose is to act as a bridge between 3D scene space and 2D image pixels. Rays are cast from the camera through the pixels on this plane to find intersections with 3D objects located beyond¬†it.&lt;/p&gt;&lt;p&gt;To help you illustrate it take a look at the below image. Let‚Äôs ‚Äúpoint A‚Äù be the camera and all ‚ÄúPoint Bs‚Äù the viewport, beyond it, is the 3D¬†scene.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*cLknuI9-kxUqoFqBkItJiw.png&quot; /&gt;&lt;figcaption&gt;Ray casted from A along the direction of B and intersecting with 3D¬†objects&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;As shown in the image above, multiple rays are cast from the camera, or point A, through the viewport in the direction of point B. These rays travel into the 3D scene and intersect with objects along their¬†paths.&lt;/p&gt;&lt;p&gt;For each ray, we check whether it intersects any object in the scene. If an intersection occurs, we compute the exact intersection point and use it to determine the final color of that¬†pixel.&lt;/p&gt;&lt;p&gt;In our case, we will start with spheres, since they are the simplest geometric primitives to work¬†with.&lt;/p&gt;&lt;h3&gt;Sphere Equation and Ray Intersection&lt;/h3&gt;&lt;p&gt;A sphere can be thought of as a circle extended into 3D space. To simplify the explanation, we‚Äôll first work in 2D using a circle, then extend the same idea to a sphere when we move to implementation. A circle or sphere is defined by two things, it‚Äôs center and¬†radius.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/119/1*RsvVJ_HuFeIrcFpCiB915w.png&quot; /&gt;&lt;figcaption&gt;if the center is at the¬†origin&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/260/1*SfmZpQ9gSYZqlzXjjUmFNA.png&quot; /&gt;&lt;figcaption&gt;when changing the origin of the circle or¬†sphere&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;where&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;em&gt;x&lt;/em&gt; and &lt;em&gt;y&lt;/em&gt; are the point on the¬†surface&lt;/li&gt;&lt;li&gt;&lt;em&gt;r&lt;/em&gt; is the distance from the center of the circle to its¬†surface&lt;/li&gt;&lt;li&gt;&lt;em&gt;Cx&lt;/em&gt; is the &lt;em&gt;x&lt;/em&gt; component center of the¬†circle&lt;/li&gt;&lt;li&gt;&lt;em&gt;Cy&lt;/em&gt; is the &lt;em&gt;y&lt;/em&gt; component center of the¬†circle&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;This equation represents a circle. It means that any point (x,y)(x, y)(x,y) whose distance from the center equals the radius &lt;em&gt;r&lt;/em&gt; lies on the surface of the¬†circle.&lt;/p&gt;&lt;p&gt;To make this easier to work with, let‚Äôs simplify the equation.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/313/1*fefmmsm7UzEPXweB5KLsNg.png&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Or&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/122/1*GZ5NveqPICRZ-3ZJ1HH9qQ.png&quot; /&gt;&lt;/figure&gt;&lt;p&gt;We can interpret this equation as the length of the vector &lt;strong&gt;D&lt;/strong&gt; from point &lt;strong&gt;P&lt;/strong&gt; to point &lt;strong&gt;C&lt;/strong&gt;, where &lt;strong&gt;P&lt;/strong&gt; lies on the surface of the circle and &lt;strong&gt;C&lt;/strong&gt; is the center of the circle. Subtracting these two points gives us the vector &lt;strong&gt;D&lt;/strong&gt;, and the magnitude of this vector is equal to the radius of the¬†circle.&lt;/p&gt;&lt;p&gt;Going a step further, this expression can also be written as the dot product of vector &lt;strong&gt;D&lt;/strong&gt; with itself, which gives¬†us&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/88/1*K5GQXKU2NbMb04V8OQwJsw.png&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Now let‚Äôs expand the dot¬†product.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/168/1*tjNp26zjd415CuwaaQdKMg.png&quot; /&gt;&lt;figcaption&gt;this is the expanded dot¬†product&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;This can be simplified as¬†well.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/71/1*PMsEnwGwhEUp7go_8qlM2g.png&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Do you notice something? It‚Äôs similar to the equation of a circle, right? Exactly! That means the dot product of vector ‚ÄòD‚Äô behaves just like a circle equation. Now we have a simplified equation that‚Äôs much easier to work¬†with.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/211/1*amFuTThwvUrg73TnQhKMgw.png&quot; /&gt;&lt;/figure&gt;&lt;p&gt;You might be wondering why we needed to simplify this equation. Well, it‚Äôs so we can more easily integrate it with the ray equation. In the simplified version, we have ‚ÄòP‚Äô, which represents a point on the surface of the circle. So, if we can find a ‚ÄòP‚Äô that satisfies this equation, that means we‚Äôve found the circle, right? But how do we actually find ‚ÄòP‚Äô? If you remember‚Ä¶&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/131/1*zWSfwGPClG6nh10JAHI38g.png&quot; /&gt;&lt;/figure&gt;&lt;p&gt;This was our ray equation, right? Do you see something here? Yes, we can use the ray equation to find the point ‚ÄòP‚Äô that satisfies this condition. That means the circle equation now¬†becomes‚Ä¶&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/315/1*c2SwdtIR4aJo0_ZWbZi5aw.png&quot; /&gt;&lt;/figure&gt;&lt;p&gt;As you can see, we‚Äôve combined the ray equation with the sphere equation. You might be wondering why we need to mix these two. The reason is simple, we want to find the intersection between the ray we cast and the sphere. I hope you‚Äôre following so far, so the next step is to simplify the combined equation.&lt;/p&gt;&lt;p&gt;if we separate ‚Äú&lt;em&gt;td&lt;/em&gt;‚Äù we¬†get&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/384/1*Eoqj87-3QG05y0R3bk9agw.png&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Now let‚Äôs expand the dot product. We¬†get&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/466/1*18t5lk051-zJhuqBoL9W3Q.png&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Let‚Äôs subtract r¬≤ from both sides. We¬†get&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/504/1*gYx0ZKuaQDPcjLcz3NE11A.png&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Now, if we take a closer look, the vectors and the radius are known because the radius ‚Äòr‚Äô is constant and the vectors are reduced to scalar values through their dot products. The only unknowns are ‚Äòt‚Äô and ‚Äòt¬≤‚Äô, which means this equation is quadratic. This also means we can solve it using the quadratic formula for equations of the form ax¬≤ + bx + c =¬†0.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/204/1*kyrFGFV_sTiZ6nvWSc2VYQ.png&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Now, let‚Äôs match our final ray-sphere equation to the familiar quadratic equation.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/258/1*QQvLXMjBJXhD8Q2g9A0S8Q.png&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Using the quadratic formula, we can solve for &lt;em&gt;t&lt;/em&gt;. The square root term, known as the discriminant, can be positive, negative, or zero. A positive discriminant means there are two solutions, zero means there is exactly one solution, and a negative value means there is no solution at all. This discriminant tells us whether the ray intersects the sphere, but not where the intersection occurs, since it only indicates the existence of a solution. At this stage, we can already render a basic sphere on the screen. However, to fully utilize the equation, we compute the actual value of &lt;em&gt;t&lt;/em&gt;. Once &lt;em&gt;t&lt;/em&gt; is known, we substitute it back into the ray equation to obtain the exact intersection point along the¬†ray.&lt;/p&gt;&lt;p&gt;In the next part we will focus on writing code and render our first 3D¬†object.&lt;/p&gt;&lt;img src=&quot;https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=8d778512120c&quot; width=&quot;1&quot; height=&quot;1&quot; alt=&quot;&quot;&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&quot;https://levelup.gitconnected.com/building-a-ray-tracer-from-scratch-in-c-part-1-mathematical-foundations-8d778512120c&quot;&gt;Building a Ray Tracer from Scratch in C++ Part 1: Mathematical Foundations&lt;/a&gt; was originally published in &lt;a href=&quot;https://levelup.gitconnected.com&quot;&gt;Level Up Coding&lt;/a&gt; on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</content:encoded>
    </item>
    <item>
      <title>Are We Ready for the ‚ÄúCountry of Geniuses‚Äù?- Anthropic CEO‚Äôs Vision of the AI Future</title>
      <link>https://levelup.gitconnected.com/are-we-ready-for-the-country-of-geniuses-anthropic-ceos-vision-of-the-ai-future-d574f19c409e?source=rss----5517fd7b58a6---4</link>
      <guid>https://levelup.gitconnected.com/are-we-ready-for-the-country-of-geniuses-anthropic-ceos-vision-of-the-ai-future-d574f19c409e?source=rss----5517fd7b58a6---4</guid>
      <pubDate>Mon, 23 Feb 2026 17:33:58 GMT</pubDate>
      <content:encoded>&lt;div class=&quot;medium-feed-item&quot;&gt;&lt;p class=&quot;medium-feed-image&quot;&gt;&lt;a href=&quot;https://levelup.gitconnected.com/are-we-ready-for-the-country-of-geniuses-anthropic-ceos-vision-of-the-ai-future-d574f19c409e?source=rss----5517fd7b58a6---4&quot;&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/2600/0*FquvphNxpwLPQr17&quot; width=&quot;4843&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;p class=&quot;medium-feed-snippet&quot;&gt;Dario Amodei, Anthropic CEO, published a blueprint for humanity&amp;#x2019;s survival in 2026. It should be a required reading for every technologist&amp;#x2026;&lt;/p&gt;&lt;p class=&quot;medium-feed-link&quot;&gt;&lt;a href=&quot;https://levelup.gitconnected.com/are-we-ready-for-the-country-of-geniuses-anthropic-ceos-vision-of-the-ai-future-d574f19c409e?source=rss----5517fd7b58a6---4&quot;&gt;Continue reading on Level Up Coding ¬ª&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</content:encoded>
    </item>
  </channel>
</rss>